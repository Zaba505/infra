<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=https://zaba505.github.io/infra/pr-preview/pr-626/rd/analysis/server-os/><link rel=alternate type=application/rss+xml href=https://zaba505.github.io/infra/pr-preview/pr-626/rd/analysis/server-os/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/infra/pr-preview/pr-626/favicons/favicon.ico><link rel=apple-touch-icon href=/infra/pr-preview/pr-626/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-192x192.png sizes=192x192><title>Server Operating System Analysis | Zaba505's Home Lab</title><meta name=description content="Evaluation of operating systems for homelab Kubernetes infrastructure"><meta property="og:url" content="https://zaba505.github.io/infra/pr-preview/pr-626/rd/analysis/server-os/"><meta property="og:site_name" content="Zaba505's Home Lab"><meta property="og:title" content="Server Operating System Analysis"><meta property="og:description" content="Evaluation of operating systems for homelab Kubernetes infrastructure"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><meta itemprop=name content="Server Operating System Analysis"><meta itemprop=description content="Evaluation of operating systems for homelab Kubernetes infrastructure"><meta itemprop=dateModified content="2025-11-24T01:18:05+00:00"><meta itemprop=wordCount content="223"><meta name=twitter:card content="summary"><meta name=twitter:title content="Server Operating System Analysis"><meta name=twitter:description content="Evaluation of operating systems for homelab Kubernetes infrastructure"><link rel=preload href=/infra/pr-preview/pr-626/scss/main.min.74eef40c5172b0e2f11bd9c3ea40dba66c2dc642ac5294c208f5dc9ff772c0e9.css as=style integrity="sha256-dO70DFFysOLxG9nD6kDbpmwtxkKsUpTCCPXcn/dywOk=" crossorigin=anonymous><link href=/infra/pr-preview/pr-626/scss/main.min.74eef40c5172b0e2f11bd9c3ea40dba66c2dc642ac5294c208f5dc9ff772c0e9.css rel=stylesheet integrity="sha256-dO70DFFysOLxG9nD6kDbpmwtxkKsUpTCCPXcn/dywOk=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-section><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/infra/pr-preview/pr-626/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>Zaba505's Home Lab</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class="td-light-dark-menu nav-item dropdown"><svg class="d-none"><symbol id="check2" viewBox="0 0 16 16"><path d="M13.854 3.646a.5.5.0 010 .708l-7 7a.5.5.0 01-.708.0l-3.5-3.5a.5.5.0 11.708-.708L6.5 10.293l6.646-6.647a.5.5.0 01.708.0z"/></symbol><symbol id="circle-half" viewBox="0 0 16 16"><path d="M8 15A7 7 0 108 1v14zm0 1A8 8 0 118 0a8 8 0 010 16z"/></symbol><symbol id="moon-stars-fill" viewBox="0 0 16 16"><path d="M6 .278a.768.768.0 01.08.858 7.208 7.208.0 00-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527.0 1.04-.055 1.533-.16a.787.787.0 01.81.316.733.733.0 01-.031.893A8.349 8.349.0 018.344 16C3.734 16 0 12.286.0 7.71.0 4.266 2.114 1.312 5.124.06A.752.752.0 016 .278z"/><path d="M10.794 3.148a.217.217.0 01.412.0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217.0 010 .412l-1.162.387A1.734 1.734.0 0011.593 7.69l-.387 1.162a.217.217.0 01-.412.0l-.387-1.162A1.734 1.734.0 009.31 6.593l-1.162-.387a.217.217.0 010-.412l1.162-.387a1.734 1.734.0 001.097-1.097l.387-1.162zM13.863.099a.145.145.0 01.274.0l.258.774c.115.346.386.617.732.732l.774.258a.145.145.0 010 .274l-.774.258a1.156 1.156.0 00-.732.732l-.258.774a.145.145.0 01-.274.0l-.258-.774a1.156 1.156.0 00-.732-.732l-.774-.258a.145.145.0 010-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"/></symbol><symbol id="sun-fill" viewBox="0 0 16 16"><path d="M8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 0zm0 13a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 13zm8-5a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2a.5.5.0 01.5.5zM3 8a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2A.5.5.0 013 8zm10.657-5.657a.5.5.0 010 .707l-1.414 1.415a.5.5.0 11-.707-.708l1.414-1.414a.5.5.0 01.707.0zm-9.193 9.193a.5.5.0 010 .707L3.05 13.657a.5.5.0 01-.707-.707l1.414-1.414a.5.5.0 01.707.0zm9.193 2.121a.5.5.0 01-.707.0l-1.414-1.414a.5.5.0 01.707-.707l1.414 1.414a.5.5.0 010 .707zM4.464 4.465a.5.5.0 01-.707.0L2.343 3.05a.5.5.0 11.707-.707l1.414 1.414a.5.5.0 010 .708z"/></symbol></svg>
<button class="btn btn-link nav-link dropdown-toggle d-flex align-items-center" id=bd-theme type=button aria-expanded=false data-bs-toggle=dropdown data-bs-display=static aria-label="Toggle theme (auto)">
<svg class="bi my-1 theme-icon-active"><use href="#circle-half"/></svg></button><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=bd-theme-text><li><button type=button class="dropdown-item d-flex align-items-center" data-bs-theme-value=light aria-pressed=false>
<svg class="bi me-2 opacity-50"><use href="#sun-fill"/></svg>
Light
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li><li><button type=button class="dropdown-item d-flex align-items-center" data-bs-theme-value=dark aria-pressed=false>
<svg class="bi me-2 opacity-50"><use href="#moon-stars-fill"/></svg>
Dark
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li><li><button type=button class="dropdown-item d-flex align-items-center active" data-bs-theme-value=auto aria-pressed=true>
<svg class="bi me-2 opacity-50"><use href="#circle-half"/></svg>
Auto
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li></ul></li></ul></div><div class="d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/infra/pr-preview/pr-626/offline-search-index.f333b4ebedab3e27d00be506a18e6cbf.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/infra/pr-preview/pr-626/rd/analysis/server-os/>Return to the regular view of this page</a>.</p></div><h1 class=title>Server Operating System Analysis</h1><div class=lead>Evaluation of operating systems for homelab Kubernetes infrastructure</div><ul><li>1: <a href=#pg-2b6064c84b17aa5904b4749ff38d16b2>Ubuntu Analysis</a></li><li>2: <a href=#pg-f8c94234b2c711850baec9a4a41ca4f8>Fedora Analysis</a></li><li>3: <a href=#pg-7e5e084a8e0ecdcf60e6401763ef0a82>Talos Linux Analysis</a></li><li>4: <a href=#pg-f633ef5d64f4d7ef2640d8077b7ca2a8>Harvester Analysis</a></li></ul><div class=content><p>This section provides detailed analysis of operating systems evaluated for the homelab server infrastructure, with a focus on Kubernetes cluster setup and maintenance.</p><h2 id=overview>Overview</h2><p>The selection of a server operating system is critical for homelab infrastructure. The primary evaluation criterion is ease of Kubernetes cluster initialization and ongoing maintenance burden.</p><h2 id=evaluated-options>Evaluated Options</h2><ul><li><p><a href=./ubuntu/><strong>Ubuntu</strong></a> - Traditional general-purpose Linux distribution</p><ul><li>Kubernetes via kubeadm, k3s, or MicroK8s</li><li>Strong community support and extensive documentation</li><li>Familiar package management and system administration</li></ul></li><li><p><a href=./fedora/><strong>Fedora</strong></a> - Cutting-edge Linux distribution</p><ul><li>Latest kernel and system components</li><li>Kubernetes via kubeadm or k3s</li><li>Shorter support lifecycle with more frequent upgrades</li></ul></li><li><p><a href=./talos-linux/><strong>Talos Linux</strong></a> - Purpose-built Kubernetes OS</p><ul><li>API-driven, immutable infrastructure</li><li>Built-in Kubernetes with minimal attack surface</li><li>Designed specifically for container workloads</li></ul></li><li><p><a href=./harvester/><strong>Harvester</strong></a> - Hyperconverged infrastructure platform</p><ul><li>Built on Rancher and K3s</li><li>Combines compute, storage, and networking</li><li>VM and container workloads on unified platform</li></ul></li></ul><h2 id=evaluation-criteria>Evaluation Criteria</h2><p>Each option is evaluated based on:</p><ol><li><strong>Kubernetes Installation Methods</strong> - Available tooling and installation approaches</li><li><strong>Cluster Initialization Process</strong> - Steps required to bootstrap a cluster</li><li><strong>Maintenance Requirements</strong> - OS updates, Kubernetes upgrades, security patches</li><li><strong>Resource Overhead</strong> - Memory, CPU, and storage footprint</li><li><strong>Learning Curve</strong> - Ease of adoption and operational complexity</li><li><strong>Community Support</strong> - Documentation quality and ecosystem maturity</li><li><strong>Security Posture</strong> - Attack surface and security-first design</li></ol><h2 id=related-adrs>Related ADRs</h2><ul><li><a href=../../adrs/0004-server-operating-system/>ADR-0004: Server Operating System Selection</a> - Final decision based on this analysis</li></ul></div></div><div class=td-content style=page-break-before:always><h1 id=pg-2b6064c84b17aa5904b4749ff38d16b2>1 - Ubuntu Analysis</h1><div class=lead>Analysis of Ubuntu for Kubernetes homelab infrastructure</div><h2 id=overview>Overview</h2><p>Ubuntu Server is a popular general-purpose Linux distribution developed by Canonical. It provides Long Term Support (LTS) releases with 5 years of standard support and optional Extended Security Maintenance (ESM).</p><p><strong>Key Facts</strong>:</p><ul><li><strong>Latest LTS</strong>: Ubuntu 24.04 LTS (Noble Numbat)</li><li><strong>Support Period</strong>: 5 years standard, 10 years with Ubuntu Pro (free for personal use)</li><li><strong>Kernel</strong>: Linux 6.8+ (LTS), regular HWE updates</li><li><strong>Package Manager</strong>: APT/DPKG, Snap</li><li><strong>Init System</strong>: systemd</li></ul><h2 id=kubernetes-installation-methods>Kubernetes Installation Methods</h2><p>Ubuntu supports multiple Kubernetes installation approaches:</p><h3 id=1-kubeadm-official-kubernetes-tool>1. kubeadm (Official Kubernetes Tool)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install container runtime (containerd)</span>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y containerd
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure containerd</span>
</span></span><span class=line><span class=cl>sudo mkdir -p /etc/containerd
</span></span><span class=line><span class=cl>containerd config default <span class=p>|</span> sudo tee /etc/containerd/config.toml
</span></span><span class=line><span class=cl>sudo systemctl restart containerd
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install kubeadm, kubelet, kubectl</span>
</span></span><span class=line><span class=cl>sudo apt-get install -y apt-transport-https ca-certificates curl gpg
</span></span><span class=line><span class=cl>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key <span class=p>|</span> sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /&#39;</span> <span class=p>|</span> sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y kubelet kubeadm kubectl
</span></span><span class=line><span class=cl>sudo apt-mark hold kubelet kubeadm kubectl
</span></span></code></pre></div><p><strong>Cluster Initialization</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Initialize control plane</span>
</span></span><span class=line><span class=cl>sudo kubeadm init --pod-network-cidr<span class=o>=</span>10.244.0.0/16
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure kubectl for admin</span>
</span></span><span class=line><span class=cl>mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install CNI (e.g., Calico, Flannel)</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Join worker nodes</span>
</span></span><span class=line><span class=cl>kubeadm token create --print-join-command
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Official Kubernetes tooling, well-documented</li><li>Full control over cluster configuration</li><li>Supports latest Kubernetes versions</li><li>Large community and extensive resources</li></ul><p><strong>Cons</strong>:</p><ul><li>More manual steps than turnkey solutions</li><li>Requires understanding of Kubernetes architecture</li><li>Manual upgrade process for each component</li><li>More complex troubleshooting</li></ul><h3 id=2-k3s-lightweight-kubernetes>2. k3s (Lightweight Kubernetes)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Single-command install on control plane</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> sh -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get node token for workers</span>
</span></span><span class=line><span class=cl>sudo cat /var/lib/rancher/k3s/server/node-token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install on worker nodes</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> <span class=nv>K3S_URL</span><span class=o>=</span>https://control-plane:6443 <span class=nv>K3S_TOKEN</span><span class=o>=</span>&lt;token&gt; sh -
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Extremely simple installation (single command)</li><li>Lightweight (&lt; 512MB RAM)</li><li>Built-in container runtime (containerd)</li><li>Automatic updates via Rancher System Upgrade Controller</li><li>Great for edge and homelab use cases</li></ul><p><strong>Cons</strong>:</p><ul><li>Less customizable than kubeadm</li><li>Some features removed (e.g., in-tree storage, cloud providers)</li><li>Slightly different from upstream Kubernetes</li></ul><h3 id=3-microk8s-canonicals-distribution>3. MicroK8s (Canonical&rsquo;s Distribution)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install via snap</span>
</span></span><span class=line><span class=cl>sudo snap install microk8s --classic
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Join cluster</span>
</span></span><span class=line><span class=cl>sudo microk8s add-node
</span></span><span class=line><span class=cl><span class=c1># Run output command on worker nodes</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Enable addons</span>
</span></span><span class=line><span class=cl>microk8s <span class=nb>enable</span> dns storage ingress
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Zero-ops, single package install</li><li>Snap-based automatic updates</li><li>Addons for common services (DNS, storage, ingress)</li><li>Canonical support available</li></ul><p><strong>Cons</strong>:</p><ul><li>Requires snap (not universally liked)</li><li>Less ecosystem compatibility than vanilla Kubernetes</li><li>Ubuntu-specific (less portable)</li></ul><h2 id=cluster-initialization-sequence>Cluster Initialization Sequence</h2><h3 id=kubeadm-approach>kubeadm Approach</h3><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Ubuntu Server
    participant K8s as Kubernetes Components
    
    Admin-&gt;&gt;Server: Install Ubuntu 24.04 LTS
    Server-&gt;&gt;Server: Configure network (static IP)
    Admin-&gt;&gt;Server: Update system (apt update &amp;&amp; upgrade)
    Admin-&gt;&gt;Server: Install containerd
    Server-&gt;&gt;Server: Configure containerd (CRI)
    Admin-&gt;&gt;Server: Install kubeadm/kubelet/kubectl
    Server-&gt;&gt;Server: Disable swap, configure kernel modules
    Admin-&gt;&gt;K8s: kubeadm init --pod-network-cidr=10.244.0.0/16
    K8s-&gt;&gt;Server: Generate certificates
    K8s-&gt;&gt;Server: Start etcd
    K8s-&gt;&gt;Server: Start API server
    K8s-&gt;&gt;Server: Start controller-manager
    K8s-&gt;&gt;Server: Start scheduler
    K8s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;K8s: kubectl apply -f calico.yaml
    K8s-&gt;&gt;Server: Deploy CNI pods
    Admin-&gt;&gt;K8s: kubeadm join (on workers)
    K8s-&gt;&gt;Server: Add worker nodes
    K8s--&gt;&gt;Admin: Cluster ready</pre><h3 id=k3s-approach>k3s Approach</h3><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Ubuntu Server
    participant K3s as k3s Components
    
    Admin-&gt;&gt;Server: Install Ubuntu 24.04 LTS
    Server-&gt;&gt;Server: Configure network (static IP)
    Admin-&gt;&gt;Server: Update system
    Admin-&gt;&gt;Server: curl -sfL https://get.k3s.io | sh -
    Server-&gt;&gt;K3s: Download k3s binary
    K3s-&gt;&gt;Server: Configure containerd
    K3s-&gt;&gt;Server: Start k3s service
    K3s-&gt;&gt;Server: Initialize etcd (embedded)
    K3s-&gt;&gt;Server: Start API server
    K3s-&gt;&gt;Server: Start controller-manager
    K3s-&gt;&gt;Server: Start scheduler
    K3s-&gt;&gt;Server: Deploy built-in CNI (Flannel)
    K3s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;Server: Retrieve node token
    Admin-&gt;&gt;Server: Install k3s agent on workers
    K3s-&gt;&gt;Server: Join workers to cluster
    K3s--&gt;&gt;Admin: Cluster ready (5-10 minutes total)</pre><h2 id=maintenance-requirements>Maintenance Requirements</h2><h3 id=os-updates>OS Updates</h3><p><strong>Security Patches</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Automatic security updates (recommended)</span>
</span></span><span class=line><span class=cl>sudo apt-get install unattended-upgrades
</span></span><span class=line><span class=cl>sudo dpkg-reconfigure -plow unattended-upgrades
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Manual updates</span>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get upgrade
</span></span></code></pre></div><p><strong>Frequency</strong>:</p><ul><li>Security patches: Weekly to monthly</li><li>Kernel updates: Monthly (may require reboot)</li><li>Major version upgrades: Every 2 years (LTS to LTS)</li></ul><h3 id=kubernetes-upgrades>Kubernetes Upgrades</h3><p><strong>kubeadm Upgrade</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade control plane</span>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y <span class=nv>kubeadm</span><span class=o>=</span>1.32.0-*
</span></span><span class=line><span class=cl>sudo kubeadm upgrade apply v1.32.0
</span></span><span class=line><span class=cl>sudo apt-get install -y <span class=nv>kubelet</span><span class=o>=</span>1.32.0-* <span class=nv>kubectl</span><span class=o>=</span>1.32.0-*
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upgrade workers</span>
</span></span><span class=line><span class=cl>kubectl drain &lt;node&gt; --ignore-daemonsets
</span></span><span class=line><span class=cl>sudo apt-get install -y <span class=nv>kubeadm</span><span class=o>=</span>1.32.0-* <span class=nv>kubelet</span><span class=o>=</span>1.32.0-* <span class=nv>kubectl</span><span class=o>=</span>1.32.0-*
</span></span><span class=line><span class=cl>sudo kubeadm upgrade node
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span><span class=line><span class=cl>kubectl uncordon &lt;node&gt;
</span></span></code></pre></div><p><strong>k3s Upgrade</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Manual upgrade</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> <span class=nv>INSTALL_K3S_VERSION</span><span class=o>=</span>v1.32.0+k3s1 sh -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Automatic upgrade via system-upgrade-controller</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://github.com/rancher/system-upgrade-controller/releases/latest/download/system-upgrade-controller.yaml
</span></span></code></pre></div><p><strong>Upgrade Frequency</strong>: Every 3-6 months (Kubernetes minor versions)</p><h2 id=resource-overhead>Resource Overhead</h2><p><strong>Minimal Installation</strong> (Ubuntu Server + k3s):</p><ul><li><strong>RAM</strong>: ~512MB (OS) + 512MB (k3s) = 1GB total</li><li><strong>CPU</strong>: 1 core minimum, 2 cores recommended</li><li><strong>Disk</strong>: 10GB (OS) + 10GB (container images) = 20GB</li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><p><strong>Full Installation</strong> (Ubuntu Server + kubeadm):</p><ul><li><strong>RAM</strong>: ~512MB (OS) + 1-2GB (Kubernetes components) = 2GB+ total</li><li><strong>CPU</strong>: 2 cores minimum</li><li><strong>Disk</strong>: 15GB (OS) + 20GB (container images/etcd) = 35GB</li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><h2 id=security-posture>Security Posture</h2><p><strong>Strengths</strong>:</p><ul><li>Regular security updates via Ubuntu Security Team</li><li>AppArmor enabled by default</li><li>SELinux support available</li><li>Kernel hardening features (ASLR, stack protection)</li><li>Ubuntu Pro ESM for extended CVE coverage (free for personal use)</li></ul><p><strong>Attack Surface</strong>:</p><ul><li>Full general-purpose OS (larger attack surface than minimal OS)</li><li>Many installed packages by default (can be minimized)</li><li>Requires manual hardening for production use</li></ul><p><strong>Hardening Steps</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Disable unnecessary services</span>
</span></span><span class=line><span class=cl>sudo systemctl disable snapd.service
</span></span><span class=line><span class=cl>sudo systemctl disable bluetooth.service
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure firewall</span>
</span></span><span class=line><span class=cl>sudo ufw default deny incoming
</span></span><span class=line><span class=cl>sudo ufw default allow outgoing
</span></span><span class=line><span class=cl>sudo ufw allow 22/tcp
</span></span><span class=line><span class=cl>sudo ufw allow 6443/tcp  <span class=c1># Kubernetes API</span>
</span></span><span class=line><span class=cl>sudo ufw allow 10250/tcp <span class=c1># Kubelet</span>
</span></span><span class=line><span class=cl>sudo ufw <span class=nb>enable</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># CIS Kubernetes Benchmark compliance</span>
</span></span><span class=line><span class=cl><span class=c1># Use tools like kube-bench for validation</span>
</span></span></code></pre></div><h2 id=learning-curve>Learning Curve</h2><p><strong>Ease of Adoption</strong>: ⭐⭐⭐⭐⭐ (Excellent)</p><ul><li>Most familiar Linux distribution for many users</li><li>Extensive documentation and tutorials</li><li>Large community support (forums, Stack Overflow)</li><li>Straightforward package management</li><li>Similar to Debian-based systems</li></ul><p><strong>Required Knowledge</strong>:</p><ul><li>Basic Linux system administration (apt, systemd, networking)</li><li>Kubernetes concepts (pods, services, deployments)</li><li>Container runtime basics (containerd, Docker)</li><li>Text editor (vim, nano) for configuration</li></ul><h2 id=community-support>Community Support</h2><p><strong>Ecosystem Maturity</strong>: ⭐⭐⭐⭐⭐ (Excellent)</p><ul><li><strong>Documentation</strong>: Comprehensive official docs, community guides</li><li><strong>Community</strong>: Massive user base, active forums</li><li><strong>Commercial Support</strong>: Available from Canonical (Ubuntu Pro)</li><li><strong>Third-Party Tools</strong>: Excellent compatibility with all Kubernetes tools</li><li><strong>Tutorials</strong>: Abundant resources for Kubernetes on Ubuntu</li></ul><p><strong>Resources</strong>:</p><ul><li><a href=https://ubuntu.com/server/docs>Ubuntu Server Documentation</a></li><li><a href=https://ubuntu.com/kubernetes>Kubernetes on Ubuntu Guide</a></li><li><a href=https://docs.k3s.io/>k3s Documentation</a></li><li><a href=https://microk8s.io/docs>MicroK8s Documentation</a></li></ul><h2 id=pros-and-cons-summary>Pros and Cons Summary</h2><h3 id=pros>Pros</h3><ul><li>Good, because most familiar and well-documented Linux distribution</li><li>Good, because 5-year LTS support (10 years with Ubuntu Pro)</li><li>Good, because multiple Kubernetes installation options (kubeadm, k3s, MicroK8s)</li><li>Good, because k3s provides extremely simple setup (single command)</li><li>Good, because extensive package ecosystem (60,000+ packages)</li><li>Good, because strong community support and resources</li><li>Good, because automatic security updates available</li><li>Good, because low learning curve for most administrators</li><li>Good, because compatible with all Kubernetes tooling and addons</li><li>Good, because Ubuntu Pro free for personal use (extended security)</li></ul><h3 id=cons>Cons</h3><ul><li>Bad, because general-purpose OS has larger attack surface than minimal OS</li><li>Bad, because more resource overhead than purpose-built Kubernetes OS (1-2GB RAM)</li><li>Bad, because requires manual OS updates and reboots</li><li>Bad, because kubeadm setup is complex with many manual steps</li><li>Bad, because snap packages controversial (for MicroK8s)</li><li>Bad, because Kubernetes upgrades require manual intervention (unless using k3s auto-upgrade)</li><li>Bad, because managing OS + Kubernetes lifecycle separately increases complexity</li><li>Neutral, because many preinstalled packages (can be removed, but require effort)</li></ul><h2 id=recommendations>Recommendations</h2><p><strong>Best for</strong>:</p><ul><li>Users familiar with Ubuntu/Debian ecosystem</li><li>Homelabs requiring general-purpose server functionality (not just Kubernetes)</li><li>Teams wanting multiple Kubernetes installation options</li><li>Users prioritizing community support and documentation</li></ul><p><strong>Best Installation Method</strong>:</p><ul><li><strong>Homelab/Learning</strong>: k3s (simplest, auto-updates, lightweight)</li><li><strong>Production-like</strong>: kubeadm (full control, upstream Kubernetes)</li><li><strong>Ubuntu-specific</strong>: MicroK8s (Canonical support, snap-based)</li></ul><p><strong>Avoid if</strong>:</p><ul><li>Seeking minimal attack surface (consider Talos Linux)</li><li>Want infrastructure-as-code for OS layer (consider Talos Linux)</li><li>Prefer hyperconverged platform (consider Harvester)</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f8c94234b2c711850baec9a4a41ca4f8>2 - Fedora Analysis</h1><div class=lead>Analysis of Fedora Server for Kubernetes homelab infrastructure</div><h2 id=overview>Overview</h2><p>Fedora Server is a cutting-edge Linux distribution sponsored by Red Hat, serving as the upstream for Red Hat Enterprise Linux (RHEL). It emphasizes innovation with the latest software packages and kernel versions.</p><p><strong>Key Facts</strong>:</p><ul><li><strong>Latest Version</strong>: Fedora 41 (October 2024)</li><li><strong>Support Period</strong>: ~13 months per release (shorter than Ubuntu LTS)</li><li><strong>Kernel</strong>: Linux 6.11+ (latest stable)</li><li><strong>Package Manager</strong>: DNF/RPM, Flatpak</li><li><strong>Init System</strong>: systemd</li></ul><h2 id=kubernetes-installation-methods>Kubernetes Installation Methods</h2><p>Fedora supports standard Kubernetes installation approaches:</p><h3 id=1-kubeadm-official-kubernetes-tool>1. kubeadm (Official Kubernetes Tool)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install container runtime (CRI-O preferred on Fedora)</span>
</span></span><span class=line><span class=cl>sudo dnf install -y cri-o
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> --now crio
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Add Kubernetes repository</span>
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
</span></span></span><span class=line><span class=cl><span class=s>[kubernetes]
</span></span></span><span class=line><span class=cl><span class=s>name=Kubernetes
</span></span></span><span class=line><span class=cl><span class=s>baseurl=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/
</span></span></span><span class=line><span class=cl><span class=s>enabled=1
</span></span></span><span class=line><span class=cl><span class=s>gpgcheck=1
</span></span></span><span class=line><span class=cl><span class=s>gpgkey=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/repodata/repomd.xml.key
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install kubeadm, kubelet, kubectl</span>
</span></span><span class=line><span class=cl>sudo dnf install -y kubelet kubeadm kubectl
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> --now kubelet
</span></span></code></pre></div><p><strong>Cluster Initialization</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Initialize control plane</span>
</span></span><span class=line><span class=cl>sudo kubeadm init --pod-network-cidr<span class=o>=</span>10.244.0.0/16 --cri-socket<span class=o>=</span>unix:///var/run/crio/crio.sock
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure kubectl</span>
</span></span><span class=line><span class=cl>mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install CNI</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Join workers</span>
</span></span><span class=line><span class=cl>kubeadm token create --print-join-command
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>CRI-O is native to Fedora ecosystem (same as RHEL/OpenShift)</li><li>Latest Kubernetes versions available quickly</li><li>Familiar to RHEL/CentOS users</li><li>Fully upstream Kubernetes</li></ul><p><strong>Cons</strong>:</p><ul><li>Manual setup process (same as Ubuntu/kubeadm)</li><li>Requires Kubernetes knowledge</li><li>More complex than turnkey solutions</li></ul><h3 id=2-k3s-lightweight-kubernetes>2. k3s (Lightweight Kubernetes)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Same single-command install</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> sh -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Retrieve token</span>
</span></span><span class=line><span class=cl>sudo cat /var/lib/rancher/k3s/server/node-token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install on workers</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> <span class=nv>K3S_URL</span><span class=o>=</span>https://control-plane:6443 <span class=nv>K3S_TOKEN</span><span class=o>=</span>&lt;token&gt; sh -
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Simple installation (identical to Ubuntu)</li><li>Lightweight and fast</li><li>Well-tested on Fedora/RHEL family</li></ul><p><strong>Cons</strong>:</p><ul><li>Less customizable</li><li>Not using native CRI-O by default (uses embedded containerd)</li></ul><h3 id=3-okd-openshift-kubernetes-distribution>3. OKD (OpenShift Kubernetes Distribution)</h3><p><strong>Installation</strong> (Single-Node):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Download and install OKD</span>
</span></span><span class=line><span class=cl>wget https://github.com/okd-project/okd/releases/download/4.15.0-0.okd-2024-01-27-070424/openshift-install-linux-4.15.0-0.okd-2024-01-27-070424.tar.gz
</span></span><span class=line><span class=cl>tar -xvf openshift-install-linux-*.tar.gz
</span></span><span class=line><span class=cl>sudo mv openshift-install /usr/local/bin/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create install config</span>
</span></span><span class=line><span class=cl>./openshift-install create install-config --dir<span class=o>=</span>cluster
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install cluster</span>
</span></span><span class=line><span class=cl>./openshift-install create cluster --dir<span class=o>=</span>cluster
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Enterprise features (operators, web console, image registry)</li><li>Built-in CI/CD and developer tools</li><li>Based on Fedora CoreOS (immutable, auto-updating)</li></ul><p><strong>Cons</strong>:</p><ul><li>Very heavy resource requirements (16GB+ RAM)</li><li>Complex installation and management</li><li>Overkill for simple homelab use</li></ul><h2 id=cluster-initialization-sequence>Cluster Initialization Sequence</h2><h3 id=kubeadm-with-cri-o>kubeadm with CRI-O</h3><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Fedora Server
    participant K8s as Kubernetes Components
    
    Admin-&gt;&gt;Server: Install Fedora 41
    Server-&gt;&gt;Server: Configure network (static IP)
    Admin-&gt;&gt;Server: Update system (dnf update)
    Admin-&gt;&gt;Server: Install CRI-O
    Server-&gt;&gt;Server: Configure CRI-O runtime
    Server-&gt;&gt;Server: Enable crio.service
    Admin-&gt;&gt;Server: Install kubeadm/kubelet/kubectl
    Server-&gt;&gt;Server: Disable swap, load kernel modules
    Server-&gt;&gt;Server: Configure SELinux (permissive for Kubernetes)
    Admin-&gt;&gt;K8s: kubeadm init --cri-socket=unix:///var/run/crio/crio.sock
    K8s-&gt;&gt;Server: Generate certificates
    K8s-&gt;&gt;Server: Start etcd
    K8s-&gt;&gt;Server: Start API server
    K8s-&gt;&gt;Server: Start controller-manager
    K8s-&gt;&gt;Server: Start scheduler
    K8s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;K8s: kubectl apply CNI
    K8s-&gt;&gt;Server: Deploy CNI pods
    Admin-&gt;&gt;K8s: kubeadm join (workers)
    K8s-&gt;&gt;Server: Add worker nodes
    K8s--&gt;&gt;Admin: Cluster ready</pre><h3 id=k3s-approach>k3s Approach</h3><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Fedora Server
    participant K3s as k3s Components
    
    Admin-&gt;&gt;Server: Install Fedora 41
    Server-&gt;&gt;Server: Configure network
    Admin-&gt;&gt;Server: Update system (dnf update)
    Admin-&gt;&gt;Server: Disable firewalld (or configure)
    Admin-&gt;&gt;Server: curl -sfL https://get.k3s.io | sh -
    Server-&gt;&gt;K3s: Download k3s binary
    K3s-&gt;&gt;Server: Configure containerd
    K3s-&gt;&gt;Server: Start k3s service
    K3s-&gt;&gt;Server: Initialize embedded etcd
    K3s-&gt;&gt;Server: Start API server
    K3s-&gt;&gt;Server: Deploy built-in CNI
    K3s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;Server: Retrieve node token
    Admin-&gt;&gt;Server: Install k3s agent on workers
    K3s-&gt;&gt;Server: Join workers
    K3s--&gt;&gt;Admin: Cluster ready (5-10 minutes)</pre><h2 id=maintenance-requirements>Maintenance Requirements</h2><h3 id=os-updates>OS Updates</h3><p><strong>Security and System Updates</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Automatic updates (dnf-automatic)</span>
</span></span><span class=line><span class=cl>sudo dnf install -y dnf-automatic
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> --now dnf-automatic.timer
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Manual updates</span>
</span></span><span class=line><span class=cl>sudo dnf update -y
</span></span><span class=line><span class=cl>sudo reboot  <span class=c1># if kernel updated</span>
</span></span></code></pre></div><p><strong>Frequency</strong>:</p><ul><li>Security patches: Weekly to monthly</li><li>Kernel updates: Monthly (frequent updates)</li><li><strong>Major version upgrades</strong>: Every ~13 months (Fedora releases)</li></ul><p><strong>Version Upgrade</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade to next Fedora release</span>
</span></span><span class=line><span class=cl>sudo dnf upgrade --refresh
</span></span><span class=line><span class=cl>sudo dnf install dnf-plugin-system-upgrade
</span></span><span class=line><span class=cl>sudo dnf system-upgrade download --releasever<span class=o>=</span><span class=m>42</span>
</span></span><span class=line><span class=cl>sudo dnf system-upgrade reboot
</span></span></code></pre></div><h3 id=kubernetes-upgrades>Kubernetes Upgrades</h3><p><strong>kubeadm Upgrade</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade control plane</span>
</span></span><span class=line><span class=cl>sudo dnf update -y kubeadm
</span></span><span class=line><span class=cl>sudo kubeadm upgrade apply v1.32.0
</span></span><span class=line><span class=cl>sudo dnf update -y kubelet kubectl
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upgrade workers</span>
</span></span><span class=line><span class=cl>kubectl drain &lt;node&gt; --ignore-daemonsets
</span></span><span class=line><span class=cl>sudo dnf update -y kubeadm kubelet kubectl
</span></span><span class=line><span class=cl>sudo kubeadm upgrade node
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span><span class=line><span class=cl>kubectl uncordon &lt;node&gt;
</span></span></code></pre></div><p><strong>k3s Upgrade</strong>: Same as Ubuntu (curl script or system-upgrade-controller)</p><p><strong>Upgrade Frequency</strong>: Kubernetes every 3-6 months, Fedora OS every ~13 months</p><h2 id=resource-overhead>Resource Overhead</h2><p><strong>Minimal Installation</strong> (Fedora Server + k3s):</p><ul><li><strong>RAM</strong>: ~600MB (OS) + 512MB (k3s) = 1.2GB total</li><li><strong>CPU</strong>: 1 core minimum, 2 cores recommended</li><li><strong>Disk</strong>: 12GB (OS) + 10GB (containers) = 22GB</li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><p><strong>Full Installation</strong> (Fedora Server + kubeadm + CRI-O):</p><ul><li><strong>RAM</strong>: ~700MB (OS) + 1.5GB (Kubernetes) = 2.2GB total</li><li><strong>CPU</strong>: 2 cores minimum</li><li><strong>Disk</strong>: 15GB (OS) + 20GB (containers) = 35GB</li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><p><strong>Note</strong>: Slightly higher overhead than Ubuntu due to SELinux and newer components.</p><h2 id=security-posture>Security Posture</h2><p><strong>Strengths</strong>:</p><ul><li><strong>SELinux enabled by default</strong> (stronger than AppArmor)</li><li>Latest security patches and kernel (bleeding edge)</li><li>CRI-O container runtime (security-focused, used by OpenShift)</li><li>Shorter support window = less legacy CVEs</li><li>Active security team and rapid response</li></ul><p><strong>Attack Surface</strong>:</p><ul><li>General-purpose OS (larger surface than minimal OS)</li><li>More installed packages than minimal server</li><li>SELinux can be complex to configure for Kubernetes</li></ul><p><strong>Hardening Steps</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Configure firewall (firewalld default on Fedora)</span>
</span></span><span class=line><span class=cl>sudo firewall-cmd --permanent --add-port<span class=o>=</span>6443/tcp  <span class=c1># API server</span>
</span></span><span class=line><span class=cl>sudo firewall-cmd --permanent --add-port<span class=o>=</span>10250/tcp <span class=c1># Kubelet</span>
</span></span><span class=line><span class=cl>sudo firewall-cmd --reload
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># SELinux configuration for Kubernetes</span>
</span></span><span class=line><span class=cl>sudo setenforce <span class=m>0</span>  <span class=c1># Permissive (Kubernetes not fully SELinux-ready)</span>
</span></span><span class=line><span class=cl>sudo sed -i <span class=s1>&#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39;</span> /etc/selinux/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Disable unnecessary services</span>
</span></span><span class=line><span class=cl>sudo systemctl disable bluetooth.service
</span></span></code></pre></div><h2 id=learning-curve>Learning Curve</h2><p><strong>Ease of Adoption</strong>: ⭐⭐⭐⭐ (Good)</p><ul><li>Familiar for RHEL/CentOS/Alma/Rocky users</li><li>DNF package manager (similar to APT)</li><li>Excellent documentation</li><li>SELinux learning curve can be steep</li></ul><p><strong>Required Knowledge</strong>:</p><ul><li>RPM-based system administration (dnf, systemd)</li><li>SELinux basics (or willingness to use permissive mode)</li><li>Kubernetes concepts</li><li>Firewalld configuration</li></ul><p><strong>Differences from Ubuntu</strong>:</p><ul><li>DNF vs APT package manager</li><li>SELinux vs AppArmor</li><li>Firewalld vs UFW</li><li>Faster release cycle (more frequent upgrades)</li></ul><h2 id=community-support>Community Support</h2><p><strong>Ecosystem Maturity</strong>: ⭐⭐⭐⭐ (Good)</p><ul><li><strong>Documentation</strong>: Excellent official docs, Red Hat resources</li><li><strong>Community</strong>: Large user base, active forums</li><li><strong>Commercial Support</strong>: RHEL support available (paid)</li><li><strong>Third-Party Tools</strong>: Good compatibility with Kubernetes tools</li><li><strong>Tutorials</strong>: Abundant resources, especially for RHEL ecosystem</li></ul><p><strong>Resources</strong>:</p><ul><li><a href=https://docs.fedoraproject.org/en-US/fedora-server/>Fedora Server Documentation</a></li><li><a href=https://fedoraproject.org/wiki/SIGs/Kubernetes>Fedora Kubernetes SIG</a></li><li><a href=https://cri-o.io/>CRI-O Documentation</a></li><li><a href=https://docs.k3s.io/>k3s on Fedora</a></li></ul><h2 id=pros-and-cons-summary>Pros and Cons Summary</h2><h3 id=pros>Pros</h3><ul><li>Good, because latest kernel and software packages (bleeding edge)</li><li>Good, because SELinux enabled by default (stronger MAC than AppArmor)</li><li>Good, because native CRI-O support (same as RHEL/OpenShift)</li><li>Good, because upstream for RHEL (enterprise compatibility)</li><li>Good, because multiple Kubernetes installation options</li><li>Good, because k3s simplifies setup dramatically</li><li>Good, because strong security focus and rapid CVE response</li><li>Good, because familiar to RHEL/CentOS ecosystem</li><li>Good, because automatic updates available (dnf-automatic)</li><li>Neutral, because shorter support cycle (13 months) ensures latest features</li></ul><h3 id=cons>Cons</h3><ul><li>Bad, because short support cycle requires frequent OS upgrades (every ~13 months)</li><li>Bad, because bleeding-edge packages can introduce instability</li><li>Bad, because SELinux configuration for Kubernetes is complex (often set to permissive)</li><li>Bad, because smaller community than Ubuntu (though still large)</li><li>Bad, because general-purpose OS has larger attack surface than minimal OS</li><li>Bad, because more resource overhead than purpose-built Kubernetes OS</li><li>Bad, because OS upgrade every 13 months adds maintenance burden</li><li>Bad, because less beginner-friendly than Ubuntu</li><li>Bad, because managing OS + Kubernetes lifecycle separately</li><li>Neutral, because rapid release cycle can be pro or con depending on preference</li></ul><h2 id=recommendations>Recommendations</h2><p><strong>Best for</strong>:</p><ul><li>Users familiar with RHEL/CentOS/Rocky/Alma ecosystem</li><li>Teams wanting latest kernel and software features</li><li>Environments requiring SELinux (compliance, enterprise standards)</li><li>Learning OpenShift/OKD ecosystem (Fedora CoreOS foundation)</li><li>Users comfortable with frequent OS upgrades</li></ul><p><strong>Best Installation Method</strong>:</p><ul><li><strong>Homelab/Learning</strong>: k3s (simplest, lightweight)</li><li><strong>Enterprise-like</strong>: kubeadm + CRI-O (OpenShift compatibility)</li><li><strong>Advanced</strong>: OKD (if resources available, 16GB+ RAM)</li></ul><p><strong>Avoid if</strong>:</p><ul><li>Prefer long-term stability (choose Ubuntu LTS)</li><li>Want minimal maintenance (frequent Fedora upgrades required)</li><li>Seeking minimal attack surface (consider Talos Linux)</li><li>Uncomfortable with SELinux complexity</li><li>Want infrastructure-as-code for OS (consider Talos Linux)</li></ul><h2 id=comparison-with-ubuntu>Comparison with Ubuntu</h2><table><thead><tr><th>Aspect</th><th>Fedora</th><th>Ubuntu LTS</th></tr></thead><tbody><tr><td><strong>Support Period</strong></td><td>13 months</td><td>5 years (10 with Pro)</td></tr><tr><td><strong>Kernel</strong></td><td>Latest (6.11+)</td><td>LTS (6.8+)</td></tr><tr><td><strong>Security</strong></td><td>SELinux</td><td>AppArmor</td></tr><tr><td><strong>Package Manager</strong></td><td>DNF/RPM</td><td>APT/DEB</td></tr><tr><td><strong>Release Cycle</strong></td><td>6 months</td><td>2 years (LTS)</td></tr><tr><td><strong>Upgrade Frequency</strong></td><td>Every 13 months</td><td>Every 2-5 years</td></tr><tr><td><strong>Community Size</strong></td><td>Large</td><td>Very Large</td></tr><tr><td><strong>Enterprise Upstream</strong></td><td>RHEL</td><td>N/A</td></tr><tr><td><strong>Stability</strong></td><td>Bleeding edge</td><td>Stable/Conservative</td></tr><tr><td><strong>Learning Curve</strong></td><td>Moderate</td><td>Easy</td></tr></tbody></table><p><strong>Verdict</strong>: Fedora is excellent for those wanting latest features and comfortable with frequent upgrades. Ubuntu LTS is better for long-term stability and minimal maintenance.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7e5e084a8e0ecdcf60e6401763ef0a82>3 - Talos Linux Analysis</h1><div class=lead>Analysis of Talos Linux for Kubernetes homelab infrastructure</div><h2 id=overview>Overview</h2><p>Talos Linux is a modern operating system designed specifically for running Kubernetes. It is API-driven, immutable, and minimal, with no SSH access, shell, or package manager. All configuration is done via a declarative API.</p><p><strong>Key Facts</strong>:</p><ul><li><strong>Latest Version</strong>: Talos 1.9 (supports Kubernetes 1.31)</li><li><strong>Support</strong>: Community-driven, commercial support available from Sidero Labs</li><li><strong>Kernel</strong>: Linux 6.6+ LTS</li><li><strong>Architecture</strong>: Immutable, API-driven, no shell access</li><li><strong>Management</strong>: talosctl CLI + Kubernetes API</li></ul><h2 id=kubernetes-installation-methods>Kubernetes Installation Methods</h2><p>Talos Linux has <strong>built-in Kubernetes</strong> - there is only one installation method.</p><h3 id=built-in-kubernetes-only-option>Built-in Kubernetes (Only Option)</h3><p><strong>Installation Process</strong>:</p><ol><li><strong>Boot Talos ISO/PXE</strong> (maintenance mode)</li><li><strong>Apply machine configuration</strong> via talosctl</li><li><strong>Bootstrap Kubernetes</strong> via talosctl bootstrap</li></ol><p><strong>Machine Configuration</strong> (YAML):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># controlplane.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=l>v1alpha1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>controlplane</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>disk</span><span class=p>:</span><span class=w> </span><span class=l>/dev/sda</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>control-plane-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>interfaces</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>interface</span><span class=p>:</span><span class=w> </span><span class=l>eth0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>dhcp</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>addresses</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=m>192.168.1.10</span><span class=l>/24</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>routes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=nt>network</span><span class=p>:</span><span class=w> </span><span class=m>0.0.0.0</span><span class=l>/0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>gateway</span><span class=p>:</span><span class=w> </span><span class=m>192.168.1.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>cluster</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>clusterName</span><span class=p>:</span><span class=w> </span><span class=l>homelab</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>controlPlane</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>endpoint</span><span class=p>:</span><span class=w> </span><span class=l>https://192.168.1.10:6443</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cni</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>custom</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>urls</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml</span><span class=w>
</span></span></span></code></pre></div><p><strong>Cluster Initialization</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Generate machine configs</span>
</span></span><span class=line><span class=cl>talosctl gen config homelab https://192.168.1.10:6443
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply config to control plane node (booted from ISO)</span>
</span></span><span class=line><span class=cl>talosctl apply-config --insecure --nodes 192.168.1.10 --file controlplane.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Wait for install to complete, then bootstrap</span>
</span></span><span class=line><span class=cl>talosctl bootstrap --nodes 192.168.1.10 --endpoints 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Retrieve kubeconfig</span>
</span></span><span class=line><span class=cl>talosctl kubeconfig --nodes 192.168.1.10 --endpoints 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply config to worker nodes</span>
</span></span><span class=line><span class=cl>talosctl apply-config --insecure --nodes 192.168.1.11 --file worker.yaml
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Kubernetes built-in, no separate installation</li><li>Declarative configuration (GitOps-friendly)</li><li>Extremely minimal attack surface (no shell, no SSH)</li><li>Immutable infrastructure (config changes require reboot)</li><li>Automatic updates via Talos controller</li><li>Designed from ground up for Kubernetes</li></ul><p><strong>Cons</strong>:</p><ul><li>Steep learning curve (completely different paradigm)</li><li>No SSH/shell access (all via API)</li><li>Troubleshooting requires different mindset</li><li>Limited to Kubernetes workloads only (not general-purpose)</li><li>Smaller community than traditional distros</li></ul><h2 id=cluster-initialization-sequence>Cluster Initialization Sequence</h2><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Bare Metal Server
    participant Talos as Talos Linux
    participant K8s as Kubernetes Components
    
    Admin-&gt;&gt;Server: Boot Talos ISO (PXE or USB)
    Server-&gt;&gt;Talos: Start in maintenance mode
    Talos--&gt;&gt;Admin: API endpoint ready (no shell)
    Admin-&gt;&gt;Admin: Generate configs (talosctl gen config)
    Admin-&gt;&gt;Talos: talosctl apply-config (controlplane.yaml)
    Talos-&gt;&gt;Server: Partition disk
    Talos-&gt;&gt;Server: Install Talos to /dev/sda
    Talos-&gt;&gt;Server: Write machine config
    Server-&gt;&gt;Server: Reboot from disk
    Talos-&gt;&gt;Talos: Load machine config
    Talos-&gt;&gt;K8s: Start kubelet
    Talos-&gt;&gt;K8s: Start etcd
    Talos-&gt;&gt;K8s: Start API server
    Admin-&gt;&gt;Talos: talosctl bootstrap
    Talos-&gt;&gt;K8s: Initialize cluster
    K8s-&gt;&gt;Talos: Start controller-manager
    K8s-&gt;&gt;Talos: Start scheduler
    K8s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;K8s: Apply CNI (via talosctl or kubectl)
    K8s-&gt;&gt;Talos: Deploy CNI pods
    Admin-&gt;&gt;Talos: Apply worker configs
    Talos-&gt;&gt;K8s: Join workers to cluster
    K8s--&gt;&gt;Admin: Cluster ready (10-15 minutes)</pre><h2 id=maintenance-requirements>Maintenance Requirements</h2><h3 id=os-updates>OS Updates</h3><p><strong>Declarative Upgrades</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade Talos version (rolling upgrade)</span>
</span></span><span class=line><span class=cl>talosctl upgrade --nodes 192.168.1.10 --image ghcr.io/siderolabs/installer:v1.9.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Kubernetes version upgrade (also declarative)</span>
</span></span><span class=line><span class=cl>talosctl upgrade-k8s --nodes 192.168.1.10 --to 1.32.0
</span></span></code></pre></div><p><strong>Automatic Updates</strong> (via Talos System Extensions):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># machine config with auto-update extension</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>extensions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ghcr.io/siderolabs/system-upgrade-controller</span><span class=w>
</span></span></span></code></pre></div><p><strong>Frequency</strong>:</p><ul><li>Talos releases: Every 2-3 months</li><li>Kubernetes upgrades: Follow upstream cadence (quarterly)</li><li>Security patches: Built into Talos releases</li><li><strong>No traditional OS patching</strong> (immutable system)</li></ul><h3 id=configuration-changes>Configuration Changes</h3><p><strong>All changes via machine config</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Edit machine config YAML</span>
</span></span><span class=line><span class=cl>vim controlplane.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply updated config (triggers reboot if needed)</span>
</span></span><span class=line><span class=cl>talosctl apply-config --nodes 192.168.1.10 --file controlplane.yaml
</span></span></code></pre></div><p><strong>No manual package installs</strong> - everything declarative.</p><h2 id=resource-overhead>Resource Overhead</h2><p><strong>Minimal Footprint</strong> (Talos Linux + Kubernetes):</p><ul><li><strong>RAM</strong>: ~256MB (OS) + 512MB (Kubernetes) = <strong>768MB total</strong></li><li><strong>CPU</strong>: 1 core minimum, 2 cores recommended</li><li><strong>Disk</strong>: ~500MB (OS) + 10GB (container images/etcd) = <strong>10-15GB total</strong></li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><p><strong>Comparison</strong>:</p><ul><li>Ubuntu + k3s: ~1GB RAM</li><li>Talos: ~768MB RAM (lighter)</li><li>Ubuntu + kubeadm: ~2GB RAM</li><li>Talos: ~768MB RAM (much lighter)</li></ul><p><strong>Minimal install size</strong>: ~500MB (vs 10GB+ for Ubuntu/Fedora)</p><h2 id=security-posture>Security Posture</h2><p><strong>Strengths</strong>: ⭐⭐⭐⭐⭐ (Excellent)</p><ul><li><strong>No SSH access</strong> - attack surface eliminated</li><li><strong>No shell</strong> - cannot install malware</li><li><strong>No package manager</strong> - no additional software installation</li><li><strong>Immutable filesystem</strong> - rootfs read-only</li><li><strong>Minimal components</strong>: Only Kubernetes and essential services</li><li><strong>API-only access</strong> - mTLS-authenticated talosctl</li><li><strong>KSPP compliance</strong>: Kernel Self-Protection Project standards</li><li><strong>Signed images</strong>: Cryptographically signed Talos images</li><li><strong>Secure Boot support</strong>: UEFI Secure Boot compatible</li></ul><p><strong>Attack Surface</strong>:</p><ul><li><strong>Smallest possible</strong>: Only Kubernetes API, kubelet, and Talos API</li><li>~30 running processes (vs 100+ on Ubuntu/Fedora)</li><li>~200MB filesystem (vs 5-10GB on Ubuntu/Fedora)</li></ul><p><strong>No hardening needed</strong> - secure by default.</p><p><strong>Security Features</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># Built-in security (example config)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>sysctls</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>kernel.kptr_restrict</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>kernel.yama.ptrace_scope</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;1&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kernel</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>modules</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>br_netfilter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>features</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>kubernetesTalosAPIAccess</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>allowedRoles</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>os:reader</span><span class=w>
</span></span></span></code></pre></div><h2 id=learning-curve>Learning Curve</h2><p><strong>Ease of Adoption</strong>: ⭐⭐ (Challenging)</p><ul><li><strong>Paradigm shift</strong>: No shell/SSH, API-only management</li><li>Requires understanding of declarative infrastructure</li><li>Talosctl CLI has learning curve</li><li>Excellent documentation helps</li><li>Different troubleshooting approach (logs via API)</li></ul><p><strong>Required Knowledge</strong>:</p><ul><li>Kubernetes fundamentals (critical)</li><li>YAML configuration syntax</li><li>Networking basics (especially CNI)</li><li>GitOps concepts helpful</li><li>Comfort with &ldquo;infrastructure as code&rdquo;</li></ul><p><strong>Debugging without shell</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># View logs via API</span>
</span></span><span class=line><span class=cl>talosctl logs --nodes 192.168.1.10 kubelet
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get system metrics</span>
</span></span><span class=line><span class=cl>talosctl dashboard --nodes 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Interactive mode (limited shell in emergency)</span>
</span></span><span class=line><span class=cl>talosctl dashboard --nodes 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Service status</span>
</span></span><span class=line><span class=cl>talosctl service --nodes 192.168.1.10
</span></span></code></pre></div><h2 id=community-support>Community Support</h2><p><strong>Ecosystem Maturity</strong>: ⭐⭐⭐ (Growing)</p><ul><li><strong>Documentation</strong>: Excellent official docs</li><li><strong>Community</strong>: Smaller but very active (Slack, GitHub Discussions)</li><li><strong>Commercial Support</strong>: Available from Sidero Labs</li><li><strong>Third-Party Tools</strong>: Growing ecosystem (Cluster API, GitOps tools)</li><li><strong>Tutorials</strong>: Increasing number of community guides</li></ul><p><strong>Resources</strong>:</p><ul><li><a href=https://www.talos.dev/v1.9/introduction/what-is-talos/>Talos Linux Documentation</a></li><li><a href=https://slack.dev.talos-systems.io/>Talos Community Slack</a></li><li><a href=https://github.com/siderolabs/talos>Sidero Labs GitHub</a></li><li><a href=https://github.com/budimanjojo/awesome-talos>Awesome Talos</a></li></ul><p><strong>Community Size</strong>: Smaller than Ubuntu/Fedora, but dedicated and helpful.</p><h2 id=pros-and-cons-summary>Pros and Cons Summary</h2><h3 id=pros>Pros</h3><ul><li>Good, because Kubernetes is built-in (no separate installation)</li><li>Good, because minimal attack surface (no SSH, shell, or package manager)</li><li>Good, because immutable infrastructure (config drift impossible)</li><li>Good, because API-driven management (GitOps-friendly)</li><li>Good, because extremely low resource overhead (~768MB RAM)</li><li>Good, because automatic security patches via Talos upgrades</li><li>Good, because declarative configuration (version-controlled)</li><li>Good, because secure by default (no hardening required)</li><li>Good, because smallest disk footprint (~500MB OS)</li><li>Good, because designed specifically for Kubernetes (opinionated and optimized)</li><li>Good, because UEFI Secure Boot support</li><li>Good, because upgrades are simple and declarative (talosctl upgrade)</li></ul><h3 id=cons>Cons</h3><ul><li>Bad, because steep learning curve (no shell/SSH paradigm shift)</li><li>Bad, because limited to Kubernetes workloads only (not general-purpose)</li><li>Bad, because troubleshooting without shell requires different approach</li><li>Bad, because smaller community than Ubuntu/Fedora</li><li>Bad, because relatively new (less mature than traditional distros)</li><li>Bad, because no escape hatch for manual intervention</li><li>Bad, because requires comfort with declarative infrastructure</li><li>Bad, because debugging is harder for beginners</li><li>Neutral, because opinionated design (pro for K8s-only, con for general use)</li></ul><h2 id=recommendations>Recommendations</h2><p><strong>Best for</strong>:</p><ul><li>Kubernetes-dedicated infrastructure (no general-purpose workloads)</li><li>Security-focused environments (minimal attack surface)</li><li>GitOps workflows (declarative configuration)</li><li>Immutable infrastructure advocates</li><li>Teams comfortable with API-driven management</li><li>Production Kubernetes clusters (once team is trained)</li></ul><p><strong>Best Installation Method</strong>:</p><ul><li><strong>Only option</strong>: Built-in Kubernetes via talosctl</li></ul><p><strong>Avoid if</strong>:</p><ul><li>Need general-purpose server functionality (SSH, cron jobs, etc.)</li><li>Team unfamiliar with Kubernetes (too steep a learning curve)</li><li>Require shell access for troubleshooting comfort</li><li>Want traditional package management (apt, dnf)</li><li>Prefer familiar Linux administration tools</li></ul><h2 id=comparison-with-ubuntu-and-fedora>Comparison with Ubuntu and Fedora</h2><table><thead><tr><th>Aspect</th><th>Talos Linux</th><th>Ubuntu + k3s</th><th>Fedora + kubeadm</th></tr></thead><tbody><tr><td><strong>K8s Installation</strong></td><td>Built-in</td><td>Single command</td><td>Manual (kubeadm)</td></tr><tr><td><strong>Attack Surface</strong></td><td>Minimal (~30 processes)</td><td>Medium (~100)</td><td>Medium (~100)</td></tr><tr><td><strong>Resource Overhead</strong></td><td>768MB RAM</td><td>1GB RAM</td><td>2.2GB RAM</td></tr><tr><td><strong>Disk Footprint</strong></td><td>500MB</td><td>10GB</td><td>15GB</td></tr><tr><td><strong>Security Model</strong></td><td>Immutable, no shell</td><td>AppArmor, shell</td><td>SELinux, shell</td></tr><tr><td><strong>Management</strong></td><td>API-only (talosctl)</td><td>SSH + kubectl</td><td>SSH + kubectl</td></tr><tr><td><strong>Learning Curve</strong></td><td>Steep</td><td>Easy</td><td>Moderate</td></tr><tr><td><strong>Community Size</strong></td><td>Small (growing)</td><td>Very Large</td><td>Large</td></tr><tr><td><strong>Support Period</strong></td><td>Rolling releases</td><td>5-10 years</td><td>13 months</td></tr><tr><td><strong>Use Case</strong></td><td>Kubernetes only</td><td>General-purpose</td><td>General-purpose</td></tr><tr><td><strong>Upgrades</strong></td><td>Declarative, simple</td><td>Manual OS + K8s</td><td>Manual OS + K8s</td></tr><tr><td><strong>Configuration</strong></td><td>Declarative YAML</td><td>Imperative + YAML</td><td>Imperative + YAML</td></tr><tr><td><strong>Troubleshooting</strong></td><td>API logs/metrics</td><td>SSH + logs</td><td>SSH + logs</td></tr><tr><td><strong>GitOps-Friendly</strong></td><td>Excellent</td><td>Good</td><td>Good</td></tr><tr><td><strong>Best for</strong></td><td>K8s-dedicated infra</td><td>Homelabs, learning</td><td>RHEL ecosystem</td></tr></tbody></table><p><strong>Verdict</strong>: Talos is the most secure and efficient option for Kubernetes-only infrastructure, but requires team buy-in to API-driven, immutable paradigm. Ubuntu/Fedora better for general-purpose servers or teams wanting shell access.</p><h2 id=advanced-features>Advanced Features</h2><h3 id=talos-system-extensions>Talos System Extensions</h3><p>Extend Talos functionality with extensions:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>extensions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ghcr.io/siderolabs/intel-ucode:20240312</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ghcr.io/siderolabs/iscsi-tools:v0.1.4</span><span class=w>
</span></span></span></code></pre></div><h3 id=cluster-api-integration>Cluster API Integration</h3><p>Talos works natively with Cluster API:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install Cluster API + Talos provider</span>
</span></span><span class=line><span class=cl>clusterctl init --infrastructure talos
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create cluster from template</span>
</span></span><span class=line><span class=cl>clusterctl generate cluster homelab --infrastructure talos &gt; cluster.yaml
</span></span><span class=line><span class=cl>kubectl apply -f cluster.yaml
</span></span></code></pre></div><h3 id=image-factory>Image Factory</h3><p>Custom Talos images with extensions:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Build custom image</span>
</span></span><span class=line><span class=cl>curl -X POST https://factory.talos.dev/image <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d <span class=s1>&#39;{&#34;talos_version&#34;:&#34;v1.9.0&#34;,&#34;extensions&#34;:[&#34;siderolabs/intel-ucode&#34;]}&#39;</span>
</span></span></code></pre></div><h3 id=disaster-recovery>Disaster Recovery</h3><p>Talos supports etcd backup/restore:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Backup etcd</span>
</span></span><span class=line><span class=cl>talosctl etcd snapshot --nodes 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Restore from snapshot</span>
</span></span><span class=line><span class=cl>talosctl bootstrap --recover-from ./etcd-snapshot.db
</span></span></code></pre></div><h2 id=production-readiness>Production Readiness</h2><p><strong>Production Use</strong>: ✅ Yes (many companies run Talos in production)</p><p><strong>High Availability</strong>:</p><ul><li>3+ control plane nodes recommended</li><li>External etcd supported</li><li>Load balancer for API server</li></ul><p><strong>Monitoring</strong>:</p><ul><li>Prometheus metrics built-in</li><li>Talos dashboard for health</li><li>Standard Kubernetes observability tools</li></ul><p><strong>Example Production Clusters</strong>:</p><ul><li>Sidero Metal (bare metal provisioning)</li><li>Various cloud providers (AWS, GCP, Azure)</li><li>Edge deployments (minimal footprint)</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f633ef5d64f4d7ef2640d8077b7ca2a8>4 - Harvester Analysis</h1><div class=lead>Analysis of Harvester HCI for Kubernetes homelab infrastructure</div><h2 id=overview>Overview</h2><p>Harvester is a Hyperconverged Infrastructure (HCI) platform built on Kubernetes, designed to provide VM and container management on a unified platform. It combines compute, storage, and networking with built-in K3s for orchestration.</p><p><strong>Key Facts</strong>:</p><ul><li><strong>Latest Version</strong>: Harvester 1.4 (based on K3s 1.30+)</li><li><strong>Foundation</strong>: Built on RancherOS 2.0, K3s, and KubeVirt</li><li><strong>Support</strong>: Supported by SUSE (acquired Rancher)</li><li><strong>Architecture</strong>: HCI platform with VM + container workloads</li><li><strong>Management</strong>: Web UI + kubectl + Rancher integration</li></ul><h2 id=kubernetes-installation-methods>Kubernetes Installation Methods</h2><p>Harvester <strong>includes K3s as its foundation</strong> - Kubernetes is built-in.</p><h3 id=built-in-k3s-only-option>Built-in K3s (Only Option)</h3><p><strong>Installation Process</strong>:</p><ol><li><strong>Boot Harvester ISO</strong> (interactive installer or PXE)</li><li><strong>Complete installation wizard</strong> (web UI or console)</li><li><strong>Create cluster</strong> (automatic K3s deployment)</li><li><strong>Access via web UI</strong> or kubectl</li></ol><p><strong>Interactive Installation</strong>:</p><pre tabindex=0><code># Boot from Harvester ISO
1. Choose &#34;Create a new Harvester cluster&#34;
2. Configure:
   - Cluster token
   - Node role (management/worker/witness)
   - Network interface (management network)
   - VIP (Virtual IP for cluster access)
   - Storage disk (Longhorn persistent storage)
3. Install completes (15-20 minutes)
4. Access web UI at https://&lt;VIP&gt;
</code></pre><p><strong>Configuration</strong> (cloud-init for automated install):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># config.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>token</span><span class=p>:</span><span class=w> </span><span class=l>my-cluster-token</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>os</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>harvester-node-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>modules</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>kvm</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kernel_parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>intel_iommu=on</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=l>create</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>device</span><span class=p>:</span><span class=w> </span><span class=l>/dev/sda</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>iso_url</span><span class=p>:</span><span class=w> </span><span class=l>https://releases.rancher.com/harvester/v1.4.0/harvester-v1.4.0-amd64.iso</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>vip</span><span class=p>:</span><span class=w> </span><span class=m>192.168.1.100</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>vip_mode</span><span class=p>:</span><span class=w> </span><span class=l>static</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>harvester-mgmt</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>interfaces</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>eth0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>default_route</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>ip</span><span class=p>:</span><span class=w> </span><span class=m>192.168.1.10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>subnet_mask</span><span class=p>:</span><span class=w> </span><span class=m>255.255.255.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>gateway</span><span class=p>:</span><span class=w> </span><span class=m>192.168.1.1</span><span class=w>
</span></span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Complete HCI solution (VMs + containers)</li><li>Web UI for management (no CLI required)</li><li>Built-in storage (Longhorn CSI)</li><li>Built-in networking (multus, SR-IOV)</li><li>VM live migration</li><li>Rancher integration for multi-cluster management</li><li>K3s built-in (no separate Kubernetes install)</li></ul><p><strong>Cons</strong>:</p><ul><li>Heavy resource requirements (8GB+ RAM per node)</li><li>Complex architecture (steep learning curve)</li><li>Larger attack surface than minimal OS</li><li>Overkill for container-only workloads</li><li>Requires 3+ nodes for production HA</li></ul><h2 id=cluster-initialization-sequence>Cluster Initialization Sequence</h2><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Bare Metal Server
    participant Harvester as Harvester HCI
    participant K3s as K3s / KubeVirt
    participant Storage as Longhorn Storage
    
    Admin-&gt;&gt;Server: Boot Harvester ISO
    Server-&gt;&gt;Harvester: Start installation wizard
    Harvester--&gt;&gt;Admin: Interactive console/web UI
    Admin-&gt;&gt;Harvester: Configure cluster (token, VIP, storage)
    Harvester-&gt;&gt;Server: Partition disks (OS &#43; Longhorn storage)
    Harvester-&gt;&gt;Server: Install RancherOS 2.0 base
    Harvester-&gt;&gt;Server: Install K3s components
    Server-&gt;&gt;Server: Reboot
    Harvester-&gt;&gt;K3s: Start K3s server
    K3s-&gt;&gt;Server: Initialize control plane
    K3s-&gt;&gt;Server: Deploy Harvester operators
    K3s-&gt;&gt;Storage: Deploy Longhorn for persistent storage
    K3s-&gt;&gt;Server: Deploy KubeVirt for VM management
    K3s-&gt;&gt;Server: Deploy multus CNI (multi-network)
    Harvester--&gt;&gt;Admin: Web UI ready at https://&lt;VIP&gt;
    Admin-&gt;&gt;Harvester: Add additional nodes (join cluster)
    Harvester-&gt;&gt;K3s: Join nodes to cluster
    K3s-&gt;&gt;Storage: Replicate storage across nodes
    Harvester--&gt;&gt;Admin: Cluster ready (20-30 minutes)
    Admin-&gt;&gt;Harvester: Create VMs or deploy containers</pre><h2 id=maintenance-requirements>Maintenance Requirements</h2><h3 id=os-updates>OS Updates</h3><p><strong>Harvester Upgrades</strong> (includes OS + K3s):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Via Web UI:</span>
</span></span><span class=line><span class=cl><span class=c1># Settings → Upgrade → Select version → Start upgrade</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Via kubectl (after downloading upgrade image):</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://releases.rancher.com/harvester/v1.4.0/version.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Monitor upgrade progress</span>
</span></span><span class=line><span class=cl>kubectl get upgrades -n harvester-system
</span></span></code></pre></div><p><strong>Frequency</strong>:</p><ul><li>Harvester releases: Every 2-3 months (minor versions)</li><li>Security patches: Included in Harvester releases</li><li>K3s upgrades: Bundled with Harvester upgrades</li><li><strong>No separate OS patching</strong> (managed by Harvester)</li></ul><h3 id=kubernetes-upgrades>Kubernetes Upgrades</h3><p><strong>K3s is upgraded with Harvester</strong> - no separate upgrade process.</p><p><strong>Version Compatibility</strong>:</p><ul><li>Harvester 1.4.x → K3s 1.30+</li><li>Harvester 1.3.x → K3s 1.28+</li><li>Harvester 1.2.x → K3s 1.26+</li></ul><p><strong>Upgrade Process</strong>:</p><ol><li>Web UI or kubectl to trigger upgrade</li><li>Rolling upgrade of nodes (one at a time)</li><li>VM live migration during node upgrades</li><li>Automatic rollback on failure</li></ol><h2 id=resource-overhead>Resource Overhead</h2><p><strong>Single Node</strong> (Harvester HCI):</p><ul><li><strong>RAM</strong>: 8GB minimum (16GB recommended for VMs)</li><li><strong>CPU</strong>: 4 cores minimum (8 cores recommended)</li><li><strong>Disk</strong>: 250GB minimum (SSD recommended)<ul><li>100GB for OS/Harvester components</li><li>150GB+ for Longhorn storage (VM disks)</li></ul></li><li><strong>Network</strong>: 1 Gbps minimum (10 Gbps for production)</li></ul><p><strong>Three-Node Cluster</strong> (Production HA):</p><ul><li><strong>RAM</strong>: 32GB per node (64GB for VM-heavy workloads)</li><li><strong>CPU</strong>: 8 cores per node minimum</li><li><strong>Disk</strong>: 500GB+ per node (NVMe SSD recommended)</li><li><strong>Network</strong>: 10 Gbps recommended (separate storage network ideal)</li></ul><p><strong>Comparison</strong>:</p><ul><li>Ubuntu + k3s: 1GB RAM</li><li>Talos: 768MB RAM</li><li><strong>Harvester: 8GB+ RAM</strong> (much heavier)</li></ul><p><strong>Note</strong>: Harvester is designed for <strong>multi-node HCI</strong>, not single-node homelabs.</p><h2 id=security-posture>Security Posture</h2><p><strong>Strengths</strong>:</p><ul><li>SELinux-based (RancherOS 2.0 foundation)</li><li>Immutable OS layer (similar to Talos)</li><li>RBAC built-in (Kubernetes + Rancher)</li><li>Network segmentation (multus CNI)</li><li>VM isolation (KubeVirt)</li><li>Signed images and secure boot support</li></ul><p><strong>Attack Surface</strong>:</p><ul><li><strong>Larger than Talos/k3s</strong>: Includes web UI, VM management, storage layer</li><li>KubeVirt adds additional components</li><li>Web UI is additional attack vector</li><li>More processes than minimal OS (~50+ services)</li></ul><p><strong>Security Features</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># VM network isolation example</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>network.harvesterhci.io/v1beta1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>VlanConfig</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>production-vlan</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>vlanID</span><span class=p>:</span><span class=w> </span><span class=m>100</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>uplink</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>linkAttributes</span><span class=p>:</span><span class=w> </span><span class=m>1500</span><span class=w>
</span></span></span></code></pre></div><p><strong>Hardening</strong>:</p><ul><li>Firewall rules (web UI or kubectl)</li><li>RBAC policies (restrict VM/namespace access)</li><li>Network policies (isolate workloads)</li><li>Rancher authentication integration (LDAP, SAML)</li></ul><h2 id=learning-curve>Learning Curve</h2><p><strong>Ease of Adoption</strong>: ⭐⭐⭐ (Moderate)</p><ul><li><strong>Web UI simplifies management</strong> (no CLI required for basic tasks)</li><li>Requires understanding of VMs + containers</li><li>Kubernetes knowledge helpful but not required initially</li><li>Longhorn storage concepts (replicas, snapshots)</li><li>KubeVirt for VM management (learning curve)</li></ul><p><strong>Required Knowledge</strong>:</p><ul><li>Basic Kubernetes concepts (pods, services)</li><li>VM management (KubeVirt/libvirt)</li><li>Storage concepts (Longhorn, CSI)</li><li>Networking (VLANs, SR-IOV optional)</li><li>Web UI navigation</li></ul><p><strong>Debugging</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Access via kubectl (kubeconfig from web UI)</span>
</span></span><span class=line><span class=cl>kubectl get nodes -n harvester-system
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># View Harvester logs</span>
</span></span><span class=line><span class=cl>kubectl logs -n harvester-system &lt;pod-name&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># VM console access (via web UI or virtctl)</span>
</span></span><span class=line><span class=cl>virtctl console &lt;vm-name&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Storage debugging</span>
</span></span><span class=line><span class=cl>kubectl get volumes -A
</span></span></code></pre></div><h2 id=community-support>Community Support</h2><p><strong>Ecosystem Maturity</strong>: ⭐⭐⭐⭐ (Good)</p><ul><li><strong>Documentation</strong>: Excellent official docs</li><li><strong>Community</strong>: Active Slack, GitHub Discussions, forums</li><li><strong>Commercial Support</strong>: Available from SUSE/Rancher</li><li><strong>Third-Party Tools</strong>: Rancher ecosystem integration</li><li><strong>Tutorials</strong>: Growing number of guides and videos</li></ul><p><strong>Resources</strong>:</p><ul><li><a href=https://docs.harvesterhci.io/>Harvester Documentation</a></li><li><a href=https://github.com/harvester/harvester>Harvester GitHub</a></li><li><a href=https://slack.rancher.io/>Rancher Community Slack</a></li><li><a href=https://www.suse.com/support/>SUSE Support</a></li></ul><h2 id=pros-and-cons-summary>Pros and Cons Summary</h2><h3 id=pros>Pros</h3><ul><li>Good, because unified platform for VMs + containers (no separate hypervisor)</li><li>Good, because built-in K3s (Kubernetes included)</li><li>Good, because web UI simplifies management (no CLI required)</li><li>Good, because built-in persistent storage (Longhorn CSI)</li><li>Good, because VM live migration (no downtime during maintenance)</li><li>Good, because multi-network support (multus CNI, SR-IOV)</li><li>Good, because Rancher integration (multi-cluster management)</li><li>Good, because automatic upgrades (OS + K3s + components)</li><li>Good, because commercial support available (SUSE)</li><li>Good, because designed for bare-metal HCI (no cloud dependencies)</li><li>Neutral, because immutable OS layer (similar to Talos benefits)</li></ul><h3 id=cons>Cons</h3><ul><li>Bad, because very heavy resource requirements (8GB+ RAM minimum)</li><li>Bad, because complex architecture (KubeVirt, Longhorn, multus, etc.)</li><li>Bad, because overkill for container-only workloads (use k3s/Talos instead)</li><li>Bad, because larger attack surface than minimal OS (web UI, VM layer)</li><li>Bad, because requires 3+ nodes for production HA (not single-node friendly)</li><li>Bad, because steep learning curve for full feature set (VMs + storage + networking)</li><li>Bad, because relatively new platform (less mature than Ubuntu/Fedora)</li><li>Bad, because limited to Rancher ecosystem (vendor lock-in)</li><li>Bad, because slower to adopt latest Kubernetes versions (depends on K3s bundle)</li><li>Neutral, because opinionated HCI design (pro for VM use cases, con for simplicity)</li></ul><h2 id=recommendations>Recommendations</h2><p><strong>Best for</strong>:</p><ul><li><strong>Hybrid workloads</strong> (VMs + containers on same platform)</li><li>Homelab users wanting to consolidate VM hypervisor + Kubernetes</li><li>Teams familiar with Rancher ecosystem</li><li>Multi-node clusters (3+ nodes)</li><li>Environments requiring VM live migration</li><li>Users wanting web UI for infrastructure management</li><li>Replacing VMware/Proxmox + Kubernetes with unified platform</li></ul><p><strong>Best Installation Method</strong>:</p><ul><li><strong>Only option</strong>: Interactive ISO install or PXE with cloud-init</li></ul><p><strong>Avoid if</strong>:</p><ul><li>Running container-only workloads (use k3s or Talos instead)</li><li>Limited resources (&lt; 8GB RAM per node)</li><li>Single-node homelab (Harvester designed for multi-node)</li><li>Want minimal attack surface (use Talos)</li><li>Prefer traditional Linux shell access (use Ubuntu/Fedora)</li><li>Need latest Kubernetes versions immediately (Harvester lags upstream)</li></ul><h2 id=comparison-with-other-options>Comparison with Other Options</h2><table><thead><tr><th>Aspect</th><th>Harvester</th><th>Talos Linux</th><th>Ubuntu + k3s</th><th>Fedora + kubeadm</th></tr></thead><tbody><tr><td><strong>Primary Use Case</strong></td><td>VMs + Containers</td><td>Containers only</td><td>General-purpose</td><td>General-purpose</td></tr><tr><td><strong>Resource Overhead</strong></td><td>8GB+ RAM</td><td>768MB RAM</td><td>1GB RAM</td><td>2.2GB RAM</td></tr><tr><td><strong>Kubernetes</strong></td><td>Built-in K3s</td><td>Built-in</td><td>Install k3s</td><td>Install kubeadm</td></tr><tr><td><strong>Management</strong></td><td>Web UI + kubectl</td><td>API-only (talosctl)</td><td>SSH + kubectl</td><td>SSH + kubectl</td></tr><tr><td><strong>Storage</strong></td><td>Built-in Longhorn</td><td>External CSI</td><td>External CSI</td><td>External CSI</td></tr><tr><td><strong>VM Support</strong></td><td>Native (KubeVirt)</td><td>No</td><td>Via KubeVirt</td><td>Via KubeVirt</td></tr><tr><td><strong>Learning Curve</strong></td><td>Moderate</td><td>Steep</td><td>Easy</td><td>Moderate</td></tr><tr><td><strong>Attack Surface</strong></td><td>Large</td><td>Minimal</td><td>Medium</td><td>Medium</td></tr><tr><td><strong>Multi-Node</strong></td><td>Designed for</td><td>Supports</td><td>Supports</td><td>Supports</td></tr><tr><td><strong>Single-Node</strong></td><td>Not ideal</td><td>Excellent</td><td>Excellent</td><td>Good</td></tr><tr><td><strong>Best for</strong></td><td>VM + K8s hybrid</td><td>K8s-only</td><td>Homelab/learning</td><td>RHEL ecosystem</td></tr></tbody></table><p><strong>Verdict</strong>: Harvester is excellent for <strong>VM + container hybrid workloads</strong> with 3+ nodes, but overkill for container-only infrastructure. Use Talos or k3s for Kubernetes-only clusters, Ubuntu/Fedora for general-purpose servers.</p><h2 id=advanced-features>Advanced Features</h2><h3 id=vm-management-kubevirt>VM Management (KubeVirt)</h3><p>Create VMs via YAML:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>kubevirt.io/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>VirtualMachine</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-vm</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>running</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>domain</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>devices</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>disks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>root</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>disk</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>bus</span><span class=p>:</span><span class=w> </span><span class=l>virtio</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>4Gi</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>root</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>containerDisk</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>docker.io/harvester/ubuntu:22.04</span><span class=w>
</span></span></span></code></pre></div><h3 id=live-migration>Live Migration</h3><p>Move VMs between nodes:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Via web UI: VM → Actions → Migrate</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Via kubectl</span>
</span></span><span class=line><span class=cl>kubectl patch vm ubuntu-vm --type merge -p <span class=s1>&#39;{&#34;spec&#34;:{&#34;running&#34;:false}}&#39;</span>
</span></span><span class=line><span class=cl>kubectl patch vm ubuntu-vm --type merge -p <span class=s1>&#39;{&#34;spec&#34;:{&#34;running&#34;:true}}&#39;</span>
</span></span></code></pre></div><h3 id=backup-and-restore>Backup and Restore</h3><p>Harvester supports VM backups:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Configure S3 backup target (web UI)</span>
</span></span><span class=line><span class=cl><span class=c1># Create VM snapshot</span>
</span></span><span class=line><span class=cl><span class=c1># Restore from snapshot or backup</span>
</span></span></code></pre></div><h3 id=rancher-integration>Rancher Integration</h3><p>Manage multiple clusters:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Import Harvester cluster into Rancher</span>
</span></span><span class=line><span class=cl><span class=c1># Deploy workloads across clusters</span>
</span></span><span class=line><span class=cl><span class=c1># Central authentication and RBAC</span>
</span></span></code></pre></div><h2 id=use-case-examples>Use Case Examples</h2><h3 id=use-case-1-replace-vmware--kubernetes>Use Case 1: Replace VMware + Kubernetes</h3><p><strong>Scenario</strong>: Currently running VMware ESXi for VMs + separate Kubernetes cluster</p><p><strong>Harvester Solution</strong>:</p><ul><li>Consolidate to 3-node Harvester cluster</li><li>Migrate VMs to KubeVirt</li><li>Deploy containers on same cluster</li><li>Save VMware licensing costs</li></ul><p><strong>Benefits</strong>:</p><ul><li>Single platform for VMs + containers</li><li>Unified management (web UI + kubectl)</li><li>Built-in HA and live migration</li></ul><h3 id=use-case-2-homelab-with-mixed-workloads>Use Case 2: Homelab with Mixed Workloads</h3><p><strong>Scenario</strong>: Need Windows VMs + Linux containers + storage server</p><p><strong>Harvester Solution</strong>:</p><ul><li>Windows VMs via KubeVirt (GPU passthrough supported)</li><li>Linux containers via K3s workloads</li><li>Longhorn for persistent storage (NFS export supported)</li></ul><p><strong>Benefits</strong>:</p><ul><li>No need for separate Proxmox/ESXi</li><li>Kubernetes-native management</li><li>Learn enterprise HCI platform</li></ul><h3 id=use-case-3-edge-computing>Use Case 3: Edge Computing</h3><p><strong>Scenario</strong>: Deploy compute at remote sites (3-5 nodes each)</p><p><strong>Harvester Solution</strong>:</p><ul><li>Harvester cluster at each edge location</li><li>Rancher for central management</li><li>VM + container workloads</li></ul><p><strong>Benefits</strong>:</p><ul><li>Autonomous operation (no cloud dependency)</li><li>Rancher multi-cluster management</li><li>Built-in storage and networking</li></ul><h2 id=production-readiness>Production Readiness</h2><p><strong>Production Use</strong>: ✅ Yes (used in enterprise environments)</p><p><strong>High Availability</strong>:</p><ul><li><strong>3+ nodes required</strong> for HA</li><li>Witness node for even-node clusters</li><li>VM live migration during maintenance</li><li>Longhorn 3-replica storage</li></ul><p><strong>Monitoring</strong>:</p><ul><li>Built-in Prometheus + Grafana</li><li>Rancher monitoring integration</li><li>Alerting and notifications</li></ul><p><strong>Disaster Recovery</strong>:</p><ul><li>VM backups to S3</li><li>Cluster backups (etcd + config)</li><li>Restore to new cluster</li></ul><p><strong>Enterprise Features</strong>:</p><ul><li>Rancher authentication (LDAP, SAML, OAuth)</li><li>Multi-tenancy (namespaces, RBAC)</li><li>Audit logging</li><li>Network policies</li></ul></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/Zaba505/infra aria-label=GitHub><i class="fab fa-github"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2024&ndash;2025
<span class=td-footer__authors>Zaba505 | <a href=https://creativecommons.org/licenses/by/4.0>CC BY 4.0</a> |</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span></div></div></div></footer></div><script src=/infra/pr-preview/pr-626/js/main.min.eb40505784d893e4b5c8dbd67b59c353e735d847f4ffbfe9d6921dec08dbacba.js integrity="sha256-60BQV4TYk+S1yNvWe1nDU+c12Ef0/7/p1pId7AjbrLo=" crossorigin=anonymous></script><script defer src=/infra/pr-preview/pr-626/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/infra/pr-preview/pr-626/js/tabpane-persist.js></script></body></html>