<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=https://zaba505.github.io/infra/pr-preview/pr-626/rd/><link rel=alternate type=application/rss+xml href=https://zaba505.github.io/infra/pr-preview/pr-626/rd/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/infra/pr-preview/pr-626/favicons/favicon.ico><link rel=apple-touch-icon href=/infra/pr-preview/pr-626/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/infra/pr-preview/pr-626/favicons/android-192x192.png sizes=192x192><title>Research and Development | Zaba505's Home Lab</title><meta name=description content><meta property="og:url" content="https://zaba505.github.io/infra/pr-preview/pr-626/rd/"><meta property="og:site_name" content="Zaba505's Home Lab"><meta property="og:title" content="Research and Development"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><meta itemprop=name content="Research and Development"><meta itemprop=dateModified content="2025-11-24T01:42:30+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Research and Development"><link rel=preload href=/infra/pr-preview/pr-626/scss/main.min.74eef40c5172b0e2f11bd9c3ea40dba66c2dc642ac5294c208f5dc9ff772c0e9.css as=style integrity="sha256-dO70DFFysOLxG9nD6kDbpmwtxkKsUpTCCPXcn/dywOk=" crossorigin=anonymous><link href=/infra/pr-preview/pr-626/scss/main.min.74eef40c5172b0e2f11bd9c3ea40dba66c2dc642ac5294c208f5dc9ff772c0e9.css rel=stylesheet integrity="sha256-dO70DFFysOLxG9nD6kDbpmwtxkKsUpTCCPXcn/dywOk=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-section><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/infra/pr-preview/pr-626/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>Zaba505's Home Lab</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class="td-light-dark-menu nav-item dropdown"><svg class="d-none"><symbol id="check2" viewBox="0 0 16 16"><path d="M13.854 3.646a.5.5.0 010 .708l-7 7a.5.5.0 01-.708.0l-3.5-3.5a.5.5.0 11.708-.708L6.5 10.293l6.646-6.647a.5.5.0 01.708.0z"/></symbol><symbol id="circle-half" viewBox="0 0 16 16"><path d="M8 15A7 7 0 108 1v14zm0 1A8 8 0 118 0a8 8 0 010 16z"/></symbol><symbol id="moon-stars-fill" viewBox="0 0 16 16"><path d="M6 .278a.768.768.0 01.08.858 7.208 7.208.0 00-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527.0 1.04-.055 1.533-.16a.787.787.0 01.81.316.733.733.0 01-.031.893A8.349 8.349.0 018.344 16C3.734 16 0 12.286.0 7.71.0 4.266 2.114 1.312 5.124.06A.752.752.0 016 .278z"/><path d="M10.794 3.148a.217.217.0 01.412.0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217.0 010 .412l-1.162.387A1.734 1.734.0 0011.593 7.69l-.387 1.162a.217.217.0 01-.412.0l-.387-1.162A1.734 1.734.0 009.31 6.593l-1.162-.387a.217.217.0 010-.412l1.162-.387a1.734 1.734.0 001.097-1.097l.387-1.162zM13.863.099a.145.145.0 01.274.0l.258.774c.115.346.386.617.732.732l.774.258a.145.145.0 010 .274l-.774.258a1.156 1.156.0 00-.732.732l-.258.774a.145.145.0 01-.274.0l-.258-.774a1.156 1.156.0 00-.732-.732l-.774-.258a.145.145.0 010-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"/></symbol><symbol id="sun-fill" viewBox="0 0 16 16"><path d="M8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 0zm0 13a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 13zm8-5a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2a.5.5.0 01.5.5zM3 8a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2A.5.5.0 013 8zm10.657-5.657a.5.5.0 010 .707l-1.414 1.415a.5.5.0 11-.707-.708l1.414-1.414a.5.5.0 01.707.0zm-9.193 9.193a.5.5.0 010 .707L3.05 13.657a.5.5.0 01-.707-.707l1.414-1.414a.5.5.0 01.707.0zm9.193 2.121a.5.5.0 01-.707.0l-1.414-1.414a.5.5.0 01.707-.707l1.414 1.414a.5.5.0 010 .707zM4.464 4.465a.5.5.0 01-.707.0L2.343 3.05a.5.5.0 11.707-.707l1.414 1.414a.5.5.0 010 .708z"/></symbol></svg>
<button class="btn btn-link nav-link dropdown-toggle d-flex align-items-center" id=bd-theme type=button aria-expanded=false data-bs-toggle=dropdown data-bs-display=static aria-label="Toggle theme (auto)">
<svg class="bi my-1 theme-icon-active"><use href="#circle-half"/></svg></button><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=bd-theme-text><li><button type=button class="dropdown-item d-flex align-items-center" data-bs-theme-value=light aria-pressed=false>
<svg class="bi me-2 opacity-50"><use href="#sun-fill"/></svg>
Light
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li><li><button type=button class="dropdown-item d-flex align-items-center" data-bs-theme-value=dark aria-pressed=false>
<svg class="bi me-2 opacity-50"><use href="#moon-stars-fill"/></svg>
Dark
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li><li><button type=button class="dropdown-item d-flex align-items-center active" data-bs-theme-value=auto aria-pressed=true>
<svg class="bi me-2 opacity-50"><use href="#circle-half"/></svg>
Auto
<svg class="bi ms-auto d-none"><use href="#check2"/></svg></button></li></ul></li></ul></div><div class="d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this siteâ€¦" aria-label="Search this siteâ€¦" autocomplete=off data-offline-search-index-json-src=/infra/pr-preview/pr-626/offline-search-index.4a501c5052031474ed5a6f810074e84a.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/infra/pr-preview/pr-626/rd/>Return to the regular view of this page</a>.</p></div><h1 class=title>Research and Development</h1><ul><li>1: <a href=#pg-6768158cb3ee96c1f23fec6f77328e52>Technology Analysis</a></li><ul><li>1.1: <a href=#pg-8892c999ccbda3c9dcd2b4753afdab62>Resource Identifiers Analysis</a></li><ul><li>1.1.1: <a href=#pg-95c685912a6c8633373e2ea37cbf5347>Universally Unique Identifier (UUID) Analysis</a></li><li>1.1.2: <a href=#pg-7cb3eb798477cf3e1c5bdea6c59611a5>Universally Unique Lexicographically Sortable Identifier (ULID) Analysis</a></li><li>1.1.3: <a href=#pg-c0553e3c5388fa96911545ec8861a4bf>Snowflake ID Analysis</a></li></ul><li>1.2: <a href=#pg-d96c900d85acfbbf726f419f7a9837ce>Server Operating System Analysis</a></li><ul><li>1.2.1: <a href=#pg-2b6064c84b17aa5904b4749ff38d16b2>Ubuntu Analysis</a></li><li>1.2.2: <a href=#pg-f8c94234b2c711850baec9a4a41ca4f8>Fedora Analysis</a></li><li>1.2.3: <a href=#pg-7e5e084a8e0ecdcf60e6401763ef0a82>Talos Linux Analysis</a></li><li>1.2.4: <a href=#pg-f633ef5d64f4d7ef2640d8077b7ca2a8>Harvester Analysis</a></li></ul><li>1.3: <a href=#pg-67bf1a793f6a1c844dbc6e04272ebdb5>Amazon Web Services Analysis</a></li><ul><li>1.3.1: <a href=#pg-284e5fccd8c32dbd4ae3bfdb2a6d41ff>AWS Network Boot Protocol Support</a></li><li>1.3.2: <a href=#pg-7800b35f37709f63e0f12019a82ee550>AWS WireGuard VPN Support</a></li></ul><li>1.4: <a href=#pg-5fc1fe2c927f9c765cb98268d4cb8c5e>Google Cloud Platform Analysis</a></li><ul><li>1.4.1: <a href=#pg-8349b2324a2beea2d0650a6b39802b81>Cloud Storage FUSE (gcsfuse)</a></li><li>1.4.2: <a href=#pg-40e0d560582430a6e545597f7b73eb02>GCP Network Boot Protocol Support</a></li><li>1.4.3: <a href=#pg-35563ff6a8a7c7f31535b56d4156bd8b>GCP WireGuard VPN Support</a></li></ul><li>1.5: <a href=#pg-a435c4bc001f7e96c63864b68229ddbc>HP ProLiant DL360 Gen9 Analysis</a></li><ul><li>1.5.1: <a href=#pg-710c910de90953be84ae3a14c4b93a47>Configuration Guide</a></li><li>1.5.2: <a href=#pg-5edcb2c8881ecaa41f34154035642bcf>Hardware Specifications</a></li><li>1.5.3: <a href=#pg-602c9477ffd24c9d6b744176ac0355ba>Network Boot Capabilities</a></li></ul><li>1.6: <a href=#pg-cfa22b3ce5fc949a63e23e3219b26f83>Matchbox Analysis</a></li><ul><li>1.6.1: <a href=#pg-a23269e9072cc20bff941edf0359244d>Configuration Model</a></li><li>1.6.2: <a href=#pg-8e3a89622c44227eb5a7e5a4a31bef5c>Deployment Patterns</a></li><li>1.6.3: <a href=#pg-62ea704f9d07efc4c09282944f58f495>Network Boot Support</a></li><li>1.6.4: <a href=#pg-177196d5d574619d0c7d1eb930af7a44>Use Case Evaluation</a></li></ul><li>1.7: <a href=#pg-060cca738381ff58ec9069c277a6de51>Ubiquiti Dream Machine Pro Analysis</a></li><ul><li>1.7.1: <a href=#pg-a5703edd46d747411f78cc846c637cab>UDM Pro VLAN Configuration & Capabilities</a></li></ul></ul><li>2: <a href=#pg-83f5166c05747376993ebd67b3a6de36>Architecture Decision Records</a></li><ul><li>2.1: <a href=#pg-be14bb13e79709979af80fa8e61452c5>[0001] Use MADR for Architecture Decision Records</a></li><li>2.2: <a href=#pg-79e3b41ba15ba3a179ad4b5df5f3f2fe>[0002] Network Boot Architecture for Home Lab</a></li><li>2.3: <a href=#pg-853f5ec590d44937c1ebd528cd046965>[0003] Cloud Provider Selection for Network Boot Infrastructure</a></li><li>2.4: <a href=#pg-dab026fd06f98a03a459f97073d21662>[0004] Server Operating System Selection</a></li><li>2.5: <a href=#pg-be9e21cdab9183bad0c60fa6e3ba225b>[0005] Network Boot Infrastructure Implementation on Google Cloud</a></li><li>2.6: <a href=#pg-d234efec001fb7b9899c0a45bea1ae5d>[0006] Universal Resource Identifier Standard</a></li><li>2.7: <a href=#pg-2c1965560a830318e2bbed312ba620ee>[0007] Standard API Error Response Format</a></li></ul><li>3: <a href=#pg-8c73fa9172ced19b5feab910bc9e7f1e>Services</a></li><ul><li>3.1: <a href=#pg-4ce2427a9523f0ff078049ecbd3abed9>Boot Service</a></li><ul><li>3.1.1: <a href=#pg-45291fef6ecf8bf28903c56a01df0197>GET /boot.ipxe</a></li><li>3.1.2: <a href=#pg-49010b536d53c75102b246a30e774cb6>GET /asset/{boot_profile_id}/kernel</a></li><li>3.1.3: <a href=#pg-5874d39e2aede664368cbb3c16dfb190>GET /asset/{boot_profile_id}/initrd</a></li><li>3.1.4: <a href=#pg-a68897d6c4ed5365b996f10a697552e4>POST /api/v1/profiles</a></li><li>3.1.5: <a href=#pg-c820ed2058fb4588fc0c6b0b04c9d922>GET /api/v1/boot/{machine_id}/profile</a></li><li>3.1.6: <a href=#pg-24acd1badff3bbd194cd6cb31d3500cd>PUT /api/v1/boot/{machine_id}/profile</a></li><li>3.1.7: <a href=#pg-7cfea44dc34c48588b9295791a22e7b8>DELETE /api/v1/boot/{machine_id}/profile</a></li><li>3.1.8: <a href=#pg-4f0fd89b3946db2c7d5ec65a6880347c>GET /health/startup</a></li><li>3.1.9: <a href=#pg-c0c1465faa50c9fac75d82a69edfcd31>GET /health/liveness</a></li></ul><li>3.2: <a href=#pg-0fbab3644f8f6a3202867e1dbfd01125>Machine Service</a></li><ul><li>3.2.1: <a href=#pg-8161b025f023eea715281eff4619dd04>POST /api/v1/machines</a></li><li>3.2.2: <a href=#pg-ab6cbac66e8cf3fa0a5a8998d224f183>GET /api/v1/machines</a></li><li>3.2.3: <a href=#pg-5c3e0835220581b8bba64831f6f7f2be>GET /api/v1/machines/{id}</a></li><li>3.2.4: <a href=#pg-469e776cf0ea53aa67c4999bef12df53>PUT /api/v1/machines/{id}</a></li><li>3.2.5: <a href=#pg-8b6e001a582334f5057d88dd3d1a31c3>DELETE /api/v1/machines/{id}</a></li></ul></ul></ul><div class=content></div></div><div class=td-content><h1 id=pg-6768158cb3ee96c1f23fec6f77328e52>1 - Technology Analysis</h1><div class=lead>In-depth analysis of technologies and tools evaluated for home lab infrastructure</div><h2 id=network-boot--provisioning>Network Boot & Provisioning</h2><ul><li><a href=./matchbox/><strong>Matchbox</strong></a> - Network boot service for bare-metal provisioning<ul><li>Comprehensive analysis of PXE/iPXE/GRUB support</li><li>Configuration model (profiles, groups, templating)</li><li>Deployment patterns and operational considerations</li><li>Use case evaluation and comparison with alternatives</li></ul></li></ul><h2 id=cloud-providers>Cloud Providers</h2><ul><li><a href=./google-cloud/><strong>Google Cloud Platform</strong></a> - GCP capabilities for network boot infrastructure<ul><li>Network boot protocol support (TFTP, HTTP, HTTPS)</li><li>WireGuard VPN deployment and integration</li><li>Cost analysis and performance considerations</li></ul></li><li><a href=./aws/><strong>Amazon Web Services</strong></a> - AWS capabilities for network boot infrastructure<ul><li>Network boot protocol support (TFTP, HTTP, HTTPS)</li><li>WireGuard VPN deployment and integration</li><li>Cost analysis and performance considerations</li></ul></li></ul><h2 id=operating-systems>Operating Systems</h2><ul><li><a href=./server-os/><strong>Server Operating Systems</strong></a> - OS evaluation for Kubernetes homelab infrastructure<ul><li>Ubuntu Server analysis (kubeadm, k3s, MicroK8s)</li><li>Fedora Server analysis (kubeadm with CRI-O)</li><li>Talos Linux analysis (purpose-built Kubernetes OS)</li><li>Harvester HCI analysis (hyperconverged platform)</li><li>Comparison of setup complexity, maintenance, security, and resource overhead</li></ul></li></ul><h2 id=hardware>Hardware</h2><ul><li><a href=./hp_dl360_gen9/><strong>HP DL360 Gen9</strong></a> - Enterprise server hardware analysis</li><li><a href=./udm_pro/><strong>UniFi Dream Machine Pro</strong></a> - Network gateway and controller</li></ul><h2 id=future-analysis-topics>Future Analysis Topics</h2><p>Planned technology evaluations:</p><ul><li><strong>Storage Solutions</strong>: Ceph, GlusterFS, ZFS over iSCSI</li><li><strong>Container Orchestration</strong>: Kubernetes distributions (k3s, Talos, etc.)</li><li><strong>Observability</strong>: Prometheus, Grafana, Loki, Tempo stack</li><li><strong>Service Mesh</strong>: Istio, Linkerd, Cilium comparison</li><li><strong>CI/CD</strong>: GitLab Runner, Tekton, Argo Workflows</li><li><strong>Secret Management</strong>: Vault, External Secrets Operator</li><li><strong>Load Balancing</strong>: MetalLB, kube-vip, Cilium LB-IPAM</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8892c999ccbda3c9dcd2b4753afdab62>1.1 - Resource Identifiers Analysis</h1><p>This analysis compares three popular distributed identifier strategies for use in modern systems: UUID (particularly v4 and v7), ULID, and Snowflake ID. The comparison focuses on three critical aspects:</p><ol><li><strong>URI Safety</strong>: Can they be used directly in URLs without encoding?</li><li><strong>Database Performance</strong>: Storage size and index performance implications</li><li><strong>Generation Model</strong>: Centralized vs decentralized generation</li></ol><h2 id=quick-comparison-table>Quick Comparison Table</h2><table><thead><tr><th>Aspect</th><th>UUID v4</th><th>UUID v7</th><th>ULID</th><th>Snowflake ID</th></tr></thead><tbody><tr><td><strong>Size (binary)</strong></td><td>16 bytes</td><td>16 bytes</td><td>16 bytes</td><td>8 bytes</td></tr><tr><td><strong>Size (string)</strong></td><td>36 chars</td><td>36 chars</td><td>26 chars</td><td>18-19 chars</td></tr><tr><td><strong>URI Safe</strong></td><td>âœ… Yes</td><td>âœ… Yes</td><td>âœ… Yes</td><td>âœ… Yes</td></tr><tr><td><strong>Time-Ordered</strong></td><td>âŒ No</td><td>âœ… Yes</td><td>âœ… Yes</td><td>âœ… Yes</td></tr><tr><td><strong>Decentralized</strong></td><td>âœ… Yes</td><td>âœ… Yes</td><td>âœ… Yes</td><td>âš ï¸ Mostly</td></tr><tr><td><strong>Index Performance</strong></td><td>âš ï¸ Poor</td><td>âœ… Good</td><td>âœ… Good</td><td>âœ… Excellent</td></tr><tr><td><strong>Standardized</strong></td><td>âœ… RFC 9562</td><td>âœ… RFC 9562</td><td>âŒ Spec only</td><td>âŒ Pattern</td></tr><tr><td><strong>Database Support</strong></td><td>âœ… Native</td><td>ğŸ†• Limited</td><td>âŒ Custom</td><td>âŒ Custom</td></tr></tbody></table><h2 id=detailed-analyses>Detailed Analyses</h2><ul><li><a href=uuid/>UUID Analysis</a></li><li><a href=ulid/>ULID Analysis</a></li><li><a href=snowflake/>Snowflake ID Analysis</a></li></ul><h2 id=decision-guide>Decision Guide</h2><h3 id=use-uuid-v7-when>Use UUID v7 when:</h3><ul><li>âœ… RFC standardization is important</li><li>âœ… Native database support is desired (PostgreSQL 18+)</li><li>âœ… You need URN compatibility (<code>urn:uuid:...</code>)</li><li>âœ… You want official vendor support and tooling</li></ul><h3 id=use-ulid-when>Use ULID when:</h3><ul><li>âœ… Human readability is valued (Crockford Base32)</li><li>âœ… You prefer compact string representation (26 vs 36 chars)</li><li>âœ… Lexicographic sorting is important</li><li>âœ… You want case-insensitive identifiers</li></ul><h3 id=use-snowflake-id-when>Use Snowflake ID when:</h3><ul><li>âœ… Storage efficiency is critical (8 vs 16 bytes)</li><li>âœ… Numeric IDs are required</li><li>âœ… You can manage worker ID allocation</li><li>âœ… Maximum database performance is needed</li><li>âœ… You have a fixed number of generator nodes (&lt;1024)</li></ul><h3 id=use-uuid-v4-when>Use UUID v4 when:</h3><ul><li>âœ… Maximum randomness is required</li><li>âœ… Session tokens or one-time IDs</li><li>âœ… Time ordering is unimportant</li><li>âŒ Avoid for database primary keys</li></ul><h2 id=modern-recommendations-2024-2025>Modern Recommendations (2024-2025)</h2><p><strong>For new projects with database primary keys:</strong></p><ol><li><p><strong>First choice: UUID v7 or ULID</strong></p><ul><li>Both offer excellent performance with time-ordering</li><li>UUID v7: Better standardization and tooling</li><li>ULID: Better readability and compact format</li></ul></li><li><p><strong>Storage-constrained systems: Snowflake ID</strong></p><ul><li>50% smaller than UUID/ULID</li><li>Best database performance</li><li>Requires worker ID coordination</li></ul></li><li><p><strong>Legacy compatibility: UUID v4</strong></p><ul><li>Only if required by existing systems</li><li>Significant performance penalty for databases</li></ul></li></ol><p><strong>Avoid entirely:</strong></p><ul><li>UUID v1: Privacy concerns (leaks MAC address)</li><li>UUID v6: Superseded by v7</li><li>Auto-increment integers: Not distributed-system safe</li></ul><h2 id=key-insights>Key Insights</h2><h3 id=uri-safety>URI Safety</h3><p>All three identifier types are completely safe for direct use in URIs without percent-encoding:</p><ul><li><strong>UUID</strong>: Hexadecimal + hyphens (RFC 3986 unreserved characters)</li><li><strong>ULID</strong>: Crockford Base32 alphabet (no confusing characters)</li><li><strong>Snowflake</strong>: Decimal integers (0-9 only)</li></ul><h3 id=database-performance>Database Performance</h3><p>The critical factor is <strong>sequential vs random insertion</strong>:</p><p><strong>Random insertion (UUID v4):</strong></p><ul><li>Causes B-tree page splits throughout the index</li><li>Results in fragmentation and bloat</li><li>Poor cache utilization</li><li>2-5Ã— slower than sequential</li></ul><p><strong>Sequential insertion (UUID v7, ULID, Snowflake):</strong></p><ul><li>Appends to end of B-tree</li><li>Minimal page splits</li><li>Better cache locality</li><li>Comparable to auto-increment integers</li></ul><p><strong>Storage comparison:</strong></p><pre tabindex=0><code>Snowflake ID:  8 bytes  (baseline)
UUID/ULID:    16 bytes  (2Ã— larger)
UUID string:  36 bytes  (4.5Ã— larger)
</code></pre><h3 id=generation-models>Generation Models</h3><p><strong>Fully decentralized (no coordination):</strong></p><ul><li>UUID v4: Pure randomness</li><li>UUID v7: Timestamp + randomness</li><li>ULID: Timestamp + randomness</li></ul><p><strong>Minimal coordination (worker ID only):</strong></p><ul><li>Snowflake ID: Requires unique worker ID per generator<ul><li>One-time configuration</li><li>Supports 1,024 workers (10 bits)</li><li>Challenge: Auto-scaling environments</li></ul></li></ul><h2 id=performance-benchmarks>Performance Benchmarks</h2><p>From recent studies (2024-2025):</p><p><strong>PostgreSQL INSERT operations:</strong></p><ul><li>Snowflake ID: ~34,000 ops/sec</li><li>UUID v7: ~34,000 ops/sec (33% faster than v4)</li><li>ULID: ~34,000 ops/sec (comparable to v7)</li><li>UUID v4: ~25,000 ops/sec</li></ul><p><strong>Index fragmentation (PostgreSQL):</strong></p><ul><li>UUID v4: 85% larger indexes, 54% larger tables</li><li>UUID v7/ULID: Minimal fragmentation</li><li>Snowflake: Minimal fragmentation, 50% smaller indexes</li></ul><p><strong>Write-Ahead Log (WAL) generation:</strong></p><ul><li>UUID v7: 50% reduction vs UUID v4</li><li>Sequential IDs reduce database write amplification</li></ul><h2 id=collision-resistance>Collision Resistance</h2><p>All three approaches provide exceptional collision resistance:</p><p><strong>UUID v4:</strong></p><ul><li>122 bits of randomness</li><li>Need ~2.7 Ã— 10Â¹â¸ IDs for 50% collision probability</li></ul><p><strong>UUID v7:</strong></p><ul><li>48-bit timestamp + 74-bit random</li><li>Negligible collision risk even at millions per millisecond</li></ul><p><strong>ULID:</strong></p><ul><li>48-bit timestamp + 80-bit random</li><li>1.21 Ã— 10Â²â´ unique IDs per millisecond possible</li></ul><p><strong>Snowflake ID:</strong></p><ul><li>Mathematical uniqueness guarantee</li><li>No collisions possible if worker IDs are unique</li><li>4,096 IDs per millisecond per worker</li></ul><h2 id=implementation-considerations>Implementation Considerations</h2><h3 id=postgresql>PostgreSQL</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- UUID v7 (PostgreSQL 18+)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=n>UUID</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>gen_uuid_v7</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- UUID v7 (PostgreSQL &lt;18 with extension)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=n>EXTENSION</span><span class=w> </span><span class=k>IF</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>EXISTS</span><span class=w> </span><span class=n>pgcrypto</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Use custom function or library
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- ULID (custom type or text/bytea)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=n>BYTEA</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>ulid_generate</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Snowflake (bigint)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=nb>BIGINT</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>snowflake_generate</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><h3 id=mysql>MySQL</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- UUID (binary storage recommended)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=nb>BINARY</span><span class=p>(</span><span class=mi>16</span><span class=p>)</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=p>(</span><span class=n>UUID_TO_BIN</span><span class=p>(</span><span class=n>UUID</span><span class=p>()))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Snowflake
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=nb>BIGINT</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><h3 id=application-level-generation>Application-Level Generation</h3><p><strong>Advantages:</strong></p><ul><li>No database dependency</li><li>Works with any database</li><li>Consistent across different storage systems</li><li>Better control over implementation</li></ul><p><strong>Disadvantages:</strong></p><ul><li>Requires library/code maintenance</li><li>Clock synchronization considerations</li><li>Worker ID management (Snowflake only)</li></ul><h2 id=migration-strategies>Migration Strategies</h2><h3 id=moving-from-auto-increment>Moving from Auto-Increment</h3><p><strong>Considerations:</strong></p><ul><li>Foreign key updates required</li><li>Index rebuilds may be needed</li><li>Application code changes</li><li>Dual-write period during migration</li></ul><p><strong>Recommended approach:</strong></p><ol><li>Add new ID column alongside existing</li><li>Generate IDs for existing rows</li><li>Update foreign keys progressively</li><li>Migrate application code</li><li>Remove old ID column</li></ol><h3 id=moving-from-uuid-v4-to-v7ulid>Moving from UUID v4 to v7/ULID</h3><p><strong>Benefits:</strong></p><ul><li>Same storage size (16 bytes)</li><li>Can keep existing IDs</li><li>Only new records use v7/ULID</li><li>Gradual performance improvement</li></ul><h2 id=security-considerations>Security Considerations</h2><h3 id=information-leakage>Information Leakage</h3><p><strong>UUID v4:</strong></p><ul><li>âœ… Reveals nothing (pure randomness)</li></ul><p><strong>UUID v7 / ULID:</strong></p><ul><li>âš ï¸ Reveals creation timestamp (usually acceptable)</li><li>âš ï¸ May reveal approximate volume (via sequence patterns)</li></ul><p><strong>Snowflake ID:</strong></p><ul><li>âš ï¸ Reveals exact creation time (41-bit timestamp)</li><li>âš ï¸ Reveals which worker generated it</li><li>âš ï¸ Reveals sequence count within millisecond</li></ul><h3 id=enumeration-attacks>Enumeration Attacks</h3><p><strong>Random IDs (UUID v4):</strong></p><ul><li>âœ… Resistant to enumeration</li><li>Guessing next ID is infeasible</li></ul><p><strong>Sequential IDs (v7, ULID, Snowflake):</strong></p><ul><li>âš ï¸ Predictable patterns</li><li>Can estimate next ID value</li><li><strong>Mitigation</strong>: Use authentication/authorization, don&rsquo;t rely on ID secrecy</li></ul><h3 id=recommendation>Recommendation</h3><p>Never rely on ID unpredictability as a security mechanism. Always use proper authentication and authorization regardless of ID type.</p><h2 id=conclusion>Conclusion</h2><p>The landscape of distributed identifiers has evolved significantly:</p><p><strong>2010-2020:</strong> UUID v4 was the default distributed identifier despite performance issues</p><p><strong>2020-2024:</strong> Community alternatives (ULID, Snowflake) gained popularity for performance</p><p><strong>2024+:</strong> UUID v7 (RFC 9562) provides standardized time-ordered IDs with vendor support</p><p>For most modern applications, <strong>UUID v7 or ULID</strong> represent the optimal balance of performance, standardization, and operational simplicity. <strong>Snowflake IDs</strong> remain compelling for storage-constrained systems where the 8-byte size and numeric format provide tangible benefits.</p><p>The days of suffering UUID v4&rsquo;s random insertion penalty for database primary keys are overâ€”time-ordered identifiers are now the recommended default.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-95c685912a6c8633373e2ea37cbf5347>1.1.1 - Universally Unique Identifier (UUID) Analysis</h1><h2 id=overview>Overview</h2><p>UUIDs are 128-bit identifiers standardized in RFC 9562 (May 2024), which obsoletes the previous RFC 4122. The latest specification introduces three new versions (v6, v7, v8) while maintaining backward compatibility with existing versions.</p><h2 id=uri-safety>URI Safety</h2><h3 id=-fully-uri-safe>âœ… Fully URI-Safe</h3><p>UUIDs are inherently safe for use in URIs without any encoding required.</p><p><strong>Standard format:</strong></p><pre tabindex=0><code>550e8400-e29b-41d4-a716-446655440000
</code></pre><p><strong>Characteristics:</strong></p><ul><li>36 characters: 32 hexadecimal digits + 4 hyphens</li><li>Character set: <code>a-f</code>, <code>0-9</code>, <code>-</code></li><li>All characters are in RFC 3986 Â§2.3 unreserved set</li><li>Case-insensitive (lowercase recommended per RFC 9562)</li></ul><p><strong>Usage in URIs:</strong></p><pre tabindex=0><code>/api/users/550e8400-e29b-41d4-a716-446655440000
?id=550e8400-e29b-41d4-a716-446655440000
urn:uuid:550e8400-e29b-41d4-a716-446655440000
</code></pre><p><strong>Alternative encodings:</strong></p><ul><li>Base64 URL-safe: 22 characters (optimization, not required)</li><li>Base62: Similar length, avoids <code>+</code> and <code>/</code></li><li>These are for compactness, not safety</li></ul><h2 id=database-storage-and-performance>Database Storage and Performance</h2><h3 id=storage-size>Storage Size</h3><p><strong>Binary format:</strong></p><ul><li><strong>16 bytes (128 bits)</strong> - canonical storage format</li><li>Defined in RFC 9562</li></ul><p><strong>String format:</strong></p><ul><li>36 characters (<code>CHAR(36)</code>)</li><li>Actual storage: 36-40 bytes depending on database encoding</li></ul><p><strong>Storage comparison:</strong></p><table><thead><tr><th>Format</th><th>Size</th><th>Overhead</th></tr></thead><tbody><tr><td>Binary (<code>BINARY(16)</code>)</td><td>16 bytes</td><td>baseline</td></tr><tr><td>String (<code>CHAR(36)</code>)</td><td>36 bytes</td><td>2.25Ã—</td></tr><tr><td>String (<code>VARCHAR(36)</code>)</td><td>38-40 bytes</td><td>~2.5Ã—</td></tr></tbody></table><h3 id=database-specific-implementations>Database-Specific Implementations</h3><p><strong>PostgreSQL:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Use native UUID type (16 bytes internally)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=n>UUID</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>gen_random_uuid</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- PostgreSQL 18+ supports UUIDv7
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>posts</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=n>UUID</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>gen_uuid_v7</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><p><strong>Performance impact:</strong></p><ul><li>Native <code>UUID</code> type: 16 bytes</li><li>Text storage: Tables 54% larger, indexes 85% larger</li></ul><p><strong>MySQL:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Use BINARY(16) with conversion functions
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=nb>BINARY</span><span class=p>(</span><span class=mi>16</span><span class=p>)</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=p>(</span><span class=n>UUID_TO_BIN</span><span class=p>(</span><span class=n>UUID</span><span class=p>()))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Retrieve with conversion
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>SELECT</span><span class=w> </span><span class=n>BIN_TO_UUID</span><span class=p>(</span><span class=n>id</span><span class=p>)</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>id</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>users</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p><strong>SQL Server:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>id</span><span class=w> </span><span class=n>UNIQUEIDENTIFIER</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>NEWSEQUENTIALID</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><ul><li>Note: <code>NEWSEQUENTIALID()</code> generates sequential UUIDs, not <code>NEWID()</code> which is random</li></ul><h3 id=index-performance>Index Performance</h3><h4 id=the-uuid-v4-problem>The UUID v4 Problem</h4><p><strong>Random insertion issues:</strong></p><ol><li><strong>Page splits:</strong> New UUIDs insert at arbitrary positions in B-tree</li><li><strong>Fragmentation:</strong> Index becomes scattered across non-contiguous pages</li><li><strong>Wasted space:</strong> Page splits leave gaps throughout index</li><li><strong>Cache inefficiency:</strong> Poor locality leads to more cache misses</li><li><strong>Write amplification:</strong> More disk I/O per insert</li></ol><p><strong>Measured impact:</strong></p><ul><li>Constant page splits during INSERT operations</li><li>Index bloat (more pages for same data)</li><li>2-5Ã— slower than sequential IDs</li><li>Degraded SELECT performance</li></ul><h4 id=the-uuid-v7-solution>The UUID v7 Solution</h4><p><strong>Sequential insertion benefits:</strong></p><ol><li><strong>Append-only writes:</strong> New entries go to end of index</li><li><strong>Minimal page splits:</strong> Only last page splits when full</li><li><strong>Low fragmentation:</strong> Index remains mostly contiguous</li><li><strong>Better caching:</strong> Sequential access patterns</li><li><strong>Reduced I/O:</strong> Fewer disk operations</li></ol><p><strong>Measured improvements:</strong></p><ul><li>2-5Ã— faster insert performance vs v4</li><li>50% reduction in Write-Ahead Log (WAL) rate</li><li>Fewer page splits comparable to auto-increment</li><li>Better storage efficiency</li></ul><h3 id=binary-vs-string-storage>Binary vs String Storage</h3><p><strong>Index size comparison (PostgreSQL):</strong></p><table><thead><tr><th>Storage Type</th><th>Table Size</th><th>Index Size</th></tr></thead><tbody><tr><td>Binary (UUID)</td><td>100% (baseline)</td><td>100% (baseline)</td></tr><tr><td>String (TEXT)</td><td>154%</td><td>185%</td></tr></tbody></table><p><strong>Why binary is faster:</strong></p><ul><li>Smaller indexes (fewer pages)</li><li>Better cache utilization</li><li>Faster CPU comparisons (128-bit integers)</li><li>Reduced I/O (less data transfer)</li></ul><h2 id=generation-approach>Generation Approach</h2><h3 id=-fully-decentralized>âœ… Fully Decentralized</h3><p>One of UUID&rsquo;s core design goals is <strong>decentralized generation without coordination</strong>. Multiple systems can generate UUIDs independently without collision risk.</p><h3 id=uuid-version-comparison>UUID Version Comparison</h3><h4 id=uuid-v1---time-based--mac-address>UUID v1 - Time-based + MAC Address</h4><p><strong>Structure:</strong></p><pre tabindex=0><code>Timestamp (60 bits) + Clock Sequence (14 bits) + MAC Address (48 bits)
</code></pre><p><strong>Generation:</strong></p><ul><li>Timestamp: 100-nanosecond intervals since Oct 15, 1582</li><li>Node ID: System&rsquo;s MAC address</li><li>Clock sequence: Random value to prevent duplicates</li></ul><p><strong>Pros:</strong></p><ul><li>Sequential (sorts chronologically)</li><li>Very low collision risk</li><li>Decentralized</li></ul><p><strong>Cons:</strong></p><ul><li>âŒ <strong>Privacy concern:</strong> Leaks MAC address (physical location)</li><li>âŒ Timestamp not in sortable byte order</li><li>âŒ Modern systems avoid for security reasons</li></ul><p><strong>Use case:</strong> Legacy systems only (prefer v7)</p><h4 id=uuid-v4---random>UUID v4 - Random</h4><p><strong>Structure:</strong></p><pre tabindex=0><code>122 random bits + 6 version/variant bits
</code></pre><p><strong>Generation:</strong></p><ul><li>Entirely random (cryptographically secure RNG recommended)</li><li>No coordination needed</li><li>No sequential ordering</li></ul><p><strong>Pros:</strong></p><ul><li>âœ… Maximum privacy (no identifying information)</li><li>âœ… Simplest to generate</li><li>âœ… Works offline</li><li>âœ… Truly decentralized</li></ul><p><strong>Cons:</strong></p><ul><li>âŒ <strong>Poor database performance:</strong> Random insertion causes fragmentation</li><li>âŒ No time information</li><li>âŒ Higher collision probability (still astronomically low)</li></ul><p><strong>Collision probability:</strong></p><ul><li>122 bits of entropy</li><li>Need ~2.7 Ã— 10Â¹â¸ UUIDs for 50% collision chance</li><li>In practice: negligible</li></ul><p><strong>Use cases:</strong></p><ul><li>Session IDs</li><li>One-time tokens</li><li>Non-database identifiers</li><li>When pure randomness is desired</li></ul><h4 id=uuid-v6---reordered-time-based>UUID v6 - Reordered Time-based</h4><p><strong>Structure:</strong></p><pre tabindex=0><code>Timestamp (60 bits, big-endian) + Clock Sequence + Node ID
</code></pre><p><strong>Generation:</strong></p><ul><li>Like v1 but timestamp bytes reordered for sorting</li><li>Maintains MAC address (privacy concern)</li></ul><p><strong>Pros:</strong></p><ul><li>Sortable (better than v1)</li><li>Sequential insertion performance</li></ul><p><strong>Cons:</strong></p><ul><li>âŒ Still leaks MAC address</li><li>âŒ <strong>Superseded by v7:</strong> RFC 9562 recommends v7</li></ul><p><strong>Use case:</strong> None - v7 is better</p><h4 id=uuid-v7---time-ordered--random--recommended>UUID v7 - Time-ordered + Random â­ RECOMMENDED</h4><p><strong>Structure:</strong></p><pre tabindex=0><code>Unix Timestamp (48 bits, millisecond) + Random (74 bits)
</code></pre><p><strong>Generation:</strong></p><ul><li>Top 48 bits: Unix epoch milliseconds</li><li>Bottom 74 bits: Random data</li><li>No MAC address</li><li>Monotonically increasing</li></ul><p><strong>Pros:</strong></p><ul><li>âœ… <strong>Excellent database performance:</strong> Sequential inserts</li><li>âœ… <strong>Privacy-preserving:</strong> No MAC address</li><li>âœ… <strong>Sortable:</strong> Natural time ordering</li><li>âœ… <strong>Decentralized:</strong> No coordination needed</li><li>âœ… <strong>Random component:</strong> Prevents collisions from multiple nodes</li></ul><p><strong>Performance measured:</strong></p><ul><li>2-5Ã— faster inserts than v4</li><li>50% reduction in WAL rate</li><li>Minimal page splits</li><li>Better cache locality</li></ul><p><strong>Cons:</strong></p><ul><li>âš ï¸ Exposes creation timestamp (usually acceptable)</li><li>Slightly more complex than v4</li></ul><p><strong>Use cases:</strong></p><ul><li><strong>Database primary keys</strong> (optimal choice)</li><li>Distributed systems</li><li>Event IDs with time ordering</li><li>Modern applications (default recommendation)</li></ul><h3 id=decentralization-requirements>Decentralization Requirements</h3><p><strong>No central service required for any version:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=c1>// Example: Independent generation</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Node A</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>uuid1</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>uuid</span><span class=p>.</span><span class=nf>NewV7</span><span class=p>()</span><span class=w> </span><span class=c1>// 0191e1a6-8b2c-7890-abcd-123456789abc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Node B (same time)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>uuid2</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>uuid</span><span class=p>.</span><span class=nf>NewV7</span><span class=p>()</span><span class=w> </span><span class=c1>// 0191e1a6-8b2c-7890-xyz1-987654321def</span><span class=w>
</span></span></span></code></pre></div><p><strong>How v7 avoids collisions:</strong></p><ol><li><strong>Time component:</strong> Millisecond precision provides separation</li><li><strong>Random component:</strong> 74 bits prevents same-millisecond collisions</li><li><strong>No coordination:</strong> Each node generates independently</li></ol><p><strong>Collision risk (UUID v7):</strong></p><ul><li>Within same millisecond: 2â·â´ unique values possible</li><li>Even at 1 billion IDs per millisecond: negligible collision risk</li></ul><h2 id=version-selection-guide>Version Selection Guide</h2><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Which UUID Version?                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  Database Primary Key? â”€â”€YESâ”€â”€&gt; UUID v7            â”‚
â”‚         â”‚                                            â”‚
â”‚         NO                                           â”‚
â”‚         â”‚                                            â”‚
â”‚  Need time ordering? â”€â”€YESâ”€â”€&gt; UUID v7              â”‚
â”‚         â”‚                                            â”‚
â”‚         NO                                           â”‚
â”‚         â”‚                                            â”‚
â”‚  Need pure randomness? â”€â”€YESâ”€â”€&gt; UUID v4            â”‚
â”‚                                                      â”‚
â”‚  âŒ Avoid: v1 (privacy), v6 (superseded)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><h2 id=go-library-support>Go Library Support</h2><h3 id=-official-google-uuid-library>âœ… Official Google UUID Library</h3><p>The most widely-used Go library for UUIDs is <a href=https://github.com/google/uuid><code>github.com/google/uuid</code></a>, which provides full support for UUID versions 1, 3, 4, 5, 6, and 7.</p><p><strong>Installation:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>go get github.com/google/uuid
</span></span></code></pre></div><p><strong>Usage examples:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kn>import</span><span class=w> </span><span class=s>&#34;github.com/google/uuid&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Generate UUID v4 (random)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>id</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>uuid</span><span class=p>.</span><span class=nf>New</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=nx>id</span><span class=p>.</span><span class=nf>String</span><span class=p>())</span><span class=w> </span><span class=c1>// e.g., 550e8400-e29b-41d4-a716-446655440000</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Generate UUID v7 (time-ordered, recommended for databases)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>id</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>uuid</span><span class=p>.</span><span class=nf>Must</span><span class=p>(</span><span class=nx>uuid</span><span class=p>.</span><span class=nf>NewV7</span><span class=p>())</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=nx>id</span><span class=p>.</span><span class=nf>String</span><span class=p>())</span><span class=w> </span><span class=c1>// e.g., 0191e1a6-8b2c-7890-abcd-123456789abc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Parse existing UUID</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>parsed</span><span class=p>,</span><span class=w> </span><span class=nx>err</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>uuid</span><span class=p>.</span><span class=nf>Parse</span><span class=p>(</span><span class=s>&#34;550e8400-e29b-41d4-a716-446655440000&#34;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>if</span><span class=w> </span><span class=nx>err</span><span class=w> </span><span class=o>!=</span><span class=w> </span><span class=kc>nil</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nx>log</span><span class=p>.</span><span class=nf>Fatal</span><span class=p>(</span><span class=nx>err</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><h2 id=modern-recommendations-2024-2025>Modern Recommendations (2024-2025)</h2><p><strong>For new projects:</strong></p><ol><li><p><strong>Default choice: UUID v7</strong></p><ul><li>Best performance</li><li>Decentralized generation</li><li>No privacy concerns</li><li>Sortable</li></ul></li><li><p><strong>Special cases: UUID v4</strong></p><ul><li>Explicit randomness needed</li><li>Non-database contexts</li><li>Legacy compatibility</li></ul></li><li><p><strong>Avoid: v1, v6</strong></p><ul><li>v1: Privacy issues (MAC address)</li><li>v6: v7 is better in every way</li></ul></li></ol><h2 id=recent-developments>Recent Developments</h2><h3 id=rfc-9562-may-2024>RFC 9562 (May 2024)</h3><ul><li>Obsoletes RFC 4122</li><li>Introduces v6, v7, v8</li><li>Recommends v7 for database keys</li></ul><h3 id=postgresql-18-2025>PostgreSQL 18 (2025)</h3><ul><li>Native <code>gen_uuid_v7()</code> function</li><li>Solves B-tree fragmentation</li><li>Built-in time-ordered UUID generation</li></ul><h3 id=industry-adoption>Industry Adoption</h3><ul><li>Buildkite: &ldquo;Goodbye to sequential integers, hello UUIDv7&rdquo;</li><li>Cloud providers adding native support</li><li>Database vendors implementing optimizations</li></ul><h2 id=summary>Summary</h2><table><thead><tr><th>Aspect</th><th>UUID v4</th><th>UUID v7</th></tr></thead><tbody><tr><td><strong>Storage</strong></td><td>16 bytes binary</td><td>16 bytes binary</td></tr><tr><td><strong>Generation</strong></td><td>Fully random</td><td>Time + random</td></tr><tr><td><strong>Decentralized</strong></td><td>âœ… Yes</td><td>âœ… Yes</td></tr><tr><td><strong>Coordination</strong></td><td>âŒ No</td><td>âŒ No</td></tr><tr><td><strong>URI safe</strong></td><td>âœ… Yes</td><td>âœ… Yes</td></tr><tr><td><strong>DB inserts</strong></td><td>âš ï¸ Slow (random)</td><td>âœ… Fast (sequential)</td></tr><tr><td><strong>Fragmentation</strong></td><td>âš ï¸ High</td><td>âœ… Low</td></tr><tr><td><strong>Page splits</strong></td><td>âš ï¸ Frequent</td><td>âœ… Minimal</td></tr><tr><td><strong>Sortable</strong></td><td>âŒ No</td><td>âœ… Yes (by time)</td></tr><tr><td><strong>Privacy</strong></td><td>âœ… Maximum</td><td>âœ… Good</td></tr><tr><td><strong>Best for</strong></td><td>Tokens, session IDs</td><td>Database keys</td></tr></tbody></table><h2 id=key-takeaways>Key Takeaways</h2><ol><li><strong>Always use binary storage</strong> in databases (16 bytes vs 36-40 bytes)</li><li><strong>UUID v7 is the modern default</strong> for database primary keys</li><li><strong>UUID v4 still useful</strong> for session tokens and random IDs</li><li><strong>No coordination required</strong> - all versions are fully decentralized</li><li><strong>URI-safe by design</strong> - use directly in URLs without encoding</li><li><strong>RFC standardized</strong> - wide vendor support and tooling available</li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-7cb3eb798477cf3e1c5bdea6c59611a5>1.1.2 - Universally Unique Lexicographically Sortable Identifier (ULID) Analysis</h1><h2 id=overview>Overview</h2><p>ULID is a community-driven specification for unique identifiers that combine the decentralized generation of UUIDs with the performance benefits of time-ordered sequential IDs. Created as an alternative to UUID v4&rsquo;s poor database performance, ULID predates UUID v7 but shares similar design goals.</p><h2 id=uri-safety>URI Safety</h2><h3 id=-completely-uri-safe>âœ… Completely URI-Safe</h3><p>ULIDs are designed with URI usage as a primary consideration.</p><p><strong>Character set:</strong></p><ul><li>Uses Crockford&rsquo;s Base32 alphabet</li><li>Characters: <code>0123456789ABCDEFGHJKMNPQRSTVWXYZ</code></li><li>Excluded: <code>I</code>, <code>L</code>, <code>O</code>, <code>U</code> (avoid confusion and potential abuse)</li><li>32 unique characters</li></ul><p><strong>Format:</strong></p><pre tabindex=0><code>01ARZ3NDEKTSV4RRFFQ69G5FAV
</code></pre><p><strong>Characteristics:</strong></p><ul><li><strong>26 characters</strong> (10 timestamp + 16 randomness)</li><li><strong>No hyphens</strong> (unlike UUID&rsquo;s 36 chars with hyphens)</li><li><strong>Case-insensitive</strong> (can be normalized)</li><li><strong>More compact</strong> than UUID string representation</li></ul><p><strong>Advantages over UUID:</strong></p><ul><li>Shorter (26 vs 36 characters)</li><li>No special characters required</li><li>More human-readable</li><li>Case-insensitive (easier to communicate verbally)</li></ul><p><strong>Usage in URIs:</strong></p><pre tabindex=0><code>/api/users/01ARZ3NDEKTSV4RRFFQ69G5FAV
?id=01ARZ3NDEKTSV4RRFFQ69G5FAV
</code></pre><h2 id=database-storage-and-performance>Database Storage and Performance</h2><h3 id=storage-size>Storage Size</h3><p><strong>Binary representation:</strong></p><ul><li><strong>128 bits = 16 bytes</strong></li><li>Same as UUID</li></ul><p><strong>String representation:</strong></p><ul><li><strong>26 characters</strong></li><li>As UTF-8 string: 26 bytes minimum</li><li>As MySQL <code>CHAR(26)</code> with <code>utf8mb4</code>: 72 bytes</li><li><strong>Recommendation:</strong> Store as binary (16 bytes) for optimal efficiency</li></ul><p><strong>Storage comparison:</strong></p><table><thead><tr><th>Format</th><th>Size</th><th>Efficiency</th></tr></thead><tbody><tr><td>Binary (<code>BYTEA</code>/<code>BINARY(16)</code>)</td><td>16 bytes</td><td>Optimal</td></tr><tr><td>String (<code>CHAR(26)</code>)</td><td>26+ bytes</td><td>1.6Ã— larger</td></tr><tr><td>UUID string (<code>CHAR(36)</code>)</td><td>36+ bytes</td><td>2.25Ã— larger</td></tr></tbody></table><h3 id=index-performance>Index Performance</h3><p>ULIDs provide <strong>significant performance advantages</strong> over random identifiers:</p><h4 id=b-tree-index-benefits>B-tree Index Benefits</h4><p><strong>Sequential insertion pattern:</strong></p><ul><li>âœ… Dramatically reduces page splits vs UUID v4</li><li>âœ… Minimizes write amplification</li><li>âœ… Improves cache utilization</li><li>âœ… Reduces I/O operations</li><li>âœ… Prevents index fragmentation and bloat</li></ul><p><strong>Recent benchmarks (PostgreSQL, 2024-2025):</strong></p><table><thead><tr><th>ID Type</th><th>Ops/Second</th><th>Latency</th><th>Index Size</th></tr></thead><tbody><tr><td>ULID (bytea)</td><td>~34,000</td><td>58 Î¼s</td><td>Baseline</td></tr><tr><td>UUID v7</td><td>~34,000</td><td>58 Î¼s</td><td>Similar</td></tr><tr><td>UUID v4</td><td>~25,000</td><td>85 Î¼s</td><td>85% larger</td></tr></tbody></table><p><strong>Key findings:</strong></p><ul><li>ULID performance comparable to or slightly better than UUID v7</li><li>33% faster than UUID v4</li><li>Significantly more stable performance (lower variance)</li></ul><h3 id=lexicographic-sorting-benefits>Lexicographic Sorting Benefits</h3><p><strong>Chronological ordering:</strong></p><ul><li>ULIDs sort lexicographically in timestamp order</li><li>No need for additional timestamp indexes</li><li>Natural time-based ordering</li></ul><p><strong>Query optimization benefits:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Time-range queries are efficient
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>events</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>WHERE</span><span class=w> </span><span class=n>event_id</span><span class=w> </span><span class=o>&gt;=</span><span class=w> </span><span class=s1>&#39;01ARZ3NDEK000000000000000&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>AND</span><span class=w> </span><span class=n>event_id</span><span class=w> </span><span class=o>&lt;=</span><span class=w> </span><span class=s1>&#39;01ARZ3NDEKZZZZZZZZZZZZZZ&#39;</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p><strong>Advantages:</strong></p><ul><li>Efficient range queries on time-based data</li><li>Simplified debugging (IDs reveal creation time)</li><li>Better query planner optimization</li><li>Natural partitioning by time ranges</li></ul><h3 id=impact-on-page-splits-and-fragmentation>Impact on Page Splits and Fragmentation</h3><p><strong>Dramatically reduced fragmentation compared to UUID v4:</strong></p><p><strong>UUID v4 problems:</strong></p><ul><li>Excessive page splits even before pages are full</li><li>Random writes throughout B-tree structure</li><li>Index bloat increases size on disk</li><li>Temporally related rows spread across index</li></ul><p><strong>ULID advantages:</strong></p><ul><li>Inserts at end of B-tree</li><li>Minimizes splits to only last page</li><li>Sequential writes optimize for append-heavy workloads</li><li>Reduced index maintenance overhead</li></ul><p><strong>Storage efficiency:</strong></p><ul><li>Less wasted space from partial pages</li><li>More compact indexes</li><li>Better compression ratios</li><li>Lower storage costs for write-heavy applications</li></ul><h3 id=sequential-nature-and-timestamp-ordering>Sequential Nature and Timestamp Ordering</h3><p><strong>48-bit timestamp component:</strong></p><ul><li>Millisecond precision Unix timestamp</li><li>Representation until year <strong>10889 AD</strong></li><li>High-order bits ensure chronological insertion</li><li>Enables time-based partitioning strategies</li></ul><p><strong>Performance characteristics:</strong></p><ul><li>New records naturally fall at end of B-tree</li><li>Predictable insertion patterns</li><li>Optimizes for sequential writes</li><li>Reduces fragmentation over time</li></ul><h2 id=generation-approach>Generation Approach</h2><h3 id=-fully-decentralized>âœ… Fully Decentralized</h3><p>ULIDs can be generated in a completely decentralized manner with no coordination required.</p><p><strong>No centralized service needed:</strong></p><ul><li>Each system/node generates independently</li><li>Only requires system clock access</li><li>Cryptographically secure random number generator (CSPRNG)</li><li>No network coordination overhead</li></ul><h3 id=structure-timestamp--randomness>Structure: Timestamp + Randomness</h3><p><strong>128 bits total:</strong></p><pre tabindex=0><code> 01AN4Z07BY      79KA1307SR9X4MV3
|----------|    |----------------|
 Timestamp          Randomness
   48bits             80bits
</code></pre><p><strong>Timestamp component (48 bits):</strong></p><ul><li>Milliseconds since Unix epoch</li><li>First 10 characters in encoded form</li><li>Provides temporal ordering</li></ul><p><strong>Randomness component (80 bits):</strong></p><ul><li>Cryptographically secure random value</li><li>Remaining 16 characters</li><li>Ensures uniqueness within same millisecond</li></ul><p><strong>Binary encoding:</strong></p><ul><li>Most Significant Byte first (network byte order)</li><li>Each component encoded as octets</li><li>Total: 16 octets (bytes)</li></ul><h3 id=collision-resistance>Collision Resistance</h3><p><strong>Extremely high collision resistance:</strong></p><ul><li><strong>1.21 Ã— 10Â²â´ unique IDs per millisecond</strong> (2â¸â° possible values)</li><li>Collision probability is practically zero</li><li>Even in distributed systems, likelihood of collision is exceedingly low</li></ul><p><strong>Example scale:</strong></p><ul><li>Would need to generate <strong>trillions of IDs per millisecond</strong> to see collisions</li><li>Far exceeds any practical generation rate</li><li>Safe for production at any realistic scale</li></ul><h3 id=monotonicity-guarantees>Monotonicity Guarantees</h3><h4 id=standard-generation-non-monotonic>Standard Generation (Non-Monotonic)</h4><p><strong>Default behavior:</strong></p><ul><li>Each ULID uses fresh random 80 bits</li><li>Sortable by timestamp (millisecond precision)</li><li>No guarantee of order within same millisecond</li></ul><h4 id=monotonic-mode-optional>Monotonic Mode (Optional)</h4><p><strong>Algorithm:</strong></p><ol><li>If timestamp same as previous: increment previous random component</li><li>If timestamp advanced: generate fresh random component</li><li>If overflow (2â¸â° increments): wait for next millisecond or fail</li></ol><p><strong>Benefits:</strong></p><ul><li>âœ… Guarantees strict ordering even at sub-millisecond generation</li><li>âœ… Better collision resistance through sequential randomness</li><li>âœ… Maintains sortability within same timestamp</li></ul><p><strong>Trade-offs:</strong></p><ul><li>âš ï¸ Leaks information about IDs generated within same millisecond</li><li>âš ï¸ Potential security concern: enables enumeration attacks</li><li>âš ï¸ Can overflow if > 2â¸â° IDs generated in one millisecond (theoretical only)</li></ul><p><strong>Collision probability in monotonic mode:</strong></p><ul><li>Actually reduces collision risk</li><li>Incrementing creates number groups less likely to collide</li><li>Safe to use in production systems</li></ul><h2 id=comparison-to-uuid-v7>Comparison to UUID v7</h2><p>Both ULID and UUID v7 solve similar problems with different approaches:</p><table><thead><tr><th>Aspect</th><th>ULID</th><th>UUID v7</th></tr></thead><tbody><tr><td><strong>Size</strong></td><td>16 bytes</td><td>16 bytes</td></tr><tr><td><strong>Timestamp bits</strong></td><td>48</td><td>48</td></tr><tr><td><strong>Random bits</strong></td><td>80</td><td>74</td></tr><tr><td><strong>String format</strong></td><td>26 chars (Base32)</td><td>36 chars (hex + hyphens)</td></tr><tr><td><strong>Standardization</strong></td><td>Community spec</td><td>RFC 9562 (official)</td></tr><tr><td><strong>DB support</strong></td><td>Custom</td><td>Native (PostgreSQL 18+)</td></tr><tr><td><strong>Readability</strong></td><td>Better (Base32)</td><td>Standard (hex)</td></tr><tr><td><strong>Case sensitivity</strong></td><td>Insensitive</td><td>Insensitive</td></tr><tr><td><strong>Hyphens</strong></td><td>None</td><td>4 hyphens</td></tr></tbody></table><p><strong>ULID advantages:</strong></p><ul><li>More compact string representation (26 vs 36)</li><li>Slightly more random bits (80 vs 74)</li><li>Better human readability (Crockford Base32)</li><li>No hyphens (simpler to handle)</li></ul><p><strong>UUID v7 advantages:</strong></p><ul><li>Official RFC standardization</li><li>Growing native database support</li><li>URN namespace compatibility (<code>urn:uuid:...</code>)</li><li>Wider vendor tooling support</li></ul><h2 id=2024-2025-landscape>2024-2025 Landscape</h2><p><strong>Current state:</strong></p><ul><li>UUID v7 (RFC 9562, 2024) now offers similar benefits with standardization</li><li>ULID remains compelling for human readability and compact representation</li><li>Both vastly superior to UUID v4 for database performance</li><li>Choice often: standardization (v7) vs. readability (ULID)</li></ul><p><strong>Industry adoption:</strong></p><ul><li>incident.io uses ULIDs for all identifiers</li><li>Various startups prefer ULID for API design</li><li>UUID v7 gaining traction in enterprise systems</li></ul><h2 id=use-cases>Use Cases</h2><p><strong>ULIDs are excellent for:</strong></p><ul><li>âœ… Database primary keys (especially write-heavy workloads)</li><li>âœ… Distributed systems requiring decentralized ID generation</li><li>âœ… Applications needing URI-safe identifiers</li><li>âœ… Systems benefiting from time-ordered IDs</li><li>âœ… Scenarios requiring human-readable identifiers</li><li>âœ… APIs where compact IDs are valued</li></ul><p><strong>Consider alternatives when:</strong></p><ul><li>âš ï¸ Strict RFC/ISO standardization required (use UUID v7)</li><li>âš ï¸ Native database support is priority (UUID v7 has better tooling)</li><li>âš ï¸ Absolute minimal storage (auto-increment or Snowflake)</li><li>âš ï¸ High-security scenarios sensitive to timing information leakage</li></ul><h2 id=implementation-examples>Implementation Examples</h2><h3 id=postgresql>PostgreSQL</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Store as bytea for optimal performance
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>events</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>event_id</span><span class=w> </span><span class=n>BYTEA</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>ulid_generate</span><span class=p>(),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>created_at</span><span class=w> </span><span class=n>TIMESTAMPTZ</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=n>NOW</span><span class=p>(),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>data</span><span class=w> </span><span class=n>JSONB</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Custom function needed (no native support)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>OR</span><span class=w> </span><span class=k>REPLACE</span><span class=w> </span><span class=k>FUNCTION</span><span class=w> </span><span class=n>ulid_generate</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>RETURNS</span><span class=w> </span><span class=n>BYTEA</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=err>$$</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>-- Implementation using pgcrypto or external library
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=err>$$</span><span class=w> </span><span class=k>LANGUAGE</span><span class=w> </span><span class=n>plpgsql</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><h3 id=mysql>MySQL</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Store as BINARY(16)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>events</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>event_id</span><span class=w> </span><span class=nb>BINARY</span><span class=p>(</span><span class=mi>16</span><span class=p>)</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>created_at</span><span class=w> </span><span class=k>TIMESTAMP</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=k>CURRENT_TIMESTAMP</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>data</span><span class=w> </span><span class=n>JSON</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Generate in application layer
</span></span></span></code></pre></div><h3 id=application-level-generation>Application-Level Generation</h3><p><strong>Go example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kn>import</span><span class=w> </span><span class=s>&#34;github.com/oklog/ulid/v2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Standard generation</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>id</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>ulid</span><span class=p>.</span><span class=nf>Make</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=nx>id</span><span class=p>.</span><span class=nf>String</span><span class=p>())</span><span class=w> </span><span class=c1>// 01ARZ3NDEKTSV4RRFFQ69G5FAV</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Monotonic generation</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>entropy</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>ulid</span><span class=p>.</span><span class=nf>Monotonic</span><span class=p>(</span><span class=nx>rand</span><span class=p>.</span><span class=nf>New</span><span class=p>(</span><span class=nx>rand</span><span class=p>.</span><span class=nf>NewSource</span><span class=p>(</span><span class=nx>time</span><span class=p>.</span><span class=nf>Now</span><span class=p>().</span><span class=nf>UnixNano</span><span class=p>())),</span><span class=w> </span><span class=mi>0</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>id</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>ulid</span><span class=p>.</span><span class=nf>MustNew</span><span class=p>(</span><span class=nx>ulid</span><span class=p>.</span><span class=nf>Timestamp</span><span class=p>(</span><span class=nx>time</span><span class=p>.</span><span class=nf>Now</span><span class=p>()),</span><span class=w> </span><span class=nx>entropy</span><span class=p>)</span><span class=w>
</span></span></span></code></pre></div><h2 id=go-library-support>Go Library Support</h2><h3 id=-oklogulid-library>âœ… oklog/ulid Library</h3><p>The canonical Go library for ULIDs is <a href=https://github.com/oklog/ulid><code>github.com/oklog/ulid/v2</code></a>, which provides full ULID specification support with both standard and monotonic generation modes.</p><p><strong>Installation:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>go get github.com/oklog/ulid/v2
</span></span></code></pre></div><p><strong>Usage examples:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kn>import</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=s>&#34;crypto/rand&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=s>&#34;github.com/oklog/ulid/v2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Simple generation with default entropy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>id</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>ulid</span><span class=p>.</span><span class=nf>Make</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=nx>id</span><span class=p>.</span><span class=nf>String</span><span class=p>())</span><span class=w> </span><span class=c1>// e.g., 01ARZ3NDEKTSV4RRFFQ69G5FAV</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Monotonic generation for strict ordering</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>entropy</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>ulid</span><span class=p>.</span><span class=nf>Monotonic</span><span class=p>(</span><span class=nx>rand</span><span class=p>.</span><span class=nx>Reader</span><span class=p>,</span><span class=w> </span><span class=mi>0</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>id</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>ulid</span><span class=p>.</span><span class=nf>MustNew</span><span class=p>(</span><span class=nx>ulid</span><span class=p>.</span><span class=nf>Timestamp</span><span class=p>(</span><span class=nx>time</span><span class=p>.</span><span class=nf>Now</span><span class=p>()),</span><span class=w> </span><span class=nx>entropy</span><span class=p>)</span><span class=w>
</span></span></span></code></pre></div><h2 id=summary>Summary</h2><p>ULID represents an excellent choice for modern distributed systems:</p><p><strong>Key strengths:</strong></p><ol><li><strong>Fully decentralized</strong> - no coordination required</li><li><strong>URI-safe and compact</strong> - 26 characters, no special chars</li><li><strong>Excellent database performance</strong> - time-ordered, minimal fragmentation</li><li><strong>Human-readable</strong> - Crockford Base32 alphabet</li><li><strong>High collision resistance</strong> - 1.21 Ã— 10Â²â´ IDs per millisecond</li></ol><p><strong>Key considerations:</strong></p><ol><li>Not officially standardized (community spec)</li><li>Requires custom database functions (no native support)</li><li>Exposes creation timestamp (like UUID v7)</li><li>Slightly more complex than UUID v4 generation</li></ol><p><strong>Bottom line:</strong>
ULID is an excellent choice when you value compact, human-readable identifiers and don&rsquo;t require strict RFC compliance. For official standardization, UUID v7 offers similar performance with growing vendor support.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c0553e3c5388fa96911545ec8861a4bf>1.1.3 - Snowflake ID Analysis</h1><h2 id=overview>Overview</h2><p>Snowflake IDs are 64-bit unique identifiers originally developed by Twitter (now X) in 2010 to replace auto-incrementing integer IDs that became problematic as they scaled across multiple database shards. The format has been widely adopted by other distributed systems including Discord, Instagram, and many platforms requiring globally unique, time-ordered identifiers.</p><p><strong>Key differentiator:</strong> Half the size of UUIDs/ULIDs while maintaining distributed generation and time-ordering properties.</p><h2 id=uri-safety>URI Safety</h2><h3 id=-completely-uri-safe>âœ… Completely URI-Safe</h3><p>Snowflake IDs are inherently URI-safe in their native numeric form.</p><p><strong>Native format:</strong></p><ul><li>64-bit signed integer</li><li>Decimal string representation: 18-19 characters</li><li>Contains only digits: <code>0-9</code></li><li>No URL encoding required</li></ul><p><strong>Usage examples:</strong></p><pre tabindex=0><code>https://api.twitter.com/tweets/175928847299117063
https://discord.com/api/users/53908232506183680
</code></pre><h3 id=alternative-encodings>Alternative Encodings</h3><h4 id=decimal-string-recommended>Decimal String (Recommended)</h4><pre tabindex=0><code>175928847299117063
</code></pre><ul><li>Most common format (Twitter, Discord, etc.)</li><li>No encoding required</li><li>Human-readable (though not easily interpretable)</li><li>Length: 18-19 characters</li><li>Safe for both path parameters and query strings</li></ul><h4 id=base62-encoding>Base62 Encoding</h4><pre tabindex=0><code>2BisCQ
</code></pre><ul><li>Often used in URL shorteners</li><li>Compact, alphanumeric identifiers</li><li>No special characters requiring URL encoding</li><li>Length: ~11 characters</li><li>Characters: <code>[A-Za-z0-9]</code></li></ul><h4 id=base64url-encoding>Base64URL Encoding</h4><pre tabindex=0><code>AJ8CWJ-eR2Q
</code></pre><ul><li>Used by Twitter for media keys</li><li>URL-safe alphabet: <code>-</code> and <code>_</code> instead of <code>+</code> and <code>/</code></li><li>Padding (<code>=</code>) typically omitted</li><li>Length: ~11 characters</li></ul><h3 id=encoding-concerns>Encoding Concerns</h3><p><strong>None for standard numeric representation.</strong> Snowflake IDs as decimal integers naturally comply with URI specifications (RFC 3986) as unreserved characters.</p><h2 id=database-storage-and-performance>Database Storage and Performance</h2><h3 id=storage-size>Storage Size</h3><p><strong>8 bytes (64 bits)</strong> per Snowflake ID</p><p><strong>Comparison table:</strong></p><table><thead><tr><th>ID Type</th><th>Storage Size</th><th>vs Snowflake</th></tr></thead><tbody><tr><td><strong>Snowflake ID</strong></td><td>8 bytes</td><td>baseline</td></tr><tr><td>Auto-increment INT32</td><td>4 bytes</td><td>0.5Ã—</td></tr><tr><td>Auto-increment BIGINT</td><td>8 bytes</td><td>1Ã—</td></tr><tr><td>UUID/ULID (binary)</td><td>16 bytes</td><td>2Ã— larger</td></tr><tr><td>UUID (string)</td><td>36 bytes</td><td>4.5Ã— larger</td></tr></tbody></table><p><strong>Impact at scale:</strong></p><ul><li>For Twitter&rsquo;s billions of tweets, 8-byte advantage over UUIDs saves massive storage</li><li>Reduced memory footprint for indexes</li><li>Better cache utilization</li><li>Lower network transfer costs</li></ul><h3 id=index-performance>Index Performance</h3><p>Snowflake IDs provide <strong>exceptional B-tree index performance</strong> due to their time-ordered nature.</p><h4 id=sequential-insert-benefits>Sequential Insert Benefits</h4><p><strong>Optimal write performance:</strong></p><ul><li>âœ… No page splits (appends to end of index)</li><li>âœ… No expensive B-tree reorganizations</li><li>âœ… Minimal I/O (sequential writes minimize disk seeks)</li><li>âœ… Better cache utilization (hot pages remain in memory)</li></ul><h4 id=comparison-to-random-ids>Comparison to Random IDs</h4><p><strong>UUID v4 causes:</strong></p><ul><li>âŒ Random index insertions throughout tree</li><li>âŒ Frequent page splits and reorganizations</li><li>âŒ Index fragmentation</li><li>âŒ Reduced cache efficiency</li><li>âŒ Higher write amplification</li></ul><p><strong>Benchmarks:</strong></p><ul><li>Snowflake IDs: <strong>Lower mean, variance, and standard deviation</strong> for ordered operations</li><li>UUID v4: <strong>Very high variance</strong> with unstable performance</li><li>Snowflake: <strong>Significantly better</strong> for ordered queries</li></ul><h3 id=time-ordered-nature-and-benefits>Time-Ordered Nature and Benefits</h3><p>The first 41 bits represent a timestamp (milliseconds since epoch), providing natural time-ordering.</p><h4 id=query-optimization>Query Optimization</h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Time-range queries are highly efficient
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>tweets</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>WHERE</span><span class=w> </span><span class=n>tweet_id</span><span class=w> </span><span class=o>&gt;=</span><span class=w> </span><span class=mi>175928847299117063</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=k>AND</span><span class=w> </span><span class=n>tweet_id</span><span class=w> </span><span class=o>&lt;=</span><span class=w> </span><span class=mi>175928847299999999</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p><strong>Benefits:</strong></p><ul><li>Database can use range scans effectively</li><li>No need for separate <code>created_at</code> timestamp indexes (in many cases)</li><li>Natural partitioning by time is straightforward</li><li>Query planner optimizations leverage time-ordering</li></ul><h4 id=sorting-benefits>Sorting Benefits</h4><ul><li>IDs are <strong>lexicographically sortable</strong> by creation time</li><li><code>ORDER BY id</code> implicitly orders by creation time</li><li>No need for separate sort operations in many scenarios</li><li>Simpler query plans</li></ul><h4 id=data-partitioning>Data Partitioning</h4><ul><li>Time-based partitioning schemes align naturally with ID ranges</li><li>Simplifies archival strategies</li><li>Facilitates efficient data retention policies</li><li>Easy to implement hot/cold data separation</li></ul><h3 id=impact-on-database-operations>Impact on Database Operations</h3><p><strong>Write operations:</strong></p><ul><li>âœ… <strong>INSERT</strong>: Exceptional performance (sequential, append-only)</li><li>âœ… <strong>Batch inserts</strong>: Highly efficient due to sequential nature</li><li>âœ… <strong>Index maintenance</strong>: Minimal overhead</li></ul><p><strong>Read operations:</strong></p><ul><li>âœ… <strong>Point queries by ID</strong>: Standard B-tree performance (O(log n))</li><li>âœ… <strong>Range queries</strong>: Excellent for time-based ranges</li><li>âœ… <strong>Ordered queries</strong>: Superior to UUID-based systems</li><li>âš ï¸ <strong>Join operations</strong>: Standard performance (64-bit integer comparison)</li></ul><p><strong>Storage:</strong></p><ul><li>âœ… <strong>Primary key</strong>: 8 bytes (optimal for 64-bit systems)</li><li>âœ… <strong>Foreign keys</strong>: 8 bytes</li><li>âœ… <strong>Index size</strong>: 50% smaller than UUID-based indexes</li><li>âœ… <strong>Memory footprint</strong>: More cache-efficient than UUIDs</li></ul><h3 id=comparison-to-other-numeric-ids>Comparison to Other Numeric IDs</h3><table><thead><tr><th>ID Type</th><th>Size</th><th>Time-Ordered</th><th>Distributed</th><th>Index Perf</th><th>Sortable by Time</th></tr></thead><tbody><tr><td><strong>Snowflake</strong></td><td>8 bytes</td><td>âœ… Yes</td><td>âœ… Yes</td><td>Excellent</td><td>âœ… Yes</td></tr><tr><td>Auto-increment</td><td>4-8 bytes</td><td>âœ… Yes</td><td>âŒ No</td><td>Excellent</td><td>âœ… Yes</td></tr><tr><td>UUID v4</td><td>16 bytes</td><td>âŒ No</td><td>âœ… Yes</td><td>Poor</td><td>âŒ No</td></tr><tr><td>UUID v7</td><td>16 bytes</td><td>âœ… Yes</td><td>âœ… Yes</td><td>Good</td><td>âœ… Yes</td></tr><tr><td>ULID</td><td>16 bytes</td><td>âœ… Yes</td><td>âœ… Yes</td><td>Good</td><td>âœ… Yes</td></tr></tbody></table><p><strong>Unique combination:</strong></p><ul><li>Distributed generation capability (like UUID)</li><li>Time-ordered properties (like auto-increment)</li><li><strong>Compact size (8 bytes)</strong></li><li>Excellent index performance</li></ul><h2 id=generation-approach>Generation Approach</h2><h3 id=-mostly-decentralized>âš ï¸ Mostly Decentralized</h3><p>Snowflake IDs can be generated in a <strong>mostly decentralized manner</strong> with minimal coordination.</p><p><strong>Key characteristics:</strong></p><ul><li>âœ… No centralized coordination during ID generation</li><li>âœ… No network calls required between generators</li><li>âœ… No database round-trips for ID allocation</li><li>âœ… High throughput: Up to 4,096 IDs per millisecond per worker</li><li>âœ… Low latency: Sub-microsecond generation time</li><li>âš ï¸ Requires one-time worker ID allocation</li></ul><h3 id=structure-breakdown>Structure Breakdown</h3><p>A Snowflake ID is a <strong>63-bit signed integer</strong> (within 64-bit type):</p><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Timestamp (41 bits)            â”‚ Worker (10)  â”‚ Sequence (12)|
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â† Most Significant                                  Least Significant â†’
</code></pre><h4 id=1-timestamp-component-41-bits>1. Timestamp Component (41 bits)</h4><p><strong>Purpose:</strong> Milliseconds since custom epoch</p><p><strong>Characteristics:</strong></p><ul><li>Range: ~69 years of unique timestamps</li><li>Epoch: Configurable (Twitter: 1288834974657, Discord: 1420070400000)</li><li>Most significant bits ensure chronological sorting</li><li>Enables time-range queries</li></ul><p><strong>Benefits:</strong></p><ul><li>Provides time-ordering</li><li>Natural partitioning by time</li><li>Debugging aid (can decode timestamp)</li></ul><h4 id=2-workermachine-id-10-bits>2. Worker/Machine ID (10 bits)</h4><p><strong>Purpose:</strong> Identifies the generator node</p><p><strong>Characteristics:</strong></p><ul><li>Range: 0-1023 (1,024 unique workers)</li><li>Often split further:<ul><li><strong>Twitter original</strong>: 5-bit datacenter ID + 5-bit worker ID</li><li><strong>Discord</strong>: 5-bit worker ID + 5-bit process ID</li><li><strong>Custom</strong>: Can be adapted to organizational needs</li></ul></li></ul><p><strong>Critical requirement:</strong> Each worker MUST have a unique ID</p><h4 id=3-sequence-number-12-bits>3. Sequence Number (12 bits)</h4><p><strong>Purpose:</strong> Counter for IDs generated in same millisecond</p><p><strong>Characteristics:</strong></p><ul><li>Range: 0-4095 (4,096 IDs per millisecond per worker)</li><li>Increments for each ID within the same millisecond</li><li>Resets to 0 when millisecond changes</li><li><strong>If exhausted</strong>: Generator waits until next millisecond</li></ul><p><strong>System-wide capacity:</strong></p><ul><li>Per worker: 4,096,000 IDs per second</li><li>With 1,024 workers: ~4.2 billion IDs per second theoretical maximum</li></ul><h3 id=centralized-coordination-requirements>Centralized Coordination Requirements</h3><p><strong>Minimal coordination required, but only during initial setup:</strong></p><h4 id=what-requires-coordination-one-time>What Requires Coordination (One-Time):</h4><ol><li>âœ… <strong>Worker ID allocation</strong> (during node provisioning)</li><li>âœ… <strong>Epoch selection</strong> (at system design time)</li><li>âš ï¸ <strong>Clock synchronization</strong> (ongoing, but not critical)</li></ol><h4 id=what-does-not-require-coordination>What Does NOT Require Coordination:</h4><ul><li>âŒ Individual ID generation</li><li>âŒ Real-time communication between nodes</li><li>âŒ Distributed locks or consensus</li><li>âŒ Database queries for next ID</li></ul><h3 id=worker-id-allocation-requirements>Worker ID Allocation Requirements</h3><p><strong>This is the primary coordination challenge in Snowflake ID systems.</strong></p><h4 id=static-allocation-simple>Static Allocation (Simple)</h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># Configuration file</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>servers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>host</span><span class=p>:</span><span class=w> </span><span class=l>server-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>worker_id</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>host</span><span class=p>:</span><span class=w> </span><span class=l>server-2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>worker_id</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>host</span><span class=p>:</span><span class=w> </span><span class=l>server-3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>worker_id</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span></code></pre></div><p><strong>Pros:</strong></p><ul><li>âœ… Simple to implement</li><li>âœ… No runtime coordination</li><li>âœ… Predictable and debuggable</li></ul><p><strong>Cons:</strong></p><ul><li>âŒ Doesn&rsquo;t work with auto-scaling</li><li>âŒ Manual reconfiguration needed</li><li>âŒ Worker ID exhaustion in large deployments</li></ul><h4 id=dynamic-allocation-complex>Dynamic Allocation (Complex)</h4><p><strong>Common strategies for dynamic environments:</strong></p><p><strong>1. Zookeeper/etcd Coordination</strong></p><pre tabindex=0><code>- Nodes register and receive unique worker IDs
- Lease-based assignment with TTL
- Automatic reclamation of dead workers
</code></pre><ul><li>âœ… Automatic worker ID management</li><li>âŒ Requires external coordination service</li><li>âŒ Added operational complexity</li></ul><p><strong>2. Database-Based Registry</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>worker_registry</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>worker_id</span><span class=w> </span><span class=nb>INT</span><span class=w> </span><span class=k>PRIMARY</span><span class=w> </span><span class=k>KEY</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>instance_id</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>(</span><span class=mi>255</span><span class=p>),</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>last_heartbeat</span><span class=w> </span><span class=k>TIMESTAMP</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><ul><li>âœ… No additional infrastructure</li><li>âŒ Database dependency</li><li>âŒ Requires heartbeat mechanism</li></ul><p><strong>3. Consistent Hashing</strong></p><pre tabindex=0><code>worker_id = hash(node_ip_or_mac) % 1024
</code></pre><ul><li>âœ… No coordination needed</li><li>âŒ Risk of collisions in large clusters</li><li>âŒ Requires careful hash function selection</li></ul><p><strong>4. Container Orchestration Integration</strong></p><pre tabindex=0><code>- Kubernetes StatefulSets with ordinal indexes
- Cloud provider instance metadata
- Environment variable injection
</code></pre><ul><li>âœ… Integrates with existing infrastructure</li><li>âŒ Platform-specific</li><li>âŒ May limit to 1,024 pods/instances</li></ul><p><strong>Challenge in auto-scaling:</strong></p><blockquote><p>&ldquo;In a dynamic environment with auto-scaling, managing worker IDs becomes challenging. You need a strategy to assign unique worker IDs to new instances.&rdquo;</p></blockquote><h3 id=collision-avoidance-mechanisms>Collision Avoidance Mechanisms</h3><p>Snowflake IDs guarantee uniqueness through multiple layers:</p><h4 id=1-temporal-uniqueness>1. Temporal Uniqueness</h4><ul><li>41-bit timestamp ensures different milliseconds get different IDs</li><li>System clock monotonicity prevents duplicate timestamps</li></ul><h4 id=2-spatial-uniqueness>2. Spatial Uniqueness</h4><ul><li>10-bit worker ID ensures different nodes generate different IDs</li><li><strong>Critical requirement:</strong> Each worker MUST have a unique ID</li></ul><h4 id=3-sequential-uniqueness>3. Sequential Uniqueness</h4><ul><li>12-bit sequence counter within same millisecond</li><li>Allows up to 4,096 IDs per worker per millisecond</li></ul><h4 id=mathematical-guarantee>Mathematical Guarantee</h4><pre tabindex=0><code>Unique ID = f(timestamp, worker_id, sequence)
</code></pre><p><strong>As long as:</strong></p><ul><li><code>worker_id</code> is unique per node (most critical)</li><li>Clock doesn&rsquo;t move backwards significantly</li><li>Sequence doesn&rsquo;t overflow (wait 1ms if it does)</li></ul><p><strong>Then collisions are mathematically impossible.</strong></p><h3 id=collision-risk-scenarios>Collision Risk Scenarios</h3><p><strong>Very Low Risk:</strong></p><ul><li>âš ï¸ Clock skew between nodes (IDs remain unique, may not be perfectly ordered)</li><li>âš ï¸ Leap second handling (typically managed by NTP)</li></ul><p><strong>High Risk (Configuration Errors):</strong></p><ul><li>âŒ <strong>Duplicate worker IDs:</strong> Multiple nodes with same worker ID</li><li>âŒ <strong>Clock moving backwards:</strong> System time reset or NTP correction</li><li>âŒ <strong>Worker ID overflow:</strong> Attempting to use more than 1,024 workers</li></ul><h3 id=generation-rate-limits>Generation Rate Limits</h3><p><strong>Per worker:</strong></p><ul><li>Maximum: 4,096 IDs per millisecond</li><li>Per second: 4,096,000 IDs per worker</li><li>Typical usage: Far below maximum in most applications</li></ul><p><strong>Handling exhaustion:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=c1>// Pseudocode</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>if</span><span class=w> </span><span class=nx>sequence</span><span class=w> </span><span class=o>&gt;=</span><span class=w> </span><span class=mi>4096</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c1>// Wait until next millisecond</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nf>waitUntil</span><span class=p>(</span><span class=nx>nextMillisecond</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nx>sequence</span><span class=w> </span><span class=p>=</span><span class=w> </span><span class=mi>0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><h2 id=implementation-considerations>Implementation Considerations</h2><h3 id=advantages>Advantages</h3><ul><li>âœ… <strong>No single point of failure</strong> (after worker ID allocation)</li><li>âœ… <strong>Minimal coordination overhead</strong></li><li>âœ… <strong>Extremely high throughput</strong></li><li>âœ… <strong>Low generation latency</strong></li><li>âœ… <strong>Natural load distribution</strong></li><li>âœ… <strong>Smallest storage size</strong> (8 bytes)</li><li>âœ… <strong>Best database performance</strong></li></ul><h3 id=disadvantages>Disadvantages</h3><ul><li>âš ï¸ <strong>Requires unique worker ID management</strong></li><li>âš ï¸ <strong>Clock synchronization needed</strong> (NTP recommended)</li><li>âš ï¸ <strong>Fixed worker limit</strong> (1,024 without redesign)</li><li>âš ï¸ <strong>Not truly random</strong> (predictable structure)</li><li>âš ï¸ <strong>Information leakage</strong> (creation time, rough volume)</li><li>âš ï¸ <strong>Auto-scaling complexity</strong> (worker ID allocation)</li></ul><h2 id=security-considerations>Security Considerations</h2><h3 id=information-leakage>Information Leakage</h3><p>Snowflake IDs reveal more information than UUIDs:</p><p><strong>What&rsquo;s exposed:</strong></p><ul><li>âš ï¸ <strong>Exact creation time</strong> (41-bit timestamp)</li><li>âš ï¸ <strong>Which worker generated it</strong> (10-bit worker ID)</li><li>âš ï¸ <strong>Sequence count</strong> within millisecond (12-bit sequence)</li></ul><p><strong>Potential concerns:</strong></p><ul><li>Business activity levels can be inferred</li><li>Worker distribution visible</li><li>Timeline of events can be reconstructed</li></ul><h3 id=enumeration-attacks>Enumeration Attacks</h3><p><strong>Predictable patterns:</strong></p><ul><li>âš ï¸ Can estimate next ID value</li><li>âš ï¸ Can enumerate recent IDs</li><li>âš ï¸ Can probe for existence of IDs in ranges</li></ul><p><strong>Mitigation:</strong></p><ul><li>âœ… Use authentication/authorization (don&rsquo;t rely on ID secrecy)</li><li>âœ… Implement rate limiting</li><li>âœ… Add additional access controls</li><li>âœ… Consider signing/encrypting IDs if necessary</li></ul><p><strong>Important:</strong> Never rely on ID unpredictability as a security mechanism.</p><h2 id=real-world-implementations>Real-World Implementations</h2><h3 id=twitter-original>Twitter (Original)</h3><pre tabindex=0><code>1 bit (unused) + 41 bits (timestamp) + 5 bits (datacenter) +
5 bits (worker) + 12 bits (sequence)
</code></pre><ul><li>Epoch: November 4, 2010, 01:42:54 UTC</li><li>32 datacenters, 32 workers per datacenter</li><li>Up to 4,096 IDs per millisecond per worker</li></ul><h3 id=discord>Discord</h3><pre tabindex=0><code>1 bit (unused) + 41 bits (timestamp) + 5 bits (worker) +
5 bits (process) + 12 bits (sequence)
</code></pre><ul><li>Epoch: January 1, 2015, 00:00:00 UTC</li><li>Allows multiple processes per worker</li><li>Custom epoch for longer lifespan</li></ul><h3 id=instagram>Instagram</h3><ul><li>Similar structure to Twitter</li><li>Sharded database architecture</li><li>Combines Snowflake with PostgreSQL sequences</li></ul><h2 id=go-library-support>Go Library Support</h2><h3 id=-bwmarrinsnowflake-library>âœ… bwmarrin/snowflake Library</h3><p>The most popular Go library for Snowflake IDs is <a href=https://github.com/bwmarrin/snowflake><code>github.com/bwmarrin/snowflake</code></a>, which provides a production-ready implementation with configurable epoch and node ID.</p><p><strong>Installation:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>go get github.com/bwmarrin/snowflake
</span></span></code></pre></div><p><strong>Usage example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kn>import</span><span class=w> </span><span class=s>&#34;github.com/bwmarrin/snowflake&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Create a new node with worker ID (must be unique per instance)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>node</span><span class=p>,</span><span class=w> </span><span class=nx>err</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>snowflake</span><span class=p>.</span><span class=nf>NewNode</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span><span class=w> </span><span class=c1>// Worker ID: 1 (range: 0-1023)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>if</span><span class=w> </span><span class=nx>err</span><span class=w> </span><span class=o>!=</span><span class=w> </span><span class=kc>nil</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nx>log</span><span class=p>.</span><span class=nf>Fatal</span><span class=p>(</span><span class=nx>err</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Generate a Snowflake ID</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>id</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>node</span><span class=p>.</span><span class=nf>Generate</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=nx>id</span><span class=p>.</span><span class=nf>Int64</span><span class=p>())</span><span class=w>   </span><span class=c1>// e.g., 175928847299117063</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=nx>id</span><span class=p>.</span><span class=nf>String</span><span class=p>())</span><span class=w>  </span><span class=c1>// e.g., &#34;175928847299117063&#34;</span><span class=w>
</span></span></span></code></pre></div><p><strong>Alternative: sony/sonyflake</strong></p><p><a href=https://github.com/sony/sonyflake><code>github.com/sony/sonyflake</code></a> is another option that uses a different bit layout (39-bit time, 8-bit sequence, 16-bit machine ID), providing finer-grained machine ID space at the cost of time precision.</p><h2 id=migration-strategies>Migration Strategies</h2><h3 id=from-auto-increment>From Auto-Increment</h3><p><strong>Considerations:</strong></p><ul><li>Must provision worker ID allocation system</li><li>May need to widen integer columns (INT to BIGINT)</li><li>Application code changes for ID generation</li><li>Foreign key updates required</li></ul><p><strong>Recommended approach:</strong></p><ol><li>Add Snowflake ID column alongside auto-increment</li><li>Generate Snowflake IDs for existing rows</li><li>Update application to use Snowflake IDs for new records</li><li>Migrate foreign keys progressively</li><li>Eventually remove auto-increment column</li></ol><h3 id=from-uuid>From UUID</h3><p><strong>Considerations:</strong></p><ul><li>Significant storage reduction (16 â†’ 8 bytes)</li><li>Different data type (binary/string â†’ bigint)</li><li>Worker ID allocation system needed</li><li>May require application changes</li></ul><p><strong>Benefits:</strong></p><ul><li>50% storage reduction</li><li>Better performance</li><li>Numeric type easier for some use cases</li></ul><h2 id=summary>Summary</h2><p>Snowflake IDs represent an elegant solution for distributed systems:</p><p><strong>Key Strengths:</strong></p><ol><li><strong>Compact size:</strong> 8 bytes (half of UUID/ULID)</li><li><strong>Excellent performance:</strong> Sequential insertion, optimal for B-trees</li><li><strong>Time-ordered:</strong> Natural sorting and partitioning</li><li><strong>High throughput:</strong> Millions of IDs per second per worker</li><li><strong>URI-safe:</strong> Decimal integers require no encoding</li></ol><p><strong>Key Challenges:</strong></p><ol><li><strong>Worker ID management:</strong> Requires coordination (one-time)</li><li><strong>Auto-scaling complexity:</strong> Dynamic worker ID allocation needed</li><li><strong>Information leakage:</strong> Exposes timestamp and worker information</li><li><strong>Fixed limits:</strong> 1,024 workers without redesign</li></ol><p><strong>Best For:</strong></p><ul><li>High-scale distributed systems with predictable worker counts</li><li>Storage-constrained environments</li><li>Systems requiring time-ordered numeric IDs</li><li>Applications where 8-byte size matters</li></ul><p><strong>Consider Alternatives When:</strong></p><ul><li>Auto-scaling is critical and worker ID management is complex</li><li>Strict randomness required (use UUID v4)</li><li>Official standardization needed (use UUID v7)</li><li>More than 1,024 concurrent generators needed</li></ul><p><strong>Bottom Line:</strong>
For systems that can manage worker IDs and value storage efficiency, Snowflake IDs offer the best combination of size, performance, and distributed generation capabilities.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d96c900d85acfbbf726f419f7a9837ce>1.2 - Server Operating System Analysis</h1><div class=lead>Evaluation of operating systems for homelab Kubernetes infrastructure</div><p>This section provides detailed analysis of operating systems evaluated for the homelab server infrastructure, with a focus on Kubernetes cluster setup and maintenance.</p><h2 id=overview>Overview</h2><p>The selection of a server operating system is critical for homelab infrastructure. The primary evaluation criterion is ease of Kubernetes cluster initialization and ongoing maintenance burden.</p><h2 id=evaluated-options>Evaluated Options</h2><ul><li><p><a href=./ubuntu/><strong>Ubuntu</strong></a> - Traditional general-purpose Linux distribution</p><ul><li>Kubernetes via kubeadm, k3s, or MicroK8s</li><li>Strong community support and extensive documentation</li><li>Familiar package management and system administration</li></ul></li><li><p><a href=./fedora/><strong>Fedora</strong></a> - Cutting-edge Linux distribution</p><ul><li>Latest kernel and system components</li><li>Kubernetes via kubeadm or k3s</li><li>Shorter support lifecycle with more frequent upgrades</li></ul></li><li><p><a href=./talos-linux/><strong>Talos Linux</strong></a> - Purpose-built Kubernetes OS</p><ul><li>API-driven, immutable infrastructure</li><li>Built-in Kubernetes with minimal attack surface</li><li>Designed specifically for container workloads</li></ul></li><li><p><a href=./harvester/><strong>Harvester</strong></a> - Hyperconverged infrastructure platform</p><ul><li>Built on Rancher and K3s</li><li>Combines compute, storage, and networking</li><li>VM and container workloads on unified platform</li></ul></li></ul><h2 id=evaluation-criteria>Evaluation Criteria</h2><p>Each option is evaluated based on:</p><ol><li><strong>Kubernetes Installation Methods</strong> - Available tooling and installation approaches</li><li><strong>Cluster Initialization Process</strong> - Steps required to bootstrap a cluster</li><li><strong>Maintenance Requirements</strong> - OS updates, Kubernetes upgrades, security patches</li><li><strong>Resource Overhead</strong> - Memory, CPU, and storage footprint</li><li><strong>Learning Curve</strong> - Ease of adoption and operational complexity</li><li><strong>Community Support</strong> - Documentation quality and ecosystem maturity</li><li><strong>Security Posture</strong> - Attack surface and security-first design</li></ol><h2 id=related-adrs>Related ADRs</h2><ul><li><a href=../../adrs/0004-server-operating-system/>ADR-0004: Server Operating System Selection</a> - Final decision based on this analysis</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2b6064c84b17aa5904b4749ff38d16b2>1.2.1 - Ubuntu Analysis</h1><div class=lead>Analysis of Ubuntu for Kubernetes homelab infrastructure</div><h2 id=overview>Overview</h2><p>Ubuntu Server is a popular general-purpose Linux distribution developed by Canonical. It provides Long Term Support (LTS) releases with 5 years of standard support and optional Extended Security Maintenance (ESM).</p><p><strong>Key Facts</strong>:</p><ul><li><strong>Latest LTS</strong>: Ubuntu 24.04 LTS (Noble Numbat)</li><li><strong>Support Period</strong>: 5 years standard, 10 years with Ubuntu Pro (free for personal use)</li><li><strong>Kernel</strong>: Linux 6.8+ (LTS), regular HWE updates</li><li><strong>Package Manager</strong>: APT/DPKG, Snap</li><li><strong>Init System</strong>: systemd</li></ul><h2 id=kubernetes-installation-methods>Kubernetes Installation Methods</h2><p>Ubuntu supports multiple Kubernetes installation approaches:</p><h3 id=1-kubeadm-official-kubernetes-tool>1. kubeadm (Official Kubernetes Tool)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install container runtime (containerd)</span>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y containerd
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure containerd</span>
</span></span><span class=line><span class=cl>sudo mkdir -p /etc/containerd
</span></span><span class=line><span class=cl>containerd config default <span class=p>|</span> sudo tee /etc/containerd/config.toml
</span></span><span class=line><span class=cl>sudo systemctl restart containerd
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install kubeadm, kubelet, kubectl</span>
</span></span><span class=line><span class=cl>sudo apt-get install -y apt-transport-https ca-certificates curl gpg
</span></span><span class=line><span class=cl>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key <span class=p>|</span> sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /&#39;</span> <span class=p>|</span> sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y kubelet kubeadm kubectl
</span></span><span class=line><span class=cl>sudo apt-mark hold kubelet kubeadm kubectl
</span></span></code></pre></div><p><strong>Cluster Initialization</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Initialize control plane</span>
</span></span><span class=line><span class=cl>sudo kubeadm init --pod-network-cidr<span class=o>=</span>10.244.0.0/16
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure kubectl for admin</span>
</span></span><span class=line><span class=cl>mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install CNI (e.g., Calico, Flannel)</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Join worker nodes</span>
</span></span><span class=line><span class=cl>kubeadm token create --print-join-command
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Official Kubernetes tooling, well-documented</li><li>Full control over cluster configuration</li><li>Supports latest Kubernetes versions</li><li>Large community and extensive resources</li></ul><p><strong>Cons</strong>:</p><ul><li>More manual steps than turnkey solutions</li><li>Requires understanding of Kubernetes architecture</li><li>Manual upgrade process for each component</li><li>More complex troubleshooting</li></ul><h3 id=2-k3s-lightweight-kubernetes>2. k3s (Lightweight Kubernetes)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Single-command install on control plane</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> sh -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get node token for workers</span>
</span></span><span class=line><span class=cl>sudo cat /var/lib/rancher/k3s/server/node-token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install on worker nodes</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> <span class=nv>K3S_URL</span><span class=o>=</span>https://control-plane:6443 <span class=nv>K3S_TOKEN</span><span class=o>=</span>&lt;token&gt; sh -
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Extremely simple installation (single command)</li><li>Lightweight (&lt; 512MB RAM)</li><li>Built-in container runtime (containerd)</li><li>Automatic updates via Rancher System Upgrade Controller</li><li>Great for edge and homelab use cases</li></ul><p><strong>Cons</strong>:</p><ul><li>Less customizable than kubeadm</li><li>Some features removed (e.g., in-tree storage, cloud providers)</li><li>Slightly different from upstream Kubernetes</li></ul><h3 id=3-microk8s-canonicals-distribution>3. MicroK8s (Canonical&rsquo;s Distribution)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install via snap</span>
</span></span><span class=line><span class=cl>sudo snap install microk8s --classic
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Join cluster</span>
</span></span><span class=line><span class=cl>sudo microk8s add-node
</span></span><span class=line><span class=cl><span class=c1># Run output command on worker nodes</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Enable addons</span>
</span></span><span class=line><span class=cl>microk8s <span class=nb>enable</span> dns storage ingress
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Zero-ops, single package install</li><li>Snap-based automatic updates</li><li>Addons for common services (DNS, storage, ingress)</li><li>Canonical support available</li></ul><p><strong>Cons</strong>:</p><ul><li>Requires snap (not universally liked)</li><li>Less ecosystem compatibility than vanilla Kubernetes</li><li>Ubuntu-specific (less portable)</li></ul><h2 id=cluster-initialization-sequence>Cluster Initialization Sequence</h2><h3 id=kubeadm-approach>kubeadm Approach</h3><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Ubuntu Server
    participant K8s as Kubernetes Components
    
    Admin-&gt;&gt;Server: Install Ubuntu 24.04 LTS
    Server-&gt;&gt;Server: Configure network (static IP)
    Admin-&gt;&gt;Server: Update system (apt update &amp;&amp; upgrade)
    Admin-&gt;&gt;Server: Install containerd
    Server-&gt;&gt;Server: Configure containerd (CRI)
    Admin-&gt;&gt;Server: Install kubeadm/kubelet/kubectl
    Server-&gt;&gt;Server: Disable swap, configure kernel modules
    Admin-&gt;&gt;K8s: kubeadm init --pod-network-cidr=10.244.0.0/16
    K8s-&gt;&gt;Server: Generate certificates
    K8s-&gt;&gt;Server: Start etcd
    K8s-&gt;&gt;Server: Start API server
    K8s-&gt;&gt;Server: Start controller-manager
    K8s-&gt;&gt;Server: Start scheduler
    K8s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;K8s: kubectl apply -f calico.yaml
    K8s-&gt;&gt;Server: Deploy CNI pods
    Admin-&gt;&gt;K8s: kubeadm join (on workers)
    K8s-&gt;&gt;Server: Add worker nodes
    K8s--&gt;&gt;Admin: Cluster ready</pre><h3 id=k3s-approach>k3s Approach</h3><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Ubuntu Server
    participant K3s as k3s Components
    
    Admin-&gt;&gt;Server: Install Ubuntu 24.04 LTS
    Server-&gt;&gt;Server: Configure network (static IP)
    Admin-&gt;&gt;Server: Update system
    Admin-&gt;&gt;Server: curl -sfL https://get.k3s.io | sh -
    Server-&gt;&gt;K3s: Download k3s binary
    K3s-&gt;&gt;Server: Configure containerd
    K3s-&gt;&gt;Server: Start k3s service
    K3s-&gt;&gt;Server: Initialize etcd (embedded)
    K3s-&gt;&gt;Server: Start API server
    K3s-&gt;&gt;Server: Start controller-manager
    K3s-&gt;&gt;Server: Start scheduler
    K3s-&gt;&gt;Server: Deploy built-in CNI (Flannel)
    K3s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;Server: Retrieve node token
    Admin-&gt;&gt;Server: Install k3s agent on workers
    K3s-&gt;&gt;Server: Join workers to cluster
    K3s--&gt;&gt;Admin: Cluster ready (5-10 minutes total)</pre><h2 id=maintenance-requirements>Maintenance Requirements</h2><h3 id=os-updates>OS Updates</h3><p><strong>Security Patches</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Automatic security updates (recommended)</span>
</span></span><span class=line><span class=cl>sudo apt-get install unattended-upgrades
</span></span><span class=line><span class=cl>sudo dpkg-reconfigure -plow unattended-upgrades
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Manual updates</span>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get upgrade
</span></span></code></pre></div><p><strong>Frequency</strong>:</p><ul><li>Security patches: Weekly to monthly</li><li>Kernel updates: Monthly (may require reboot)</li><li>Major version upgrades: Every 2 years (LTS to LTS)</li></ul><h3 id=kubernetes-upgrades>Kubernetes Upgrades</h3><p><strong>kubeadm Upgrade</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade control plane</span>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y <span class=nv>kubeadm</span><span class=o>=</span>1.32.0-*
</span></span><span class=line><span class=cl>sudo kubeadm upgrade apply v1.32.0
</span></span><span class=line><span class=cl>sudo apt-get install -y <span class=nv>kubelet</span><span class=o>=</span>1.32.0-* <span class=nv>kubectl</span><span class=o>=</span>1.32.0-*
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upgrade workers</span>
</span></span><span class=line><span class=cl>kubectl drain &lt;node&gt; --ignore-daemonsets
</span></span><span class=line><span class=cl>sudo apt-get install -y <span class=nv>kubeadm</span><span class=o>=</span>1.32.0-* <span class=nv>kubelet</span><span class=o>=</span>1.32.0-* <span class=nv>kubectl</span><span class=o>=</span>1.32.0-*
</span></span><span class=line><span class=cl>sudo kubeadm upgrade node
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span><span class=line><span class=cl>kubectl uncordon &lt;node&gt;
</span></span></code></pre></div><p><strong>k3s Upgrade</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Manual upgrade</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> <span class=nv>INSTALL_K3S_VERSION</span><span class=o>=</span>v1.32.0+k3s1 sh -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Automatic upgrade via system-upgrade-controller</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://github.com/rancher/system-upgrade-controller/releases/latest/download/system-upgrade-controller.yaml
</span></span></code></pre></div><p><strong>Upgrade Frequency</strong>: Every 3-6 months (Kubernetes minor versions)</p><h2 id=resource-overhead>Resource Overhead</h2><p><strong>Minimal Installation</strong> (Ubuntu Server + k3s):</p><ul><li><strong>RAM</strong>: ~512MB (OS) + 512MB (k3s) = 1GB total</li><li><strong>CPU</strong>: 1 core minimum, 2 cores recommended</li><li><strong>Disk</strong>: 10GB (OS) + 10GB (container images) = 20GB</li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><p><strong>Full Installation</strong> (Ubuntu Server + kubeadm):</p><ul><li><strong>RAM</strong>: ~512MB (OS) + 1-2GB (Kubernetes components) = 2GB+ total</li><li><strong>CPU</strong>: 2 cores minimum</li><li><strong>Disk</strong>: 15GB (OS) + 20GB (container images/etcd) = 35GB</li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><h2 id=security-posture>Security Posture</h2><p><strong>Strengths</strong>:</p><ul><li>Regular security updates via Ubuntu Security Team</li><li>AppArmor enabled by default</li><li>SELinux support available</li><li>Kernel hardening features (ASLR, stack protection)</li><li>Ubuntu Pro ESM for extended CVE coverage (free for personal use)</li></ul><p><strong>Attack Surface</strong>:</p><ul><li>Full general-purpose OS (larger attack surface than minimal OS)</li><li>Many installed packages by default (can be minimized)</li><li>Requires manual hardening for production use</li></ul><p><strong>Hardening Steps</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Disable unnecessary services</span>
</span></span><span class=line><span class=cl>sudo systemctl disable snapd.service
</span></span><span class=line><span class=cl>sudo systemctl disable bluetooth.service
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure firewall</span>
</span></span><span class=line><span class=cl>sudo ufw default deny incoming
</span></span><span class=line><span class=cl>sudo ufw default allow outgoing
</span></span><span class=line><span class=cl>sudo ufw allow 22/tcp
</span></span><span class=line><span class=cl>sudo ufw allow 6443/tcp  <span class=c1># Kubernetes API</span>
</span></span><span class=line><span class=cl>sudo ufw allow 10250/tcp <span class=c1># Kubelet</span>
</span></span><span class=line><span class=cl>sudo ufw <span class=nb>enable</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># CIS Kubernetes Benchmark compliance</span>
</span></span><span class=line><span class=cl><span class=c1># Use tools like kube-bench for validation</span>
</span></span></code></pre></div><h2 id=learning-curve>Learning Curve</h2><p><strong>Ease of Adoption</strong>: â­â­â­â­â­ (Excellent)</p><ul><li>Most familiar Linux distribution for many users</li><li>Extensive documentation and tutorials</li><li>Large community support (forums, Stack Overflow)</li><li>Straightforward package management</li><li>Similar to Debian-based systems</li></ul><p><strong>Required Knowledge</strong>:</p><ul><li>Basic Linux system administration (apt, systemd, networking)</li><li>Kubernetes concepts (pods, services, deployments)</li><li>Container runtime basics (containerd, Docker)</li><li>Text editor (vim, nano) for configuration</li></ul><h2 id=community-support>Community Support</h2><p><strong>Ecosystem Maturity</strong>: â­â­â­â­â­ (Excellent)</p><ul><li><strong>Documentation</strong>: Comprehensive official docs, community guides</li><li><strong>Community</strong>: Massive user base, active forums</li><li><strong>Commercial Support</strong>: Available from Canonical (Ubuntu Pro)</li><li><strong>Third-Party Tools</strong>: Excellent compatibility with all Kubernetes tools</li><li><strong>Tutorials</strong>: Abundant resources for Kubernetes on Ubuntu</li></ul><p><strong>Resources</strong>:</p><ul><li><a href=https://ubuntu.com/server/docs>Ubuntu Server Documentation</a></li><li><a href=https://ubuntu.com/kubernetes>Kubernetes on Ubuntu Guide</a></li><li><a href=https://docs.k3s.io/>k3s Documentation</a></li><li><a href=https://microk8s.io/docs>MicroK8s Documentation</a></li></ul><h2 id=pros-and-cons-summary>Pros and Cons Summary</h2><h3 id=pros>Pros</h3><ul><li>Good, because most familiar and well-documented Linux distribution</li><li>Good, because 5-year LTS support (10 years with Ubuntu Pro)</li><li>Good, because multiple Kubernetes installation options (kubeadm, k3s, MicroK8s)</li><li>Good, because k3s provides extremely simple setup (single command)</li><li>Good, because extensive package ecosystem (60,000+ packages)</li><li>Good, because strong community support and resources</li><li>Good, because automatic security updates available</li><li>Good, because low learning curve for most administrators</li><li>Good, because compatible with all Kubernetes tooling and addons</li><li>Good, because Ubuntu Pro free for personal use (extended security)</li></ul><h3 id=cons>Cons</h3><ul><li>Bad, because general-purpose OS has larger attack surface than minimal OS</li><li>Bad, because more resource overhead than purpose-built Kubernetes OS (1-2GB RAM)</li><li>Bad, because requires manual OS updates and reboots</li><li>Bad, because kubeadm setup is complex with many manual steps</li><li>Bad, because snap packages controversial (for MicroK8s)</li><li>Bad, because Kubernetes upgrades require manual intervention (unless using k3s auto-upgrade)</li><li>Bad, because managing OS + Kubernetes lifecycle separately increases complexity</li><li>Neutral, because many preinstalled packages (can be removed, but require effort)</li></ul><h2 id=recommendations>Recommendations</h2><p><strong>Best for</strong>:</p><ul><li>Users familiar with Ubuntu/Debian ecosystem</li><li>Homelabs requiring general-purpose server functionality (not just Kubernetes)</li><li>Teams wanting multiple Kubernetes installation options</li><li>Users prioritizing community support and documentation</li></ul><p><strong>Best Installation Method</strong>:</p><ul><li><strong>Homelab/Learning</strong>: k3s (simplest, auto-updates, lightweight)</li><li><strong>Production-like</strong>: kubeadm (full control, upstream Kubernetes)</li><li><strong>Ubuntu-specific</strong>: MicroK8s (Canonical support, snap-based)</li></ul><p><strong>Avoid if</strong>:</p><ul><li>Seeking minimal attack surface (consider Talos Linux)</li><li>Want infrastructure-as-code for OS layer (consider Talos Linux)</li><li>Prefer hyperconverged platform (consider Harvester)</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f8c94234b2c711850baec9a4a41ca4f8>1.2.2 - Fedora Analysis</h1><div class=lead>Analysis of Fedora Server for Kubernetes homelab infrastructure</div><h2 id=overview>Overview</h2><p>Fedora Server is a cutting-edge Linux distribution sponsored by Red Hat, serving as the upstream for Red Hat Enterprise Linux (RHEL). It emphasizes innovation with the latest software packages and kernel versions.</p><p><strong>Key Facts</strong>:</p><ul><li><strong>Latest Version</strong>: Fedora 41 (October 2024)</li><li><strong>Support Period</strong>: ~13 months per release (shorter than Ubuntu LTS)</li><li><strong>Kernel</strong>: Linux 6.11+ (latest stable)</li><li><strong>Package Manager</strong>: DNF/RPM, Flatpak</li><li><strong>Init System</strong>: systemd</li></ul><h2 id=kubernetes-installation-methods>Kubernetes Installation Methods</h2><p>Fedora supports standard Kubernetes installation approaches:</p><h3 id=1-kubeadm-official-kubernetes-tool>1. kubeadm (Official Kubernetes Tool)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install container runtime (CRI-O preferred on Fedora)</span>
</span></span><span class=line><span class=cl>sudo dnf install -y cri-o
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> --now crio
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Add Kubernetes repository</span>
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
</span></span></span><span class=line><span class=cl><span class=s>[kubernetes]
</span></span></span><span class=line><span class=cl><span class=s>name=Kubernetes
</span></span></span><span class=line><span class=cl><span class=s>baseurl=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/
</span></span></span><span class=line><span class=cl><span class=s>enabled=1
</span></span></span><span class=line><span class=cl><span class=s>gpgcheck=1
</span></span></span><span class=line><span class=cl><span class=s>gpgkey=https://pkgs.k8s.io/core:/stable:/v1.31/rpm/repodata/repomd.xml.key
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install kubeadm, kubelet, kubectl</span>
</span></span><span class=line><span class=cl>sudo dnf install -y kubelet kubeadm kubectl
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> --now kubelet
</span></span></code></pre></div><p><strong>Cluster Initialization</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Initialize control plane</span>
</span></span><span class=line><span class=cl>sudo kubeadm init --pod-network-cidr<span class=o>=</span>10.244.0.0/16 --cri-socket<span class=o>=</span>unix:///var/run/crio/crio.sock
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure kubectl</span>
</span></span><span class=line><span class=cl>mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install CNI</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Join workers</span>
</span></span><span class=line><span class=cl>kubeadm token create --print-join-command
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>CRI-O is native to Fedora ecosystem (same as RHEL/OpenShift)</li><li>Latest Kubernetes versions available quickly</li><li>Familiar to RHEL/CentOS users</li><li>Fully upstream Kubernetes</li></ul><p><strong>Cons</strong>:</p><ul><li>Manual setup process (same as Ubuntu/kubeadm)</li><li>Requires Kubernetes knowledge</li><li>More complex than turnkey solutions</li></ul><h3 id=2-k3s-lightweight-kubernetes>2. k3s (Lightweight Kubernetes)</h3><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Same single-command install</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> sh -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Retrieve token</span>
</span></span><span class=line><span class=cl>sudo cat /var/lib/rancher/k3s/server/node-token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install on workers</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> <span class=nv>K3S_URL</span><span class=o>=</span>https://control-plane:6443 <span class=nv>K3S_TOKEN</span><span class=o>=</span>&lt;token&gt; sh -
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Simple installation (identical to Ubuntu)</li><li>Lightweight and fast</li><li>Well-tested on Fedora/RHEL family</li></ul><p><strong>Cons</strong>:</p><ul><li>Less customizable</li><li>Not using native CRI-O by default (uses embedded containerd)</li></ul><h3 id=3-okd-openshift-kubernetes-distribution>3. OKD (OpenShift Kubernetes Distribution)</h3><p><strong>Installation</strong> (Single-Node):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Download and install OKD</span>
</span></span><span class=line><span class=cl>wget https://github.com/okd-project/okd/releases/download/4.15.0-0.okd-2024-01-27-070424/openshift-install-linux-4.15.0-0.okd-2024-01-27-070424.tar.gz
</span></span><span class=line><span class=cl>tar -xvf openshift-install-linux-*.tar.gz
</span></span><span class=line><span class=cl>sudo mv openshift-install /usr/local/bin/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create install config</span>
</span></span><span class=line><span class=cl>./openshift-install create install-config --dir<span class=o>=</span>cluster
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install cluster</span>
</span></span><span class=line><span class=cl>./openshift-install create cluster --dir<span class=o>=</span>cluster
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Enterprise features (operators, web console, image registry)</li><li>Built-in CI/CD and developer tools</li><li>Based on Fedora CoreOS (immutable, auto-updating)</li></ul><p><strong>Cons</strong>:</p><ul><li>Very heavy resource requirements (16GB+ RAM)</li><li>Complex installation and management</li><li>Overkill for simple homelab use</li></ul><h2 id=cluster-initialization-sequence>Cluster Initialization Sequence</h2><h3 id=kubeadm-with-cri-o>kubeadm with CRI-O</h3><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Fedora Server
    participant K8s as Kubernetes Components
    
    Admin-&gt;&gt;Server: Install Fedora 41
    Server-&gt;&gt;Server: Configure network (static IP)
    Admin-&gt;&gt;Server: Update system (dnf update)
    Admin-&gt;&gt;Server: Install CRI-O
    Server-&gt;&gt;Server: Configure CRI-O runtime
    Server-&gt;&gt;Server: Enable crio.service
    Admin-&gt;&gt;Server: Install kubeadm/kubelet/kubectl
    Server-&gt;&gt;Server: Disable swap, load kernel modules
    Server-&gt;&gt;Server: Configure SELinux (permissive for Kubernetes)
    Admin-&gt;&gt;K8s: kubeadm init --cri-socket=unix:///var/run/crio/crio.sock
    K8s-&gt;&gt;Server: Generate certificates
    K8s-&gt;&gt;Server: Start etcd
    K8s-&gt;&gt;Server: Start API server
    K8s-&gt;&gt;Server: Start controller-manager
    K8s-&gt;&gt;Server: Start scheduler
    K8s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;K8s: kubectl apply CNI
    K8s-&gt;&gt;Server: Deploy CNI pods
    Admin-&gt;&gt;K8s: kubeadm join (workers)
    K8s-&gt;&gt;Server: Add worker nodes
    K8s--&gt;&gt;Admin: Cluster ready</pre><h3 id=k3s-approach>k3s Approach</h3><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Fedora Server
    participant K3s as k3s Components
    
    Admin-&gt;&gt;Server: Install Fedora 41
    Server-&gt;&gt;Server: Configure network
    Admin-&gt;&gt;Server: Update system (dnf update)
    Admin-&gt;&gt;Server: Disable firewalld (or configure)
    Admin-&gt;&gt;Server: curl -sfL https://get.k3s.io | sh -
    Server-&gt;&gt;K3s: Download k3s binary
    K3s-&gt;&gt;Server: Configure containerd
    K3s-&gt;&gt;Server: Start k3s service
    K3s-&gt;&gt;Server: Initialize embedded etcd
    K3s-&gt;&gt;Server: Start API server
    K3s-&gt;&gt;Server: Deploy built-in CNI
    K3s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;Server: Retrieve node token
    Admin-&gt;&gt;Server: Install k3s agent on workers
    K3s-&gt;&gt;Server: Join workers
    K3s--&gt;&gt;Admin: Cluster ready (5-10 minutes)</pre><h2 id=maintenance-requirements>Maintenance Requirements</h2><h3 id=os-updates>OS Updates</h3><p><strong>Security and System Updates</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Automatic updates (dnf-automatic)</span>
</span></span><span class=line><span class=cl>sudo dnf install -y dnf-automatic
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> --now dnf-automatic.timer
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Manual updates</span>
</span></span><span class=line><span class=cl>sudo dnf update -y
</span></span><span class=line><span class=cl>sudo reboot  <span class=c1># if kernel updated</span>
</span></span></code></pre></div><p><strong>Frequency</strong>:</p><ul><li>Security patches: Weekly to monthly</li><li>Kernel updates: Monthly (frequent updates)</li><li><strong>Major version upgrades</strong>: Every ~13 months (Fedora releases)</li></ul><p><strong>Version Upgrade</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade to next Fedora release</span>
</span></span><span class=line><span class=cl>sudo dnf upgrade --refresh
</span></span><span class=line><span class=cl>sudo dnf install dnf-plugin-system-upgrade
</span></span><span class=line><span class=cl>sudo dnf system-upgrade download --releasever<span class=o>=</span><span class=m>42</span>
</span></span><span class=line><span class=cl>sudo dnf system-upgrade reboot
</span></span></code></pre></div><h3 id=kubernetes-upgrades>Kubernetes Upgrades</h3><p><strong>kubeadm Upgrade</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade control plane</span>
</span></span><span class=line><span class=cl>sudo dnf update -y kubeadm
</span></span><span class=line><span class=cl>sudo kubeadm upgrade apply v1.32.0
</span></span><span class=line><span class=cl>sudo dnf update -y kubelet kubectl
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upgrade workers</span>
</span></span><span class=line><span class=cl>kubectl drain &lt;node&gt; --ignore-daemonsets
</span></span><span class=line><span class=cl>sudo dnf update -y kubeadm kubelet kubectl
</span></span><span class=line><span class=cl>sudo kubeadm upgrade node
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span><span class=line><span class=cl>kubectl uncordon &lt;node&gt;
</span></span></code></pre></div><p><strong>k3s Upgrade</strong>: Same as Ubuntu (curl script or system-upgrade-controller)</p><p><strong>Upgrade Frequency</strong>: Kubernetes every 3-6 months, Fedora OS every ~13 months</p><h2 id=resource-overhead>Resource Overhead</h2><p><strong>Minimal Installation</strong> (Fedora Server + k3s):</p><ul><li><strong>RAM</strong>: ~600MB (OS) + 512MB (k3s) = 1.2GB total</li><li><strong>CPU</strong>: 1 core minimum, 2 cores recommended</li><li><strong>Disk</strong>: 12GB (OS) + 10GB (containers) = 22GB</li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><p><strong>Full Installation</strong> (Fedora Server + kubeadm + CRI-O):</p><ul><li><strong>RAM</strong>: ~700MB (OS) + 1.5GB (Kubernetes) = 2.2GB total</li><li><strong>CPU</strong>: 2 cores minimum</li><li><strong>Disk</strong>: 15GB (OS) + 20GB (containers) = 35GB</li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><p><strong>Note</strong>: Slightly higher overhead than Ubuntu due to SELinux and newer components.</p><h2 id=security-posture>Security Posture</h2><p><strong>Strengths</strong>:</p><ul><li><strong>SELinux enabled by default</strong> (stronger than AppArmor)</li><li>Latest security patches and kernel (bleeding edge)</li><li>CRI-O container runtime (security-focused, used by OpenShift)</li><li>Shorter support window = less legacy CVEs</li><li>Active security team and rapid response</li></ul><p><strong>Attack Surface</strong>:</p><ul><li>General-purpose OS (larger surface than minimal OS)</li><li>More installed packages than minimal server</li><li>SELinux can be complex to configure for Kubernetes</li></ul><p><strong>Hardening Steps</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Configure firewall (firewalld default on Fedora)</span>
</span></span><span class=line><span class=cl>sudo firewall-cmd --permanent --add-port<span class=o>=</span>6443/tcp  <span class=c1># API server</span>
</span></span><span class=line><span class=cl>sudo firewall-cmd --permanent --add-port<span class=o>=</span>10250/tcp <span class=c1># Kubelet</span>
</span></span><span class=line><span class=cl>sudo firewall-cmd --reload
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># SELinux configuration for Kubernetes</span>
</span></span><span class=line><span class=cl>sudo setenforce <span class=m>0</span>  <span class=c1># Permissive (Kubernetes not fully SELinux-ready)</span>
</span></span><span class=line><span class=cl>sudo sed -i <span class=s1>&#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39;</span> /etc/selinux/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Disable unnecessary services</span>
</span></span><span class=line><span class=cl>sudo systemctl disable bluetooth.service
</span></span></code></pre></div><h2 id=learning-curve>Learning Curve</h2><p><strong>Ease of Adoption</strong>: â­â­â­â­ (Good)</p><ul><li>Familiar for RHEL/CentOS/Alma/Rocky users</li><li>DNF package manager (similar to APT)</li><li>Excellent documentation</li><li>SELinux learning curve can be steep</li></ul><p><strong>Required Knowledge</strong>:</p><ul><li>RPM-based system administration (dnf, systemd)</li><li>SELinux basics (or willingness to use permissive mode)</li><li>Kubernetes concepts</li><li>Firewalld configuration</li></ul><p><strong>Differences from Ubuntu</strong>:</p><ul><li>DNF vs APT package manager</li><li>SELinux vs AppArmor</li><li>Firewalld vs UFW</li><li>Faster release cycle (more frequent upgrades)</li></ul><h2 id=community-support>Community Support</h2><p><strong>Ecosystem Maturity</strong>: â­â­â­â­ (Good)</p><ul><li><strong>Documentation</strong>: Excellent official docs, Red Hat resources</li><li><strong>Community</strong>: Large user base, active forums</li><li><strong>Commercial Support</strong>: RHEL support available (paid)</li><li><strong>Third-Party Tools</strong>: Good compatibility with Kubernetes tools</li><li><strong>Tutorials</strong>: Abundant resources, especially for RHEL ecosystem</li></ul><p><strong>Resources</strong>:</p><ul><li><a href=https://docs.fedoraproject.org/en-US/fedora-server/>Fedora Server Documentation</a></li><li><a href=https://fedoraproject.org/wiki/SIGs/Kubernetes>Fedora Kubernetes SIG</a></li><li><a href=https://cri-o.io/>CRI-O Documentation</a></li><li><a href=https://docs.k3s.io/>k3s on Fedora</a></li></ul><h2 id=pros-and-cons-summary>Pros and Cons Summary</h2><h3 id=pros>Pros</h3><ul><li>Good, because latest kernel and software packages (bleeding edge)</li><li>Good, because SELinux enabled by default (stronger MAC than AppArmor)</li><li>Good, because native CRI-O support (same as RHEL/OpenShift)</li><li>Good, because upstream for RHEL (enterprise compatibility)</li><li>Good, because multiple Kubernetes installation options</li><li>Good, because k3s simplifies setup dramatically</li><li>Good, because strong security focus and rapid CVE response</li><li>Good, because familiar to RHEL/CentOS ecosystem</li><li>Good, because automatic updates available (dnf-automatic)</li><li>Neutral, because shorter support cycle (13 months) ensures latest features</li></ul><h3 id=cons>Cons</h3><ul><li>Bad, because short support cycle requires frequent OS upgrades (every ~13 months)</li><li>Bad, because bleeding-edge packages can introduce instability</li><li>Bad, because SELinux configuration for Kubernetes is complex (often set to permissive)</li><li>Bad, because smaller community than Ubuntu (though still large)</li><li>Bad, because general-purpose OS has larger attack surface than minimal OS</li><li>Bad, because more resource overhead than purpose-built Kubernetes OS</li><li>Bad, because OS upgrade every 13 months adds maintenance burden</li><li>Bad, because less beginner-friendly than Ubuntu</li><li>Bad, because managing OS + Kubernetes lifecycle separately</li><li>Neutral, because rapid release cycle can be pro or con depending on preference</li></ul><h2 id=recommendations>Recommendations</h2><p><strong>Best for</strong>:</p><ul><li>Users familiar with RHEL/CentOS/Rocky/Alma ecosystem</li><li>Teams wanting latest kernel and software features</li><li>Environments requiring SELinux (compliance, enterprise standards)</li><li>Learning OpenShift/OKD ecosystem (Fedora CoreOS foundation)</li><li>Users comfortable with frequent OS upgrades</li></ul><p><strong>Best Installation Method</strong>:</p><ul><li><strong>Homelab/Learning</strong>: k3s (simplest, lightweight)</li><li><strong>Enterprise-like</strong>: kubeadm + CRI-O (OpenShift compatibility)</li><li><strong>Advanced</strong>: OKD (if resources available, 16GB+ RAM)</li></ul><p><strong>Avoid if</strong>:</p><ul><li>Prefer long-term stability (choose Ubuntu LTS)</li><li>Want minimal maintenance (frequent Fedora upgrades required)</li><li>Seeking minimal attack surface (consider Talos Linux)</li><li>Uncomfortable with SELinux complexity</li><li>Want infrastructure-as-code for OS (consider Talos Linux)</li></ul><h2 id=comparison-with-ubuntu>Comparison with Ubuntu</h2><table><thead><tr><th>Aspect</th><th>Fedora</th><th>Ubuntu LTS</th></tr></thead><tbody><tr><td><strong>Support Period</strong></td><td>13 months</td><td>5 years (10 with Pro)</td></tr><tr><td><strong>Kernel</strong></td><td>Latest (6.11+)</td><td>LTS (6.8+)</td></tr><tr><td><strong>Security</strong></td><td>SELinux</td><td>AppArmor</td></tr><tr><td><strong>Package Manager</strong></td><td>DNF/RPM</td><td>APT/DEB</td></tr><tr><td><strong>Release Cycle</strong></td><td>6 months</td><td>2 years (LTS)</td></tr><tr><td><strong>Upgrade Frequency</strong></td><td>Every 13 months</td><td>Every 2-5 years</td></tr><tr><td><strong>Community Size</strong></td><td>Large</td><td>Very Large</td></tr><tr><td><strong>Enterprise Upstream</strong></td><td>RHEL</td><td>N/A</td></tr><tr><td><strong>Stability</strong></td><td>Bleeding edge</td><td>Stable/Conservative</td></tr><tr><td><strong>Learning Curve</strong></td><td>Moderate</td><td>Easy</td></tr></tbody></table><p><strong>Verdict</strong>: Fedora is excellent for those wanting latest features and comfortable with frequent upgrades. Ubuntu LTS is better for long-term stability and minimal maintenance.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7e5e084a8e0ecdcf60e6401763ef0a82>1.2.3 - Talos Linux Analysis</h1><div class=lead>Analysis of Talos Linux for Kubernetes homelab infrastructure</div><h2 id=overview>Overview</h2><p>Talos Linux is a modern operating system designed specifically for running Kubernetes. It is API-driven, immutable, and minimal, with no SSH access, shell, or package manager. All configuration is done via a declarative API.</p><p><strong>Key Facts</strong>:</p><ul><li><strong>Latest Version</strong>: Talos 1.9 (supports Kubernetes 1.31)</li><li><strong>Support</strong>: Community-driven, commercial support available from Sidero Labs</li><li><strong>Kernel</strong>: Linux 6.6+ LTS</li><li><strong>Architecture</strong>: Immutable, API-driven, no shell access</li><li><strong>Management</strong>: talosctl CLI + Kubernetes API</li></ul><h2 id=kubernetes-installation-methods>Kubernetes Installation Methods</h2><p>Talos Linux has <strong>built-in Kubernetes</strong> - there is only one installation method.</p><h3 id=built-in-kubernetes-only-option>Built-in Kubernetes (Only Option)</h3><p><strong>Installation Process</strong>:</p><ol><li><strong>Boot Talos ISO/PXE</strong> (maintenance mode)</li><li><strong>Apply machine configuration</strong> via talosctl</li><li><strong>Bootstrap Kubernetes</strong> via talosctl bootstrap</li></ol><p><strong>Machine Configuration</strong> (YAML):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># controlplane.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=l>v1alpha1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>controlplane</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>disk</span><span class=p>:</span><span class=w> </span><span class=l>/dev/sda</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>control-plane-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>interfaces</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>interface</span><span class=p>:</span><span class=w> </span><span class=l>eth0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>dhcp</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>addresses</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=m>192.168.1.10</span><span class=l>/24</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>routes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=nt>network</span><span class=p>:</span><span class=w> </span><span class=m>0.0.0.0</span><span class=l>/0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>gateway</span><span class=p>:</span><span class=w> </span><span class=m>192.168.1.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>cluster</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>clusterName</span><span class=p>:</span><span class=w> </span><span class=l>homelab</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>controlPlane</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>endpoint</span><span class=p>:</span><span class=w> </span><span class=l>https://192.168.1.10:6443</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cni</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>custom</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>urls</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml</span><span class=w>
</span></span></span></code></pre></div><p><strong>Cluster Initialization</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Generate machine configs</span>
</span></span><span class=line><span class=cl>talosctl gen config homelab https://192.168.1.10:6443
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply config to control plane node (booted from ISO)</span>
</span></span><span class=line><span class=cl>talosctl apply-config --insecure --nodes 192.168.1.10 --file controlplane.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Wait for install to complete, then bootstrap</span>
</span></span><span class=line><span class=cl>talosctl bootstrap --nodes 192.168.1.10 --endpoints 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Retrieve kubeconfig</span>
</span></span><span class=line><span class=cl>talosctl kubeconfig --nodes 192.168.1.10 --endpoints 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply config to worker nodes</span>
</span></span><span class=line><span class=cl>talosctl apply-config --insecure --nodes 192.168.1.11 --file worker.yaml
</span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Kubernetes built-in, no separate installation</li><li>Declarative configuration (GitOps-friendly)</li><li>Extremely minimal attack surface (no shell, no SSH)</li><li>Immutable infrastructure (config changes require reboot)</li><li>Automatic updates via Talos controller</li><li>Designed from ground up for Kubernetes</li></ul><p><strong>Cons</strong>:</p><ul><li>Steep learning curve (completely different paradigm)</li><li>No SSH/shell access (all via API)</li><li>Troubleshooting requires different mindset</li><li>Limited to Kubernetes workloads only (not general-purpose)</li><li>Smaller community than traditional distros</li></ul><h2 id=cluster-initialization-sequence>Cluster Initialization Sequence</h2><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Bare Metal Server
    participant Talos as Talos Linux
    participant K8s as Kubernetes Components
    
    Admin-&gt;&gt;Server: Boot Talos ISO (PXE or USB)
    Server-&gt;&gt;Talos: Start in maintenance mode
    Talos--&gt;&gt;Admin: API endpoint ready (no shell)
    Admin-&gt;&gt;Admin: Generate configs (talosctl gen config)
    Admin-&gt;&gt;Talos: talosctl apply-config (controlplane.yaml)
    Talos-&gt;&gt;Server: Partition disk
    Talos-&gt;&gt;Server: Install Talos to /dev/sda
    Talos-&gt;&gt;Server: Write machine config
    Server-&gt;&gt;Server: Reboot from disk
    Talos-&gt;&gt;Talos: Load machine config
    Talos-&gt;&gt;K8s: Start kubelet
    Talos-&gt;&gt;K8s: Start etcd
    Talos-&gt;&gt;K8s: Start API server
    Admin-&gt;&gt;Talos: talosctl bootstrap
    Talos-&gt;&gt;K8s: Initialize cluster
    K8s-&gt;&gt;Talos: Start controller-manager
    K8s-&gt;&gt;Talos: Start scheduler
    K8s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;K8s: Apply CNI (via talosctl or kubectl)
    K8s-&gt;&gt;Talos: Deploy CNI pods
    Admin-&gt;&gt;Talos: Apply worker configs
    Talos-&gt;&gt;K8s: Join workers to cluster
    K8s--&gt;&gt;Admin: Cluster ready (10-15 minutes)</pre><h2 id=maintenance-requirements>Maintenance Requirements</h2><h3 id=os-updates>OS Updates</h3><p><strong>Declarative Upgrades</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade Talos version (rolling upgrade)</span>
</span></span><span class=line><span class=cl>talosctl upgrade --nodes 192.168.1.10 --image ghcr.io/siderolabs/installer:v1.9.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Kubernetes version upgrade (also declarative)</span>
</span></span><span class=line><span class=cl>talosctl upgrade-k8s --nodes 192.168.1.10 --to 1.32.0
</span></span></code></pre></div><p><strong>Automatic Updates</strong> (via Talos System Extensions):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># machine config with auto-update extension</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>extensions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ghcr.io/siderolabs/system-upgrade-controller</span><span class=w>
</span></span></span></code></pre></div><p><strong>Frequency</strong>:</p><ul><li>Talos releases: Every 2-3 months</li><li>Kubernetes upgrades: Follow upstream cadence (quarterly)</li><li>Security patches: Built into Talos releases</li><li><strong>No traditional OS patching</strong> (immutable system)</li></ul><h3 id=configuration-changes>Configuration Changes</h3><p><strong>All changes via machine config</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Edit machine config YAML</span>
</span></span><span class=line><span class=cl>vim controlplane.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply updated config (triggers reboot if needed)</span>
</span></span><span class=line><span class=cl>talosctl apply-config --nodes 192.168.1.10 --file controlplane.yaml
</span></span></code></pre></div><p><strong>No manual package installs</strong> - everything declarative.</p><h2 id=resource-overhead>Resource Overhead</h2><p><strong>Minimal Footprint</strong> (Talos Linux + Kubernetes):</p><ul><li><strong>RAM</strong>: ~256MB (OS) + 512MB (Kubernetes) = <strong>768MB total</strong></li><li><strong>CPU</strong>: 1 core minimum, 2 cores recommended</li><li><strong>Disk</strong>: ~500MB (OS) + 10GB (container images/etcd) = <strong>10-15GB total</strong></li><li><strong>Network</strong>: 1 Gbps recommended</li></ul><p><strong>Comparison</strong>:</p><ul><li>Ubuntu + k3s: ~1GB RAM</li><li>Talos: ~768MB RAM (lighter)</li><li>Ubuntu + kubeadm: ~2GB RAM</li><li>Talos: ~768MB RAM (much lighter)</li></ul><p><strong>Minimal install size</strong>: ~500MB (vs 10GB+ for Ubuntu/Fedora)</p><h2 id=security-posture>Security Posture</h2><p><strong>Strengths</strong>: â­â­â­â­â­ (Excellent)</p><ul><li><strong>No SSH access</strong> - attack surface eliminated</li><li><strong>No shell</strong> - cannot install malware</li><li><strong>No package manager</strong> - no additional software installation</li><li><strong>Immutable filesystem</strong> - rootfs read-only</li><li><strong>Minimal components</strong>: Only Kubernetes and essential services</li><li><strong>API-only access</strong> - mTLS-authenticated talosctl</li><li><strong>KSPP compliance</strong>: Kernel Self-Protection Project standards</li><li><strong>Signed images</strong>: Cryptographically signed Talos images</li><li><strong>Secure Boot support</strong>: UEFI Secure Boot compatible</li></ul><p><strong>Attack Surface</strong>:</p><ul><li><strong>Smallest possible</strong>: Only Kubernetes API, kubelet, and Talos API</li><li>~30 running processes (vs 100+ on Ubuntu/Fedora)</li><li>~200MB filesystem (vs 5-10GB on Ubuntu/Fedora)</li></ul><p><strong>No hardening needed</strong> - secure by default.</p><p><strong>Security Features</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># Built-in security (example config)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>sysctls</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>kernel.kptr_restrict</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>kernel.yama.ptrace_scope</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;1&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kernel</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>modules</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>br_netfilter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>features</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>kubernetesTalosAPIAccess</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>allowedRoles</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>os:reader</span><span class=w>
</span></span></span></code></pre></div><h2 id=learning-curve>Learning Curve</h2><p><strong>Ease of Adoption</strong>: â­â­ (Challenging)</p><ul><li><strong>Paradigm shift</strong>: No shell/SSH, API-only management</li><li>Requires understanding of declarative infrastructure</li><li>Talosctl CLI has learning curve</li><li>Excellent documentation helps</li><li>Different troubleshooting approach (logs via API)</li></ul><p><strong>Required Knowledge</strong>:</p><ul><li>Kubernetes fundamentals (critical)</li><li>YAML configuration syntax</li><li>Networking basics (especially CNI)</li><li>GitOps concepts helpful</li><li>Comfort with &ldquo;infrastructure as code&rdquo;</li></ul><p><strong>Debugging without shell</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># View logs via API</span>
</span></span><span class=line><span class=cl>talosctl logs --nodes 192.168.1.10 kubelet
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get system metrics</span>
</span></span><span class=line><span class=cl>talosctl dashboard --nodes 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Interactive mode (limited shell in emergency)</span>
</span></span><span class=line><span class=cl>talosctl dashboard --nodes 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Service status</span>
</span></span><span class=line><span class=cl>talosctl service --nodes 192.168.1.10
</span></span></code></pre></div><h2 id=community-support>Community Support</h2><p><strong>Ecosystem Maturity</strong>: â­â­â­ (Growing)</p><ul><li><strong>Documentation</strong>: Excellent official docs</li><li><strong>Community</strong>: Smaller but very active (Slack, GitHub Discussions)</li><li><strong>Commercial Support</strong>: Available from Sidero Labs</li><li><strong>Third-Party Tools</strong>: Growing ecosystem (Cluster API, GitOps tools)</li><li><strong>Tutorials</strong>: Increasing number of community guides</li></ul><p><strong>Resources</strong>:</p><ul><li><a href=https://www.talos.dev/v1.9/introduction/what-is-talos/>Talos Linux Documentation</a></li><li><a href=https://slack.dev.talos-systems.io/>Talos Community Slack</a></li><li><a href=https://github.com/siderolabs/talos>Sidero Labs GitHub</a></li><li><a href=https://github.com/budimanjojo/awesome-talos>Awesome Talos</a></li></ul><p><strong>Community Size</strong>: Smaller than Ubuntu/Fedora, but dedicated and helpful.</p><h2 id=pros-and-cons-summary>Pros and Cons Summary</h2><h3 id=pros>Pros</h3><ul><li>Good, because Kubernetes is built-in (no separate installation)</li><li>Good, because minimal attack surface (no SSH, shell, or package manager)</li><li>Good, because immutable infrastructure (config drift impossible)</li><li>Good, because API-driven management (GitOps-friendly)</li><li>Good, because extremely low resource overhead (~768MB RAM)</li><li>Good, because automatic security patches via Talos upgrades</li><li>Good, because declarative configuration (version-controlled)</li><li>Good, because secure by default (no hardening required)</li><li>Good, because smallest disk footprint (~500MB OS)</li><li>Good, because designed specifically for Kubernetes (opinionated and optimized)</li><li>Good, because UEFI Secure Boot support</li><li>Good, because upgrades are simple and declarative (talosctl upgrade)</li></ul><h3 id=cons>Cons</h3><ul><li>Bad, because steep learning curve (no shell/SSH paradigm shift)</li><li>Bad, because limited to Kubernetes workloads only (not general-purpose)</li><li>Bad, because troubleshooting without shell requires different approach</li><li>Bad, because smaller community than Ubuntu/Fedora</li><li>Bad, because relatively new (less mature than traditional distros)</li><li>Bad, because no escape hatch for manual intervention</li><li>Bad, because requires comfort with declarative infrastructure</li><li>Bad, because debugging is harder for beginners</li><li>Neutral, because opinionated design (pro for K8s-only, con for general use)</li></ul><h2 id=recommendations>Recommendations</h2><p><strong>Best for</strong>:</p><ul><li>Kubernetes-dedicated infrastructure (no general-purpose workloads)</li><li>Security-focused environments (minimal attack surface)</li><li>GitOps workflows (declarative configuration)</li><li>Immutable infrastructure advocates</li><li>Teams comfortable with API-driven management</li><li>Production Kubernetes clusters (once team is trained)</li></ul><p><strong>Best Installation Method</strong>:</p><ul><li><strong>Only option</strong>: Built-in Kubernetes via talosctl</li></ul><p><strong>Avoid if</strong>:</p><ul><li>Need general-purpose server functionality (SSH, cron jobs, etc.)</li><li>Team unfamiliar with Kubernetes (too steep a learning curve)</li><li>Require shell access for troubleshooting comfort</li><li>Want traditional package management (apt, dnf)</li><li>Prefer familiar Linux administration tools</li></ul><h2 id=comparison-with-ubuntu-and-fedora>Comparison with Ubuntu and Fedora</h2><table><thead><tr><th>Aspect</th><th>Talos Linux</th><th>Ubuntu + k3s</th><th>Fedora + kubeadm</th></tr></thead><tbody><tr><td><strong>K8s Installation</strong></td><td>Built-in</td><td>Single command</td><td>Manual (kubeadm)</td></tr><tr><td><strong>Attack Surface</strong></td><td>Minimal (~30 processes)</td><td>Medium (~100)</td><td>Medium (~100)</td></tr><tr><td><strong>Resource Overhead</strong></td><td>768MB RAM</td><td>1GB RAM</td><td>2.2GB RAM</td></tr><tr><td><strong>Disk Footprint</strong></td><td>500MB</td><td>10GB</td><td>15GB</td></tr><tr><td><strong>Security Model</strong></td><td>Immutable, no shell</td><td>AppArmor, shell</td><td>SELinux, shell</td></tr><tr><td><strong>Management</strong></td><td>API-only (talosctl)</td><td>SSH + kubectl</td><td>SSH + kubectl</td></tr><tr><td><strong>Learning Curve</strong></td><td>Steep</td><td>Easy</td><td>Moderate</td></tr><tr><td><strong>Community Size</strong></td><td>Small (growing)</td><td>Very Large</td><td>Large</td></tr><tr><td><strong>Support Period</strong></td><td>Rolling releases</td><td>5-10 years</td><td>13 months</td></tr><tr><td><strong>Use Case</strong></td><td>Kubernetes only</td><td>General-purpose</td><td>General-purpose</td></tr><tr><td><strong>Upgrades</strong></td><td>Declarative, simple</td><td>Manual OS + K8s</td><td>Manual OS + K8s</td></tr><tr><td><strong>Configuration</strong></td><td>Declarative YAML</td><td>Imperative + YAML</td><td>Imperative + YAML</td></tr><tr><td><strong>Troubleshooting</strong></td><td>API logs/metrics</td><td>SSH + logs</td><td>SSH + logs</td></tr><tr><td><strong>GitOps-Friendly</strong></td><td>Excellent</td><td>Good</td><td>Good</td></tr><tr><td><strong>Best for</strong></td><td>K8s-dedicated infra</td><td>Homelabs, learning</td><td>RHEL ecosystem</td></tr></tbody></table><p><strong>Verdict</strong>: Talos is the most secure and efficient option for Kubernetes-only infrastructure, but requires team buy-in to API-driven, immutable paradigm. Ubuntu/Fedora better for general-purpose servers or teams wanting shell access.</p><h2 id=advanced-features>Advanced Features</h2><h3 id=talos-system-extensions>Talos System Extensions</h3><p>Extend Talos functionality with extensions:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>extensions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ghcr.io/siderolabs/intel-ucode:20240312</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ghcr.io/siderolabs/iscsi-tools:v0.1.4</span><span class=w>
</span></span></span></code></pre></div><h3 id=cluster-api-integration>Cluster API Integration</h3><p>Talos works natively with Cluster API:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install Cluster API + Talos provider</span>
</span></span><span class=line><span class=cl>clusterctl init --infrastructure talos
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create cluster from template</span>
</span></span><span class=line><span class=cl>clusterctl generate cluster homelab --infrastructure talos &gt; cluster.yaml
</span></span><span class=line><span class=cl>kubectl apply -f cluster.yaml
</span></span></code></pre></div><h3 id=image-factory>Image Factory</h3><p>Custom Talos images with extensions:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Build custom image</span>
</span></span><span class=line><span class=cl>curl -X POST https://factory.talos.dev/image <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d <span class=s1>&#39;{&#34;talos_version&#34;:&#34;v1.9.0&#34;,&#34;extensions&#34;:[&#34;siderolabs/intel-ucode&#34;]}&#39;</span>
</span></span></code></pre></div><h3 id=disaster-recovery>Disaster Recovery</h3><p>Talos supports etcd backup/restore:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Backup etcd</span>
</span></span><span class=line><span class=cl>talosctl etcd snapshot --nodes 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Restore from snapshot</span>
</span></span><span class=line><span class=cl>talosctl bootstrap --recover-from ./etcd-snapshot.db
</span></span></code></pre></div><h2 id=production-readiness>Production Readiness</h2><p><strong>Production Use</strong>: âœ… Yes (many companies run Talos in production)</p><p><strong>High Availability</strong>:</p><ul><li>3+ control plane nodes recommended</li><li>External etcd supported</li><li>Load balancer for API server</li></ul><p><strong>Monitoring</strong>:</p><ul><li>Prometheus metrics built-in</li><li>Talos dashboard for health</li><li>Standard Kubernetes observability tools</li></ul><p><strong>Example Production Clusters</strong>:</p><ul><li>Sidero Metal (bare metal provisioning)</li><li>Various cloud providers (AWS, GCP, Azure)</li><li>Edge deployments (minimal footprint)</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f633ef5d64f4d7ef2640d8077b7ca2a8>1.2.4 - Harvester Analysis</h1><div class=lead>Analysis of Harvester HCI for Kubernetes homelab infrastructure</div><h2 id=overview>Overview</h2><p>Harvester is a Hyperconverged Infrastructure (HCI) platform built on Kubernetes, designed to provide VM and container management on a unified platform. It combines compute, storage, and networking with built-in K3s for orchestration.</p><p><strong>Key Facts</strong>:</p><ul><li><strong>Latest Version</strong>: Harvester 1.4 (based on K3s 1.30+)</li><li><strong>Foundation</strong>: Built on RancherOS 2.0, K3s, and KubeVirt</li><li><strong>Support</strong>: Supported by SUSE (acquired Rancher)</li><li><strong>Architecture</strong>: HCI platform with VM + container workloads</li><li><strong>Management</strong>: Web UI + kubectl + Rancher integration</li></ul><h2 id=kubernetes-installation-methods>Kubernetes Installation Methods</h2><p>Harvester <strong>includes K3s as its foundation</strong> - Kubernetes is built-in.</p><h3 id=built-in-k3s-only-option>Built-in K3s (Only Option)</h3><p><strong>Installation Process</strong>:</p><ol><li><strong>Boot Harvester ISO</strong> (interactive installer or PXE)</li><li><strong>Complete installation wizard</strong> (web UI or console)</li><li><strong>Create cluster</strong> (automatic K3s deployment)</li><li><strong>Access via web UI</strong> or kubectl</li></ol><p><strong>Interactive Installation</strong>:</p><pre tabindex=0><code># Boot from Harvester ISO
1. Choose &#34;Create a new Harvester cluster&#34;
2. Configure:
   - Cluster token
   - Node role (management/worker/witness)
   - Network interface (management network)
   - VIP (Virtual IP for cluster access)
   - Storage disk (Longhorn persistent storage)
3. Install completes (15-20 minutes)
4. Access web UI at https://&lt;VIP&gt;
</code></pre><p><strong>Configuration</strong> (cloud-init for automated install):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># config.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>token</span><span class=p>:</span><span class=w> </span><span class=l>my-cluster-token</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>os</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>harvester-node-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>modules</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>kvm</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kernel_parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>intel_iommu=on</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=l>create</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>device</span><span class=p>:</span><span class=w> </span><span class=l>/dev/sda</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>iso_url</span><span class=p>:</span><span class=w> </span><span class=l>https://releases.rancher.com/harvester/v1.4.0/harvester-v1.4.0-amd64.iso</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>vip</span><span class=p>:</span><span class=w> </span><span class=m>192.168.1.100</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>vip_mode</span><span class=p>:</span><span class=w> </span><span class=l>static</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>harvester-mgmt</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>interfaces</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>eth0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>default_route</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>ip</span><span class=p>:</span><span class=w> </span><span class=m>192.168.1.10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>subnet_mask</span><span class=p>:</span><span class=w> </span><span class=m>255.255.255.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>gateway</span><span class=p>:</span><span class=w> </span><span class=m>192.168.1.1</span><span class=w>
</span></span></span></code></pre></div><p><strong>Pros</strong>:</p><ul><li>Complete HCI solution (VMs + containers)</li><li>Web UI for management (no CLI required)</li><li>Built-in storage (Longhorn CSI)</li><li>Built-in networking (multus, SR-IOV)</li><li>VM live migration</li><li>Rancher integration for multi-cluster management</li><li>K3s built-in (no separate Kubernetes install)</li></ul><p><strong>Cons</strong>:</p><ul><li>Heavy resource requirements (8GB+ RAM per node)</li><li>Complex architecture (steep learning curve)</li><li>Larger attack surface than minimal OS</li><li>Overkill for container-only workloads</li><li>Requires 3+ nodes for production HA</li></ul><h2 id=cluster-initialization-sequence>Cluster Initialization Sequence</h2><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Bare Metal Server
    participant Harvester as Harvester HCI
    participant K3s as K3s / KubeVirt
    participant Storage as Longhorn Storage
    
    Admin-&gt;&gt;Server: Boot Harvester ISO
    Server-&gt;&gt;Harvester: Start installation wizard
    Harvester--&gt;&gt;Admin: Interactive console/web UI
    Admin-&gt;&gt;Harvester: Configure cluster (token, VIP, storage)
    Harvester-&gt;&gt;Server: Partition disks (OS &#43; Longhorn storage)
    Harvester-&gt;&gt;Server: Install RancherOS 2.0 base
    Harvester-&gt;&gt;Server: Install K3s components
    Server-&gt;&gt;Server: Reboot
    Harvester-&gt;&gt;K3s: Start K3s server
    K3s-&gt;&gt;Server: Initialize control plane
    K3s-&gt;&gt;Server: Deploy Harvester operators
    K3s-&gt;&gt;Storage: Deploy Longhorn for persistent storage
    K3s-&gt;&gt;Server: Deploy KubeVirt for VM management
    K3s-&gt;&gt;Server: Deploy multus CNI (multi-network)
    Harvester--&gt;&gt;Admin: Web UI ready at https://&lt;VIP&gt;
    Admin-&gt;&gt;Harvester: Add additional nodes (join cluster)
    Harvester-&gt;&gt;K3s: Join nodes to cluster
    K3s-&gt;&gt;Storage: Replicate storage across nodes
    Harvester--&gt;&gt;Admin: Cluster ready (20-30 minutes)
    Admin-&gt;&gt;Harvester: Create VMs or deploy containers</pre><h2 id=maintenance-requirements>Maintenance Requirements</h2><h3 id=os-updates>OS Updates</h3><p><strong>Harvester Upgrades</strong> (includes OS + K3s):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Via Web UI:</span>
</span></span><span class=line><span class=cl><span class=c1># Settings â†’ Upgrade â†’ Select version â†’ Start upgrade</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Via kubectl (after downloading upgrade image):</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://releases.rancher.com/harvester/v1.4.0/version.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Monitor upgrade progress</span>
</span></span><span class=line><span class=cl>kubectl get upgrades -n harvester-system
</span></span></code></pre></div><p><strong>Frequency</strong>:</p><ul><li>Harvester releases: Every 2-3 months (minor versions)</li><li>Security patches: Included in Harvester releases</li><li>K3s upgrades: Bundled with Harvester upgrades</li><li><strong>No separate OS patching</strong> (managed by Harvester)</li></ul><h3 id=kubernetes-upgrades>Kubernetes Upgrades</h3><p><strong>K3s is upgraded with Harvester</strong> - no separate upgrade process.</p><p><strong>Version Compatibility</strong>:</p><ul><li>Harvester 1.4.x â†’ K3s 1.30+</li><li>Harvester 1.3.x â†’ K3s 1.28+</li><li>Harvester 1.2.x â†’ K3s 1.26+</li></ul><p><strong>Upgrade Process</strong>:</p><ol><li>Web UI or kubectl to trigger upgrade</li><li>Rolling upgrade of nodes (one at a time)</li><li>VM live migration during node upgrades</li><li>Automatic rollback on failure</li></ol><h2 id=resource-overhead>Resource Overhead</h2><p><strong>Single Node</strong> (Harvester HCI):</p><ul><li><strong>RAM</strong>: 8GB minimum (16GB recommended for VMs)</li><li><strong>CPU</strong>: 4 cores minimum (8 cores recommended)</li><li><strong>Disk</strong>: 250GB minimum (SSD recommended)<ul><li>100GB for OS/Harvester components</li><li>150GB+ for Longhorn storage (VM disks)</li></ul></li><li><strong>Network</strong>: 1 Gbps minimum (10 Gbps for production)</li></ul><p><strong>Three-Node Cluster</strong> (Production HA):</p><ul><li><strong>RAM</strong>: 32GB per node (64GB for VM-heavy workloads)</li><li><strong>CPU</strong>: 8 cores per node minimum</li><li><strong>Disk</strong>: 500GB+ per node (NVMe SSD recommended)</li><li><strong>Network</strong>: 10 Gbps recommended (separate storage network ideal)</li></ul><p><strong>Comparison</strong>:</p><ul><li>Ubuntu + k3s: 1GB RAM</li><li>Talos: 768MB RAM</li><li><strong>Harvester: 8GB+ RAM</strong> (much heavier)</li></ul><p><strong>Note</strong>: Harvester is designed for <strong>multi-node HCI</strong>, not single-node homelabs.</p><h2 id=security-posture>Security Posture</h2><p><strong>Strengths</strong>:</p><ul><li>SELinux-based (RancherOS 2.0 foundation)</li><li>Immutable OS layer (similar to Talos)</li><li>RBAC built-in (Kubernetes + Rancher)</li><li>Network segmentation (multus CNI)</li><li>VM isolation (KubeVirt)</li><li>Signed images and secure boot support</li></ul><p><strong>Attack Surface</strong>:</p><ul><li><strong>Larger than Talos/k3s</strong>: Includes web UI, VM management, storage layer</li><li>KubeVirt adds additional components</li><li>Web UI is additional attack vector</li><li>More processes than minimal OS (~50+ services)</li></ul><p><strong>Security Features</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># VM network isolation example</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>network.harvesterhci.io/v1beta1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>VlanConfig</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>production-vlan</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>vlanID</span><span class=p>:</span><span class=w> </span><span class=m>100</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>uplink</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>linkAttributes</span><span class=p>:</span><span class=w> </span><span class=m>1500</span><span class=w>
</span></span></span></code></pre></div><p><strong>Hardening</strong>:</p><ul><li>Firewall rules (web UI or kubectl)</li><li>RBAC policies (restrict VM/namespace access)</li><li>Network policies (isolate workloads)</li><li>Rancher authentication integration (LDAP, SAML)</li></ul><h2 id=learning-curve>Learning Curve</h2><p><strong>Ease of Adoption</strong>: â­â­â­ (Moderate)</p><ul><li><strong>Web UI simplifies management</strong> (no CLI required for basic tasks)</li><li>Requires understanding of VMs + containers</li><li>Kubernetes knowledge helpful but not required initially</li><li>Longhorn storage concepts (replicas, snapshots)</li><li>KubeVirt for VM management (learning curve)</li></ul><p><strong>Required Knowledge</strong>:</p><ul><li>Basic Kubernetes concepts (pods, services)</li><li>VM management (KubeVirt/libvirt)</li><li>Storage concepts (Longhorn, CSI)</li><li>Networking (VLANs, SR-IOV optional)</li><li>Web UI navigation</li></ul><p><strong>Debugging</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Access via kubectl (kubeconfig from web UI)</span>
</span></span><span class=line><span class=cl>kubectl get nodes -n harvester-system
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># View Harvester logs</span>
</span></span><span class=line><span class=cl>kubectl logs -n harvester-system &lt;pod-name&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># VM console access (via web UI or virtctl)</span>
</span></span><span class=line><span class=cl>virtctl console &lt;vm-name&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Storage debugging</span>
</span></span><span class=line><span class=cl>kubectl get volumes -A
</span></span></code></pre></div><h2 id=community-support>Community Support</h2><p><strong>Ecosystem Maturity</strong>: â­â­â­â­ (Good)</p><ul><li><strong>Documentation</strong>: Excellent official docs</li><li><strong>Community</strong>: Active Slack, GitHub Discussions, forums</li><li><strong>Commercial Support</strong>: Available from SUSE/Rancher</li><li><strong>Third-Party Tools</strong>: Rancher ecosystem integration</li><li><strong>Tutorials</strong>: Growing number of guides and videos</li></ul><p><strong>Resources</strong>:</p><ul><li><a href=https://docs.harvesterhci.io/>Harvester Documentation</a></li><li><a href=https://github.com/harvester/harvester>Harvester GitHub</a></li><li><a href=https://slack.rancher.io/>Rancher Community Slack</a></li><li><a href=https://www.suse.com/support/>SUSE Support</a></li></ul><h2 id=pros-and-cons-summary>Pros and Cons Summary</h2><h3 id=pros>Pros</h3><ul><li>Good, because unified platform for VMs + containers (no separate hypervisor)</li><li>Good, because built-in K3s (Kubernetes included)</li><li>Good, because web UI simplifies management (no CLI required)</li><li>Good, because built-in persistent storage (Longhorn CSI)</li><li>Good, because VM live migration (no downtime during maintenance)</li><li>Good, because multi-network support (multus CNI, SR-IOV)</li><li>Good, because Rancher integration (multi-cluster management)</li><li>Good, because automatic upgrades (OS + K3s + components)</li><li>Good, because commercial support available (SUSE)</li><li>Good, because designed for bare-metal HCI (no cloud dependencies)</li><li>Neutral, because immutable OS layer (similar to Talos benefits)</li></ul><h3 id=cons>Cons</h3><ul><li>Bad, because very heavy resource requirements (8GB+ RAM minimum)</li><li>Bad, because complex architecture (KubeVirt, Longhorn, multus, etc.)</li><li>Bad, because overkill for container-only workloads (use k3s/Talos instead)</li><li>Bad, because larger attack surface than minimal OS (web UI, VM layer)</li><li>Bad, because requires 3+ nodes for production HA (not single-node friendly)</li><li>Bad, because steep learning curve for full feature set (VMs + storage + networking)</li><li>Bad, because relatively new platform (less mature than Ubuntu/Fedora)</li><li>Bad, because limited to Rancher ecosystem (vendor lock-in)</li><li>Bad, because slower to adopt latest Kubernetes versions (depends on K3s bundle)</li><li>Neutral, because opinionated HCI design (pro for VM use cases, con for simplicity)</li></ul><h2 id=recommendations>Recommendations</h2><p><strong>Best for</strong>:</p><ul><li><strong>Hybrid workloads</strong> (VMs + containers on same platform)</li><li>Homelab users wanting to consolidate VM hypervisor + Kubernetes</li><li>Teams familiar with Rancher ecosystem</li><li>Multi-node clusters (3+ nodes)</li><li>Environments requiring VM live migration</li><li>Users wanting web UI for infrastructure management</li><li>Replacing VMware/Proxmox + Kubernetes with unified platform</li></ul><p><strong>Best Installation Method</strong>:</p><ul><li><strong>Only option</strong>: Interactive ISO install or PXE with cloud-init</li></ul><p><strong>Avoid if</strong>:</p><ul><li>Running container-only workloads (use k3s or Talos instead)</li><li>Limited resources (&lt; 8GB RAM per node)</li><li>Single-node homelab (Harvester designed for multi-node)</li><li>Want minimal attack surface (use Talos)</li><li>Prefer traditional Linux shell access (use Ubuntu/Fedora)</li><li>Need latest Kubernetes versions immediately (Harvester lags upstream)</li></ul><h2 id=comparison-with-other-options>Comparison with Other Options</h2><table><thead><tr><th>Aspect</th><th>Harvester</th><th>Talos Linux</th><th>Ubuntu + k3s</th><th>Fedora + kubeadm</th></tr></thead><tbody><tr><td><strong>Primary Use Case</strong></td><td>VMs + Containers</td><td>Containers only</td><td>General-purpose</td><td>General-purpose</td></tr><tr><td><strong>Resource Overhead</strong></td><td>8GB+ RAM</td><td>768MB RAM</td><td>1GB RAM</td><td>2.2GB RAM</td></tr><tr><td><strong>Kubernetes</strong></td><td>Built-in K3s</td><td>Built-in</td><td>Install k3s</td><td>Install kubeadm</td></tr><tr><td><strong>Management</strong></td><td>Web UI + kubectl</td><td>API-only (talosctl)</td><td>SSH + kubectl</td><td>SSH + kubectl</td></tr><tr><td><strong>Storage</strong></td><td>Built-in Longhorn</td><td>External CSI</td><td>External CSI</td><td>External CSI</td></tr><tr><td><strong>VM Support</strong></td><td>Native (KubeVirt)</td><td>No</td><td>Via KubeVirt</td><td>Via KubeVirt</td></tr><tr><td><strong>Learning Curve</strong></td><td>Moderate</td><td>Steep</td><td>Easy</td><td>Moderate</td></tr><tr><td><strong>Attack Surface</strong></td><td>Large</td><td>Minimal</td><td>Medium</td><td>Medium</td></tr><tr><td><strong>Multi-Node</strong></td><td>Designed for</td><td>Supports</td><td>Supports</td><td>Supports</td></tr><tr><td><strong>Single-Node</strong></td><td>Not ideal</td><td>Excellent</td><td>Excellent</td><td>Good</td></tr><tr><td><strong>Best for</strong></td><td>VM + K8s hybrid</td><td>K8s-only</td><td>Homelab/learning</td><td>RHEL ecosystem</td></tr></tbody></table><p><strong>Verdict</strong>: Harvester is excellent for <strong>VM + container hybrid workloads</strong> with 3+ nodes, but overkill for container-only infrastructure. Use Talos or k3s for Kubernetes-only clusters, Ubuntu/Fedora for general-purpose servers.</p><h2 id=advanced-features>Advanced Features</h2><h3 id=vm-management-kubevirt>VM Management (KubeVirt)</h3><p>Create VMs via YAML:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>kubevirt.io/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>VirtualMachine</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-vm</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>running</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>domain</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>devices</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>disks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>root</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>disk</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>bus</span><span class=p>:</span><span class=w> </span><span class=l>virtio</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>4Gi</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>root</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>containerDisk</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>docker.io/harvester/ubuntu:22.04</span><span class=w>
</span></span></span></code></pre></div><h3 id=live-migration>Live Migration</h3><p>Move VMs between nodes:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Via web UI: VM â†’ Actions â†’ Migrate</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Via kubectl</span>
</span></span><span class=line><span class=cl>kubectl patch vm ubuntu-vm --type merge -p <span class=s1>&#39;{&#34;spec&#34;:{&#34;running&#34;:false}}&#39;</span>
</span></span><span class=line><span class=cl>kubectl patch vm ubuntu-vm --type merge -p <span class=s1>&#39;{&#34;spec&#34;:{&#34;running&#34;:true}}&#39;</span>
</span></span></code></pre></div><h3 id=backup-and-restore>Backup and Restore</h3><p>Harvester supports VM backups:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Configure S3 backup target (web UI)</span>
</span></span><span class=line><span class=cl><span class=c1># Create VM snapshot</span>
</span></span><span class=line><span class=cl><span class=c1># Restore from snapshot or backup</span>
</span></span></code></pre></div><h3 id=rancher-integration>Rancher Integration</h3><p>Manage multiple clusters:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Import Harvester cluster into Rancher</span>
</span></span><span class=line><span class=cl><span class=c1># Deploy workloads across clusters</span>
</span></span><span class=line><span class=cl><span class=c1># Central authentication and RBAC</span>
</span></span></code></pre></div><h2 id=use-case-examples>Use Case Examples</h2><h3 id=use-case-1-replace-vmware--kubernetes>Use Case 1: Replace VMware + Kubernetes</h3><p><strong>Scenario</strong>: Currently running VMware ESXi for VMs + separate Kubernetes cluster</p><p><strong>Harvester Solution</strong>:</p><ul><li>Consolidate to 3-node Harvester cluster</li><li>Migrate VMs to KubeVirt</li><li>Deploy containers on same cluster</li><li>Save VMware licensing costs</li></ul><p><strong>Benefits</strong>:</p><ul><li>Single platform for VMs + containers</li><li>Unified management (web UI + kubectl)</li><li>Built-in HA and live migration</li></ul><h3 id=use-case-2-homelab-with-mixed-workloads>Use Case 2: Homelab with Mixed Workloads</h3><p><strong>Scenario</strong>: Need Windows VMs + Linux containers + storage server</p><p><strong>Harvester Solution</strong>:</p><ul><li>Windows VMs via KubeVirt (GPU passthrough supported)</li><li>Linux containers via K3s workloads</li><li>Longhorn for persistent storage (NFS export supported)</li></ul><p><strong>Benefits</strong>:</p><ul><li>No need for separate Proxmox/ESXi</li><li>Kubernetes-native management</li><li>Learn enterprise HCI platform</li></ul><h3 id=use-case-3-edge-computing>Use Case 3: Edge Computing</h3><p><strong>Scenario</strong>: Deploy compute at remote sites (3-5 nodes each)</p><p><strong>Harvester Solution</strong>:</p><ul><li>Harvester cluster at each edge location</li><li>Rancher for central management</li><li>VM + container workloads</li></ul><p><strong>Benefits</strong>:</p><ul><li>Autonomous operation (no cloud dependency)</li><li>Rancher multi-cluster management</li><li>Built-in storage and networking</li></ul><h2 id=production-readiness>Production Readiness</h2><p><strong>Production Use</strong>: âœ… Yes (used in enterprise environments)</p><p><strong>High Availability</strong>:</p><ul><li><strong>3+ nodes required</strong> for HA</li><li>Witness node for even-node clusters</li><li>VM live migration during maintenance</li><li>Longhorn 3-replica storage</li></ul><p><strong>Monitoring</strong>:</p><ul><li>Built-in Prometheus + Grafana</li><li>Rancher monitoring integration</li><li>Alerting and notifications</li></ul><p><strong>Disaster Recovery</strong>:</p><ul><li>VM backups to S3</li><li>Cluster backups (etcd + config)</li><li>Restore to new cluster</li></ul><p><strong>Enterprise Features</strong>:</p><ul><li>Rancher authentication (LDAP, SAML, OAuth)</li><li>Multi-tenancy (namespaces, RBAC)</li><li>Audit logging</li><li>Network policies</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-67bf1a793f6a1c844dbc6e04272ebdb5>1.3 - Amazon Web Services Analysis</h1><div class=lead>Technical analysis of Amazon Web Services capabilities for hosting network boot infrastructure</div><p>This section contains detailed analysis of Amazon Web Services (AWS) for hosting the network boot server infrastructure, evaluating its support for TFTP, HTTP/HTTPS routing, and WireGuard VPN connectivity as required by ADR-0002.</p><h2 id=overview>Overview</h2><p>Amazon Web Services is Amazon&rsquo;s comprehensive cloud computing platform, offering compute, storage, networking, and managed services. This analysis focuses on AWS&rsquo;s capabilities to support the network boot architecture decided in <a href=../../adrs/0002-network-boot-architecture/>ADR-0002</a>.</p><h2 id=key-services-evaluated>Key Services Evaluated</h2><ul><li><strong>EC2</strong>: Virtual machine instances for hosting boot server</li><li><strong>VPN / VPC</strong>: Network connectivity and VPN capabilities</li><li><strong>Elastic Load Balancing</strong>: Application and Network Load Balancers</li><li><strong>NAT Gateway</strong>: Network address translation for outbound connectivity</li><li><strong>VPC</strong>: Virtual Private Cloud networking and routing</li></ul><h2 id=documentation-sections>Documentation Sections</h2><ul><li><a href=./network-boot/>Network Boot Support</a> - Analysis of TFTP, HTTP, and HTTPS routing capabilities</li><li><a href=./wireguard/>WireGuard Support</a> - Evaluation of WireGuard VPN integration options</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-284e5fccd8c32dbd4ae3bfdb2a6d41ff>1.3.1 - AWS Network Boot Protocol Support</h1><div class=lead>Analysis of Amazon Web Services support for TFTP, HTTP, and HTTPS routing for network boot infrastructure</div><h1 id=network-boot-protocol-support-on-amazon-web-services>Network Boot Protocol Support on Amazon Web Services</h1><p>This document analyzes AWS&rsquo;s capabilities for hosting network boot infrastructure, specifically focusing on TFTP, HTTP, and HTTPS protocol support.</p><h2 id=tftp-trivial-file-transfer-protocol-support>TFTP (Trivial File Transfer Protocol) Support</h2><h3 id=native-support>Native Support</h3><p><strong>Status</strong>: âŒ <strong>Not natively supported by Elastic Load Balancing</strong></p><p>AWS&rsquo;s Elastic Load Balancing services do <strong>not</strong> support TFTP protocol natively:</p><ul><li><strong>Application Load Balancer (ALB)</strong>: HTTP/HTTPS only (Layer 7)</li><li><strong>Network Load Balancer (NLB)</strong>: TCP/UDP support, but <strong>not TFTP-aware</strong></li><li><strong>Classic Load Balancer</strong>: Deprecated, similar limitations</li></ul><p>TFTP operates on UDP port 69 with unique protocol semantics (variable block sizes, retransmissions, port negotiation) that standard load balancers cannot parse.</p><h3 id=implementation-options>Implementation Options</h3><h4 id=option-1-direct-ec2-instance-access-recommended-for-vpn-scenario>Option 1: Direct EC2 Instance Access (Recommended for VPN Scenario)</h4><p>Since ADR-0002 specifies a VPN-based architecture, TFTP can be served directly from an EC2 instance:</p><ul><li><strong>Approach</strong>: Run TFTP server (e.g., <code>tftpd-hpa</code>, <code>dnsmasq</code>) on an EC2 instance</li><li><strong>Access</strong>: Home lab connects via VPN tunnel to instance&rsquo;s private IP</li><li><strong>Security Group</strong>: Allow UDP/69 from VPN subnet/security group</li><li><strong>Pros</strong>:<ul><li>Simple implementation</li><li>No load balancer needed (single boot server sufficient for home lab)</li><li>TFTP traffic encrypted through VPN tunnel</li><li>Direct instance-to-client communication</li></ul></li><li><strong>Cons</strong>:<ul><li>Single point of failure (no HA)</li><li>Manual failover if instance fails</li></ul></li></ul><h4 id=option-2-network-load-balancer-nlb-udp-passthrough>Option 2: Network Load Balancer (NLB) UDP Passthrough</h4><p>While NLB doesn&rsquo;t understand TFTP protocol, it can forward UDP traffic:</p><ul><li><strong>Approach</strong>: Configure NLB to forward UDP/69 to target group</li><li><strong>Limitations</strong>:<ul><li>No TFTP-specific health checks</li><li>Health checks would use TCP or different protocol</li><li>Adds cost and complexity without significant benefit for single server</li></ul></li><li><strong>Use Case</strong>: Only relevant for multi-AZ HA deployment (overkill for home lab)</li></ul><h3 id=tftp-security-considerations>TFTP Security Considerations</h3><ul><li><strong>Encryption</strong>: TFTP itself is unencrypted, but VPN tunnel provides encryption</li><li><strong>Security Groups</strong>: Restrict UDP/69 to VPN security group or CIDR only</li><li><strong>File Access Control</strong>: Configure TFTP server with restricted file access</li><li><strong>Read-Only Mode</strong>: Deploy TFTP server in read-only mode to prevent uploads</li></ul><h2 id=http-support>HTTP Support</h2><h3 id=native-support-1>Native Support</h3><p><strong>Status</strong>: âœ… <strong>Fully supported</strong></p><p>AWS provides comprehensive HTTP support through multiple services:</p><h4 id=elastic-load-balancing---application-load-balancer>Elastic Load Balancing - Application Load Balancer</h4><ul><li><strong>Protocol Support</strong>: HTTP/1.1, HTTP/2, HTTP/3 (preview)</li><li><strong>Port</strong>: Any port (typically 80 for HTTP)</li><li><strong>Routing</strong>: Path-based, host-based, query string, header-based routing</li><li><strong>Health Checks</strong>: HTTP health checks with configurable paths and response codes</li><li><strong>SSL Offloading</strong>: Terminate SSL at ALB and use HTTP to backend</li><li><strong>Backend</strong>: EC2 instances, ECS, EKS, Lambda</li></ul><h4 id=ec2-direct-access>EC2 Direct Access</h4><p>For VPN scenario, HTTP can be served directly from EC2 instance:</p><ul><li><strong>Approach</strong>: Run HTTP server (nginx, Apache, custom service) on EC2</li><li><strong>Access</strong>: Home lab accesses via VPN tunnel to private IP</li><li><strong>Security Group</strong>: Allow TCP/80 from VPN security group</li><li><strong>Pros</strong>: Simpler than ALB for single boot server</li></ul><h3 id=http-boot-flow-for-network-boot>HTTP Boot Flow for Network Boot</h3><ol><li><strong>PXE â†’ TFTP</strong>: Initial bootloader (iPXE) loaded via TFTP</li><li><strong>iPXE â†’ HTTP</strong>: iPXE chainloads kernel/initrd via HTTP</li><li><strong>Kernel/Initrd</strong>: Large boot files served efficiently over HTTP</li></ol><h3 id=performance-considerations>Performance Considerations</h3><ul><li><strong>Connection Pooling</strong>: HTTP/1.1 keep-alive reduces connection overhead</li><li><strong>Compression</strong>: gzip compression for text-based configs</li><li><strong>CloudFront</strong>: Optional CDN for caching boot files (probably overkill for VPN scenario)</li><li><strong>TCP Optimization</strong>: AWS network optimized for low-latency TCP</li></ul><h2 id=https-support>HTTPS Support</h2><h3 id=native-support-2>Native Support</h3><p><strong>Status</strong>: âœ… <strong>Fully supported with advanced features</strong></p><p>AWS provides enterprise-grade HTTPS support:</p><h4 id=elastic-load-balancing---application-load-balancer-1>Elastic Load Balancing - Application Load Balancer</h4><ul><li><strong>Protocol Support</strong>: HTTPS/1.1, HTTP/2 over TLS, HTTP/3 (preview)</li><li><strong>SSL/TLS Termination</strong>: Terminate SSL at ALB</li><li><strong>Certificate Management</strong>:<ul><li>AWS Certificate Manager (ACM) - free SSL certificates with automatic renewal</li><li>Import custom certificates</li><li>Integration with private CA via ACM Private CA</li></ul></li><li><strong>TLS Versions</strong>: TLS 1.0, 1.1, 1.2, 1.3 (configurable via security policy)</li><li><strong>Cipher Suites</strong>: Predefined security policies (modern, compatible, legacy)</li><li><strong>SNI Support</strong>: Multiple certificates on single load balancer</li></ul><h4 id=aws-certificate-manager-acm>AWS Certificate Manager (ACM)</h4><ul><li><strong>Free Certificates</strong>: No cost for public SSL certificates used with AWS services</li><li><strong>Automatic Renewal</strong>: ACM automatically renews certificates before expiration</li><li><strong>Private CA</strong>: ACM Private CA for internal PKI (additional cost)</li><li><strong>Integration</strong>: Native integration with ALB, CloudFront, API Gateway</li></ul><h3 id=https-for-network-boot>HTTPS for Network Boot</h3><h4 id=use-case>Use Case</h4><p>Modern UEFI firmware and iPXE support HTTPS boot:</p><ul><li><strong>iPXE HTTPS</strong>: iPXE compiled with <code>DOWNLOAD_PROTO_HTTPS</code> can fetch over HTTPS</li><li><strong>UEFI HTTP Boot</strong>: UEFI firmware natively supports HTTP/HTTPS boot</li><li><strong>Security</strong>: Boot file integrity verified via HTTPS chain of trust</li></ul><h4 id=implementation-on-aws>Implementation on AWS</h4><ol><li><p><strong>Certificate Provisioning</strong>:</p><ul><li>Use ACM certificate for public domain (free, auto-renewed)</li><li>Use self-signed certificate for VPN-only access (add to iPXE trust store)</li><li>Use ACM Private CA for internal PKI ($400/month - expensive for home lab)</li></ul></li><li><p><strong>ALB Configuration</strong>:</p><ul><li>HTTPS listener on port 443</li><li>Target group pointing to EC2 boot server</li><li>Security policy with TLS 1.2+ minimum</li></ul></li><li><p><strong>Alternative: Direct EC2 HTTPS</strong>:</p><ul><li>Run nginx/Apache with TLS on EC2 instance</li><li>Access via VPN tunnel to private IP with HTTPS</li><li>Simpler setup for VPN-only scenario</li><li>Use Let&rsquo;s Encrypt or self-signed certificate</li></ul></li></ol><h3 id=mutual-tls-mtls-support>Mutual TLS (mTLS) Support</h3><p>AWS ALB supports mutual TLS authentication (as of 2022):</p><ul><li><strong>Client Certificates</strong>: Require client certificates for authentication</li><li><strong>Trust Store</strong>: Upload trusted CA certificates to ALB</li><li><strong>Use Case</strong>: Ensure only authorized home lab servers can access boot files</li><li><strong>Integration</strong>: Combine with VPN for defense-in-depth</li><li><strong>Passthrough Mode</strong>: ALB can pass client cert to backend for validation</li></ul><h2 id=routing-and-load-balancing-capabilities>Routing and Load Balancing Capabilities</h2><h3 id=vpc-routing>VPC Routing</h3><ul><li><strong>Route Tables</strong>: Define routes to direct traffic through VPN gateway</li><li><strong>Route Propagation</strong>: BGP route propagation for VPN connections</li><li><strong>Transit Gateway</strong>: Advanced multi-VPC/VPN routing (overkill for home lab)</li></ul><h3 id=security-groups>Security Groups</h3><ul><li><strong>Stateful Firewall</strong>: Automatic return traffic handling</li><li><strong>Ingress/Egress Rules</strong>: Fine-grained control by protocol, port, source/destination</li><li><strong>Security Group Chaining</strong>: Reference security groups in rules (elegant for VPN setup)</li><li><strong>VPN Subnet Restriction</strong>: Allow traffic only from VPN-connected subnet</li></ul><h3 id=network-acls-optional>Network ACLs (Optional)</h3><ul><li><strong>Stateless Firewall</strong>: Subnet-level access control</li><li><strong>Defense in Depth</strong>: Additional layer beyond security groups</li><li><strong>Use Case</strong>: Probably unnecessary for simple VPN boot server</li></ul><h2 id=cost-implications>Cost Implications</h2><h3 id=data-transfer-costs>Data Transfer Costs</h3><ul><li><strong>VPN Traffic</strong>: Data transfer through VPN gateway charged at standard rates</li><li><strong>Intra-Region</strong>: Free for traffic within same region/VPC</li><li><strong>Boot File Sizes</strong>: Typical kernel + initrd = 50-200MB per boot</li><li><strong>Monthly Estimate</strong>: 10 boots/month Ã— 150MB = 1.5GB â‰ˆ $0.14/month (US East egress)</li></ul><h3 id=load-balancing-costs>Load Balancing Costs</h3><ul><li><strong>Application Load Balancer</strong>: <del>$0.0225/hour + $0.008 per LCU-hour (</del>$16-20/month minimum)</li><li><strong>Network Load Balancer</strong>: <del>$0.0225/hour + $0.006 per NLCU-hour (</del>$16-18/month minimum)</li><li><strong>For VPN Scenario</strong>: Load balancer unnecessary (single EC2 instance sufficient)</li></ul><h3 id=compute-costs>Compute Costs</h3><ul><li><strong>t3.micro Instance</strong>: ~$7.50/month (on-demand pricing, US East)</li><li><strong>t4g.micro Instance</strong>: ~$6.00/month (ARM-based, cheaper, sufficient for boot server)</li><li><strong>Reserved Instances</strong>: Up to 72% savings with 1-year or 3-year commitment</li><li><strong>Savings Plans</strong>: Flexible discounts for consistent compute usage</li></ul><h3 id=acm-certificate-costs>ACM Certificate Costs</h3><ul><li><strong>Public Certificates</strong>: <strong>Free</strong> when used with AWS services</li><li><strong>Private CA</strong>: $400/month (too expensive for home lab)</li></ul><h2 id=comparison-with-requirements>Comparison with Requirements</h2><table><thead><tr><th>Requirement</th><th>AWS Support</th><th>Implementation</th></tr></thead><tbody><tr><td>TFTP</td><td>âš ï¸ Via EC2, not ELB</td><td>Direct EC2 access via VPN</td></tr><tr><td>HTTP</td><td>âœ… Full support</td><td>EC2 or ALB</td></tr><tr><td>HTTPS</td><td>âœ… Full support</td><td>EC2 or ALB with ACM</td></tr><tr><td>VPN Integration</td><td>âœ… Native VPN</td><td>Site-to-Site VPN or self-managed</td></tr><tr><td>Load Balancing</td><td>âœ… ALB, NLB</td><td>Optional for HA</td></tr><tr><td>Certificate Mgmt</td><td>âœ… ACM (free)</td><td>Automatic renewal</td></tr><tr><td>Cost Efficiency</td><td>âœ… Low-cost instances</td><td>t4g.micro sufficient</td></tr></tbody></table><h2 id=recommendations>Recommendations</h2><h3 id=for-vpn-based-architecture-per-adr-0002>For VPN-Based Architecture (per ADR-0002)</h3><ol><li><p><strong>EC2 Instance</strong>: Deploy single t4g.micro or t3.micro instance with:</p><ul><li>TFTP server (<code>tftpd-hpa</code> or <code>dnsmasq</code>)</li><li>HTTP server (nginx or simple Python HTTP server)</li><li>Optional HTTPS with Let&rsquo;s Encrypt or self-signed certificate</li></ul></li><li><p><strong>VPN Connection</strong>: Connect home lab to AWS via:</p><ul><li>Site-to-Site VPN (IPsec) - managed service, higher cost (~$36/month)</li><li>Self-managed WireGuard on EC2 - lower cost, more control</li></ul></li><li><p><strong>Security Groups</strong>: Restrict access to:</p><ul><li>UDP/69 (TFTP) from VPN security group only</li><li>TCP/80 (HTTP) from VPN security group only</li><li>TCP/443 (HTTPS) from VPN security group only</li></ul></li><li><p><strong>No Load Balancer</strong>: For home lab scale, direct EC2 access is sufficient</p></li><li><p><strong>Health Monitoring</strong>: Use CloudWatch for instance and service health</p></li></ol><h3 id=if-ha-required-future-enhancement>If HA Required (Future Enhancement)</h3><ul><li>Deploy multi-AZ EC2 instances with Network Load Balancer</li><li>Use S3 as backend for boot files with EC2 serving as cache</li><li>Implement auto-recovery with Auto Scaling Group (min=max=1)</li></ul><h2 id=references>References</h2><ul><li><a href=https://docs.aws.amazon.com/elasticloadbalancing/>AWS Elastic Load Balancing Documentation</a></li><li><a href=https://docs.aws.amazon.com/acm/>AWS Certificate Manager</a></li><li><a href=https://docs.aws.amazon.com/vpn/>AWS Site-to-Site VPN</a></li><li><a href=https://ipxe.org/crypto>iPXE HTTPS Boot</a></li><li><a href=https://uefi.org/specs/UEFI/2.10/24_Network_Protocols.html#http-boot>UEFI HTTP Boot Specification</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-7800b35f37709f63e0f12019a82ee550>1.3.2 - AWS WireGuard VPN Support</h1><div class=lead>Analysis of WireGuard VPN deployment options on Amazon Web Services for secure site-to-site connectivity</div><h1 id=wireguard-vpn-support-on-amazon-web-services>WireGuard VPN Support on Amazon Web Services</h1><p>This document analyzes options for deploying WireGuard VPN on AWS to establish secure site-to-site connectivity between the home lab and cloud-hosted network boot infrastructure.</p><h2 id=wireguard-overview>WireGuard Overview</h2><p>WireGuard is a modern VPN protocol that provides:</p><ul><li><strong>Simplicity</strong>: Minimal codebase (~4,000 lines vs 100,000+ for IPsec)</li><li><strong>Performance</strong>: High throughput with low overhead</li><li><strong>Security</strong>: Modern cryptography (Curve25519, ChaCha20, Poly1305, BLAKE2s)</li><li><strong>Configuration</strong>: Simple key-based configuration</li><li><strong>Kernel Integration</strong>: Mainline Linux kernel support since 5.6</li></ul><h2 id=aws-native-vpn-support>AWS Native VPN Support</h2><h3 id=site-to-site-vpn-ipsec>Site-to-Site VPN (IPsec)</h3><p><strong>Status</strong>: âŒ <strong>WireGuard not natively supported</strong></p><p>AWS&rsquo;s managed Site-to-Site VPN supports:</p><ul><li><strong>IPsec VPN</strong>: IKEv1, IKEv2 with pre-shared keys</li><li><strong>Redundancy</strong>: Two VPN tunnels per connection for high availability</li><li><strong>BGP Support</strong>: Dynamic routing via BGP</li><li><strong>Transit Gateway</strong>: Scalable multi-VPC VPN hub</li></ul><p><strong>Limitation</strong>: Site-to-Site VPN does <strong>not</strong> support WireGuard protocol natively.</p><h3 id=cost-site-to-site-vpn>Cost: Site-to-Site VPN</h3><ul><li><strong>VPN Connection</strong>: ~$0.05/hour = ~$36/month</li><li><strong>Data Transfer</strong>: Standard data transfer out rates (~$0.09/GB for first 10TB)</li><li><strong>Total Estimate</strong>: ~$36-50/month for managed IPsec VPN</li></ul><h2 id=self-managed-wireguard-on-ec2>Self-Managed WireGuard on EC2</h2><h3 id=implementation-approach>Implementation Approach</h3><p>Since AWS doesn&rsquo;t offer managed WireGuard, deploy WireGuard on an EC2 instance:</p><p><strong>Status</strong>: âœ… <strong>Fully supported via EC2</strong></p><h4 id=architecture>Architecture</h4><pre class=mermaid>graph LR
    A[Home Lab] --&gt;|WireGuard Tunnel| B[AWS EC2 Instance]
    B --&gt;|VPC Network| C[Boot Server EC2]
    B --&gt;|IP Forwarding| C
    
    subgraph &#34;Home Network&#34;
        A
        D[UDM Pro]
        D -.WireGuard Client.- A
    end
    
    subgraph &#34;AWS VPC&#34;
        B[WireGuard Gateway EC2]
        C[Boot Server EC2]
    end</pre><h4 id=ec2-configuration>EC2 Configuration</h4><ol><li><p><strong>WireGuard Gateway Instance</strong>:</p><ul><li><strong>Instance Type</strong>: t4g.micro or t3.micro ($6-7.50/month)</li><li><strong>OS</strong>: Ubuntu 22.04 LTS or Amazon Linux 2023 (native WireGuard support)</li><li><strong>Source/Dest Check</strong>: <strong>Disable</strong> to allow IP forwarding</li><li><strong>Elastic IP</strong>: Allocate Elastic IP for stable WireGuard endpoint</li><li><strong>Security Group</strong>: Allow UDP port 51820 from home lab public IP</li></ul></li><li><p><strong>Boot Server Instance</strong>:</p><ul><li><strong>Network</strong>: Same VPC as WireGuard gateway</li><li><strong>Private IP Only</strong>: No Elastic IP (accessed via VPN)</li><li><strong>Route Traffic</strong>: Through WireGuard gateway instance</li></ul></li></ol><h4 id=installation-steps>Installation Steps</h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># On EC2 Instance (Ubuntu 22.04+)</span>
</span></span><span class=line><span class=cl>sudo apt update
</span></span><span class=line><span class=cl>sudo apt install wireguard wireguard-tools
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Generate server keys</span>
</span></span><span class=line><span class=cl>wg genkey <span class=p>|</span> tee /etc/wireguard/server_private.key <span class=p>|</span> wg pubkey &gt; /etc/wireguard/server_public.key
</span></span><span class=line><span class=cl>chmod <span class=m>600</span> /etc/wireguard/server_private.key
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure WireGuard interface</span>
</span></span><span class=line><span class=cl>sudo nano /etc/wireguard/wg0.conf
</span></span></code></pre></div><p><strong>Example <code>/etc/wireguard/wg0.conf</code> on AWS EC2</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=k>[Interface]</span>
</span></span><span class=line><span class=cl><span class=na>Address</span> <span class=o>=</span> <span class=s>10.200.0.1/24</span>
</span></span><span class=line><span class=cl><span class=na>ListenPort</span> <span class=o>=</span> <span class=s>51820</span>
</span></span><span class=line><span class=cl><span class=na>PrivateKey</span> <span class=o>=</span> <span class=s>&lt;SERVER_PRIVATE_KEY&gt;</span>
</span></span><span class=line><span class=cl><span class=na>PostUp</span> <span class=o>=</span> <span class=s>sysctl -w net.ipv4.ip_forward=1</span>
</span></span><span class=line><span class=cl><span class=na>PostUp</span> <span class=o>=</span> <span class=s>iptables -A FORWARD -i wg0 -j ACCEPT</span>
</span></span><span class=line><span class=cl><span class=na>PostUp</span> <span class=o>=</span> <span class=s>iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</span>
</span></span><span class=line><span class=cl><span class=na>PostDown</span> <span class=o>=</span> <span class=s>iptables -D FORWARD -i wg0 -j ACCEPT</span>
</span></span><span class=line><span class=cl><span class=na>PostDown</span> <span class=o>=</span> <span class=s>iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>[Peer]</span>
</span></span><span class=line><span class=cl><span class=c1># Home Lab (UDM Pro)</span>
</span></span><span class=line><span class=cl><span class=na>PublicKey</span> <span class=o>=</span> <span class=s>&lt;CLIENT_PUBLIC_KEY&gt;</span>
</span></span><span class=line><span class=cl><span class=na>AllowedIPs</span> <span class=o>=</span> <span class=s>10.200.0.2/32, 192.168.1.0/24</span>
</span></span></code></pre></div><p><strong>Corresponding config on UDM Pro</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=k>[Interface]</span>
</span></span><span class=line><span class=cl><span class=na>Address</span> <span class=o>=</span> <span class=s>10.200.0.2/24</span>
</span></span><span class=line><span class=cl><span class=na>PrivateKey</span> <span class=o>=</span> <span class=s>&lt;CLIENT_PRIVATE_KEY&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>[Peer]</span>
</span></span><span class=line><span class=cl><span class=na>PublicKey</span> <span class=o>=</span> <span class=s>&lt;SERVER_PUBLIC_KEY&gt;</span>
</span></span><span class=line><span class=cl><span class=na>Endpoint</span> <span class=o>=</span> <span class=s>&lt;AWS_ELASTIC_IP&gt;:51820</span>
</span></span><span class=line><span class=cl><span class=na>AllowedIPs</span> <span class=o>=</span> <span class=s>10.200.0.0/24, 10.0.0.0/16</span>
</span></span><span class=line><span class=cl><span class=na>PersistentKeepalive</span> <span class=o>=</span> <span class=s>25</span>
</span></span></code></pre></div><h4 id=enable-and-start-wireguard>Enable and Start WireGuard</h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Enable IP forwarding permanently</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;net.ipv4.ip_forward=1&#34;</span> <span class=p>|</span> sudo tee -a /etc/sysctl.conf
</span></span><span class=line><span class=cl>sudo sysctl -p
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Enable WireGuard interface</span>
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> wg-quick@wg0
</span></span><span class=line><span class=cl>sudo systemctl start wg-quick@wg0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Verify status</span>
</span></span><span class=line><span class=cl>sudo wg show
</span></span></code></pre></div><h3 id=aws-vpc-configuration>AWS VPC Configuration</h3><h4 id=security-groups>Security Groups</h4><p>Create security group for WireGuard gateway:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>aws ec2 create-security-group <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --group-name wireguard-gateway-sg <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --description <span class=s2>&#34;WireGuard VPN gateway&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --vpc-id vpc-xxxxxx
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>aws ec2 authorize-security-group-ingress <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --group-id sg-xxxxxx <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --protocol udp <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --port <span class=m>51820</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --cidr &lt;HOME_LAB_PUBLIC_IP&gt;/32
</span></span></code></pre></div><p>Allow SSH for management (optional, restrict to trusted IP):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>aws ec2 authorize-security-group-ingress <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --group-id sg-xxxxxx <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --protocol tcp <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --port <span class=m>22</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --cidr &lt;TRUSTED_IP&gt;/32
</span></span></code></pre></div><h4 id=disable-sourcedestination-check>Disable Source/Destination Check</h4><p>Required for IP forwarding to work:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>aws ec2 modify-instance-attribute <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --instance-id i-xxxxxx <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --no-source-dest-check
</span></span></code></pre></div><h4 id=elastic-ip-allocation>Elastic IP Allocation</h4><p>Allocate and associate Elastic IP for stable endpoint:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>aws ec2 allocate-address --domain vpc
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>aws ec2 associate-address <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --instance-id i-xxxxxx <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --allocation-id eipalloc-xxxxxx
</span></span></code></pre></div><p><strong>Cost</strong>: Elastic IP is <strong>free</strong> when associated with running instance, but charged ~$3.60/month if unattached.</p><h4 id=route-table-configuration>Route Table Configuration</h4><p>Add route to direct home lab subnet traffic through WireGuard gateway:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>aws ec2 create-route <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --route-table-id rtb-xxxxxx <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --destination-cidr-block 192.168.1.0/24 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --instance-id i-xxxxxx
</span></span></code></pre></div><p>This routes home lab subnet (192.168.1.0/24) through the WireGuard gateway instance.</p><h2 id=udm-pro-wireguard-integration>UDM Pro WireGuard Integration</h2><h3 id=native-support>Native Support</h3><p><strong>Status</strong>: âœ… <strong>WireGuard supported natively</strong> (UniFi OS 1.12.22+)</p><p>The UniFi Dream Machine Pro includes native WireGuard VPN support:</p><ul><li><strong>GUI Configuration</strong>: Web UI for WireGuard VPN setup</li><li><strong>Site-to-Site</strong>: Support for site-to-site VPN tunnels</li><li><strong>Performance</strong>: Hardware acceleration for encryption (if available)</li><li><strong>Routing</strong>: Automatic route injection for remote subnets</li></ul><h3 id=configuration-steps-on-udm-pro>Configuration Steps on UDM Pro</h3><ol><li><p><strong>Network Settings â†’ VPN</strong>:</p><ul><li>Create new VPN connection</li><li>Select &ldquo;WireGuard&rdquo;</li><li>Generate key pair or import existing</li></ul></li><li><p><strong>Peer Configuration</strong>:</p><ul><li><strong>Peer Public Key</strong>: AWS EC2 WireGuard instance&rsquo;s public key</li><li><strong>Endpoint</strong>: AWS Elastic IP address</li><li><strong>Port</strong>: 51820</li><li><strong>Allowed IPs</strong>: AWS VPC CIDR (e.g., 10.0.0.0/16)</li><li><strong>Persistent Keepalive</strong>: 25 seconds</li></ul></li><li><p><strong>Route Injection</strong>:</p><ul><li>UDM Pro automatically adds routes to AWS subnets</li><li>Home lab servers can reach AWS boot server via VPN</li></ul></li><li><p><strong>Firewall Rules</strong>:</p><ul><li>Add firewall rule to allow boot traffic (TFTP, HTTP) from LAN to VPN</li></ul></li></ol><h3 id=alternative-manual-wireguard-on-udm-pro>Alternative: Manual WireGuard on UDM Pro</h3><p>If native support is insufficient, use <code>wireguard-go</code> via <code>udm-utilities</code>:</p><ul><li><strong>Repository</strong>: <a href=https://github.com/boostchicken/udm-utilities>boostchicken/udm-utilities</a></li><li><strong>Script</strong>: <code>on_boot.d</code> script to start WireGuard on boot</li><li><strong>Persistence</strong>: Survives firmware updates with on-boot script</li></ul><h2 id=performance-considerations>Performance Considerations</h2><h3 id=throughput>Throughput</h3><p>WireGuard on EC2 performance varies by instance type:</p><ul><li><strong>t4g.micro</strong> (2 vCPU, ARM): ~100-300 Mbps</li><li><strong>t3.micro</strong> (2 vCPU, x86): ~100-300 Mbps</li><li><strong>t3.small</strong> (2 vCPU): ~500-800 Mbps</li><li><strong>t3.medium</strong> (2 vCPU): ~1+ Gbps</li></ul><p>For network boot (typical boot = 50-200MB), even t4g.micro is sufficient:</p><ul><li><strong>Boot Time</strong>: 150MB at 100 Mbps = ~12 seconds transfer time</li><li><strong>Recommendation</strong>: t4g.micro adequate and most cost-effective</li></ul><h3 id=latency>Latency</h3><ul><li><strong>VPN Overhead</strong>: WireGuard adds minimal latency (~1-5ms)</li><li><strong>AWS Network</strong>: Low-latency network infrastructure</li><li><strong>Total Latency</strong>: Primarily dependent on home ISP and AWS region proximity</li></ul><h3 id=cpu-usage>CPU Usage</h3><ul><li><strong>Encryption</strong>: ChaCha20 is CPU-efficient</li><li><strong>Kernel Module</strong>: Minimal CPU overhead in kernel space</li><li><strong>t4g.micro</strong>: Sufficient CPU for home lab VPN throughput</li><li><strong>ARM Advantage</strong>: t4g instances use Graviton processors (better price/performance)</li></ul><h2 id=security-considerations>Security Considerations</h2><h3 id=key-management>Key Management</h3><ul><li><strong>Private Keys</strong>: Store securely, never commit to version control</li><li><strong>Key Rotation</strong>: Rotate keys periodically (e.g., annually)</li><li><strong>Secrets Manager</strong>: Store WireGuard private keys in AWS Secrets Manager<ul><li>Retrieve at instance startup via user data script</li><li>Avoid storing in AMIs or instance metadata</li></ul></li><li><strong>IAM Role</strong>: Grant EC2 instance IAM role to read secret</li></ul><h3 id=firewall-hardening>Firewall Hardening</h3><ul><li><strong>Security Group Restriction</strong>: Limit WireGuard port to home lab public IP only</li><li><strong>Least Privilege</strong>: Boot server security group allows only VPN security group</li><li><strong>No Public Access</strong>: Boot server has no Elastic IP or public route</li></ul><h3 id=monitoring-and-alerts>Monitoring and Alerts</h3><ul><li><strong>CloudWatch Logs</strong>: Stream WireGuard logs to CloudWatch</li><li><strong>CloudWatch Alarms</strong>: Alert on VPN tunnel down (no recent handshakes)</li><li><strong>VPC Flow Logs</strong>: Monitor VPN traffic patterns</li></ul><h3 id=ddos-protection>DDoS Protection</h3><ul><li><strong>UDP Amplification</strong>: WireGuard resistant to DDoS amplification attacks</li><li><strong>AWS Shield</strong>: Basic DDoS protection included free on all AWS resources</li><li><strong>Shield Advanced</strong>: Optional ($3,000/month - overkill for VPN endpoint)</li></ul><h2 id=high-availability-options>High Availability Options</h2><h3 id=multi-az-failover>Multi-AZ Failover</h3><p>Deploy WireGuard gateways in multiple Availability Zones:</p><ul><li><strong>Primary</strong>: us-east-1a WireGuard instance</li><li><strong>Secondary</strong>: us-east-1b WireGuard instance</li><li><strong>Failover</strong>: UDM Pro switches endpoints if primary fails</li><li><strong>Cost</strong>: Doubles instance costs (~$12-15/month for 2 instances)</li></ul><h3 id=auto-scaling-group-single-instance>Auto Scaling Group (Single Instance)</h3><p>Use Auto Scaling Group with min=max=1 for auto-recovery:</p><ul><li><strong>Health Checks</strong>: EC2 status checks</li><li><strong>Auto-Recovery</strong>: ASG replaces failed instance automatically</li><li><strong>Elastic IP</strong>: Reassociate Elastic IP to new instance via Lambda/script</li><li><strong>Limitation</strong>: Brief downtime during recovery (~2-5 minutes)</li></ul><h3 id=health-monitoring>Health Monitoring</h3><p>Monitor WireGuard tunnel health with CloudWatch custom metrics:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># On EC2 instance, run periodically via cron</span>
</span></span><span class=line><span class=cl><span class=c1>#!/bin/bash</span>
</span></span><span class=line><span class=cl><span class=nv>HANDSHAKE</span><span class=o>=</span><span class=k>$(</span>wg show wg0 latest-handshakes <span class=p>|</span> awk <span class=s1>&#39;{print $2}&#39;</span><span class=k>)</span>
</span></span><span class=line><span class=cl><span class=nv>NOW</span><span class=o>=</span><span class=k>$(</span>date +%s<span class=k>)</span>
</span></span><span class=line><span class=cl><span class=nv>AGE</span><span class=o>=</span><span class=k>$((</span>NOW <span class=o>-</span> HANDSHAKE<span class=k>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>aws cloudwatch put-metric-data <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --namespace WireGuard <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --metric-name TunnelAge <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --value <span class=nv>$AGE</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --unit Seconds
</span></span></code></pre></div><p>Alert if handshake age exceeds threshold (e.g., 180 seconds).</p><h3 id=user-data-script-for-auto-configuration>User Data Script for Auto-Configuration</h3><p>EC2 user data script to configure WireGuard on launch:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=c1># Install WireGuard</span>
</span></span><span class=line><span class=cl>apt update <span class=o>&amp;&amp;</span> apt install -y wireguard wireguard-tools
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Retrieve private key from Secrets Manager</span>
</span></span><span class=line><span class=cl>aws secretsmanager get-secret-value <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --secret-id wireguard-server-key <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --query SecretString <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --output text &gt; /etc/wireguard/server_private.key
</span></span><span class=line><span class=cl>chmod <span class=m>600</span> /etc/wireguard/server_private.key
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure interface (full config omitted for brevity)</span>
</span></span><span class=line><span class=cl><span class=c1># ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Enable and start WireGuard</span>
</span></span><span class=line><span class=cl>systemctl <span class=nb>enable</span> wg-quick@wg0
</span></span><span class=line><span class=cl>systemctl start wg-quick@wg0
</span></span></code></pre></div><p>Requires IAM instance role with <code>secretsmanager:GetSecretValue</code> permission.</p><h2 id=cost-analysis>Cost Analysis</h2><h3 id=self-managed-wireguard-on-ec2-1>Self-Managed WireGuard on EC2</h3><table><thead><tr><th>Component</th><th>Cost (US East)</th></tr></thead><tbody><tr><td>t4g.micro instance (730 hrs/month)</td><td>~$6.00</td></tr><tr><td>Elastic IP (attached)</td><td>$0.00</td></tr><tr><td>Data transfer out (1GB/month)</td><td>~$0.09</td></tr><tr><td><strong>Monthly Total</strong></td><td><strong>~$6.09</strong></td></tr><tr><td><strong>Annual Total</strong></td><td><strong>~$73</strong></td></tr></tbody></table><p>With Reserved Instance (1-year, no upfront):</p><table><thead><tr><th>Component</th><th>Cost</th></tr></thead><tbody><tr><td>t4g.micro RI (1-year)</td><td>~$3.50/month</td></tr><tr><td>Elastic IP</td><td>$0.00</td></tr><tr><td>Data transfer</td><td>~$0.09</td></tr><tr><td><strong>Monthly Total</strong></td><td><strong>~$3.59</strong></td></tr><tr><td><strong>Annual Total</strong></td><td><strong>~$43</strong></td></tr></tbody></table><h3 id=site-to-site-vpn-ipsec---if-wireguard-not-used>Site-to-Site VPN (IPsec - if WireGuard not used)</h3><table><thead><tr><th>Component</th><th>Cost</th></tr></thead><tbody><tr><td>VPN Connection (2 tunnels)</td><td>~$36</td></tr><tr><td>Data transfer (1GB/month)</td><td>~$0.09</td></tr><tr><td><strong>Monthly Total</strong></td><td><strong>~$36</strong></td></tr><tr><td><strong>Annual Total</strong></td><td><strong>~$432</strong></td></tr></tbody></table><p><strong>Cost Savings</strong>: Self-managed WireGuard saves <strong>~$360/year</strong> vs Site-to-Site VPN (or <strong>~$390/year</strong> with Reserved Instance).</p><h2 id=comparison-with-requirements>Comparison with Requirements</h2><table><thead><tr><th>Requirement</th><th>AWS Support</th><th>Implementation</th></tr></thead><tbody><tr><td>WireGuard Protocol</td><td>âœ… Via EC2</td><td>Self-managed on instance</td></tr><tr><td>Site-to-Site VPN</td><td>âœ… Yes</td><td>WireGuard tunnel</td></tr><tr><td>UDM Pro Integration</td><td>âœ… Native support</td><td>WireGuard peer config</td></tr><tr><td>Cost Efficiency</td><td>âœ… Very low cost</td><td>t4g.micro ~$6/month (on-demand)</td></tr><tr><td>Performance</td><td>âœ… Sufficient</td><td>100+ Mbps on t4g.micro</td></tr><tr><td>Security</td><td>âœ… Modern crypto</td><td>ChaCha20, Curve25519</td></tr><tr><td>HA (optional)</td><td>âš ï¸ Manual setup</td><td>Multi-AZ or ASG</td></tr></tbody></table><h2 id=recommendations>Recommendations</h2><h3 id=for-home-lab-vpn-per-adr-0002>For Home Lab VPN (per ADR-0002)</h3><ol><li><p><strong>Self-Managed WireGuard</strong>: Deploy on EC2 t4g.micro instance</p><ul><li><strong>Cost</strong>: ~$6/month on-demand, ~$3.50/month with Reserved Instance</li><li><strong>Performance</strong>: Sufficient for network boot traffic</li><li><strong>Simplicity</strong>: Easy to configure and maintain</li></ul></li><li><p><strong>Single AZ Deployment</strong>: Unless HA required, single instance adequate</p><ul><li><strong>Region Selection</strong>: Choose region closest to home lab for lowest latency</li><li><strong>AZ</strong>: Single AZ sufficient (boot server not mission-critical)</li></ul></li><li><p><strong>UDM Pro Native WireGuard</strong>: Use built-in WireGuard client</p><ul><li><strong>Configuration</strong>: Add AWS instance as WireGuard peer in UDM Pro UI</li><li><strong>Route Injection</strong>: UDM Pro automatically routes AWS subnets</li></ul></li><li><p><strong>Security Best Practices</strong>:</p><ul><li>Store WireGuard private key in Secrets Manager</li><li>Restrict security group to home lab public IP only</li><li>Use user data script to retrieve key and configure on boot</li><li>Enable CloudWatch logging for VPN events</li><li>Assign IAM instance role with minimal permissions</li></ul></li><li><p><strong>Monitoring</strong>: Set up CloudWatch alarms for:</p><ul><li>Instance status check failures</li><li>High CPU usage</li><li>VPN tunnel age (custom metric)</li></ul></li></ol><h3 id=cost-optimization>Cost Optimization</h3><ul><li><strong>Reserved Instance</strong>: Commit to 1-year Reserved Instance for ~40% savings</li><li><strong>Spot Instance</strong>: Consider Spot for even lower cost (~70% savings), but adds complexity (handle interruptions)</li><li><strong>ARM Architecture</strong>: Use t4g (Graviton) for 20% better price/performance vs t3</li></ul><h3 id=future-enhancements>Future Enhancements</h3><ul><li><strong>HA Setup</strong>: Deploy secondary WireGuard instance in different AZ</li><li><strong>Automated Failover</strong>: Lambda function to reassociate Elastic IP on failure</li><li><strong>IPv6 Support</strong>: Enable WireGuard over IPv6 if home ISP supports</li><li><strong>Mesh VPN</strong>: Expand to mesh topology if multiple sites added</li></ul><h2 id=references>References</h2><ul><li><a href=https://www.wireguard.com/>WireGuard Official Site</a></li><li><a href=https://ubuntu.com/server/docs/wireguard-vpn>WireGuard on Ubuntu</a></li><li><a href=https://docs.aws.amazon.com/vpc/latest/userguide/VPC_NAT_Instance.html#EIP_Disable_SrcDestCheck>AWS EC2 IP Forwarding (Disable Source/Dest Check)</a></li><li><a href=https://help.ui.com/hc/en-us/articles/115015971688>UniFi WireGuard VPN</a></li><li><a href=https://github.com/boostchicken/udm-utilities>udm-utilities GitHub</a></li><li><a href=https://docs.aws.amazon.com/secretsmanager/>AWS Secrets Manager</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-5fc1fe2c927f9c765cb98268d4cb8c5e>1.4 - Google Cloud Platform Analysis</h1><div class=lead>Technical analysis of Google Cloud Platform capabilities for hosting network boot infrastructure</div><p>This section contains detailed analysis of Google Cloud Platform (GCP) for hosting the network boot server infrastructure, evaluating its support for TFTP, HTTP/HTTPS routing, and WireGuard VPN connectivity as required by ADR-0002.</p><h2 id=overview>Overview</h2><p>Google Cloud Platform is Google&rsquo;s suite of cloud computing services, offering compute, storage, networking, and managed services. This analysis focuses on GCP&rsquo;s capabilities to support the network boot architecture decided in <a href=../../adrs/0002-network-boot-architecture/>ADR-0002</a>.</p><h2 id=key-services-evaluated>Key Services Evaluated</h2><ul><li><strong>Compute Engine</strong>: Virtual machine instances for hosting boot server</li><li><strong>Cloud VPN / VPC</strong>: Network connectivity and VPN capabilities</li><li><strong>Cloud Load Balancing</strong>: Layer 4 and Layer 7 load balancing for HTTP/HTTPS</li><li><strong>Cloud NAT</strong>: Network address translation for outbound connectivity</li><li><strong>VPC Network</strong>: Software-defined networking and routing</li></ul><h2 id=documentation-sections>Documentation Sections</h2><ul><li><a href=./network-boot/>Network Boot Support</a> - Analysis of TFTP, HTTP, and HTTPS routing capabilities</li><li><a href=./wireguard/>WireGuard Support</a> - Evaluation of WireGuard VPN integration options</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8349b2324a2beea2d0650a6b39802b81>1.4.1 - Cloud Storage FUSE (gcsfuse)</h1><div class=lead>Analysis of Google Cloud Storage FUSE for mounting GCS buckets as local filesystems in network boot infrastructure</div><h2 id=overview>Overview</h2><p>Cloud Storage FUSE (gcsfuse) is a FUSE-based filesystem adapter that allows Google Cloud Storage (GCS) buckets to be mounted and accessed as local filesystems on Linux systems. This enables applications to interact with object storage using standard filesystem operations (open, read, write, etc.) rather than requiring GCS-specific APIs.</p><p><strong>Project</strong>: <a href=https://github.com/GoogleCloudPlatform/gcsfuse>GoogleCloudPlatform/gcsfuse</a>
<strong>License</strong>: Apache 2.0
<strong>Status</strong>: Generally Available (GA)
<strong>Latest Version</strong>: v2.x (as of 2024)</p><h2 id=how-gcsfuse-works>How gcsfuse Works</h2><p>gcsfuse translates filesystem operations into GCS API calls:</p><ol><li><strong>Mount Operation</strong>: <code>gcsfuse bucket-name /mount/point</code> maps a GCS bucket to a local directory</li><li><strong>Directory Structure</strong>: Interprets <code>/</code> in object names as directory separators</li><li><strong>File Operations</strong>: Translates <code>read()</code>, <code>write()</code>, <code>open()</code>, etc. into GCS API requests</li><li><strong>Metadata</strong>: Maintains file attributes (size, modification time) via GCS metadata</li><li><strong>Caching</strong>: Optional stat, type, list, and file caching to reduce API calls</li></ol><p><strong>Example</strong>:</p><ul><li>GCS object: <code>gs://boot-assets/kernels/talos-v1.6.0.img</code></li><li>Mounted path: <code>/mnt/boot-assets/kernels/talos-v1.6.0.img</code></li></ul><h2 id=relevance-to-network-boot-infrastructure>Relevance to Network Boot Infrastructure</h2><p>In the context of <a href=../../adrs/0005-network-boot-infrastructure-gcp.md>ADR-0005 Network Boot Infrastructure</a>, gcsfuse offers a potential approach for serving boot assets from Cloud Storage without custom integration code.</p><h3 id=potential-use-cases>Potential Use Cases</h3><ol><li><strong>Boot Asset Storage</strong>: Mount <code>gs://boot-assets/</code> to <code>/var/lib/boot-server/assets/</code></li><li><strong>Configuration Sync</strong>: Access boot profiles and machine mappings from GCS as local files</li><li><strong>Matchbox Integration</strong>: Mount GCS bucket to <code>/var/lib/matchbox/</code> for assets/profiles/groups</li><li><strong>Simplified Development</strong>: Eliminate custom Cloud Storage SDK integration in boot server code</li></ol><h3 id=architecture-pattern>Architecture Pattern</h3><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Boot Server Process   â”‚
â”‚  (Cloud Run/Compute)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ filesystem operations
            â”‚ (read, open, stat)
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   gcsfuse mount point   â”‚
â”‚   /var/lib/boot-assets  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ FUSE layer
            â”‚ (translates to GCS API)
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cloud Storage Bucket   â”‚
â”‚   gs://boot-assets/     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><h2 id=performance-characteristics>Performance Characteristics</h2><h3 id=latency>Latency</h3><ul><li><strong>Much higher latency than local filesystem</strong>: Every operation requires GCS API call(s)</li><li><strong>No default caching</strong>: Without caching enabled, every read re-fetches from GCS</li><li><strong>Network round-trip</strong>: Minimum ~10-50ms latency per operation (depending on region)</li></ul><h3 id=throughput>Throughput</h3><p><strong>Single Large File</strong>:</p><ul><li>Read: ~4.1 MiB/s (individual file), up to 63.3 MiB/s (archive files)</li><li>Write: Comparable to <code>gsutil cp</code> for large files</li><li><strong>With parallel downloads</strong>: Up to 9x faster for single-threaded reads of large files</li></ul><p><strong>Small Files</strong>:</p><ul><li>Poor performance for random I/O on small files</li><li>Bulk operations on many small files create significant bottlenecks</li><li><code>ls</code> on directories with thousands of objects can take minutes</li></ul><p><strong>Concurrent Access</strong>:</p><ul><li>Performance degrades significantly with parallel readers (8 instances: ~30 hours vs 16 minutes with local data)</li><li>Not recommended for high-concurrency scenarios (web servers, NAS)</li></ul><h3 id=performance-improvements-recent-features>Performance Improvements (Recent Features)</h3><ol><li><p><strong>Streaming Writes</strong> (default): Upload data directly to GCS as written</p><ul><li>Up to 40% faster for large sequential writes</li><li>Reduces local disk usage (no staging file)</li></ul></li><li><p><strong>Parallel Downloads</strong>: Download large files using multiple workers</p><ul><li>Up to 9x faster model load times</li><li>Best for single-threaded reads of large files</li></ul></li><li><p><strong>File Cache</strong>: Cache file contents locally (Local SSD, Persistent Disk, or tmpfs)</p><ul><li>Up to 2.3x faster training time (AI/ML workloads)</li><li>Up to 3.4x higher throughput</li><li>Requires explicit cache directory configuration</li></ul></li><li><p><strong>Metadata Cache</strong>: Cache stat, type, and list operations</p><ul><li>Stat and type caches enabled by default</li><li>Configurable TTL (default: 60s, set <code>-1</code> for unlimited)</li></ul></li></ol><h2 id=caching-configuration>Caching Configuration</h2><p>gcsfuse provides four types of caching:</p><h3 id=1-stat-cache>1. Stat Cache</h3><p>Caches file attributes (size, modification time, existence).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Enable with unlimited size and TTL</span>
</span></span><span class=line><span class=cl>gcsfuse <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stat-cache-max-size-mb<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --metadata-cache-ttl-secs<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  bucket-name /mount/point
</span></span></code></pre></div><p><strong>Use case</strong>: Reduces API calls for repeated <code>stat()</code> operations (e.g., checking file existence).</p><h3 id=2-type-cache>2. Type Cache</h3><p>Caches file vs directory type information.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcsfuse <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --type-cache-max-size-mb<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --metadata-cache-ttl-secs<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  bucket-name /mount/point
</span></span></code></pre></div><p><strong>Use case</strong>: Speeds up directory traversal and <code>ls</code> operations.</p><h3 id=3-list-cache>3. List Cache</h3><p>Caches directory listing results.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcsfuse <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --max-conns-per-host<span class=o>=</span><span class=m>100</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --metadata-cache-ttl-secs<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  bucket-name /mount/point
</span></span></code></pre></div><p><strong>Use case</strong>: Improves performance for applications that repeatedly list directory contents.</p><h3 id=4-file-cache>4. File Cache</h3><p>Caches actual file contents locally.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcsfuse <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --file-cache-max-size-mb<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --cache-dir<span class=o>=</span>/mnt/local-ssd <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --file-cache-cache-file-for-range-read<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --file-cache-enable-parallel-downloads<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  bucket-name /mount/point
</span></span></code></pre></div><p><strong>Use case</strong>: Essential for AI/ML training, repeated reads of large files.</p><p><strong>Recommended cache storage</strong>:</p><ul><li><strong>Local SSD</strong>: Fastest, but ephemeral (data lost on restart)</li><li><strong>Persistent Disk</strong>: Persistent but slower than Local SSD</li><li><strong>tmpfs</strong> (RAM disk): Fastest but limited by memory</li></ul><h3 id=production-configuration-example>Production Configuration Example</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># config.yaml for gcsfuse</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata-cache</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>ttl-secs</span><span class=p>:</span><span class=w> </span>-<span class=m>1</span><span class=w>  </span><span class=c># Never expire (use only if bucket is read-only or single-writer)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>stat-cache-max-size-mb</span><span class=p>:</span><span class=w> </span>-<span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type-cache-max-size-mb</span><span class=p>:</span><span class=w> </span>-<span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>file-cache</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max-size-mb</span><span class=p>:</span><span class=w> </span>-<span class=m>1</span><span class=w>  </span><span class=c># Unlimited (limited by disk space)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>cache-file-for-range-read</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>enable-parallel-downloads</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>parallel-downloads-per-file</span><span class=p>:</span><span class=w> </span><span class=m>16</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>download-chunk-size-mb</span><span class=p>:</span><span class=w> </span><span class=m>50</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>write</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>create-empty-file</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>  </span><span class=c># Streaming writes (default)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>logging</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>severity</span><span class=p>:</span><span class=w> </span><span class=l>info</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>format</span><span class=p>:</span><span class=w> </span><span class=l>json</span><span class=w>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcsfuse --config-file<span class=o>=</span>config.yaml boot-assets /mnt/boot-assets
</span></span></code></pre></div><h2 id=limitations-and-considerations>Limitations and Considerations</h2><h3 id=filesystem-semantics>Filesystem Semantics</h3><p>gcsfuse provides <strong>approximate POSIX semantics</strong> but is not fully POSIX-compliant:</p><ul><li><strong>No atomic rename</strong>: Rename operations are copy-then-delete (not atomic)</li><li><strong>No hard links</strong>: GCS doesn&rsquo;t support hard links</li><li><strong>No file locking</strong>: <code>flock()</code> is a no-op</li><li><strong>Limited permissions</strong>: GCS has simpler ACLs than POSIX permissions</li><li><strong>No sparse files</strong>: Writes always materialize full file content</li></ul><h3 id=performance-anti-patterns>Performance Anti-Patterns</h3><p>âŒ <strong>Avoid</strong>:</p><ul><li>Serving web content or acting as NAS (concurrent connections)</li><li>Random I/O on many small files (image datasets, text corpora)</li><li>Reading during ML training loops (download first, then train)</li><li>High-concurrency workloads (multiple parallel readers/writers)</li></ul><p>âœ… <strong>Good for</strong>:</p><ul><li>Sequential reads of large files (models, checkpoints, kernels)</li><li>Infrequent writes of entire files</li><li>Read-mostly workloads with caching enabled</li><li>Single-writer scenarios</li></ul><h3 id=consistency-trade-offs>Consistency Trade-offs</h3><p><strong>With caching enabled</strong>:</p><ul><li>Stale reads possible if cache TTL > 0 and external modifications occur</li><li>Safe only for:<ul><li>Read-only buckets</li><li>Single-writer, single-mount scenarios</li><li>Workloads tolerant of eventual consistency</li></ul></li></ul><p><strong>Without caching</strong>:</p><ul><li>Strong consistency (every read fetches latest from GCS)</li><li>Much slower performance</li></ul><h3 id=resource-requirements>Resource Requirements</h3><ul><li><strong>Disk space</strong>: File cache and streaming writes require local storage<ul><li>File cache: Size of cached files (can be large for ML datasets)</li><li>Streaming writes: Temporary staging (proportional to concurrent writes)</li></ul></li><li><strong>Memory</strong>: Metadata caches consume RAM</li><li><strong>File handles</strong>: Can exceed system limits with high concurrency</li><li><strong>Network bandwidth</strong>: All data transfers via GCS API</li></ul><h2 id=installation>Installation</h2><h3 id=on-compute-engine-container-optimized-os>On Compute Engine (Container-Optimized OS)</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install gcsfuse (Container-Optimized OS doesn&#39;t include package managers)</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>GCSFUSE_VERSION</span><span class=o>=</span>2.x.x
</span></span><span class=line><span class=cl>curl -L -O https://github.com/GoogleCloudPlatform/gcsfuse/releases/download/v<span class=si>${</span><span class=nv>GCSFUSE_VERSION</span><span class=si>}</span>/gcsfuse_<span class=si>${</span><span class=nv>GCSFUSE_VERSION</span><span class=si>}</span>_amd64.deb
</span></span><span class=line><span class=cl>sudo dpkg -i gcsfuse_<span class=si>${</span><span class=nv>GCSFUSE_VERSION</span><span class=si>}</span>_amd64.deb
</span></span></code></pre></div><h3 id=on-debianubuntu>On Debian/Ubuntu</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>GCSFUSE_REPO</span><span class=o>=</span>gcsfuse-<span class=sb>`</span>lsb_release -c -s<span class=sb>`</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;deb https://packages.cloud.google.com/apt </span><span class=nv>$GCSFUSE_REPO</span><span class=s2> main&#34;</span> <span class=p>|</span> sudo tee /etc/apt/sources.list.d/gcsfuse.list
</span></span><span class=line><span class=cl>curl https://packages.cloud.google.com/apt/doc/apt-key.gpg <span class=p>|</span> sudo apt-key add -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install gcsfuse
</span></span></code></pre></div><h3 id=in-dockercloud-run>In Docker/Cloud Run</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>FROM</span><span class=w> </span><span class=s>ubuntu:22.04</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Install gcsfuse</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> apt-get update <span class=o>&amp;&amp;</span> apt-get install -y <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    curl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    gnupg <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    lsb-release <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> <span class=nb>export</span> <span class=nv>GCSFUSE_REPO</span><span class=o>=</span>gcsfuse-<span class=k>$(</span>lsb_release -c -s<span class=k>)</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> <span class=nb>echo</span> <span class=s2>&#34;deb https://packages.cloud.google.com/apt </span><span class=nv>$GCSFUSE_REPO</span><span class=s2> main&#34;</span> <span class=p>|</span> tee /etc/apt/sources.list.d/gcsfuse.list <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> curl https://packages.cloud.google.com/apt/doc/apt-key.gpg <span class=p>|</span> apt-key add - <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> apt-get update <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> apt-get install -y gcsfuse <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> rm -rf /var/lib/apt/lists/*<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Create mount point</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> mkdir -p /mnt/boot-assets<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Mount gcsfuse at startup</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>CMD</span> gcsfuse --foreground boot-assets /mnt/boot-assets <span class=p>&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    /usr/local/bin/boot-server<span class=err>
</span></span></span></code></pre></div><p><strong>Note</strong>: Cloud Run <strong>does not support FUSE filesystems</strong> (requires privileged mode). gcsfuse only works on Compute Engine or GKE.</p><h2 id=network-boot-infrastructure-evaluation>Network Boot Infrastructure Evaluation</h2><h3 id=applicability-to-adr-0005>Applicability to ADR-0005</h3><p>Based on the analysis, gcsfuse is <strong>not recommended</strong> for the network boot infrastructure for the following reasons:</p><h4 id=-cloud-run-incompatibility>âŒ Cloud Run Incompatibility</h4><ul><li>gcsfuse requires FUSE kernel module and privileged containers</li><li>Cloud Run does not support FUSE or privileged mode</li><li>ADR-0005 prefers Cloud Run deployment (HTTP-only boot enables serverless)</li><li><strong>Impact</strong>: Blocks Cloud Run deployment, forcing Compute Engine VM</li></ul><h4 id=-boot-latency-requirements>âŒ Boot Latency Requirements</h4><ul><li>Boot file requests target &lt; 100ms latency (ADR-0005 confirmation criteria)</li><li>gcsfuse adds 10-50ms+ latency per operation (network round-trips)</li><li>Kernel/initrd downloads are latency-sensitive (network boot timeout)</li><li><strong>Impact</strong>: May exceed boot timeout thresholds</li></ul><h4 id=-no-caching-for-read-write-workloads>âŒ No Caching for Read-Write Workloads</h4><ul><li>Boot server needs to write new assets and read existing ones</li><li>File cache with unlimited TTL requires read-only or single-writer assumption</li><li>Multiple boot server instances (autoscaling) violate single-writer constraint</li><li><strong>Impact</strong>: Either accept stale reads or disable caching (slow)</li></ul><h4 id=-small-file-performance>âŒ Small File Performance</h4><ul><li>Machine mapping configs, boot scripts, profiles are small files (KB range)</li><li>gcsfuse performs poorly on small, random I/O</li><li><code>ls</code> operations on directories with many profiles can be slow</li><li><strong>Impact</strong>: Slow boot configuration lookups</li></ul><h4 id=-alternative-direct-cloud-storage-sdk>âœ… Alternative: Direct Cloud Storage SDK</h4><p>Using <code>cloud.google.com/go/storage</code> SDK directly offers:</p><ul><li><strong>Lower latency</strong>: Direct API calls without FUSE overhead</li><li><strong>Cloud Run compatible</strong>: No kernel module or privileged mode required</li><li><strong>Better control</strong>: Explicit caching, parallel downloads, streaming</li><li><strong>Simpler deployment</strong>: No mount management, no FUSE dependencies</li><li><strong>Cost</strong>: Similar API call costs to gcsfuse</li></ul><p><strong>Recommended approach</strong> (from ADR-0005):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=c1>// Custom boot server using Cloud Storage SDK</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>storage</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>storage</span><span class=p>.</span><span class=nf>NewClient</span><span class=p>(</span><span class=nx>ctx</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>bucket</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>storage</span><span class=p>.</span><span class=nf>Bucket</span><span class=p>(</span><span class=s>&#34;boot-assets&#34;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Stream kernel to boot client</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>obj</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>bucket</span><span class=p>.</span><span class=nf>Object</span><span class=p>(</span><span class=s>&#34;kernels/talos-v1.6.0.img&#34;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>reader</span><span class=p>,</span><span class=w> </span><span class=nx>_</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>obj</span><span class=p>.</span><span class=nf>NewReader</span><span class=p>(</span><span class=nx>ctx</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>defer</span><span class=w> </span><span class=nx>reader</span><span class=p>.</span><span class=nf>Close</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nx>io</span><span class=p>.</span><span class=nf>Copy</span><span class=p>(</span><span class=nx>w</span><span class=p>,</span><span class=w> </span><span class=nx>reader</span><span class=p>)</span><span class=w>  </span><span class=c1>// Stream to HTTP response</span><span class=w>
</span></span></span></code></pre></div><h3 id=when-gcsfuse-might-be-useful>When gcsfuse MIGHT Be Useful</h3><p>Despite the above limitations, gcsfuse could be considered for:</p><ol><li><p><strong>Matchbox on Compute Engine</strong>:</p><ul><li>Matchbox expects filesystem paths for assets (<code>/var/lib/matchbox/assets/</code>)</li><li>Compute Engine VM supports FUSE</li><li>Read-heavy workload (boot assets rarely change)</li><li>Could mount <code>gs://boot-assets/</code> to <code>/var/lib/matchbox/assets/</code> with file cache</li></ul></li><li><p><strong>Development/Testing</strong>:</p><ul><li>Quick prototyping without writing Cloud Storage integration</li><li>Local development with production bucket access</li><li>Not recommended for production deployment</li></ul></li><li><p><strong>Low-Throughput Scenarios</strong>:</p><ul><li>Home lab scale (&lt; 10 boots/hour)</li><li>File cache enabled with Local SSD</li><li>Single Compute Engine VM (not autoscaled)</li></ul></li></ol><p><strong>Configuration for Matchbox + gcsfuse</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=c1># Mount boot assets for Matchbox</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>BUCKET</span><span class=o>=</span><span class=s2>&#34;boot-assets&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>MOUNT_POINT</span><span class=o>=</span><span class=s2>&#34;/var/lib/matchbox/assets&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>CACHE_DIR</span><span class=o>=</span><span class=s2>&#34;/mnt/disks/local-ssd/gcsfuse-cache&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>mkdir -p <span class=s2>&#34;</span><span class=nv>$MOUNT_POINT</span><span class=s2>&#34;</span> <span class=s2>&#34;</span><span class=nv>$CACHE_DIR</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>gcsfuse <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stat-cache-max-size-mb<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --type-cache-max-size-mb<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --metadata-cache-ttl-secs<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --file-cache-max-size-mb<span class=o>=</span>-1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --cache-dir<span class=o>=</span><span class=s2>&#34;</span><span class=nv>$CACHE_DIR</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --file-cache-cache-file-for-range-read<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --file-cache-enable-parallel-downloads<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --implicit-dirs <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --foreground <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  <span class=s2>&#34;</span><span class=nv>$BUCKET</span><span class=s2>&#34;</span> <span class=s2>&#34;</span><span class=nv>$MOUNT_POINT</span><span class=s2>&#34;</span>
</span></span></code></pre></div><h2 id=monitoring-and-troubleshooting>Monitoring and Troubleshooting</h2><h3 id=metrics>Metrics</h3><p>gcsfuse exposes Prometheus metrics:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcsfuse --prometheus --prometheus-port<span class=o>=</span><span class=m>9101</span> bucket /mnt/point
</span></span></code></pre></div><p><strong>Key metrics</strong>:</p><ul><li><code>gcs_read_count</code>: Number of GCS read operations</li><li><code>gcs_write_count</code>: Number of GCS write operations</li><li><code>gcs_read_bytes</code>: Bytes read from GCS</li><li><code>gcs_write_bytes</code>: Bytes written to GCS</li><li><code>fs_ops_count</code>: Filesystem operations by type (open, read, write, etc.)</li><li><code>fs_ops_error_count</code>: Filesystem operation errors</li></ul><h3 id=logging>Logging</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># JSON logging for Cloud Logging integration</span>
</span></span><span class=line><span class=cl>gcsfuse --log-format<span class=o>=</span>json --log-file<span class=o>=</span>/var/log/gcsfuse.log bucket /mnt/point
</span></span></code></pre></div><h3 id=common-issues>Common Issues</h3><p><strong>Issue</strong>: <code>ls</code> on large directories takes minutes</p><p><strong>Solution</strong>:</p><ul><li>Enable list caching with <code>--metadata-cache-ttl-secs=-1</code></li><li>Reduce directory depth (flatten object hierarchy)</li><li>Consider prefix-based filtering instead of full listings</li></ul><p><strong>Issue</strong>: Stale reads after external bucket modifications</p><p><strong>Solution</strong>:</p><ul><li>Reduce <code>--metadata-cache-ttl-secs</code> (default 60s)</li><li>Disable caching entirely for strong consistency</li><li>Use versioned object names (immutable assets)</li></ul><p><strong>Issue</strong>: <code>Transport endpoint is not connected</code> errors</p><p><strong>Solution</strong>:</p><ul><li>Unmount cleanly before remounting: <code>fusermount -u /mnt/point</code></li><li>Check GCS bucket permissions (IAM roles)</li><li>Verify network connectivity to <code>storage.googleapis.com</code></li></ul><p><strong>Issue</strong>: High memory usage</p><p><strong>Solution</strong>:</p><ul><li>Limit metadata cache sizes: <code>--stat-cache-max-size-mb=1024</code></li><li>Disable file cache if not needed</li><li>Monitor with <code>--prometheus</code> metrics</li></ul><h2 id=comparison-to-alternatives>Comparison to Alternatives</h2><h3 id=gcsfuse-vs-direct-cloud-storage-sdk>gcsfuse vs Direct Cloud Storage SDK</h3><table><thead><tr><th>Aspect</th><th>gcsfuse</th><th>Cloud Storage SDK</th></tr></thead><tbody><tr><td><strong>Latency</strong></td><td>Higher (FUSE overhead + GCS API)</td><td>Lower (direct GCS API)</td></tr><tr><td><strong>Cloud Run</strong></td><td>âŒ Not supported</td><td>âœ… Fully supported</td></tr><tr><td><strong>Development Effort</strong></td><td>Low (standard filesystem code)</td><td>Medium (SDK integration)</td></tr><tr><td><strong>Performance</strong></td><td>Slower (filesystem abstraction)</td><td>Faster (optimized for use case)</td></tr><tr><td><strong>Caching</strong></td><td>Built-in (stat, type, list, file)</td><td>Manual (application-level)</td></tr><tr><td><strong>Streaming</strong></td><td>Automatic</td><td>Explicit (<code>io.Copy</code>)</td></tr><tr><td><strong>Dependencies</strong></td><td>FUSE kernel module, privileged mode</td><td>None (pure Go library)</td></tr></tbody></table><p><strong>Recommendation</strong>: Use Cloud Storage SDK directly for production network boot infrastructure.</p><h3 id=gcsfuse-vs-rsyncgsutil-sync>gcsfuse vs rsync/gsutil Sync</h3><p><strong>Periodic sync pattern</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Sync bucket to local disk every 5 minutes</span>
</span></span><span class=line><span class=cl>*/5 * * * * gsutil -m rsync -r gs://boot-assets /var/lib/boot-assets
</span></span></code></pre></div><table><thead><tr><th>Aspect</th><th>gcsfuse</th><th>rsync/gsutil sync</th></tr></thead><tbody><tr><td><strong>Consistency</strong></td><td>Eventual (with caching)</td><td>Strong (within sync interval)</td></tr><tr><td><strong>Disk Usage</strong></td><td>Minimal (file cache optional)</td><td>Full copy of assets</td></tr><tr><td><strong>Latency</strong></td><td>GCS API per request</td><td>Local disk (fast)</td></tr><tr><td><strong>Sync Lag</strong></td><td>Real-time (no caching) or TTL</td><td>Sync interval (minutes)</td></tr><tr><td><strong>Deployment</strong></td><td>Requires FUSE</td><td>Simple cron job</td></tr></tbody></table><p><strong>Recommendation</strong>: For read-heavy, infrequent-write workloads on Compute Engine, rsync/gsutil sync is simpler and faster than gcsfuse.</p><h2 id=conclusion>Conclusion</h2><p>Cloud Storage FUSE (gcsfuse) provides a convenient filesystem abstraction over GCS buckets, but <strong>is not recommended for the network boot infrastructure</strong> due to:</p><ol><li>Cloud Run incompatibility (requires FUSE kernel module)</li><li>Added latency (FUSE overhead + network round-trips)</li><li>Poor performance for small files and concurrent access</li><li>Caching trade-offs (consistency vs performance)</li></ol><p><strong>Recommended alternatives</strong>:</p><ul><li><strong>Custom Boot Server</strong>: Direct Cloud Storage SDK integration (<code>cloud.google.com/go/storage</code>)</li><li><strong>Matchbox on Compute Engine</strong>: rsync/gsutil sync to local disk</li><li><strong>Cloud Run Deployment</strong>: Direct SDK (no gcsfuse possible)</li></ul><p>gcsfuse may be useful for <strong>development/testing</strong> or <strong>Matchbox prototyping</strong> on Compute Engine, but production deployments should use direct SDK integration or periodic sync for optimal performance and Cloud Run compatibility.</p><h2 id=references>References</h2><ul><li><a href=https://cloud.google.com/storage/docs/cloud-storage-fuse/overview>Cloud Storage FUSE Documentation</a></li><li><a href=https://github.com/GoogleCloudPlatform/gcsfuse>gcsfuse GitHub Repository</a></li><li><a href=https://cloud.google.com/storage/docs/gcsfuse-performance-and-best-practices>Performance Tuning Best Practices</a></li><li><a href=https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/docs/semantics.md>gcsfuse Semantics</a></li><li><a href=../../adrs/0005-network-boot-infrastructure-gcp.md>ADR-0005: Network Boot Infrastructure Implementation on Google Cloud</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-40e0d560582430a6e545597f7b73eb02>1.4.2 - GCP Network Boot Protocol Support</h1><div class=lead>Analysis of Google Cloud Platform&rsquo;s support for TFTP, HTTP, and HTTPS routing for network boot infrastructure</div><h1 id=network-boot-protocol-support-on-google-cloud-platform>Network Boot Protocol Support on Google Cloud Platform</h1><p>This document analyzes GCP&rsquo;s capabilities for hosting network boot infrastructure, specifically focusing on TFTP, HTTP, and HTTPS protocol support.</p><h2 id=tftp-trivial-file-transfer-protocol-support>TFTP (Trivial File Transfer Protocol) Support</h2><h3 id=native-support>Native Support</h3><p><strong>Status</strong>: âŒ <strong>Not natively supported by Cloud Load Balancing</strong></p><p>GCP&rsquo;s Cloud Load Balancing services (Application Load Balancer, Network Load Balancer) do <strong>not</strong> support TFTP protocol natively. TFTP operates on UDP port 69 and has unique protocol requirements that are not compatible with GCP&rsquo;s load balancing services.</p><h3 id=implementation-options>Implementation Options</h3><h4 id=option-1-direct-vm-access-recommended-for-vpn-scenario>Option 1: Direct VM Access (Recommended for VPN Scenario)</h4><p>Since ADR-0002 specifies a VPN-based architecture, TFTP can be served directly from a Compute Engine VM without load balancing:</p><ul><li><strong>Approach</strong>: Run TFTP server (e.g., <code>tftpd-hpa</code>, <code>dnsmasq</code>) on a Compute Engine VM</li><li><strong>Access</strong>: Home lab connects via VPN tunnel to the VM&rsquo;s private IP</li><li><strong>Routing</strong>: VPC firewall rules allow UDP/69 from VPN subnet</li><li><strong>Pros</strong>:<ul><li>Simple implementation</li><li>No need for load balancing (single boot server sufficient)</li><li>TFTP traffic encrypted through VPN tunnel</li><li>Direct VM-to-client communication</li></ul></li><li><strong>Cons</strong>:<ul><li>Single point of failure (no load balancing/HA)</li><li>Manual failover required if VM fails</li></ul></li></ul><h4 id=option-2-network-load-balancer-nlb-passthrough>Option 2: Network Load Balancer (NLB) Passthrough</h4><p>While NLB doesn&rsquo;t parse TFTP protocol, it can forward UDP traffic:</p><ul><li><strong>Approach</strong>: Configure Network Load Balancer for UDP/69 passthrough</li><li><strong>Limitations</strong>:<ul><li>No protocol-aware health checks for TFTP</li><li>Health checks would use TCP or HTTP on alternate port</li><li>Adds complexity without significant benefit for single boot server</li></ul></li><li><strong>Use Case</strong>: Only relevant for multi-region HA deployment (overkill for home lab)</li></ul><h3 id=tftp-security-considerations>TFTP Security Considerations</h3><ul><li><strong>Encryption</strong>: TFTP protocol itself is unencrypted, but VPN tunnel provides encryption</li><li><strong>Firewall Rules</strong>: Restrict UDP/69 to VPN subnet only (no public access)</li><li><strong>File Access Control</strong>: Configure TFTP server with restricted file access</li><li><strong>Read-Only Mode</strong>: Deploy TFTP server in read-only mode to prevent uploads</li></ul><h2 id=http-support>HTTP Support</h2><h3 id=native-support-1>Native Support</h3><p><strong>Status</strong>: âœ… <strong>Fully supported</strong></p><p>GCP provides comprehensive HTTP support through multiple services:</p><h4 id=cloud-load-balancing---application-load-balancer>Cloud Load Balancing - Application Load Balancer</h4><ul><li><strong>Protocol Support</strong>: HTTP/1.1, HTTP/2, HTTP/3 (QUIC)</li><li><strong>Port</strong>: Any port (typically 80 for HTTP)</li><li><strong>Routing</strong>: URL-based routing, host-based routing, path-based routing</li><li><strong>Health Checks</strong>: HTTP health checks with configurable paths</li><li><strong>SSL Offloading</strong>: Can terminate SSL at load balancer and use HTTP backend</li><li><strong>Backend</strong>: Compute Engine VMs, instance groups, Cloud Run, GKE</li></ul><h4 id=compute-engine-direct-access>Compute Engine Direct Access</h4><p>For VPN scenario, HTTP can be served directly from VM:</p><ul><li><strong>Approach</strong>: Run HTTP server (nginx, Apache, custom service) on Compute Engine VM</li><li><strong>Access</strong>: Home lab accesses via VPN tunnel to private IP</li><li><strong>Firewall</strong>: VPC firewall rules allow TCP/80 from VPN subnet</li><li><strong>Pros</strong>: Simpler than load balancer for single boot server</li></ul><h3 id=http-boot-flow-for-network-boot>HTTP Boot Flow for Network Boot</h3><ol><li><strong>PXE â†’ TFTP</strong>: Initial bootloader (iPXE) loaded via TFTP</li><li><strong>iPXE â†’ HTTP</strong>: iPXE chainloads boot files via HTTP from same server</li><li><strong>Kernel/Initrd</strong>: Large boot files served efficiently over HTTP</li></ol><h3 id=performance-considerations>Performance Considerations</h3><ul><li><strong>Connection Pooling</strong>: HTTP/1.1 keep-alive reduces connection overhead</li><li><strong>Compression</strong>: gzip compression for text-based boot configs</li><li><strong>Caching</strong>: Cloud CDN can cache boot files for faster delivery</li><li><strong>TCP Optimization</strong>: GCP&rsquo;s network optimized for low-latency TCP</li></ul><h2 id=https-support>HTTPS Support</h2><h3 id=native-support-2>Native Support</h3><p><strong>Status</strong>: âœ… <strong>Fully supported with advanced features</strong></p><p>GCP provides enterprise-grade HTTPS support:</p><h4 id=cloud-load-balancing---application-load-balancer-1>Cloud Load Balancing - Application Load Balancer</h4><ul><li><strong>Protocol Support</strong>: HTTPS/1.1, HTTP/2 over TLS, HTTP/3 with QUIC</li><li><strong>SSL/TLS Termination</strong>: Terminate SSL at load balancer</li><li><strong>Certificate Management</strong>:<ul><li>Google-managed SSL certificates (automatic renewal)</li><li>Self-managed certificates (bring your own)</li><li>Certificate Map for multiple domains</li></ul></li><li><strong>TLS Versions</strong>: TLS 1.0, 1.1, 1.2, 1.3 (configurable minimum version)</li><li><strong>Cipher Suites</strong>: Modern, compatible, or custom cipher suites</li><li><strong>mTLS Support</strong>: Mutual TLS authentication (client certificates)</li></ul><h4 id=certificate-manager>Certificate Manager</h4><ul><li><strong>Managed Certificates</strong>: Automatic provisioning and renewal via Let&rsquo;s Encrypt integration</li><li><strong>Private CA</strong>: Integration with Google Cloud Certificate Authority Service</li><li><strong>Certificate Maps</strong>: Route different domains to different backends based on SNI</li><li><strong>Certificate Monitoring</strong>: Automatic alerts before expiration</li></ul><h3 id=https-for-network-boot>HTTPS for Network Boot</h3><h4 id=use-case>Use Case</h4><p>Modern UEFI firmware and iPXE support HTTPS boot:</p><ul><li><strong>iPXE HTTPS</strong>: iPXE compiled with <code>DOWNLOAD_PROTO_HTTPS</code> can fetch over HTTPS</li><li><strong>UEFI HTTP Boot</strong>: UEFI firmware natively supports HTTP/HTTPS boot (RFC 3720 iSCSI boot)</li><li><strong>Security</strong>: Boot file integrity verified via HTTPS chain of trust</li></ul><h4 id=implementation-on-gcp>Implementation on GCP</h4><ol><li><p><strong>Certificate Provisioning</strong>:</p><ul><li>Use Google-managed certificate for public domain (if boot server has public DNS)</li><li>Use self-signed certificate for VPN-only access (add to iPXE trust store)</li><li>Use private CA for internal PKI</li></ul></li><li><p><strong>Load Balancer Configuration</strong>:</p><ul><li>HTTPS frontend (port 443)</li><li>Backend service to Compute Engine VM running boot server</li><li>SSL policy with TLS 1.2+ minimum</li></ul></li><li><p><strong>Alternative: Direct VM HTTPS</strong>:</p><ul><li>Run nginx/Apache with TLS on Compute Engine VM</li><li>Access via VPN tunnel to private IP with HTTPS</li><li>Simpler setup for VPN-only scenario</li></ul></li></ol><h3 id=mtls-support-for-enhanced-security>mTLS Support for Enhanced Security</h3><p>GCP&rsquo;s Application Load Balancer supports mutual TLS authentication:</p><ul><li><strong>Client Certificates</strong>: Require client certificates for additional authentication</li><li><strong>Certificate Validation</strong>: Validate client certificates against trusted CA</li><li><strong>Use Case</strong>: Ensure only authorized home lab servers can access boot files</li><li><strong>Integration</strong>: Combine with VPN for defense-in-depth</li></ul><h2 id=routing-and-load-balancing-capabilities>Routing and Load Balancing Capabilities</h2><h3 id=vpc-routing>VPC Routing</h3><ul><li><strong>Custom Routes</strong>: Define routes to direct traffic through VPN gateway</li><li><strong>Route Priority</strong>: Configure route priorities for failover scenarios</li><li><strong>BGP Support</strong>: Dynamic routing with Cloud Router (for advanced VPN setups)</li></ul><h3 id=firewall-rules>Firewall Rules</h3><ul><li><strong>Ingress/Egress Rules</strong>: Fine-grained control over traffic</li><li><strong>Source/Destination Filters</strong>: IP ranges, tags, service accounts</li><li><strong>Protocol Filtering</strong>: Allow specific protocols (UDP/69, TCP/80, TCP/443)</li><li><strong>VPN Subnet Restriction</strong>: Limit access to VPN-connected home lab subnet</li></ul><h3 id=cloud-armor-optional>Cloud Armor (Optional)</h3><p>For additional security if boot server has public access:</p><ul><li><strong>DDoS Protection</strong>: Layer 3/4 DDoS mitigation</li><li><strong>WAF Rules</strong>: Application-level filtering</li><li><strong>IP Allowlisting</strong>: Restrict to known public IPs</li><li><strong>Rate Limiting</strong>: Prevent abuse</li></ul><h2 id=cost-implications>Cost Implications</h2><h3 id=network-egress-costs>Network Egress Costs</h3><ul><li><strong>VPN Traffic</strong>: Egress to VPN endpoint charged at standard internet egress rates</li><li><strong>Intra-Region</strong>: Free for traffic within same region</li><li><strong>Boot File Sizes</strong>: Typical kernel + initrd = 50-200MB per boot</li><li><strong>Monthly Estimate</strong>: 10 boots/month Ã— 150MB = 1.5GB â‰ˆ $0.18/month (US egress)</li></ul><h3 id=load-balancing-costs>Load Balancing Costs</h3><ul><li><strong>Application Load Balancer</strong>: ~$0.025/hour + $0.008 per LCU-hour</li><li><strong>Network Load Balancer</strong>: ~$0.025/hour + data processing charges</li><li><strong>For VPN Scenario</strong>: Load balancer likely unnecessary (single VM sufficient)</li></ul><h3 id=compute-costs>Compute Costs</h3><ul><li><strong>e2-micro Instance</strong>: ~$6-7/month (suitable for boot server)</li><li><strong>f1-micro Instance</strong>: ~$4-5/month (even smaller, might suffice)</li><li><strong>Reserved/Committed Use</strong>: Discounts for long-term commitment</li></ul><h2 id=comparison-with-requirements>Comparison with Requirements</h2><table><thead><tr><th>Requirement</th><th>GCP Support</th><th>Implementation</th></tr></thead><tbody><tr><td>TFTP</td><td>âš ï¸ Via VM, not LB</td><td>Direct VM access via VPN</td></tr><tr><td>HTTP</td><td>âœ… Full support</td><td>VM or ALB</td></tr><tr><td>HTTPS</td><td>âœ… Full support</td><td>VM or ALB with Certificate Manager</td></tr><tr><td>VPN Integration</td><td>âœ… Native VPN</td><td>Cloud VPN or self-managed WireGuard</td></tr><tr><td>Load Balancing</td><td>âœ… ALB, NLB</td><td>Optional for HA</td></tr><tr><td>Certificate Mgmt</td><td>âœ… Managed certs</td><td>Certificate Manager</td></tr><tr><td>Cost Efficiency</td><td>âœ… Low-cost VMs</td><td>e2-micro sufficient</td></tr></tbody></table><h2 id=recommendations>Recommendations</h2><h3 id=for-vpn-based-architecture-per-adr-0002>For VPN-Based Architecture (per ADR-0002)</h3><ol><li><p><strong>Compute Engine VM</strong>: Deploy single e2-micro VM with:</p><ul><li>TFTP server (<code>tftpd-hpa</code> or <code>dnsmasq</code>)</li><li>HTTP server (nginx or simple Python HTTP server)</li><li>Optional HTTPS with self-signed certificate</li></ul></li><li><p><strong>VPN Tunnel</strong>: Connect home lab to GCP via:</p><ul><li>Cloud VPN (IPsec) - easier setup, higher cost</li><li>Self-managed WireGuard on Compute Engine - lower cost, more control</li></ul></li><li><p><strong>VPC Firewall</strong>: Restrict access to:</p><ul><li>UDP/69 (TFTP) from VPN subnet only</li><li>TCP/80 (HTTP) from VPN subnet only</li><li>TCP/443 (HTTPS) from VPN subnet only</li></ul></li><li><p><strong>No Load Balancer</strong>: For home lab scale, direct VM access is sufficient</p></li><li><p><strong>Health Monitoring</strong>: Use Cloud Monitoring for VM and service health</p></li></ol><h3 id=if-ha-required-future-enhancement>If HA Required (Future Enhancement)</h3><ul><li>Deploy multi-zone VMs with Network Load Balancer</li><li>Use Cloud Storage as backend for boot files with VM serving as cache</li><li>Implement failover automation with Cloud Functions</li></ul><h2 id=references>References</h2><ul><li><a href=https://cloud.google.com/load-balancing/docs>GCP Cloud Load Balancing Documentation</a></li><li><a href=https://cloud.google.com/certificate-manager/docs>GCP Certificate Manager</a></li><li><a href=https://cloud.google.com/network-connectivity/docs/vpn>GCP Cloud VPN</a></li><li><a href=https://ipxe.org/crypto>iPXE HTTPS Boot</a></li><li><a href=https://uefi.org/specs/UEFI/2.10/24_Network_Protocols.html#http-boot>UEFI HTTP Boot</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-35563ff6a8a7c7f31535b56d4156bd8b>1.4.3 - GCP WireGuard VPN Support</h1><div class=lead>Analysis of WireGuard VPN deployment options on Google Cloud Platform for secure site-to-site connectivity</div><h1 id=wireguard-vpn-support-on-google-cloud-platform>WireGuard VPN Support on Google Cloud Platform</h1><p>This document analyzes options for deploying WireGuard VPN on GCP to establish secure site-to-site connectivity between the home lab and cloud-hosted network boot infrastructure.</p><h2 id=wireguard-overview>WireGuard Overview</h2><p>WireGuard is a modern VPN protocol that provides:</p><ul><li><strong>Simplicity</strong>: Minimal codebase (~4,000 lines vs 100,000+ for IPsec)</li><li><strong>Performance</strong>: High throughput with low overhead</li><li><strong>Security</strong>: Modern cryptography (Curve25519, ChaCha20, Poly1305, BLAKE2s)</li><li><strong>Configuration</strong>: Simple key-based configuration</li><li><strong>Kernel Integration</strong>: Mainline Linux kernel support since 5.6</li></ul><h2 id=gcp-native-vpn-support>GCP Native VPN Support</h2><h3 id=cloud-vpn-ipsec>Cloud VPN (IPsec)</h3><p><strong>Status</strong>: âŒ <strong>WireGuard not natively supported</strong></p><p>GCP&rsquo;s managed Cloud VPN service supports:</p><ul><li><strong>IPsec VPN</strong>: IKEv1, IKEv2 with PSK or certificate authentication</li><li><strong>HA VPN</strong>: Highly available VPN with 99.99% SLA</li><li><strong>Classic VPN</strong>: Single-tunnel VPN (deprecated)</li></ul><p><strong>Limitation</strong>: Cloud VPN does <strong>not</strong> support WireGuard protocol natively.</p><h3 id=cost-cloud-vpn>Cost: Cloud VPN</h3><ul><li><strong>HA VPN</strong>: ~$0.05/hour per tunnel Ã— 2 tunnels = ~$73/month</li><li><strong>Egress</strong>: Standard internet egress rates (~$0.12/GB for first 1TB)</li><li><strong>Total Estimate</strong>: ~$75-100/month for managed VPN</li></ul><h2 id=self-managed-wireguard-on-compute-engine>Self-Managed WireGuard on Compute Engine</h2><h3 id=implementation-approach>Implementation Approach</h3><p>Since GCP doesn&rsquo;t offer managed WireGuard, deploy WireGuard on a Compute Engine VM:</p><p><strong>Status</strong>: âœ… <strong>Fully supported via Compute Engine</strong></p><h4 id=architecture>Architecture</h4><pre class=mermaid>graph LR
    A[Home Lab] --&gt;|WireGuard Tunnel| B[GCP Compute Engine VM]
    B --&gt;|Private VPC Network| C[Boot Server VM]
    B --&gt;|IP Forwarding| C
    
    subgraph &#34;Home Network&#34;
        A
        D[UDM Pro]
        D -.WireGuard Client.- A
    end
    
    subgraph &#34;GCP VPC&#34;
        B[WireGuard Gateway VM]
        C[Boot Server VM]
    end</pre><h4 id=vm-configuration>VM Configuration</h4><ol><li><p><strong>WireGuard Gateway VM</strong>:</p><ul><li><strong>Instance Type</strong>: e2-micro or f1-micro ($4-7/month)</li><li><strong>OS</strong>: Ubuntu 22.04 LTS or Debian 12 (native WireGuard kernel support)</li><li><strong>IP Forwarding</strong>: Enable IP forwarding to route traffic to other VMs</li><li><strong>External IP</strong>: Static external IP for stable WireGuard endpoint</li><li><strong>Firewall</strong>: Allow UDP port 51820 (WireGuard) from home lab public IP</li></ul></li><li><p><strong>Boot Server VM</strong>:</p><ul><li><strong>Network</strong>: Same VPC as WireGuard gateway</li><li><strong>Private IP Only</strong>: No external IP (accessed via VPN)</li><li><strong>Route Traffic</strong>: Through WireGuard gateway VM</li></ul></li></ol><h4 id=installation-steps>Installation Steps</h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># On GCP Compute Engine VM (Ubuntu 22.04+)</span>
</span></span><span class=line><span class=cl>sudo apt update
</span></span><span class=line><span class=cl>sudo apt install wireguard wireguard-tools
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Generate server keys</span>
</span></span><span class=line><span class=cl>wg genkey <span class=p>|</span> tee /etc/wireguard/server_private.key <span class=p>|</span> wg pubkey &gt; /etc/wireguard/server_public.key
</span></span><span class=line><span class=cl>chmod <span class=m>600</span> /etc/wireguard/server_private.key
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configure WireGuard interface</span>
</span></span><span class=line><span class=cl>sudo nano /etc/wireguard/wg0.conf
</span></span></code></pre></div><p><strong>Example <code>/etc/wireguard/wg0.conf</code> on GCP VM</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=k>[Interface]</span>
</span></span><span class=line><span class=cl><span class=na>Address</span> <span class=o>=</span> <span class=s>10.200.0.1/24</span>
</span></span><span class=line><span class=cl><span class=na>ListenPort</span> <span class=o>=</span> <span class=s>51820</span>
</span></span><span class=line><span class=cl><span class=na>PrivateKey</span> <span class=o>=</span> <span class=s>&lt;SERVER_PRIVATE_KEY&gt;</span>
</span></span><span class=line><span class=cl><span class=na>PostUp</span> <span class=o>=</span> <span class=s>sysctl -w net.ipv4.ip_forward=1</span>
</span></span><span class=line><span class=cl><span class=na>PostUp</span> <span class=o>=</span> <span class=s>iptables -A FORWARD -i wg0 -j ACCEPT</span>
</span></span><span class=line><span class=cl><span class=na>PostUp</span> <span class=o>=</span> <span class=s>iptables -t nat -A POSTROUTING -o ens4 -j MASQUERADE</span>
</span></span><span class=line><span class=cl><span class=na>PostDown</span> <span class=o>=</span> <span class=s>iptables -D FORWARD -i wg0 -j ACCEPT</span>
</span></span><span class=line><span class=cl><span class=na>PostDown</span> <span class=o>=</span> <span class=s>iptables -t nat -D POSTROUTING -o ens4 -j MASQUERADE</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>[Peer]</span>
</span></span><span class=line><span class=cl><span class=c1># Home Lab (UDM Pro)</span>
</span></span><span class=line><span class=cl><span class=na>PublicKey</span> <span class=o>=</span> <span class=s>&lt;CLIENT_PUBLIC_KEY&gt;</span>
</span></span><span class=line><span class=cl><span class=na>AllowedIPs</span> <span class=o>=</span> <span class=s>10.200.0.2/32, 192.168.1.0/24</span>
</span></span></code></pre></div><p><strong>Corresponding config on UDM Pro</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=k>[Interface]</span>
</span></span><span class=line><span class=cl><span class=na>Address</span> <span class=o>=</span> <span class=s>10.200.0.2/24</span>
</span></span><span class=line><span class=cl><span class=na>PrivateKey</span> <span class=o>=</span> <span class=s>&lt;CLIENT_PRIVATE_KEY&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>[Peer]</span>
</span></span><span class=line><span class=cl><span class=na>PublicKey</span> <span class=o>=</span> <span class=s>&lt;SERVER_PUBLIC_KEY&gt;</span>
</span></span><span class=line><span class=cl><span class=na>Endpoint</span> <span class=o>=</span> <span class=s>&lt;GCP_VM_EXTERNAL_IP&gt;:51820</span>
</span></span><span class=line><span class=cl><span class=na>AllowedIPs</span> <span class=o>=</span> <span class=s>10.200.0.0/24, 10.128.0.0/20</span>
</span></span><span class=line><span class=cl><span class=na>PersistentKeepalive</span> <span class=o>=</span> <span class=s>25</span>
</span></span></code></pre></div><h4 id=enable-and-start-wireguard>Enable and Start WireGuard</h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Enable IP forwarding permanently</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;net.ipv4.ip_forward=1&#34;</span> <span class=p>|</span> sudo tee -a /etc/sysctl.conf
</span></span><span class=line><span class=cl>sudo sysctl -p
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Enable WireGuard interface</span>
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> wg-quick@wg0
</span></span><span class=line><span class=cl>sudo systemctl start wg-quick@wg0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Verify status</span>
</span></span><span class=line><span class=cl>sudo wg show
</span></span></code></pre></div><h3 id=gcp-vpc-configuration>GCP VPC Configuration</h3><h4 id=firewall-rules>Firewall Rules</h4><p>Create VPC firewall rule to allow WireGuard:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcloud compute firewall-rules create allow-wireguard <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --direction<span class=o>=</span>INGRESS <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --priority<span class=o>=</span><span class=m>1000</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --network<span class=o>=</span>default <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --action<span class=o>=</span>ALLOW <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --rules<span class=o>=</span>udp:51820 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --source-ranges<span class=o>=</span>&lt;HOME_LAB_PUBLIC_IP&gt;/32 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --target-tags<span class=o>=</span>wireguard-gateway
</span></span></code></pre></div><p>Tag the WireGuard VM:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcloud compute instances add-tags wireguard-gateway-vm <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --tags<span class=o>=</span>wireguard-gateway <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --zone<span class=o>=</span>us-central1-a
</span></span></code></pre></div><h4 id=static-external-ip>Static External IP</h4><p>Reserve static IP for stable WireGuard endpoint:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcloud compute addresses create wireguard-gateway-ip <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --region<span class=o>=</span>us-central1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>gcloud compute instances delete-access-config wireguard-gateway-vm <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --access-config-name<span class=o>=</span><span class=s2>&#34;external-nat&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --zone<span class=o>=</span>us-central1-a
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>gcloud compute instances add-access-config wireguard-gateway-vm <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --access-config-name<span class=o>=</span><span class=s2>&#34;external-nat&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --address<span class=o>=</span>wireguard-gateway-ip <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --zone<span class=o>=</span>us-central1-a
</span></span></code></pre></div><p><strong>Cost</strong>: Static IP ~$3-4/month if VM is always running (free if attached to running VM in some regions).</p><h4 id=route-configuration>Route Configuration</h4><p>For traffic from boot server to reach home lab via WireGuard VM:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcloud compute routes create route-to-homelab <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --network<span class=o>=</span>default <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --priority<span class=o>=</span><span class=m>100</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --destination-range<span class=o>=</span>192.168.1.0/24 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --next-hop-instance<span class=o>=</span>wireguard-gateway-vm <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --next-hop-instance-zone<span class=o>=</span>us-central1-a
</span></span></code></pre></div><p>This routes home lab subnet (192.168.1.0/24) through the WireGuard gateway VM.</p><h2 id=udm-pro-wireguard-integration>UDM Pro WireGuard Integration</h2><h3 id=native-support>Native Support</h3><p><strong>Status</strong>: âœ… <strong>WireGuard supported natively</strong> (UniFi OS 1.12.22+)</p><p>The UniFi Dream Machine Pro includes native WireGuard VPN support:</p><ul><li><strong>GUI Configuration</strong>: Web UI for WireGuard VPN setup</li><li><strong>Site-to-Site</strong>: Support for site-to-site VPN tunnels</li><li><strong>Performance</strong>: Hardware acceleration for encryption (if available)</li><li><strong>Routing</strong>: Automatic route injection for remote subnets</li></ul><h3 id=configuration-steps-on-udm-pro>Configuration Steps on UDM Pro</h3><ol><li><p><strong>Network Settings â†’ VPN</strong>:</p><ul><li>Create new VPN connection</li><li>Select &ldquo;WireGuard&rdquo;</li><li>Generate key pair or import existing</li></ul></li><li><p><strong>Peer Configuration</strong>:</p><ul><li><strong>Peer Public Key</strong>: GCP WireGuard VM&rsquo;s public key</li><li><strong>Endpoint</strong>: GCP VM&rsquo;s static external IP</li><li><strong>Port</strong>: 51820</li><li><strong>Allowed IPs</strong>: GCP VPC subnet (e.g., 10.128.0.0/20)</li><li><strong>Persistent Keepalive</strong>: 25 seconds</li></ul></li><li><p><strong>Route Injection</strong>:</p><ul><li>UDM Pro automatically adds routes to GCP subnets</li><li>Home lab servers can reach GCP boot server via VPN</li></ul></li><li><p><strong>Firewall Rules</strong>:</p><ul><li>Add firewall rule to allow boot traffic (TFTP, HTTP) from LAN to VPN</li></ul></li></ol><h3 id=alternative-manual-wireguard-on-udm-pro>Alternative: Manual WireGuard on UDM Pro</h3><p>If native support is insufficient, use <code>wireguard-go</code> via <code>udm-utilities</code>:</p><ul><li><strong>Repository</strong>: <a href=https://github.com/boostchicken/udm-utilities>boostchicken/udm-utilities</a></li><li><strong>Script</strong>: <code>on_boot.d</code> script to start WireGuard</li><li><strong>Persistence</strong>: Survives firmware updates with on-boot script</li></ul><h2 id=performance-considerations>Performance Considerations</h2><h3 id=throughput>Throughput</h3><p>WireGuard on Compute Engine performance:</p><ul><li><strong>e2-micro</strong> (2 vCPU, shared core): ~100-300 Mbps</li><li><strong>e2-small</strong> (2 vCPU): ~500-800 Mbps</li><li><strong>e2-medium</strong> (2 vCPU): ~1+ Gbps</li></ul><p>For network boot (typical boot = 50-200MB), even e2-micro is sufficient:</p><ul><li><strong>Boot Time</strong>: 150MB at 100 Mbps = ~12 seconds transfer time</li><li><strong>Recommendation</strong>: e2-micro adequate for home lab scale</li></ul><h3 id=latency>Latency</h3><ul><li><strong>VPN Overhead</strong>: WireGuard adds minimal latency (~1-5ms overhead)</li><li><strong>GCP Network</strong>: Low-latency network to most regions</li><li><strong>Total Latency</strong>: Primarily dependent on home ISP and GCP region proximity</li></ul><h3 id=cpu-usage>CPU Usage</h3><ul><li><strong>Encryption</strong>: ChaCha20 is CPU-efficient</li><li><strong>Kernel Module</strong>: Minimal CPU overhead in kernel space</li><li><strong>e2-micro</strong>: Sufficient CPU for home lab VPN throughput</li></ul><h2 id=security-considerations>Security Considerations</h2><h3 id=key-management>Key Management</h3><ul><li><strong>Private Keys</strong>: Store securely, never commit to version control</li><li><strong>Key Rotation</strong>: Rotate keys periodically (e.g., annually)</li><li><strong>Secret Manager</strong>: Store WireGuard private keys in GCP Secret Manager<ul><li>Retrieve at VM startup via startup script</li><li>Avoid storing in VM metadata or disk images</li></ul></li></ul><h3 id=firewall-hardening>Firewall Hardening</h3><ul><li><strong>Source IP Restriction</strong>: Limit WireGuard port to home lab public IP only</li><li><strong>Least Privilege</strong>: Boot server firewall allows only VPN subnet</li><li><strong>No Public Access</strong>: Boot server has no external IP</li></ul><h3 id=monitoring-and-alerts>Monitoring and Alerts</h3><ul><li><strong>Cloud Logging</strong>: Log WireGuard connection events</li><li><strong>Cloud Monitoring</strong>: Alert on VPN tunnel down</li><li><strong>Metrics</strong>: Monitor handshake failures, data transfer</li></ul><h3 id=ddos-protection>DDoS Protection</h3><ul><li><strong>UDP Amplification</strong>: WireGuard resistant to DDoS amplification</li><li><strong>Cloud Armor</strong>: Optional layer for additional DDoS protection (overkill for VPN)</li></ul><h2 id=high-availability-options>High Availability Options</h2><h3 id=multi-region-failover>Multi-Region Failover</h3><p>Deploy WireGuard gateways in multiple regions:</p><ul><li><strong>Primary</strong>: us-central1 WireGuard VM</li><li><strong>Secondary</strong>: us-east1 WireGuard VM</li><li><strong>Failover</strong>: UDM Pro switches endpoints if primary fails</li><li><strong>Cost</strong>: Doubles VM costs (~$8-14/month for 2 VMs)</li></ul><h3 id=health-checks>Health Checks</h3><p>Monitor WireGuard tunnel health:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># On UDM Pro (via SSH)</span>
</span></span><span class=line><span class=cl>wg show wg0 latest-handshakes
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># If handshake timestamp old (&gt;3 minutes), tunnel may be down</span>
</span></span></code></pre></div><p>Automate failover with script on UDM Pro or external monitoring.</p><h3 id=startup-scripts-for-auto-healing>Startup Scripts for Auto-Healing</h3><p>GCP VM startup script to ensure WireGuard starts on boot:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=c1># /etc/startup-script.sh</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Retrieve WireGuard private key from Secret Manager</span>
</span></span><span class=line><span class=cl>gcloud secrets versions access latest --secret<span class=o>=</span><span class=s2>&#34;wireguard-server-key&#34;</span> &gt; /etc/wireguard/server_private.key
</span></span><span class=line><span class=cl>chmod <span class=m>600</span> /etc/wireguard/server_private.key
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Start WireGuard</span>
</span></span><span class=line><span class=cl>systemctl <span class=nb>enable</span> wg-quick@wg0
</span></span><span class=line><span class=cl>systemctl start wg-quick@wg0
</span></span></code></pre></div><p>Attach as metadata:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>gcloud compute instances add-metadata wireguard-gateway-vm <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --metadata-from-file startup-script<span class=o>=</span>/path/to/startup-script.sh <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --zone<span class=o>=</span>us-central1-a
</span></span></code></pre></div><h2 id=cost-analysis>Cost Analysis</h2><h3 id=self-managed-wireguard-on-compute-engine-1>Self-Managed WireGuard on Compute Engine</h3><table><thead><tr><th>Component</th><th>Cost</th></tr></thead><tbody><tr><td>e2-micro VM (730 hrs/month)</td><td>~$6.50</td></tr><tr><td>Static External IP</td><td>~$3.50</td></tr><tr><td>Egress (1GB/month boot traffic)</td><td>~$0.12</td></tr><tr><td><strong>Monthly Total</strong></td><td><strong>~$10.12</strong></td></tr><tr><td><strong>Annual Total</strong></td><td><strong>~$121</strong></td></tr></tbody></table><h3 id=cloud-vpn-ipsec---if-wireguard-not-used>Cloud VPN (IPsec - if WireGuard not used)</h3><table><thead><tr><th>Component</th><th>Cost</th></tr></thead><tbody><tr><td>HA VPN Gateway (2 tunnels)</td><td>~$73</td></tr><tr><td>Egress (1GB/month)</td><td>~$0.12</td></tr><tr><td><strong>Monthly Total</strong></td><td><strong>~$73</strong></td></tr><tr><td><strong>Annual Total</strong></td><td><strong>~$876</strong></td></tr></tbody></table><p><strong>Cost Savings</strong>: Self-managed WireGuard saves <strong>~$755/year</strong> vs Cloud VPN.</p><h2 id=comparison-with-requirements>Comparison with Requirements</h2><table><thead><tr><th>Requirement</th><th>GCP Support</th><th>Implementation</th></tr></thead><tbody><tr><td>WireGuard Protocol</td><td>âœ… Via Compute Engine</td><td>Self-managed on VM</td></tr><tr><td>Site-to-Site VPN</td><td>âœ… Yes</td><td>WireGuard tunnel</td></tr><tr><td>UDM Pro Integration</td><td>âœ… Native support</td><td>WireGuard peer config</td></tr><tr><td>Cost Efficiency</td><td>âœ… Low cost</td><td>e2-micro ~$10/month</td></tr><tr><td>Performance</td><td>âœ… Sufficient</td><td>100+ Mbps on e2-micro</td></tr><tr><td>Security</td><td>âœ… Modern crypto</td><td>ChaCha20, Curve25519</td></tr><tr><td>HA (optional)</td><td>âš ï¸ Manual setup</td><td>Multi-region VMs</td></tr></tbody></table><h2 id=recommendations>Recommendations</h2><h3 id=for-home-lab-vpn-per-adr-0002>For Home Lab VPN (per ADR-0002)</h3><ol><li><p><strong>Self-Managed WireGuard</strong>: Deploy on Compute Engine e2-micro VM</p><ul><li><strong>Cost</strong>: ~$10/month (vs ~$73/month for Cloud VPN)</li><li><strong>Performance</strong>: Sufficient for network boot traffic</li><li><strong>Simplicity</strong>: Easy to configure and maintain</li></ul></li><li><p><strong>Single Region Deployment</strong>: Unless HA required, single VM adequate</p><ul><li><strong>Region Selection</strong>: Choose region closest to home lab for lowest latency</li><li><strong>Zone</strong>: Single zone sufficient (boot server not mission-critical)</li></ul></li><li><p><strong>UDM Pro Native WireGuard</strong>: Use built-in WireGuard client</p><ul><li><strong>Configuration</strong>: Add GCP VM as WireGuard peer in UDM Pro UI</li><li><strong>Route Injection</strong>: UDM Pro automatically routes GCP subnets</li></ul></li><li><p><strong>Security Best Practices</strong>:</p><ul><li>Store WireGuard private key in Secret Manager</li><li>Restrict WireGuard port to home public IP only</li><li>Use startup script to configure VM on boot</li><li>Enable Cloud Logging for VPN events</li></ul></li><li><p><strong>Monitoring</strong>: Set up Cloud Monitoring alerts for:</p><ul><li>VM down</li><li>High CPU usage (indicates traffic spike or issue)</li><li>Firewall rule blocks (indicates misconfiguration)</li></ul></li></ol><h3 id=future-enhancements>Future Enhancements</h3><ul><li><strong>HA Setup</strong>: Deploy secondary WireGuard VM in different region</li><li><strong>Automated Failover</strong>: Script on UDM Pro to switch endpoints</li><li><strong>IPv6 Support</strong>: Enable WireGuard over IPv6 if home ISP supports</li><li><strong>Mesh VPN</strong>: Expand to mesh topology if multiple sites added</li></ul><h2 id=references>References</h2><ul><li><a href=https://www.wireguard.com/>WireGuard Official Site</a></li><li><a href=https://wiki.archlinux.org/title/WireGuard>WireGuard on Linux</a></li><li><a href=https://cloud.google.com/vpc/docs/using-routes#static-route-next-hop>GCP Compute Engine IP Forwarding</a></li><li><a href=https://help.ui.com/hc/en-us/articles/115015971688-UniFi-VPN-Server>UniFi WireGuard VPN</a></li><li><a href=https://github.com/boostchicken/udm-utilities>udm-utilities GitHub</a></li><li><a href=https://cloud.google.com/secret-manager/docs>GCP Secret Manager</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-a435c4bc001f7e96c63864b68229ddbc>1.5 - HP ProLiant DL360 Gen9 Analysis</h1><div class=lead>Technical analysis of HP ProLiant DL360 Gen9 server capabilities with focus on network boot support</div><p>This section contains detailed analysis of the HP ProLiant DL360 Gen9 server platform, including hardware specifications, network boot capabilities, and configuration guidance for home lab deployments.</p><h2 id=overview>Overview</h2><p>The HP ProLiant DL360 Gen9 is a 1U rack-mountable server released by HPE as part of their Generation 9 (Gen9) product line, introduced in 2014. It&rsquo;s a popular choice for home labs due to its balance of performance, density, and relative power efficiency compared to earlier generations.</p><h2 id=key-features>Key Features</h2><ul><li><strong>Form Factor</strong>: 1U rack-mountable</li><li><strong>Processor Support</strong>: Dual Intel Xeon E5-2600 v3/v4 processors (Haswell/Broadwell)</li><li><strong>Memory</strong>: Up to 768GB DDR4 RAM (24 DIMM slots)</li><li><strong>Storage</strong>: Flexible SFF/LFF drive configurations</li><li><strong>Network</strong>: Integrated quad-port 1GbE or 10GbE FlexibleLOM options</li><li><strong>Management</strong>: iLO 4 (Integrated Lights-Out) with remote KVM and virtual media</li><li><strong>Boot Options</strong>: UEFI and Legacy BIOS support with extensive network boot capabilities</li></ul><h2 id=documentation-sections>Documentation Sections</h2><ul><li><a href=./network-boot/>Network Boot Capabilities</a> - Detailed analysis of PXE, iPXE, and UEFI HTTP boot support</li><li><a href=./specifications/>Hardware Specifications</a> - Complete hardware configuration details</li><li><a href=./configuration/>Configuration Guide</a> - Setup and optimization recommendations</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-710c910de90953be84ae3a14c4b93a47>1.5.1 - Configuration Guide</h1><div class=lead>Setup, optimization, and configuration recommendations for HP ProLiant DL360 Gen9 in home lab environments</div><h2 id=initial-setup>Initial Setup</h2><h3 id=hardware-assembly>Hardware Assembly</h3><ol><li><p><strong>Install Processors</strong>:</p><ul><li>Use thermal paste (HPE thermal grease recommended)</li><li>Align CPU carefully with socket (LGA 2011-3)</li><li>Secure heatsink with proper torque (hand-tighten screws in cross pattern)</li><li>Install both CPUs for dual-socket configuration</li></ul></li><li><p><strong>Install Memory</strong>:</p><ul><li>Populate channels evenly (see Memory Configuration below)</li><li>Seat DIMMs firmly until retention clips engage</li><li>Verify all DIMMs recognized in POST</li></ul></li><li><p><strong>Install Storage</strong>:</p><ul><li>Insert drives into hot-swap caddies</li><li>Label drives clearly for identification</li><li>Configure RAID controller (see Storage Configuration below)</li></ul></li><li><p><strong>Install Network Cards</strong>:</p><ul><li>FlexibleLOM: Slide into dedicated slot until seated</li><li>PCIe cards: Ensure low-profile brackets, secure with screw</li><li>Note MAC addresses for DHCP reservations</li></ul></li><li><p><strong>Connect Power</strong>:</p><ul><li>Install PSUs (both for redundancy)</li><li>Connect power cords</li><li>Verify PSU LEDs indicate proper operation</li></ul></li><li><p><strong>Initial Power-On</strong>:</p><ul><li>Press power button</li><li>Monitor POST on screen or via iLO remote console</li><li>Address any POST errors before proceeding</li></ul></li></ol><h2 id=ilo-4-initial-configuration>iLO 4 Initial Configuration</h2><h3 id=physical-ilo-connection>Physical iLO Connection</h3><ol><li>Connect Ethernet cable to dedicated iLO port (not FlexibleLOM)</li><li>Default iLO IP: Obtains via DHCP, or use temporary address via RBSU</li><li>Check DHCP server logs for iLO MAC and assigned IP</li></ol><h3 id=first-login>First Login</h3><ol><li>Access iLO web interface: <code>https://&lt;ilo-ip></code></li><li>Default credentials:<ul><li>Username: <code>Administrator</code></li><li>Password: On label on server pull-out tab (or rear label)</li></ul></li><li><strong>Immediately change default password</strong> (Administration > Access Settings)</li></ol><h3 id=essential-ilo-settings>Essential iLO Settings</h3><p><strong>Network Configuration</strong> (Administration > Network):</p><ul><li>Set static IP or DHCP reservation</li><li>Configure DNS servers</li><li>Set hostname (e.g., <code>ilo-dl360-01</code>)</li><li>Enable SNTP time sync</li></ul><p><strong>Security</strong> (Administration > Security):</p><ul><li>Enforce HTTPS only (disable HTTP)</li><li>Configure SSH key authentication if using CLI</li><li>Set strong password policy</li><li>Enable iLO Security features</li></ul><p><strong>Access</strong> (Administration > Access Settings):</p><ul><li>Configure iLO username/password for automation</li><li>Create additional user accounts (separation of duties)</li><li>Set session timeout (default: 30 minutes)</li></ul><p><strong>Date and Time</strong> (Administration > Date and Time):</p><ul><li>Set NTP servers for accurate timestamps</li><li>Configure timezone</li></ul><p><strong>Licenses</strong> (Administration > Licensing):</p><ul><li>Install iLO Advanced license key (required for full virtual media)</li><li>License can be purchased or acquired from secondary market</li></ul><h3 id=ilo-firmware-update>iLO Firmware Update</h3><p>Before production use, update iLO to latest version:</p><ol><li>Download latest iLO 4 firmware from HPE Support Portal</li><li>Administration > Firmware > Update Firmware</li><li>Upload <code>.bin</code> file, apply update</li><li>iLO will reboot automatically (system stays running)</li></ol><h2 id=system-rom-biosuefi-configuration>System ROM (BIOS/UEFI) Configuration</h2><h3 id=accessing-rbsu>Accessing RBSU</h3><ul><li><strong>Local</strong>: Press F9 during POST</li><li><strong>Remote</strong>: iLO Remote Console > Power > Momentary Press > Press F9 when prompted</li></ul><h3 id=boot-mode-selection>Boot Mode Selection</h3><p><strong>System Configuration > BIOS/Platform Configuration (RBSU) > Boot Mode</strong>:</p><ul><li><p><strong>UEFI Mode</strong> (recommended for modern OS):</p><ul><li>Supports GPT partitions (>2TB disks)</li><li>Required for Secure Boot</li><li>Better UEFI HTTP boot support</li><li>IPv6 PXE boot support</li></ul></li><li><p><strong>Legacy BIOS Mode</strong>:</p><ul><li>For older OS or compatibility</li><li>MBR partition tables only</li><li>Traditional PXE boot</li></ul></li></ul><p><strong>Recommendation</strong>: Use UEFI Mode unless legacy compatibility required</p><h3 id=boot-order-configuration>Boot Order Configuration</h3><p><strong>System Configuration > BIOS/Platform Configuration (RBSU) > Boot Options > UEFI Boot Order</strong>:</p><p>Recommended order for network boot deployment:</p><ol><li><strong>Network Boot</strong>: FlexibleLOM or PCIe NIC</li><li><strong>Internal Storage</strong>: RAID controller or disk</li><li><strong>Virtual Media</strong>: iLO virtual CD/DVD (for installation media)</li><li><strong>USB</strong>: For rescue/recovery</li></ol><p><strong>Enable Network Boot</strong>:</p><ul><li>System Configuration > BIOS/Platform Configuration (RBSU) > Network Options > Network Boot</li><li>Set to &ldquo;Enabled&rdquo;</li></ul><h3 id=performance-and-power-settings>Performance and Power Settings</h3><p><strong>System Configuration > BIOS/Platform Configuration (RBSU) > Power Management</strong>:</p><ul><li><p><strong>Power Regulator Mode</strong>:</p><ul><li><strong>HP Dynamic Power Savings</strong>: Balanced power/performance (recommended for home lab)</li><li><strong>HP Static High Performance</strong>: Maximum performance, higher power draw</li><li><strong>HP Static Low Power</strong>: Minimize power, reduced performance</li><li><strong>OS Control</strong>: Let OS manage (e.g., Linux cpufreq)</li></ul></li><li><p><strong>Collaborative Power Control</strong>: Disabled (for standalone servers)</p></li><li><p><strong>Minimum Processor Idle Power Core C-State</strong>: C6 (lower idle power)</p></li><li><p><strong>Energy/Performance Bias</strong>: Balanced Performance (or Maximum Performance for compute workloads)</p></li></ul><p><strong>Recommendation</strong>: Start with &ldquo;Dynamic Power Savings&rdquo; and adjust based on workload</p><h3 id=memory-configuration>Memory Configuration</h3><p><strong>Optimal Population</strong> (dual-CPU configuration):</p><p>For maximum performance, populate all channels before adding second DIMM per channel:</p><p><strong>64GB</strong> (8x 8GB):</p><ul><li>CPU1: Slots 1, 4, 7, 10 and CPU2: Slots 1, 4, 7, 10</li><li>Result: 4 channels per CPU, 1 DIMM per channel</li></ul><p><strong>128GB</strong> (8x 16GB):</p><ul><li>Same as above with 16GB DIMMs</li></ul><p><strong>192GB</strong> (12x 16GB):</p><ul><li>CPU1: Slots 1, 4, 7, 10, 2, 5 and CPU2: Slots 1, 4, 7, 10, 2, 5</li><li>Result: 4 channels per CPU, some with 2 DIMMs per channel</li></ul><p><strong>768GB</strong> (24x 32GB):</p><ul><li>All slots populated</li></ul><p><strong>Check Configuration</strong>: RBSU > System Information > Memory Information</p><h3 id=processor-options>Processor Options</h3><p><strong>System Configuration > BIOS/Platform Configuration (RBSU) > Processor Options</strong>:</p><ul><li><p><strong>Intel Hyperthreading</strong>: Enabled (recommended for most workloads)</p><ul><li>Doubles logical cores (e.g., 12-core CPU shows as 24 cores)</li><li>Benefits most virtualization and multi-threaded workloads</li><li>Disable only for specific security compliance (e.g., some cloud providers)</li></ul></li><li><p><strong>Intel Virtualization Technology (VT-x)</strong>: Enabled (required for hypervisors)</p></li><li><p><strong>Intel VT-d (IOMMU)</strong>: Enabled (required for PCI passthrough, SR-IOV)</p></li><li><p><strong>Turbo Boost</strong>: Enabled (allows CPU to exceed base clock)</p></li><li><p><strong>Cores Enabled</strong>: All (or reduce to lower power/heat if needed)</p></li></ul><h3 id=integrated-devices>Integrated Devices</h3><p><strong>System Configuration > BIOS/Platform Configuration (RBSU) > System Options > Integrated Devices</strong>:</p><ul><li><strong>Embedded SATA Controller</strong>: Enabled (if using SATA drives)</li><li><strong>Embedded RAID Controller</strong>: Enabled (for Smart Array controllers)</li><li><strong>SR-IOV</strong>: Enabled (if using virtual network interfaces with VMs)</li></ul><h3 id=network-controller-options>Network Controller Options</h3><p>For each NIC (FlexibleLOM, PCIe):</p><p><strong>System Configuration > BIOS/Platform Configuration (RBSU) > Network Options > [Adapter]</strong>:</p><ul><li><strong>Network Boot</strong>: Enabled (for network boot on that NIC)</li><li><strong>PXE/iSCSI</strong>: Select PXE for standard network boot</li><li><strong>Link Speed</strong>: Auto-Negotiation (recommended) or force 1G/10G</li><li><strong>IPv4</strong>: Enabled (for IPv4 PXE boot)</li><li><strong>IPv6</strong>: Enabled (if using IPv6 PXE boot)</li></ul><p><strong>Boot Order</strong>: Configure which NIC boots first if multiple are enabled</p><h3 id=secure-boot-configuration>Secure Boot Configuration</h3><p><strong>System Configuration > BIOS/Platform Configuration (RBSU) > Boot Options > Secure Boot</strong>:</p><ul><li><strong>Secure Boot</strong>: Disabled (for unsigned boot loaders, custom kernels)</li><li><strong>Secure Boot</strong>: Enabled (for signed boot loaders, Windows, some Linux distros)</li></ul><p><strong>Note</strong>: If using PXE with unsigned images (e.g., custom iPXE), Secure Boot must be disabled</p><h3 id=firmware-updates>Firmware Updates</h3><p>Update System ROM to latest version:</p><ol><li><p><strong>Via iLO</strong>:</p><ul><li>iLO web > Administration > Firmware > Update Firmware</li><li>Upload System ROM <code>.fwpkg</code> or <code>.bin</code> file</li><li>Server reboots automatically to apply</li></ul></li><li><p><strong>Via Service Pack for ProLiant (SPP)</strong>:</p><ul><li>Download SPP ISO from HPE Support Portal</li><li>Mount via iLO Virtual Media</li><li>Boot server from SPP ISO</li><li>Smart Update Manager (SUM) runs in Linux environment</li><li>Select components to update (System ROM, iLO, controller firmware, NIC firmware)</li><li>Apply updates, reboot</li></ul></li></ol><p><strong>Recommendation</strong>: Use SPP for comprehensive updates on initial setup, then iLO for individual component updates</p><h2 id=storage-configuration>Storage Configuration</h2><h3 id=smart-array-controller-setup>Smart Array Controller Setup</h3><h4 id=access-smart-array-configuration>Access Smart Array Configuration</h4><ul><li><strong>During POST</strong>: Press F5 when &ldquo;Smart Array Configuration Utility&rdquo; message appears</li><li><strong>Via RBSU</strong>: System Configuration > BIOS/Platform Configuration (RBSU) > System Options > ROM-Based Setup Utility > Smart Array Configuration</li></ul><h4 id=create-raid-arrays>Create RAID Arrays</h4><ol><li><p><strong>Delete Existing Arrays</strong> (if reconfiguring):</p><ul><li>Select controller > Configuration > Delete Array</li><li>Confirm deletion (data loss warning)</li></ul></li><li><p><strong>Create New Array</strong>:</p><ul><li>Select controller > Configuration > Create Array</li><li>Select physical drives to include</li><li>Choose RAID level:<ul><li><strong>RAID 0</strong>: Striping, no redundancy (maximum performance, maximum capacity)</li><li><strong>RAID 1</strong>: Mirroring (redundancy, half capacity, good for boot drives)</li><li><strong>RAID 5</strong>: Striping + parity (redundancy, n-1 capacity, balanced)</li><li><strong>RAID 6</strong>: Striping + double parity (dual-drive failure tolerance, n-2 capacity)</li><li><strong>RAID 10</strong>: Mirror + stripe (high performance + redundancy, half capacity)</li></ul></li><li>Configure spare drives (hot spares for automatic rebuild)</li><li>Create logical drive</li><li>Set bootable flag if boot drive</li></ul></li><li><p><strong>Recommended Configurations</strong>:</p><ul><li><strong>Boot/OS</strong>: 2x SSD in RAID 1 (redundancy, fast boot)</li><li><strong>Data (performance)</strong>: 4-6x SSD in RAID 10 (fast, redundant)</li><li><strong>Data (capacity)</strong>: 4-8x HDD in RAID 6 (capacity, dual-drive tolerance)</li></ul></li></ol><h4 id=controller-settings>Controller Settings</h4><ul><li><p><strong>Cache Settings</strong>:</p><ul><li><strong>Write Cache</strong>: Enabled (requires battery/flash-backed cache)</li><li><strong>Read Cache</strong>: Enabled</li><li><strong>No-Battery Write Cache</strong>: Disabled (data safety) or Enabled (performance, risk)</li></ul></li><li><p><strong>Rebuild Priority</strong>: Medium or High (faster rebuild, may impact performance)</p></li><li><p><strong>Surface Scan Delay</strong>: 3-7 days (periodic integrity check)</p></li></ul><h3 id=hba-mode-non-raid>HBA Mode (Non-RAID)</h3><p>For software RAID (ZFS, mdadm, Ceph):</p><ol><li>Access Smart Array Configuration (F5 during POST)</li><li>Controller > Configuration > Enable HBA Mode</li><li>Confirm (RAID arrays will be deleted)</li><li>Reboot</li></ol><p><strong>Note</strong>: Not all Smart Array controllers support HBA mode. Check compatibility. Alternative: Use separate LSI HBA in PCIe slot.</p><h2 id=network-configuration-for-boot>Network Configuration for Boot</h2><h3 id=dhcp-server-setup>DHCP Server Setup</h3><p>For PXE/UEFI network boot, configure DHCP server with appropriate options:</p><p><strong>ISC DHCP Example</strong> (<code>/etc/dhcp/dhcpd.conf</code>):</p><pre tabindex=0><code class=language-dhcpd data-lang=dhcpd># Define subnet
subnet 192.168.10.0 netmask 255.255.255.0 {
    range 192.168.10.100 192.168.10.200;
    option routers 192.168.10.1;
    option domain-name-servers 192.168.10.1;
    
    # PXE boot options
    next-server 192.168.10.5;  # TFTP server IP
    
    # Differentiate UEFI vs BIOS
    if exists user-class and option user-class = &#34;iPXE&#34; {
        # iPXE boot script
        filename &#34;http://boot.example.com/boot.ipxe&#34;;
    } elsif option arch = 00:07 or option arch = 00:09 {
        # UEFI (x86-64)
        filename &#34;bootx64.efi&#34;;
    } else {
        # Legacy BIOS
        filename &#34;undionly.kpxe&#34;;
    }
}

# Static reservation for DL360
host dl360-01 {
    hardware ethernet xx:xx:xx:xx:xx:xx;  # FlexibleLOM MAC
    fixed-address 192.168.10.50;
    option host-name &#34;dl360-01&#34;;
}
</code></pre><h3 id=flexiblelom-configuration>FlexibleLOM Configuration</h3><p>Configure FlexibleLOM NIC for network boot:</p><ol><li>RBSU > Network Options > FlexibleLOM</li><li>Enable &ldquo;Network Boot&rdquo;</li><li>Select PXE or iSCSI</li><li>Configure IPv4/IPv6 as needed</li><li>Set as first boot device in boot order</li></ol><h3 id=multi-nic-boot-priority>Multi-NIC Boot Priority</h3><p>If multiple NICs have network boot enabled:</p><ol><li>RBSU > Network Options > Network Boot Order</li><li>Drag/drop to prioritize NIC boot order</li><li>First NIC in list attempts boot first</li></ol><p><strong>Recommendation</strong>: Enable network boot on one NIC (typically FlexibleLOM port 1) to avoid confusion</p><h2 id=operating-system-installation>Operating System Installation</h2><h3 id=traditional-installation-virtual-media>Traditional Installation (Virtual Media)</h3><ol><li>Download OS ISO (e.g., Ubuntu Server, ESXi, Proxmox)</li><li>Upload ISO to HTTP/HTTPS server or local file</li><li>iLO Remote Console > Virtual Devices > Image File CD-ROM/DVD</li><li>Browse to ISO location, click &ldquo;Insert Media&rdquo;</li><li>Set boot order to prioritize virtual media</li><li>Reboot server, boot from virtual CD/DVD</li><li>Proceed with OS installation</li></ol><h3 id=network-installation-pxe>Network Installation (PXE)</h3><p>See <a href=./network-boot/>Network Boot Capabilities</a> for detailed PXE/UEFI boot setup</p><p>Quick workflow:</p><ol><li>Configure DHCP server with PXE options</li><li>Setup TFTP server with boot files</li><li>Enable network boot in BIOS</li><li>Reboot, server PXE boots</li><li>Select OS installer from PXE menu</li><li>Automated installation proceeds (Kickstart/Preseed/Ignition)</li></ol><h2 id=optimization-for-specific-workloads>Optimization for Specific Workloads</h2><h3 id=virtualization-esxi-proxmox-hyper-v>Virtualization (ESXi, Proxmox, Hyper-V)</h3><p><strong>BIOS Settings</strong>:</p><ul><li>Hyperthreading: Enabled</li><li>VT-x: Enabled</li><li>VT-d: Enabled</li><li>Power Management: Dynamic or OS Control</li><li>Turbo Boost: Enabled</li></ul><p><strong>Hardware</strong>:</p><ul><li>Maximum memory (384GB+ recommended)</li><li>Fast storage (SSD RAID 10 for VM storage)</li><li>10GbE networking for VM traffic</li></ul><p><strong>Configuration</strong>:</p><ul><li>Pass through NICs to VMs (SR-IOV or PCI passthrough)</li><li>Use storage controller in HBA mode for direct disk access to VM storage (ZFS, Ceph)</li></ul><h3 id=kubernetescontainer-platforms>Kubernetes/Container Platforms</h3><p><strong>BIOS Settings</strong>:</p><ul><li>Hyperthreading: Enabled</li><li>VT-x/VT-d: Enabled (for nested virtualization, kata containers)</li><li>Power Management: Dynamic or High Performance</li></ul><p><strong>Hardware</strong>:</p><ul><li>128GB+ RAM for multi-tenant workloads</li><li>Fast local NVMe/SSD for container image cache and ephemeral storage</li><li>10GbE for pod networking</li></ul><p><strong>OS Recommendations</strong>:</p><ul><li>Talos Linux: Network-bootable, immutable k8s OS</li><li>Flatcar Container Linux: Auto-updating, minimal OS</li><li>Ubuntu Server: Broad compatibility, snap/docker native</li></ul><h3 id=storage-server-nas-san>Storage Server (NAS, SAN)</h3><p><strong>BIOS Settings</strong>:</p><ul><li>Disable Hyperthreading (slight performance improvement for ZFS)</li><li>VT-d: Enabled (if passing through HBA to VM)</li><li>Power Management: High Performance</li></ul><p><strong>Hardware</strong>:</p><ul><li>Maximum drive bays (8-10 SFF)</li><li>HBA mode or separate LSI HBA controller</li><li>10GbE or bonded 1GbE for network storage traffic</li><li>ECC memory (critical for ZFS)</li></ul><p><strong>Software</strong>:</p><ul><li>TrueNAS SCALE (Linux-based, k8s apps)</li><li>OpenMediaVault (Debian-based, plugins)</li><li>Ubuntu + ZFS (custom setup)</li></ul><h3 id=computehpc-workloads>Compute/HPC Workloads</h3><p><strong>BIOS Settings</strong>:</p><ul><li>Hyperthreading: Depends on workload (test both)</li><li>Turbo Boost: Enabled</li><li>Power Management: Maximum Performance</li><li>C-States: Disabled (reduce latency)</li></ul><p><strong>Hardware</strong>:</p><ul><li>High core count CPUs (E5-2680 v4, 2690 v4)</li><li>Maximum memory bandwidth (populate all channels)</li><li>Fast local scratch storage (NVMe)</li></ul><h2 id=monitoring-and-maintenance>Monitoring and Maintenance</h2><h3 id=ilo-health-monitoring>iLO Health Monitoring</h3><p><strong>Information > System Information</strong>:</p><ul><li>CPU temperature and status</li><li>Memory status</li><li>Drive status (via controller)</li><li>Fan speeds</li><li>PSU status</li><li>Overall system health LED status</li></ul><p><strong>Alerting</strong> (Administration > Alerting):</p><ul><li>Configure email alerts for:<ul><li>Fan failures</li><li>Temperature warnings</li><li>Drive failures</li><li>Memory errors</li><li>PSU failures</li></ul></li><li>Set up SNMP traps for integration with monitoring systems (Nagios, Zabbix, Prometheus)</li></ul><h3 id=integrated-management-log-iml>Integrated Management Log (IML)</h3><p><strong>Information > Integrated Management Log</strong>:</p><ul><li>View hardware events and errors</li><li>Filter by severity (Informational, Caution, Critical)</li><li>Export log for troubleshooting</li></ul><p><strong>Regular Checks</strong>:</p><ul><li>Review IML weekly for early warning signs</li><li>Address caution-level events before they become critical</li></ul><h3 id=firmware-update-cadence>Firmware Update Cadence</h3><p><strong>Recommendation</strong>:</p><ul><li><strong>iLO</strong>: Update quarterly or when security advisories released</li><li><strong>System ROM</strong>: Update annually or for bug fixes</li><li><strong>Storage Controller</strong>: Update when issues arise or annually</li><li><strong>NIC Firmware</strong>: Update when issues arise</li></ul><p><strong>Method</strong>: Use SPP for annual comprehensive updates, iLO web interface for individual component updates</p><h3 id=physical-maintenance>Physical Maintenance</h3><p><strong>Monthly</strong>:</p><ul><li>Check fan noise (increased noise may indicate clogged air filters or failing fan)</li><li>Verify PSU and drive LEDs (no amber lights)</li><li>Check iLO for alerts</li></ul><p><strong>Quarterly</strong>:</p><ul><li>Clean air filters (if accessible, depends on rack airflow)</li><li>Verify backup of iLO configuration</li><li>Test iLO Virtual Media functionality</li></ul><p><strong>Annually</strong>:</p><ul><li>Update all firmware via SPP</li><li>Verify RAID battery/flash-backed cache status</li><li>Review and update BIOS settings as workload evolves</li></ul><h2 id=troubleshooting-common-issues>Troubleshooting Common Issues</h2><h3 id=server-wont-power-on>Server Won&rsquo;t Power On</h3><ol><li>Check PSU power cords connected</li><li>Verify PSU LEDs indicate power</li><li>Press iLO power button via web interface</li><li>Check iLO IML for power-related errors</li><li>Reseat PSUs, check for blown fuses</li></ol><h3 id=post-errors>POST Errors</h3><p><strong>Memory Errors</strong>:</p><ul><li>Reseat memory DIMMs</li><li>Test with minimal configuration (1 DIMM per CPU)</li><li>Replace failing DIMMs identified in POST</li></ul><p><strong>CPU Errors</strong>:</p><ul><li>Verify heatsink properly seated</li><li>Check thermal paste application</li><li>Reseat CPU (careful with pins)</li></ul><p><strong>Drive Errors</strong>:</p><ul><li>Check drive connection to caddy</li><li>Verify controller recognizes drive</li><li>Replace failing drive</li></ul><h3 id=no-network-boot>No Network Boot</h3><p>See <a href=./network-boot/#troubleshooting>Network Boot Troubleshooting</a> for detailed diagnostics</p><p>Quick checks:</p><ol><li>Verify NIC link light</li><li>Confirm network boot enabled in BIOS</li><li>Check DHCP server logs for PXE request</li><li>Test TFTP server accessibility</li></ol><h3 id=ilo-not-accessible>iLO Not Accessible</h3><ol><li>Check physical Ethernet connection to iLO port</li><li>Verify switch port active</li><li>Reset iLO: Press and hold iLO NMI button (rear) for 5 seconds</li><li>Factory reset iLO via jumper (see maintenance guide)</li><li>Check iLO firmware version, update if outdated</li></ol><h3 id=high-fan-noise>High Fan Noise</h3><ol><li>Check ambient temperature (&lt;25Â°C recommended)</li><li>Verify airflow not blocked (front/rear clearance)</li><li>Clean dust from intake (compressed air)</li><li>Check iLO temperature sensors for elevated temps</li><li>Lower CPU TDP if temperatures excessive (lower power CPUs)</li><li>Verify all fans operational (replace failed fans)</li></ol><h2 id=security-hardening>Security Hardening</h2><h3 id=ilo-security>iLO Security</h3><ol><li><strong>Change Default Credentials</strong>: Immediately on first boot</li><li><strong>Disable Unused Services</strong>: SSH, IPMI if not needed</li><li><strong>Use HTTPS Only</strong>: Disable HTTP (Administration > Network > HTTP Port)</li><li><strong>Network Isolation</strong>: Dedicated management VLAN, firewall iLO access</li><li><strong>Update Firmware</strong>: Apply security patches promptly</li><li><strong>Account Management</strong>: Use separate accounts, least privilege</li></ol><h3 id=biosuefi-security>BIOS/UEFI Security</h3><ol><li><strong>BIOS Password</strong>: Set administrator password (RBSU > System Options > BIOS Admin Password)</li><li><strong>Secure Boot</strong>: Enable if using signed boot loaders</li><li><strong>Boot Order Lock</strong>: Prevent unauthorized boot device changes</li><li><strong>TPM</strong>: Enable if using BitLocker or LUKS disk encryption</li></ol><h3 id=operating-system-security>Operating System Security</h3><ol><li><strong>Minimal Installation</strong>: Install only required packages</li><li><strong>Firewall</strong>: Enable host firewall (iptables, firewalld, ufw)</li><li><strong>SSH Hardening</strong>: Key-based auth, disable password auth, non-standard port</li><li><strong>Automatic Updates</strong>: Enable for security patches</li><li><strong>Monitoring</strong>: Deploy intrusion detection (fail2ban, OSSEC)</li></ol><h2 id=conclusion>Conclusion</h2><p>Proper configuration of the HP ProLiant DL360 Gen9 ensures optimal performance, reliability, and manageability for home lab and production deployments. The combination of UEFI boot capabilities, iLO remote management, and flexible hardware configuration makes the DL360 Gen9 a versatile platform for virtualization, containerization, storage, and compute workloads.</p><p>Key takeaways:</p><ul><li>Update firmware early (iLO, System ROM, controllers)</li><li>Configure iLO for remote management and monitoring</li><li>Choose boot mode (UEFI recommended) and configure network boot appropriately</li><li>Optimize BIOS settings for specific workload (virtualization, storage, compute)</li><li>Implement security hardening (iLO, BIOS, OS)</li><li>Establish monitoring and maintenance schedule</li></ul><p>For network boot-specific configuration, refer to the <a href=./network-boot/>Network Boot Capabilities</a> guide.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5edcb2c8881ecaa41f34154035642bcf>1.5.2 - Hardware Specifications</h1><div class=lead>Detailed hardware specifications and configuration options for HP ProLiant DL360 Gen9</div><h2 id=system-overview>System Overview</h2><p>The HP ProLiant DL360 Gen9 is a dual-socket 1U rack server designed for data center and enterprise deployments, also popular in home lab environments due to its performance and manageability.</p><p><strong>Generation</strong>: Gen9 (2014-2017 product cycle)<br><strong>Form Factor</strong>: 1U rack-mountable (19-inch standard rack)<br><strong>Dimensions</strong>: 43.46 x 67.31 x 4.29 cm (17.1 x 26.5 x 1.69 in)</p><h2 id=processor-support>Processor Support</h2><h3 id=supported-cpu-families>Supported CPU Families</h3><p>The DL360 Gen9 supports Intel Xeon E5-2600 v3 and v4 series processors:</p><ul><li><p><strong>E5-2600 v3</strong> (Haswell-EP): Released Q3 2014</p><ul><li>Process: 22nm</li><li>Cores: 4-18 per socket</li><li>TDP: 55W-145W</li><li>Max Memory Speed: DDR4-2133</li></ul></li><li><p><strong>E5-2600 v4</strong> (Broadwell-EP): Released Q1 2016</p><ul><li>Process: 14nm</li><li>Cores: 4-22 per socket</li><li>TDP: 55W-145W</li><li>Max Memory Speed: DDR4-2400</li></ul></li></ul><h3 id=popular-cpu-options>Popular CPU Options</h3><p><strong>Value</strong>: E5-2620 v3/v4 (6 cores, 15MB cache, 85W)<br><strong>Balanced</strong>: E5-2650 v3/v4 (10-12 cores, 25-30MB cache, 105W)<br><strong>Performance</strong>: E5-2680 v3/v4 (12-14 cores, 30-35MB cache, 120W)<br><strong>High Core Count</strong>: E5-2699 v4 (22 cores, 55MB cache, 145W)</p><h3 id=configuration-options>Configuration Options</h3><ul><li><strong>Single Processor</strong>: One CPU socket populated (budget option)</li><li><strong>Dual Processor</strong>: Both sockets populated (full performance)</li></ul><p><strong>Note</strong>: Memory and I/O performance scales with processor count. Single-CPU configuration limits memory channels and PCIe lanes.</p><h2 id=memory-architecture>Memory Architecture</h2><h3 id=memory-specifications>Memory Specifications</h3><ul><li><strong>Type</strong>: DDR4 RDIMM or LRDIMM</li><li><strong>Speed</strong>: DDR4-2133 (v3) or DDR4-2400 (v4)</li><li><strong>Slots</strong>: 24 DIMM slots (12 per processor)</li><li><strong>Maximum Capacity</strong>:<ul><li>768GB with 32GB RDIMMs</li><li>1.5TB with 64GB LRDIMMs (v4 processors)</li></ul></li><li><strong>Minimum</strong>: 8GB (1x 8GB DIMM)</li></ul><h3 id=memory-configuration-rules>Memory Configuration Rules</h3><ul><li><strong>Channels per CPU</strong>: 4 channels, 3 DIMMs per channel</li><li><strong>Population</strong>: Populate channels evenly for optimal bandwidth</li><li><strong>Mixing</strong>: Do not mix RDIMM and LRDIMM types</li><li><strong>Speed</strong>: All DIMMs run at speed of slowest DIMM</li></ul><h3 id=recommended-configurations>Recommended Configurations</h3><p><strong>Basic Home Lab</strong> (Single CPU):</p><ul><li>4x 16GB = 64GB (one DIMM per channel on both memory boards)</li></ul><p><strong>Standard</strong> (Dual CPU):</p><ul><li>8x 16GB = 128GB (one DIMM per channel)</li><li>12x 16GB = 192GB (two DIMMs per channel on primary channels)</li></ul><p><strong>High Capacity</strong> (Dual CPU):</p><ul><li>24x 32GB = 768GB (all slots populated, RDIMM)</li></ul><p><strong>Performance Priority</strong>: Populate all channels before adding second DIMM per channel</p><h2 id=storage-options>Storage Options</h2><h3 id=drive-bay-configurations>Drive Bay Configurations</h3><p>The DL360 Gen9 offers multiple drive bay configurations:</p><ol><li><strong>8 SFF (2.5-inch)</strong>: Most common configuration</li><li><strong>10 SFF</strong>: Extended bay version</li><li><strong>4 LFF (3.5-inch)</strong>: Less common in 1U form factor</li></ol><h3 id=drive-types-supported>Drive Types Supported</h3><ul><li><strong>SAS</strong>: 12Gb/s, 6Gb/s (enterprise-grade)</li><li><strong>SATA</strong>: 6Gb/s, 3Gb/s (value option)</li><li><strong>SSD</strong>: SAS/SATA SSD, NVMe (with appropriate controller)</li></ul><h3 id=storage-controllers>Storage Controllers</h3><p><strong>Smart Array Controllers</strong> (HPE proprietary RAID):</p><ul><li><strong>P440ar</strong>: Entry-level, 2GB FBWC (Flash-Backed Write Cache), RAID 0/1/5/6/10</li><li><strong>P840ar</strong>: High-performance, 4GB FBWC, RAID 0/1/5/6/10/50/60</li><li><strong>P440</strong>: PCIe card version, 2GB FBWC</li><li><strong>P840</strong>: PCIe card version, 4GB FBWC</li></ul><p><strong>HBA Mode</strong> (non-RAID pass-through):</p><ul><li>Smart Array controllers in HBA mode for software RAID (ZFS, mdadm)</li><li>Limited support; check firmware version</li></ul><p><strong>Alternative Controllers</strong>:</p><ul><li>LSI/Broadcom HBA controllers in PCIe slots</li><li>H240ar (12Gb/s HBA mode)</li></ul><h3 id=boot-drive-options>Boot Drive Options</h3><p>For network-focused deployments:</p><ul><li><strong>Minimal Local Storage</strong>: 2x SSD in RAID 1 for hypervisor/OS</li><li><strong>USB/SD Boot</strong>: iLO supports USB boot, SD card (internal USB)</li><li><strong>Diskless</strong>: Pure network boot (subject of network-boot.md)</li></ul><h2 id=network-connectivity>Network Connectivity</h2><h3 id=integrated-flexiblelom>Integrated FlexibleLOM</h3><p>The DL360 Gen9 includes a FlexibleLOM slot for swappable network adapters:</p><p><strong>Common FlexibleLOM Options</strong>:</p><ul><li><p><strong>HPE 366FLR</strong>: 4x 1GbE (Broadcom BCM5719)</p><ul><li>Most common, good for general use</li><li>Supports PXE, UEFI network boot, SR-IOV</li></ul></li><li><p><strong>HPE 560FLR-SFP+</strong>: 2x 10GbE SFP+ (Intel X710)</p><ul><li>High performance, fiber or DAC</li><li>Supports PXE, UEFI boot, SR-IOV, RDMA (RoCE)</li></ul></li><li><p><strong>HPE 361i</strong>: 2x 1GbE (Intel I350)</p><ul><li>Entry-level, good driver support</li></ul></li></ul><h3 id=pcie-expansion-slots>PCIe Expansion Slots</h3><p><strong>Slot Configuration</strong>:</p><ul><li><strong>Slot 1</strong>: PCIe 3.0 x16 (low-profile)</li><li><strong>Slot 2</strong>: PCIe 3.0 x8 (low-profile)</li><li><strong>Slot 3</strong>: PCIe 3.0 x8 (low-profile) - optional, depends on riser</li></ul><p><strong>Network Card Options</strong>:</p><ul><li>Intel X520/X710 (10GbE)</li><li>Mellanox ConnectX-3/ConnectX-4 (10/25/40GbE, InfiniBand)</li><li>Broadcom NetXtreme (1/10/25GbE)</li></ul><p><strong>Note</strong>: Ensure cards are low-profile for 1U chassis compatibility</p><h2 id=power-supply>Power Supply</h2><h3 id=psu-options>PSU Options</h3><ul><li><strong>500W</strong>: Single PSU, non-redundant (not recommended)</li><li><strong>800W</strong>: Common, supports dual CPU + moderate expansion</li><li><strong>1400W</strong>: High-power, dual CPU with high TDP + GPUs</li><li><strong>Redundancy</strong>: 1+1 redundant hot-plug recommended</li></ul><h3 id=power-configuration>Power Configuration</h3><ul><li><strong>Platinum Efficiency</strong>: 94%+ at 50% load</li><li><strong>Hot-Plug</strong>: Replace without powering down</li><li><strong>Auto-Switching</strong>: 100-240V AC, 50/60Hz</li></ul><p><strong>Home Lab Power Draw</strong> (typical):</p><ul><li>Idle (dual E5-2650 v3, 128GB RAM): 100-130W</li><li>Load: 200-350W depending on CPU and drive configuration</li></ul><h3 id=power-management>Power Management</h3><ul><li><strong>HPE Dynamic Power Capping</strong>: Limit max power via iLO</li><li><strong>Collaborative Power</strong>: Share power budget across chassis in blade environments</li><li><strong>Energy Efficient Ethernet (EEE)</strong>: Reduce NIC power during low utilization</li></ul><h2 id=cooling-and-acoustics>Cooling and Acoustics</h2><h3 id=fan-configuration>Fan Configuration</h3><ul><li><strong>6x Hot-Plug Fans</strong>: Front-mounted, redundant (N+1)</li><li><strong>Variable Speed</strong>: Controlled by System ROM based on thermal sensors</li><li><strong>iLO Management</strong>: Monitor fan speed, temperature via iLO</li></ul><h3 id=thermal-management>Thermal Management</h3><ul><li><strong>Temperature Range</strong>: 10-35Â°C (50-95Â°F) operating</li><li><strong>Altitude</strong>: Up to 3,050m (10,000 ft) at reduced temperature</li><li><strong>Airflow</strong>: Front-to-back, ensure clear intake and exhaust</li></ul><h3 id=noise-level>Noise Level</h3><ul><li><strong>Idle</strong>: ~45 dBA (quiet for 1U server)</li><li><strong>Load</strong>: 55-70 dBA depending on thermal demand</li><li><strong>Home Lab Consideration</strong>: Audible but acceptable in dedicated space; louder than desktop workstation</li></ul><p><strong>Noise Reduction</strong>:</p><ul><li>Run lower TDP CPUs (e.g., E5-2620 series)</li><li>Maintain ambient temperature &lt;25Â°C</li><li>Ensure adequate airflow (not in enclosed cabinet without ventilation)</li></ul><h2 id=management---ilo-4>Management - iLO 4</h2><h3 id=ilo-4-features>iLO 4 Features</h3><p>The Integrated Lights-Out 4 (iLO 4) provides out-of-band management:</p><ul><li><strong>Web Interface</strong>: HTTPS management console</li><li><strong>Remote Console</strong>: HTML5 or Java-based KVM</li><li><strong>Virtual Media</strong>: Mount ISOs/images remotely</li><li><strong>Power Control</strong>: Power on/off, reset, cold boot</li><li><strong>Monitoring</strong>: Sensors, event logs, hardware health</li><li><strong>Alerting</strong>: Email alerts, SNMP traps, syslog</li><li><strong>Scripting</strong>: RESTful API (Redfish standard)</li></ul><h3 id=ilo-licensing>iLO Licensing</h3><ul><li><strong>iLO Standard</strong> (included): Basic management, remote console</li><li><strong>iLO Advanced</strong> (license required):<ul><li>Virtual media</li><li>Remote console performance improvements</li><li>Directory integration (LDAP/AD)</li><li>Graphical remote console</li></ul></li><li><strong>iLO Advanced Premium</strong> (license required):<ul><li>Insight Remote Support</li><li>Federation</li><li>Jitter smoothing</li></ul></li></ul><p><strong>Home Lab</strong>: iLO Advanced license highly recommended for virtual media and full remote console features</p><h3 id=ilo-network-configuration>iLO Network Configuration</h3><ul><li><strong>Dedicated iLO Port</strong>: Separate 1GbE management port (recommended)</li><li><strong>Shared LOM</strong>: Share FlexibleLOM port with OS (not recommended for isolation)</li></ul><p><strong>Security</strong>: Isolate iLO on dedicated management VLAN, disable if not needed</p><h2 id=bios-and-firmware>BIOS and Firmware</h2><h3 id=system-rom-biosuefi>System ROM (BIOS/UEFI)</h3><ul><li><strong>Firmware Type</strong>: UEFI 2.31 or later</li><li><strong>Boot Modes</strong>: UEFI, Legacy BIOS, or hybrid</li><li><strong>Configuration</strong>: RBSU (ROM-Based Setup Utility) accessible via F9</li></ul><h3 id=firmware-update-methods>Firmware Update Methods</h3><ol><li><strong>Service Pack for ProLiant (SPP)</strong>: Comprehensive bundle of all firmware</li><li><strong>iLO Online Flash</strong>: Update via web interface</li><li><strong>Online ROM Flash</strong>: Linux utility for online updates</li><li><strong>USB Flash</strong>: Boot from USB with firmware update utility</li></ol><p><strong>Recommended Practice</strong>: Update to latest SPP for security patches and feature improvements</p><h3 id=secure-boot>Secure Boot</h3><ul><li><strong>UEFI Secure Boot</strong>: Supported, validates boot loader signatures</li><li><strong>TPM</strong>: Optional Trusted Platform Module 1.2 or 2.0</li><li><strong>Boot Order Protection</strong>: Prevent unauthorized boot device changes</li></ul><h2 id=expansion-and-modularity>Expansion and Modularity</h2><h3 id=gpu-support>GPU Support</h3><p>Limited GPU support due to 1U form factor and power constraints:</p><ul><li><strong>Low-Profile GPUs</strong>: Nvidia T4, AMD Instinct MI25 (may require custom cooling)</li><li><strong>Power</strong>: Consider 1400W PSU for high-power GPUs</li><li><strong>Not Ideal</strong>: For GPU-heavy workloads, consider 2U+ servers (e.g., DL380 Gen9)</li></ul><h3 id=usb-ports>USB Ports</h3><ul><li><strong>Front</strong>: 1x USB 3.0</li><li><strong>Rear</strong>: 2x USB 3.0</li><li><strong>Internal</strong>: 1x USB 2.0 (for SD/USB boot device)</li></ul><h3 id=serial-port>Serial Port</h3><ul><li>Rear serial port for legacy console access</li><li>Useful for network equipment serial console, debug</li></ul><h2 id=home-lab-considerations>Home Lab Considerations</h2><h3 id=pros-for-home-lab>Pros for Home Lab</h3><ol><li><strong>Density</strong>: 1U form factor saves rack space</li><li><strong>iLO Management</strong>: Enterprise remote management without KVM</li><li><strong>Network Boot</strong>: Excellent PXE/UEFI boot support (see network-boot.md)</li><li><strong>Serviceability</strong>: Hot-swap drives, PSU, fans</li><li><strong>Documentation</strong>: Extensive HPE documentation and community support</li><li><strong>Parts Availability</strong>: Common on secondary market, affordable</li></ol><h3 id=cons-for-home-lab>Cons for Home Lab</h3><ol><li><strong>Noise</strong>: Louder than tower servers or workstations</li><li><strong>Power</strong>: Higher idle power than consumer hardware (100-130W idle)</li><li><strong>1U Limitations</strong>: Limited GPU, PCIe expansion vs 2U/4U chassis</li><li><strong>Firmware</strong>: Requires HPE account for SPP downloads (free but registration required)</li></ol><h3 id=recommended-home-lab-configuration>Recommended Home Lab Configuration</h3><p><strong>Budget (~$500-800 used)</strong>:</p><ul><li>Dual E5-2620 v3 or v4 (6 cores each, 85W TDP)</li><li>128GB RAM (8x 16GB DDR4)</li><li>2x SSD (boot), 4-6x HDD/SSD (data)</li><li>HPE 366FLR (4x 1GbE)</li><li>Dual 500W or 800W PSU (redundant)</li><li>iLO Advanced license</li></ul><p><strong>Performance (~$1000-1500 used)</strong>:</p><ul><li>Dual E5-2680 v4 (14 cores each, 120W TDP)</li><li>256GB RAM (16x 16GB DDR4)</li><li>2x NVMe SSD (boot/cache), 6-8x SSD (data)</li><li>HPE 560FLR-SFP+ (2x 10GbE) + PCIe 4x1GbE card</li><li>Dual 800W PSU</li><li>iLO Advanced license</li></ul><h2 id=comparison-with-other-generations>Comparison with Other Generations</h2><h3 id=vs-gen8-previous>vs Gen8 (Previous)</h3><p><strong>Gen9 Advantages</strong>:</p><ul><li>DDR4 vs DDR3 (lower power, higher capacity)</li><li>Better UEFI support and HTTP boot</li><li>Newer processor architecture (Haswell/Broadwell vs Sandy Bridge/Ivy Bridge)</li><li>iLO 4 vs iLO 3 (better HTML5 console)</li></ul><p><strong>Gen8 Advantages</strong>:</p><ul><li>Lower cost on secondary market</li><li>Adequate for light workloads</li></ul><h3 id=vs-gen10-next>vs Gen10 (Next)</h3><p><strong>Gen10 Advantages</strong>:</p><ul><li>Newer CPUs (Skylake-SP/Cascade Lake)</li><li>More PCIe lanes</li><li>Better UEFI firmware and security features</li><li>DDR4-2666/2933 support</li></ul><p><strong>Gen9 Advantages</strong>:</p><ul><li>Lower cost (mature product cycle)</li><li>Excellent value for performance/dollar</li><li>Still well-supported by modern OS and firmware</li></ul><h2 id=technical-resources>Technical Resources</h2><ul><li><strong>QuickSpecs</strong>: HPE ProLiant DL360 Gen9 Server QuickSpecs</li><li><strong>User Guide</strong>: HPE ProLiant DL360 Gen9 Server User Guide</li><li><strong>Maintenance and Service Guide</strong>: Detailed disassembly and part replacement</li><li><strong>Firmware Downloads</strong>: HPE Support Portal (requires free account)</li></ul><h2 id=summary>Summary</h2><p>The HP ProLiant DL360 Gen9 remains an excellent choice for home labs and small deployments in 2024-2025. Its balance of performance (dual Xeon v4, 768GB RAM capacity), manageability (iLO 4), and network boot capabilities make it particularly well-suited for virtualization, container hosting, and infrastructure automation workflows. While not the latest generation, it offers strong value with robust firmware support and wide secondary market availability.</p><p><strong>Best For</strong>:</p><ul><li>Virtualization hosts (ESXi, Proxmox, Hyper-V)</li><li>Kubernetes/container platforms</li><li>Network boot/diskless deployments</li><li>Storage servers (with appropriate controller)</li><li>General compute workloads</li></ul><p><strong>Avoid For</strong>:</p><ul><li>GPU-intensive workloads (1U constraints)</li><li>Noise-sensitive environments (unless isolated)</li><li>Extreme low-power requirements (100W+ idle)</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-602c9477ffd24c9d6b744176ac0355ba>1.5.3 - Network Boot Capabilities</h1><div class=lead>Comprehensive analysis of network boot support on HP ProLiant DL360 Gen9</div><h2 id=overview>Overview</h2><p>The HP ProLiant DL360 Gen9 provides robust network boot capabilities through multiple protocols and firmware interfaces. This makes it particularly well-suited for diskless deployments, automated provisioning, and infrastructure-as-code workflows.</p><h2 id=supported-network-boot-protocols>Supported Network Boot Protocols</h2><h3 id=pxe-preboot-execution-environment>PXE (Preboot Execution Environment)</h3><p>The DL360 Gen9 fully supports PXE boot via both legacy BIOS and UEFI firmware modes:</p><ul><li><p><strong>Legacy BIOS PXE</strong>: Traditional PXE implementation using TFTP</p><ul><li>Protocol: PXEv2 (PXE 2.1)</li><li>Network Stack: IPv4 only in legacy mode</li><li>Boot files: <code>pxelinux.0</code>, <code>undionly.kpxe</code>, or custom NBP</li><li>DHCP options: Standard options 66 (TFTP server) and 67 (boot filename)</li></ul></li><li><p><strong>UEFI PXE</strong>: Modern UEFI network boot implementation</p><ul><li>Protocol: PXEv2 with UEFI extensions</li><li>Network Stack: IPv4 and IPv6 support</li><li>Boot files: <code>bootx64.efi</code>, <code>grubx64.efi</code>, <code>shimx64.efi</code></li><li>Architecture: x64 (EFI BC)</li><li>DHCP Architecture ID: 0x0007 (EFI BC) or 0x0009 (EFI x86-64)</li></ul></li></ul><h3 id=ipxe-support>iPXE Support</h3><p>The DL360 Gen9 can boot iPXE, enabling advanced features:</p><ul><li><strong>Chainloading</strong>: Boot standard PXE, then chainload iPXE for enhanced capabilities</li><li><strong>HTTP/HTTPS Boot</strong>: Download kernels and images over HTTP(S) instead of TFTP</li><li><strong>SAN Boot</strong>: iSCSI and AoE (ATA over Ethernet) support</li><li><strong>Scripting</strong>: Conditional boot logic and dynamic configuration</li><li><strong>Embedded Scripts</strong>: iPXE can be compiled with embedded boot scripts</li></ul><p><strong>Implementation Methods</strong>:</p><ol><li>Chainload from standard PXE: DHCP points to <code>undionly.kpxe</code> or <code>ipxe.efi</code></li><li>Flash iPXE to FlexibleLOM option ROM (advanced, requires care)</li><li>Boot iPXE from USB, then continue network boot</li></ol><h3 id=uefi-http-boot>UEFI HTTP Boot</h3><p>Native UEFI HTTP boot is supported on Gen9 servers with recent firmware:</p><ul><li><strong>Protocol</strong>: RFC 7230 HTTP/1.1</li><li><strong>Requirements</strong>:<ul><li>UEFI firmware version 2.40 or later (check via iLO)</li><li>DHCP option 60 (vendor class identifier) = &ldquo;HTTPClient&rdquo;</li><li>DHCP option 67 pointing to HTTP(S) URL</li></ul></li><li><strong>Advantages</strong>:<ul><li>No TFTP server required</li><li>Faster transfers than TFTP</li><li>Support for HTTPS with certificate validation</li><li>Better suited for large images (kernels, initramfs)</li></ul></li><li><strong>Limitations</strong>:<ul><li>UEFI mode only (not available in legacy BIOS)</li><li>Requires DHCP server with HTTP URL support</li></ul></li></ul><h3 id=https-boot-configuration>HTTP(S) Boot Configuration</h3><p>For UEFI HTTP boot on DL360 Gen9:</p><pre tabindex=0><code class=language-dhcpd data-lang=dhcpd># Example ISC DHCP configuration for UEFI HTTP boot
class &#34;httpclients&#34; {
    match if substring(option vendor-class-identifier, 0, 10) = &#34;HTTPClient&#34;;
}

pool {
    allow members of &#34;httpclients&#34;;
    option vendor-class-identifier &#34;HTTPClient&#34;;
    # Point to HTTP boot URI
    filename &#34;http://boot.example.com/boot/efi/bootx64.efi&#34;;
}
</code></pre><h2 id=network-interface-options>Network Interface Options</h2><p>The DL360 Gen9 supports multiple network adapter configurations for boot:</p><h3 id=flexiblelom-lom--lan-on-motherboard>FlexibleLOM (LOM = LAN on Motherboard)</h3><p>HPE FlexibleLOM slot supports:</p><ul><li><strong>HPE 366FLR</strong>: Quad-port 1GbE (Broadcom BCM5719)</li><li><strong>HPE 560FLR-SFP+</strong>: Dual-port 10GbE (Intel X710)</li><li><strong>HPE 361i</strong>: Dual-port 1GbE (Intel I350)</li></ul><p>All FlexibleLOM adapters support PXE and UEFI network boot. The option ROM can be configured via BIOS/UEFI settings.</p><h3 id=pcie-network-adapters>PCIe Network Adapters</h3><p>Standard PCIe network cards with PXE/UEFI boot ROM support:</p><ul><li>Intel X520, X710 series (10GbE)</li><li>Broadcom NetXtreme series</li><li>Mellanox ConnectX-3/4 (with appropriate firmware)</li></ul><p><strong>Boot Priority</strong>: Configure via System ROM > Network Boot Options to select which NIC boots first.</p><h2 id=firmware-configuration>Firmware Configuration</h2><h3 id=accessing-boot-configuration>Accessing Boot Configuration</h3><ol><li><strong>RBSU (ROM-Based Setup Utility)</strong>: Press F9 during POST</li><li><strong>iLO 4 Remote Console</strong>: Access via network, then virtual F9</li><li><strong>UEFI System Utilities</strong>: Modern interface for UEFI firmware settings</li></ol><h3 id=key-settings>Key Settings</h3><p>Navigate to: <strong>System Configuration > BIOS/Platform Configuration (RBSU) > Network Boot Options</strong></p><ul><li><strong>Network Boot</strong>: Enable/Disable</li><li><strong>Boot Mode</strong>: UEFI or Legacy BIOS</li><li><strong>IPv4/IPv6</strong>: Enable protocol support</li><li><strong>Boot Retry</strong>: Number of attempts before falling back to next boot device</li><li><strong>Boot Order</strong>: Prioritize network boot in boot sequence</li></ul><h3 id=per-nic-configuration>Per-NIC Configuration</h3><p>In RBSU > Network Options:</p><ul><li><strong>Option ROM</strong>: Enable/Disable per adapter</li><li><strong>Link Speed</strong>: Force speed/duplex or auto-negotiate</li><li><strong>VLAN</strong>: VLAN tagging for boot (if supported by DHCP/PXE environment)</li><li><strong>PXE Menu</strong>: Enable interactive PXE menu (Ctrl+S during PXE boot)</li></ul><h2 id=ilo-4-integration>iLO 4 Integration</h2><p>The DL360 Gen9&rsquo;s iLO 4 provides additional network boot features:</p><h3 id=virtual-media-network-boot>Virtual Media Network Boot</h3><ul><li>Mount ISO images remotely via iLO Virtual Media</li><li>Boot from network-attached ISO without physical media</li><li>Useful for OS installation or diagnostics</li></ul><p><strong>Workflow</strong>:</p><ol><li>Upload ISO to HTTP/HTTPS server or use SMB/NFS share</li><li>iLO Remote Console > Virtual Devices > Image File CD-ROM/DVD</li><li>Set boot order to prioritize virtual optical drive</li><li>Reboot server</li></ol><h3 id=scripted-deployment-via-ilo>Scripted Deployment via iLO</h3><p>iLO 4 RESTful API allows:</p><ul><li>Setting one-time boot to network via API call</li><li>Automating PXE boot for provisioning pipelines</li><li>Integration with tools like Terraform, Ansible</li></ul><p>Example using iLO RESTful API:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -k -u admin:password -X PATCH <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  https://ilo-hostname/redfish/v1/Systems/1/ <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d <span class=s1>&#39;{&#34;Boot&#34;:{&#34;BootSourceOverrideTarget&#34;:&#34;Pxe&#34;,&#34;BootSourceOverrideEnabled&#34;:&#34;Once&#34;}}&#39;</span>
</span></span></code></pre></div><h2 id=boot-process-flow>Boot Process Flow</h2><h3 id=legacy-bios-pxe-boot>Legacy BIOS PXE Boot</h3><ol><li>Server powers on, initializes NICs</li><li>NIC sends DHCPDISCOVER with PXE vendor options</li><li>DHCP server responds with IP, TFTP server (option 66), boot file (option 67)</li><li>NIC downloads NBP (Network Bootstrap Program) via TFTP</li><li>NBP executes (e.g., pxelinux.0 loads syslinux menu)</li><li>User selects boot target or automated script continues</li><li>Kernel and initramfs download and boot</li></ol><h3 id=uefi-pxe-boot>UEFI PXE Boot</h3><ol><li>UEFI firmware initializes network stack</li><li>UEFI PXE driver sends DHCPv4/v6 DISCOVER</li><li>DHCP responds with boot file (e.g., <code>bootx64.efi</code>)</li><li>UEFI downloads boot file via TFTP</li><li>UEFI loads and executes boot loader (GRUB2, systemd-boot, iPXE)</li><li>Boot loader may download additional files (kernel, initrd, config)</li><li>OS boots</li></ol><h3 id=uefi-http-boot-1>UEFI HTTP Boot</h3><ol><li>UEFI firmware with HTTP Boot support enabled</li><li>DHCP request includes &ldquo;HTTPClient&rdquo; vendor class</li><li>DHCP responds with HTTP(S) URL in option 67</li><li>UEFI HTTP client downloads boot file over HTTP(S)</li><li>Execution continues as with UEFI PXE</li></ol><h2 id=performance-considerations>Performance Considerations</h2><h3 id=tftp-vs-http>TFTP vs HTTP</h3><ul><li><strong>TFTP</strong>: Slow for large files (typical: 1-5 MB/s)<ul><li>Use for small boot loaders only</li><li>Chainload to iPXE or HTTP boot for better performance</li></ul></li><li><strong>HTTP</strong>: 10-100x faster depending on network and server<ul><li>Recommended for kernels, initramfs, live OS images</li><li>iPXE or UEFI HTTP boot required</li></ul></li></ul><h3 id=network-speed-impact>Network Speed Impact</h3><p>DL360 Gen9 boot performance by NIC speed:</p><ul><li><strong>1GbE</strong>: Adequate for most PXE deployments (100-125 MB/s theoretical max)</li><li><strong>10GbE</strong>: Significant improvement for large image downloads (1-2 GB/s)</li><li><strong>Bonding/Teaming</strong>: Not typically used for boot (single NIC boots)</li></ul><p><strong>Recommendation</strong>: For production diskless nodes or frequent re-provisioning, 10GbE with HTTP boot provides best performance.</p><h2 id=common-use-cases>Common Use Cases</h2><h3 id=1-automated-os-provisioning>1. Automated OS Provisioning</h3><p>Boot into installer via PXE:</p><ul><li><strong>Kickstart</strong> (RHEL/CentOS/Rocky)</li><li><strong>Preseed</strong> (Debian/Ubuntu)</li><li><strong>Ignition</strong> (Fedora CoreOS, Flatcar)</li></ul><h3 id=2-diskless-boot>2. Diskless Boot</h3><p>Boot OS entirely from network/RAM:</p><ul><li><strong>Network root</strong>: NFS or iSCSI root filesystem</li><li><strong>Overlay</strong>: Persistent storage via network overlay</li><li><strong>Stateless</strong>: Boot identical image, no local state</li></ul><h3 id=3-rescue-and-diagnostics>3. Rescue and Diagnostics</h3><p>Boot live environments:</p><ul><li><strong>SystemRescue</strong></li><li><strong>Clonezilla</strong></li><li><strong>Memtest86+</strong></li><li><strong>Hardware diagnostics</strong> (HPE Service Pack for ProLiant)</li></ul><h3 id=4-kubernetescontainer-hosts>4. Kubernetes/Container Hosts</h3><p>PXE boot immutable OS images:</p><ul><li><strong>Talos Linux</strong>: API-driven, diskless k8s nodes</li><li><strong>Flatcar Container Linux</strong>: Automated updates</li><li><strong>k3OS</strong>: Lightweight k8s OS</li></ul><h2 id=troubleshooting>Troubleshooting</h2><h3 id=pxe-boot-fails>PXE Boot Fails</h3><p><strong>Symptoms</strong>: &ldquo;PXE-E51: No DHCP or proxy DHCP offers received&rdquo; or timeout</p><p><strong>Checks</strong>:</p><ol><li>Verify NIC link light and switch port status</li><li>Confirm DHCP server is responding (check DHCP logs)</li><li>Ensure DHCP options 66 and 67 are set correctly</li><li>Test TFTP server accessibility (<code>tftp -i &lt;server> GET &lt;file></code>)</li><li>Check BIOS/UEFI network boot is enabled</li><li>Verify boot order prioritizes network boot</li><li>Disable Secure Boot if using unsigned boot files</li></ol><h3 id=uefi-network-boot-not-available>UEFI Network Boot Not Available</h3><p><strong>Symptoms</strong>: Network boot option missing in UEFI boot menu</p><p><strong>Resolution</strong>:</p><ol><li>Enter RBSU (F9), navigate to Network Options</li><li>Ensure at least one NIC has &ldquo;Option ROM&rdquo; enabled</li><li>Verify Boot Mode is set to UEFI (not Legacy)</li><li>Update System ROM to latest version if option is missing</li><li>Some FlexibleLOM cards require firmware update for UEFI boot support</li></ol><h3 id=http-boot-fails>HTTP Boot Fails</h3><p><strong>Symptoms</strong>: UEFI HTTP boot option present but fails to download</p><p><strong>Checks</strong>:</p><ol><li>Verify firmware version supports HTTP boot (>=2.40)</li><li>Ensure DHCP option 67 contains valid HTTP(S) URL</li><li>Test URL accessibility from another client</li><li>Check DNS resolution if using hostname in URL</li><li>For HTTPS: Verify certificate is trusted (or disable cert validation in test)</li></ol><h3 id=slow-pxe-boot>Slow PXE Boot</h3><p><strong>Symptoms</strong>: Boot process takes minutes instead of seconds</p><p><strong>Optimizations</strong>:</p><ol><li>Switch from TFTP to HTTP (chainload iPXE or use UEFI HTTP boot)</li><li>Increase TFTP server block size (<code>tftp-hpa --blocksize 1468</code>)</li><li>Tune DHCP response times (reduce lease query delays)</li><li>Use local network segment for boot server (avoid WAN/VPN)</li><li>Enable NIC interrupt coalescing in BIOS for 10GbE</li></ol><h2 id=security-considerations>Security Considerations</h2><h3 id=secure-boot>Secure Boot</h3><p>DL360 Gen9 supports UEFI Secure Boot:</p><ul><li>Validates signed boot loaders (shim, GRUB, kernel)</li><li>Prevents unsigned code execution during boot</li><li>Required for some compliance scenarios</li></ul><p><strong>Configuration</strong>: RBSU > Boot Options > Secure Boot = Enabled</p><p><strong>Implications for Network Boot</strong>:</p><ul><li>Must use signed boot loaders (e.g., shim.efi signed by Microsoft/vendor)</li><li>Custom kernels require signing or disabling Secure Boot</li><li>iPXE must be signed or chainloaded from signed shim</li></ul><h3 id=network-security>Network Security</h3><p><strong>Risks</strong>:</p><ul><li>PXE/TFTP is unencrypted and unauthenticated</li><li>Attacker on network can serve malicious boot images</li><li>DHCP spoofing can redirect to malicious boot server</li></ul><p><strong>Mitigations</strong>:</p><ol><li><strong>Network Segmentation</strong>: Isolate PXE boot to management VLAN</li><li><strong>DHCP Snooping</strong>: Prevent rogue DHCP servers on switch</li><li><strong>HTTPS Boot</strong>: Use UEFI HTTP boot with TLS and certificate validation</li><li><strong>iPXE with HTTPS</strong>: Chainload iPXE, then use HTTPS for all downloads</li><li><strong>Signed Images</strong>: Use Secure Boot with signed boot chain</li><li><strong>802.1X</strong>: Require network authentication before DHCP (complex for PXE)</li></ol><h3 id=ilo-security>iLO Security</h3><ul><li>Change default iLO password immediately</li><li>Use TLS for iLO web interface and API</li><li>Restrict iLO network access (firewall, separate VLAN)</li><li>Disable iLO Virtual Media if not needed</li><li>Enable iLO Security Override for extra security during boot</li></ul><h2 id=firmware-and-driver-resources>Firmware and Driver Resources</h2><h3 id=required-firmware-versions>Required Firmware Versions</h3><p>For optimal network boot support:</p><ul><li><strong>System ROM</strong>: v2.60 or later (latest recommended)</li><li><strong>iLO 4 Firmware</strong>: v2.80 or later</li><li><strong>NIC Firmware</strong>: Latest for specific FlexibleLOM/PCIe card</li></ul><p>Check current versions: iLO web interface > Information > Firmware Information</p><h3 id=updating-firmware>Updating Firmware</h3><p>Methods:</p><ol><li><p><strong>HPE Service Pack for ProLiant (SPP)</strong>: Comprehensive update bundle</p><ul><li>Boot from SPP ISO (via iLO Virtual Media or USB)</li><li>Runs Smart Update Manager (SUM) in Linux environment</li><li>Updates all firmware, drivers, system ROM automatically</li></ul></li><li><p><strong>iLO Web Interface</strong>: Individual component updates</p><ul><li>System ROM: Administration > Firmware > Update Firmware</li><li>Upload .fwpkg or .bin files from HPE support site</li></ul></li><li><p><strong>Online Flash Component</strong>: Linux Online ROM Flash utility</p><ul><li>Install <code>hp-firmware-*</code> packages</li><li>Run updates while OS is running (requires reboot to apply)</li></ul></li></ol><p><strong>Download Source</strong>: <a href="https://support.hpe.com/connect/s/product?language=en_US&amp;kmpmoid=1010026910">https://support.hpe.com/connect/s/product?language=en_US&amp;kmpmoid=1010026910</a> (requires HPE Passport account, free registration)</p><h2 id=best-practices>Best Practices</h2><ol><li><strong>Use UEFI Mode</strong>: Better security, IPv6 support, larger disk support</li><li><strong>Enable HTTP Boot</strong>: Faster and more reliable than TFTP for large files</li><li><strong>Chainload iPXE</strong>: Flexibility of iPXE with standard PXE infrastructure</li><li><strong>Update Firmware</strong>: Keep System ROM and iLO current for bug fixes and features</li><li><strong>Isolate Boot Network</strong>: Use dedicated management VLAN for PXE/provisioning</li><li><strong>Test Failover</strong>: Configure multiple DHCP servers and boot mirrors for redundancy</li><li><strong>Document Configuration</strong>: Record BIOS settings, DHCP config, and boot infrastructure</li><li><strong>Monitor iLO Logs</strong>: Track boot failures and hardware issues via iLO event log</li></ol><h2 id=references>References</h2><ul><li>HPE ProLiant DL360 Gen9 Server User Guide</li><li>HPE UEFI System Utilities User Guide</li><li>iLO 4 User Guide (firmware version 2.80)</li><li>Intel PXE Specification v2.1</li><li>UEFI Specification v2.8 (HTTP Boot)</li><li>iPXE Documentation: <a href=https://ipxe.org/>https://ipxe.org/</a></li></ul><h2 id=conclusion>Conclusion</h2><p>The HP ProLiant DL360 Gen9 provides enterprise-grade network boot capabilities suitable for both traditional PXE deployments and modern UEFI HTTP boot scenarios. Its flexible configuration options, mature firmware support, and iLO integration make it an excellent platform for automated provisioning, diskless computing, and infrastructure-as-code workflows in home lab environments.</p><p>For home lab use, the recommended configuration is:</p><ul><li>UEFI boot mode with Secure Boot disabled (unless required)</li><li>iPXE chainloading for flexibility and HTTP performance</li><li>iLO 4 configured for remote management and scripted provisioning</li><li>Latest firmware for stability and feature support</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-cfa22b3ce5fc949a63e23e3219b26f83>1.6 - Matchbox Analysis</h1><div class=lead>Analysis of Matchbox network boot service capabilities and architecture</div><h1 id=matchbox-network-boot-analysis>Matchbox Network Boot Analysis</h1><p>This section contains a comprehensive analysis of <a href=https://matchbox.psdn.io/>Matchbox</a>, a network boot service for provisioning bare-metal machines.</p><h2 id=overview>Overview</h2><p>Matchbox is an HTTP and gRPC service developed by Poseidon that automates bare-metal machine provisioning through network booting. It matches machines to configuration profiles based on hardware attributes and serves boot configurations, kernel images, and provisioning configs.</p><p><strong>Primary Repository</strong>: <a href=https://github.com/poseidon/matchbox>poseidon/matchbox</a><br><strong>Documentation</strong>: <a href=https://matchbox.psdn.io/>https://matchbox.psdn.io/</a><br><strong>License</strong>: Apache 2.0</p><h2 id=key-features>Key Features</h2><ul><li><strong>Network Boot Support</strong>: iPXE, PXELINUX, GRUB2 chainloading</li><li><strong>OS Provisioning</strong>: Fedora CoreOS, Flatcar Linux, RHEL CoreOS</li><li><strong>Configuration Management</strong>: Ignition v3.x configs, Butane transpilation</li><li><strong>Machine Matching</strong>: Label-based matching (MAC, UUID, hostname, serial, custom)</li><li><strong>API</strong>: Read-only HTTP API + authenticated gRPC API</li><li><strong>Asset Serving</strong>: Local caching of OS images for faster deployment</li><li><strong>Templating</strong>: Go template support for dynamic configuration</li></ul><h2 id=use-cases>Use Cases</h2><ol><li><strong>Bare-metal Kubernetes clusters</strong> - Provision CoreOS nodes for k8s</li><li><strong>Lab/development environments</strong> - Quick PXE boot for testing</li><li><strong>Datacenter provisioning</strong> - Automate OS installation across fleets</li><li><strong>Immutable infrastructure</strong> - Declarative machine provisioning via Terraform</li></ol><h2 id=analysis-contents>Analysis Contents</h2><ul><li><a href=./network-boot/>Network Boot Architecture</a> - Deep dive into PXE, iPXE, and GRUB support</li><li><a href=./configuration/>Configuration Model</a> - Profiles, Groups, and templating system</li><li><a href=./deployment/>Deployment Patterns</a> - Installation options and operational considerations</li></ul><h2 id=quick-architecture>Quick Architecture</h2><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Machine   â”‚ PXE Boot
â”‚  (BIOS/UEFI)â”‚â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ DHCP/TFTP
â”‚   dnsmasq   â”‚â—„â”€â”€â”˜ (chainload to iPXE)
â”‚  DHCP+TFTP  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ HTTP
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Matchbox           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  HTTP Endpoints  â”‚   â”‚ /boot.ipxe, /ignition
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   gRPC API       â”‚   â”‚ Terraform provider
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Profile/Group    â”‚   â”‚ Match machines
â”‚  â”‚   Matcher        â”‚   â”‚ to configs
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><h2 id=technology-stack>Technology Stack</h2><ul><li><strong>Language</strong>: Go</li><li><strong>Config Formats</strong>: Ignition JSON, Butane YAML</li><li><strong>Boot Protocols</strong>: PXE, iPXE, GRUB2</li><li><strong>APIs</strong>: HTTP (read-only), gRPC (authenticated)</li><li><strong>Deployment</strong>: Binary, container (Podman/Docker), Kubernetes</li></ul><h2 id=integration-points>Integration Points</h2><ul><li><strong>Terraform</strong>: <code>terraform-provider-matchbox</code> for declarative provisioning</li><li><strong>Ignition/Butane</strong>: CoreOS provisioning configs</li><li><strong>dnsmasq</strong>: Reference DHCP/TFTP/DNS implementation (<code>quay.io/poseidon/dnsmasq</code>)</li><li><strong>Asset sources</strong>: Can serve local or remote (HTTPS) OS images</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-a23269e9072cc20bff941edf0359244d>1.6.1 - Configuration Model</h1><div class=lead>Analysis of Matchbox&rsquo;s profile, group, and templating system</div><h1 id=matchbox-configuration-model>Matchbox Configuration Model</h1><p>Matchbox uses a flexible configuration model based on <strong>Profiles</strong> (what to provision) and <strong>Groups</strong> (which machines get which profile), with support for templating and metadata.</p><h2 id=architecture-overview>Architecture Overview</h2><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Matchbox Store                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Profiles  â”‚  â”‚   Groups   â”‚  â”‚   Assets   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚        â”‚               â”‚                                    â”‚
â”‚        â”‚               â”‚                                    â”‚
â”‚        â–¼               â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚       Matcher Engine                â”‚                   â”‚
â”‚  â”‚  (Label-based group selection)      â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                    â”‚                                        â”‚
â”‚                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚    Template Renderer                â”‚                   â”‚
â”‚  â”‚  (Go templates + metadata)          â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            Rendered Config (iPXE, Ignition, etc.)
</code></pre><h2 id=data-directory-structure>Data Directory Structure</h2><p>Matchbox uses a FileStore (default) that reads from <code>-data-path</code> (default: <code>/var/lib/matchbox</code>):</p><pre tabindex=0><code>/var/lib/matchbox/
â”œâ”€â”€ groups/              # Machine group definitions (JSON)
â”‚   â”œâ”€â”€ default.json
â”‚   â”œâ”€â”€ node1.json
â”‚   â””â”€â”€ us-west.json
â”œâ”€â”€ profiles/            # Profile definitions (JSON)
â”‚   â”œâ”€â”€ worker.json
â”‚   â”œâ”€â”€ controller.json
â”‚   â””â”€â”€ etcd.json
â”œâ”€â”€ ignition/            # Ignition configs (.ign) or Butane (.yaml)
â”‚   â”œâ”€â”€ worker.ign
â”‚   â”œâ”€â”€ controller.ign
â”‚   â””â”€â”€ butane-example.yaml
â”œâ”€â”€ cloud/               # Cloud-Config templates (DEPRECATED)
â”‚   â””â”€â”€ legacy.yaml.tmpl
â”œâ”€â”€ generic/             # Arbitrary config templates
â”‚   â”œâ”€â”€ setup.cfg
â”‚   â””â”€â”€ metadata.yaml.tmpl
â””â”€â”€ assets/              # Static files (kernel, initrd)
    â”œâ”€â”€ fedora-coreos/
    â””â”€â”€ flatcar/
</code></pre><p><strong>Version control:</strong> Poseidon recommends keeping <code>/var/lib/matchbox</code> under git for auditability and rollback.</p><h2 id=profiles>Profiles</h2><p>Profiles define <strong>what to provision</strong>: network boot settings (kernel, initrd, args) and config references (Ignition, Cloud-Config, generic).</p><h3 id=profile-schema>Profile Schema</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;worker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Fedora CoreOS Worker Node&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;boot&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;kernel&#34;</span><span class=p>:</span> <span class=s2>&#34;/assets/fedora-coreos/36.20220906.3.2/fedora-coreos-36.20220906.3.2-live-kernel-x86_64&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;initrd&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;--name main /assets/fedora-coreos/36.20220906.3.2/fedora-coreos-36.20220906.3.2-live-initramfs.x86_64.img&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;args&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;initrd=main&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;coreos.live.rootfs_url=http://matchbox.example.com:8080/assets/fedora-coreos/36.20220906.3.2/fedora-coreos-36.20220906.3.2-live-rootfs.x86_64.img&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;coreos.inst.install_dev=/dev/sda&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;coreos.inst.ignition_url=http://matchbox.example.com:8080/ignition?uuid=${uuid}&amp;mac=${mac:hexhyp}&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;ignition_id&#34;</span><span class=p>:</span> <span class=s2>&#34;worker.ign&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;cloud_id&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;generic_id&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=profile-fields>Profile Fields</h3><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>id</code></td><td>string</td><td>âœ…</td><td>Unique profile identifier (referenced by groups)</td></tr><tr><td><code>name</code></td><td>string</td><td>âŒ</td><td>Human-readable description</td></tr><tr><td><code>boot</code></td><td>object</td><td>âŒ</td><td>Network boot configuration</td></tr><tr><td><code>boot.kernel</code></td><td>string</td><td>âŒ</td><td>Kernel URL (HTTP/HTTPS or /assets path)</td></tr><tr><td><code>boot.initrd</code></td><td>array</td><td>âŒ</td><td>Initrd URLs (can specify <code>--name</code> for multi-initrd)</td></tr><tr><td><code>boot.args</code></td><td>array</td><td>âŒ</td><td>Kernel command-line arguments</td></tr><tr><td><code>ignition_id</code></td><td>string</td><td>âŒ</td><td>Ignition/Butane config filename in <code>ignition/</code></td></tr><tr><td><code>cloud_id</code></td><td>string</td><td>âŒ</td><td>Cloud-Config filename in <code>cloud/</code> (deprecated)</td></tr><tr><td><code>generic_id</code></td><td>string</td><td>âŒ</td><td>Generic config filename in <code>generic/</code></td></tr></tbody></table><h3 id=boot-configuration-patterns>Boot Configuration Patterns</h3><h4 id=pattern-1-live-pxe-ram-based-ephemeral>Pattern 1: Live PXE (RAM-based, ephemeral)</h4><p>Boot and run OS entirely from RAM, no disk install:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;boot&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;kernel&#34;</span><span class=p>:</span> <span class=s2>&#34;/assets/fedora-coreos/VERSION/fedora-coreos-VERSION-live-kernel-x86_64&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;initrd&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;--name main /assets/fedora-coreos/VERSION/fedora-coreos-VERSION-live-initramfs.x86_64.img&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;args&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;initrd=main&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;coreos.live.rootfs_url=http://matchbox/assets/fedora-coreos/VERSION/fedora-coreos-VERSION-live-rootfs.x86_64.img&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;ignition.config.url=http://matchbox/ignition?uuid=${uuid}&amp;mac=${mac:hexhyp}&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Use case:</strong> Diskless workers, testing, ephemeral compute</p><h4 id=pattern-2-disk-install-persistent>Pattern 2: Disk Install (persistent)</h4><p>PXE boot live image, install to disk, reboot to disk:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;boot&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;kernel&#34;</span><span class=p>:</span> <span class=s2>&#34;/assets/fedora-coreos/VERSION/fedora-coreos-VERSION-live-kernel-x86_64&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;initrd&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;--name main /assets/fedora-coreos/VERSION/fedora-coreos-VERSION-live-initramfs.x86_64.img&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;args&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;initrd=main&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;coreos.live.rootfs_url=http://matchbox/assets/fedora-coreos/VERSION/fedora-coreos-VERSION-live-rootfs.x86_64.img&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;coreos.inst.install_dev=/dev/sda&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;coreos.inst.ignition_url=http://matchbox/ignition?uuid=${uuid}&amp;mac=${mac:hexhyp}&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Key difference:</strong> <code>coreos.inst.install_dev</code> triggers disk install before reboot</p><h4 id=pattern-3-multi-initrd-layered>Pattern 3: Multi-initrd (layered)</h4><p>Multiple initrds can be loaded (e.g., base + drivers):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;initrd&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;--name main /assets/fedora-coreos/VERSION/fedora-coreos-VERSION-live-initramfs.x86_64.img&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;--name drivers /assets/drivers/custom-drivers.img&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;args&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;initrd=main,drivers&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;...&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=config-references>Config References</h3><h4 id=ignition-configs>Ignition Configs</h4><p><strong>Direct Ignition (.ign files):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;ignition_id&#34;</span><span class=p>:</span> <span class=s2>&#34;worker.ign&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>File: <code>/var/lib/matchbox/ignition/worker.ign</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;ignition&#34;</span><span class=p>:</span> <span class=p>{</span> <span class=nt>&#34;version&#34;</span><span class=p>:</span> <span class=s2>&#34;3.3.0&#34;</span> <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;systemd&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;units&#34;</span><span class=p>:</span> <span class=p>[{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;example.service&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;enabled&#34;</span><span class=p>:</span> <span class=kc>true</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;contents&#34;</span><span class=p>:</span> <span class=s2>&#34;[Service]\nType=oneshot\nExecStart=/usr/bin/echo Hello\n\n[Install]\nWantedBy=multi-user.target&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Butane Configs (transpiled to Ignition):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;ignition_id&#34;</span><span class=p>:</span> <span class=s2>&#34;worker.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>File: <code>/var/lib/matchbox/ignition/worker.yaml</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>variant</span><span class=p>:</span><span class=w> </span><span class=l>fcos</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=m>1.5.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>passwd</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>users</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>core</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>ssh_authorized_keys</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>ssh-ed25519 AAAA...</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>systemd</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>units</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>etcd.service</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span></code></pre></div><p><strong>Matchbox automatically:</strong></p><ol><li>Detects Butane format (file doesn&rsquo;t end in <code>.ign</code> or <code>.ignition</code>)</li><li>Transpiles Butane â†’ Ignition using embedded library</li><li>Renders templates with group metadata</li><li>Serves as Ignition v3.3.0</li></ol><h4 id=generic-configs>Generic Configs</h4><p>For non-Ignition configs (scripts, YAML, arbitrary data):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;generic_id&#34;</span><span class=p>:</span> <span class=s2>&#34;setup-script.sh.tmpl&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>File: <code>/var/lib/matchbox/generic/setup-script.sh.tmpl</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=c1># Rendered with group metadata</span>
</span></span><span class=line><span class=cl><span class=nv>NODE_NAME</span><span class=o>={{</span>.node_name<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=nv>CLUSTER_ID</span><span class=o>={{</span>.cluster_id<span class=o>}}</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;Provisioning </span><span class=si>${</span><span class=nv>NODE_NAME</span><span class=si>}</span><span class=s2> in cluster </span><span class=si>${</span><span class=nv>CLUSTER_ID</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span></code></pre></div><p><strong>Access via:</strong> <code>GET /generic?uuid=...&amp;mac=...</code></p><h2 id=groups>Groups</h2><p>Groups match machines to profiles using <strong>selectors</strong> (label matching) and provide <strong>metadata</strong> for template rendering.</p><h3 id=group-schema>Group Schema</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;node1-worker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Worker Node 1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;profile&#34;</span><span class=p>:</span> <span class=s2>&#34;worker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;selector&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;mac&#34;</span><span class=p>:</span> <span class=s2>&#34;52:54:00:89:d8:10&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;uuid&#34;</span><span class=p>:</span> <span class=s2>&#34;550e8400-e29b-41d4-a716-446655440000&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;metadata&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;node_name&#34;</span><span class=p>:</span> <span class=s2>&#34;worker-01&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;cluster_id&#34;</span><span class=p>:</span> <span class=s2>&#34;prod-cluster&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;etcd_endpoints&#34;</span><span class=p>:</span> <span class=s2>&#34;https://10.0.1.10:2379,https://10.0.1.11:2379&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;ssh_authorized_keys&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;ssh-ed25519 AAAA...&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;ssh-rsa AAAA...&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=group-fields>Group Fields</h3><table><thead><tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>id</code></td><td>string</td><td>âœ…</td><td>Unique group identifier</td></tr><tr><td><code>name</code></td><td>string</td><td>âŒ</td><td>Human-readable description</td></tr><tr><td><code>profile</code></td><td>string</td><td>âœ…</td><td>Profile ID to apply</td></tr><tr><td><code>selector</code></td><td>object</td><td>âŒ</td><td>Label match criteria (omit for default group)</td></tr><tr><td><code>metadata</code></td><td>object</td><td>âŒ</td><td>Key-value data for template rendering</td></tr></tbody></table><h3 id=selector-matching>Selector Matching</h3><p><strong>Reserved selectors</strong> (automatically populated from machine attributes):</p><table><thead><tr><th>Selector</th><th>Source</th><th>Example</th><th>Normalized</th></tr></thead><tbody><tr><td><code>uuid</code></td><td>SMBIOS UUID</td><td><code>550e8400-e29b-41d4-a716-446655440000</code></td><td>Lowercase</td></tr><tr><td><code>mac</code></td><td>Primary NIC MAC</td><td><code>52:54:00:89:d8:10</code></td><td>Colon-separated</td></tr><tr><td><code>hostname</code></td><td>Network hostname</td><td><code>node1.example.com</code></td><td>As reported</td></tr><tr><td><code>serial</code></td><td>Hardware serial</td><td><code>VMware-42 1a...</code></td><td>As reported</td></tr></tbody></table><p><strong>Custom selectors</strong> (passed as query params):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;selector&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;region&#34;</span><span class=p>:</span> <span class=s2>&#34;us-west&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;environment&#34;</span><span class=p>:</span> <span class=s2>&#34;production&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;rack&#34;</span><span class=p>:</span> <span class=s2>&#34;A23&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Matching request:</strong> <code>/ipxe?mac=52:54:00:89:d8:10&amp;region=us-west&amp;environment=production&amp;rack=A23</code></p><p><strong>Matching logic:</strong></p><ol><li>All selector key-value pairs must match request labels (AND logic)</li><li>Most specific group wins (most selector matches)</li><li>If multiple groups have same specificity, first match wins (undefined order)</li><li>Groups with no selectors = default group (matches all)</li></ol><h3 id=default-groups>Default Groups</h3><p>Group with empty <code>selector</code> matches all machines:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;default-worker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Default Worker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;profile&#34;</span><span class=p>:</span> <span class=s2>&#34;worker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;metadata&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;environment&#34;</span><span class=p>:</span> <span class=s2>&#34;dev&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>âš ï¸ <strong>Warning:</strong> Avoid multiple default groups (non-deterministic matching)</p><h3 id=example-region-based-matching>Example: Region-based Matching</h3><p><strong>Group 1: US-West Workers</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;us-west-workers&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;profile&#34;</span><span class=p>:</span> <span class=s2>&#34;worker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;selector&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;region&#34;</span><span class=p>:</span> <span class=s2>&#34;us-west&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;metadata&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;etcd_endpoints&#34;</span><span class=p>:</span> <span class=s2>&#34;https://etcd-usw.example.com:2379&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Group 2: EU Workers</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;eu-workers&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;profile&#34;</span><span class=p>:</span> <span class=s2>&#34;worker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;selector&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;region&#34;</span><span class=p>:</span> <span class=s2>&#34;eu&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;metadata&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;etcd_endpoints&#34;</span><span class=p>:</span> <span class=s2>&#34;https://etcd-eu.example.com:2379&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Group 3: Specific Machine Override</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;node-special&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;profile&#34;</span><span class=p>:</span> <span class=s2>&#34;controller&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;selector&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;mac&#34;</span><span class=p>:</span> <span class=s2>&#34;52:54:00:89:d8:10&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;region&#34;</span><span class=p>:</span> <span class=s2>&#34;us-west&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;metadata&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;controller&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Matching precedence:</strong></p><ul><li>Machine with <code>mac=52:54:00:89:d8:10&amp;region=us-west</code> â†’ <code>node-special</code> (2 selectors)</li><li>Machine with <code>region=us-west</code> â†’ <code>us-west-workers</code> (1 selector)</li><li>Machine with <code>region=eu</code> â†’ <code>eu-workers</code> (1 selector)</li></ul><h2 id=templating-system>Templating System</h2><p>Matchbox uses Go&rsquo;s <code>text/template</code> for rendering configs with group metadata.</p><h3 id=template-context>Template Context</h3><p>Available variables in Ignition/Butane/Cloud-Config/generic templates:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=c1>// Group metadata (all keys from group.metadata)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>node_name</span><span class=p>}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>cluster_id</span><span class=p>}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>etcd_endpoints</span><span class=p>}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Group selectors (normalized)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>mac</span><span class=p>}}</span><span class=w>      </span><span class=c1>// e.g., &#34;52:54:00:89:d8:10&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>uuid</span><span class=p>}}</span><span class=w>     </span><span class=c1>// e.g., &#34;550e8400-...&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>region</span><span class=p>}}</span><span class=w>   </span><span class=c1>// Custom selector</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Request query params (raw)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>request</span><span class=p>.</span><span class=nx>query</span><span class=p>.</span><span class=nx>mac</span><span class=p>}}</span><span class=w>     </span><span class=c1>// As passed in URL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>request</span><span class=p>.</span><span class=nx>query</span><span class=p>.</span><span class=nx>foo</span><span class=p>}}</span><span class=w>     </span><span class=c1>// Custom query param</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{.</span><span class=nx>request</span><span class=p>.</span><span class=nx>raw_query</span><span class=p>}}</span><span class=w>     </span><span class=c1>// Full query string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Special functions</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{</span><span class=k>if</span><span class=w> </span><span class=nx>index</span><span class=w> </span><span class=p>.</span><span class=w> </span><span class=s>&#34;ssh_authorized_keys&#34;</span><span class=p>}}</span><span class=w>  </span><span class=c1>// Check if key exists</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{{</span><span class=k>range</span><span class=w> </span><span class=err>$</span><span class=nx>element</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=p>.</span><span class=nx>ssh_authorized_keys</span><span class=p>}}</span><span class=w>  </span><span class=c1>// Iterate arrays</span><span class=w>
</span></span></span></code></pre></div><h3 id=example-templated-butane-config>Example: Templated Butane Config</h3><p><strong>Group metadata:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;metadata&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;node_name&#34;</span><span class=p>:</span> <span class=s2>&#34;worker-01&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;ssh_authorized_keys&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;ssh-ed25519 AAA...&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;ssh-rsa BBB...&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;ntp_servers&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;time1.google.com&#34;</span><span class=p>,</span> <span class=s2>&#34;time2.google.com&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Butane template:</strong> <code>/var/lib/matchbox/ignition/worker.yaml</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>variant</span><span class=p>:</span><span class=w> </span><span class=l>fcos</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=m>1.5.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>storage</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>files</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/etc/hostname</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=m>0644</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>contents</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>inline</span><span class=p>:</span><span class=w> </span>{{<span class=l>.node_name}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/etc/systemd/timesyncd.conf</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=m>0644</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>contents</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>inline</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          [Time]
</span></span></span><span class=line><span class=cl><span class=sd>          {{range $server := .ntp_servers}}
</span></span></span><span class=line><span class=cl><span class=sd>          NTP={{$server}}
</span></span></span><span class=line><span class=cl><span class=sd>          {{end}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>{{<span class=l>if index . &#34;ssh_authorized_keys&#34;}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>passwd</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>users</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>core</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>ssh_authorized_keys</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>{{<span class=l>range $key := .ssh_authorized_keys}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- {{<span class=l>$key}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>{{<span class=l>end}}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>{{<span class=l>end}}</span><span class=w>
</span></span></span></code></pre></div><p><strong>Rendered Ignition (simplified):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;ignition&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;version&#34;</span><span class=p>:</span> <span class=s2>&#34;3.3.0&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;storage&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;files&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;path&#34;</span><span class=p>:</span> <span class=s2>&#34;/etc/hostname&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;contents&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;source&#34;</span><span class=p>:</span> <span class=s2>&#34;data:,worker-01&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;mode&#34;</span><span class=p>:</span> <span class=mi>420</span>
</span></span><span class=line><span class=cl>      <span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;path&#34;</span><span class=p>:</span> <span class=s2>&#34;/etc/systemd/timesyncd.conf&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;contents&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;source&#34;</span><span class=p>:</span> <span class=s2>&#34;data:,%5BTime%5D%0ANTP%3Dtime1.google.com%0ANTP%3Dtime2.google.com&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;mode&#34;</span><span class=p>:</span> <span class=mi>420</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;passwd&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;users&#34;</span><span class=p>:</span> <span class=p>[{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;core&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;sshAuthorizedKeys&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;ssh-ed25519 AAA...&#34;</span><span class=p>,</span> <span class=s2>&#34;ssh-rsa BBB...&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>}]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=template-best-practices>Template Best Practices</h3><ol><li><strong>Prefer external rendering:</strong> Use Terraform + <code>ct_config</code> provider for complex templates</li><li><strong>Validate Butane:</strong> Use <code>strict: true</code> in Terraform or <code>fcct --strict</code></li><li><strong>Escape carefully:</strong> Go templates use <code>{{}}</code>, Butane uses YAML - mind the interaction</li><li><strong>Test rendering:</strong> Request <code>/ignition?mac=...</code> directly to inspect output</li><li><strong>Version control:</strong> Keep templates + groups in git for auditability</li></ol><h3 id=reserved-metadata-keys>Reserved Metadata Keys</h3><p><strong>Warning:</strong> <code>.request</code> is reserved for query param access. Group metadata with <code>"request": {...}</code> will be overwritten.</p><p><strong>Reserved keys:</strong></p><ul><li><code>request.query.*</code> - Query parameters</li><li><code>request.raw_query</code> - Raw query string</li></ul><h2 id=api-integration>API Integration</h2><h3 id=http-endpoints-read-only>HTTP Endpoints (Read-only)</h3><table><thead><tr><th>Endpoint</th><th>Purpose</th><th>Template Context</th></tr></thead><tbody><tr><td><code>/ipxe</code></td><td>iPXE boot script</td><td>Profile <code>boot</code> section</td></tr><tr><td><code>/grub</code></td><td>GRUB config</td><td>Profile <code>boot</code> section</td></tr><tr><td><code>/ignition</code></td><td>Ignition config</td><td>Group metadata + selectors + query</td></tr><tr><td><code>/cloud</code></td><td>Cloud-Config (deprecated)</td><td>Group metadata + selectors + query</td></tr><tr><td><code>/generic</code></td><td>Generic config</td><td>Group metadata + selectors + query</td></tr><tr><td><code>/metadata</code></td><td>Key-value env format</td><td>Group metadata + selectors + query</td></tr></tbody></table><p><strong>Example metadata endpoint response:</strong></p><pre tabindex=0><code>GET /metadata?mac=52:54:00:89:d8:10&amp;foo=bar

NODE_NAME=worker-01
CLUSTER_ID=prod
MAC=52:54:00:89:d8:10
REQUEST_QUERY_MAC=52:54:00:89:d8:10
REQUEST_QUERY_FOO=bar
REQUEST_RAW_QUERY=mac=52:54:00:89:d8:10&amp;foo=bar
</code></pre><h3 id=grpc-api-authenticated-mutable>gRPC API (Authenticated, mutable)</h3><p>Used by <code>terraform-provider-matchbox</code> for declarative infrastructure:</p><p><strong>Terraform example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-hcl data-lang=hcl><span class=line><span class=cl><span class=k>provider</span> <span class=s2>&#34;matchbox&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>  endpoint</span>    <span class=o>=</span> <span class=s2>&#34;matchbox.example.com:8081&#34;</span>
</span></span><span class=line><span class=cl><span class=n>  client_cert</span> <span class=o>=</span> <span class=k>file</span><span class=p>(</span><span class=s2>&#34;~/.matchbox/client.crt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>  client_key</span>  <span class=o>=</span> <span class=k>file</span><span class=p>(</span><span class=s2>&#34;~/.matchbox/client.key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>  ca</span>          <span class=o>=</span> <span class=k>file</span><span class=p>(</span><span class=s2>&#34;~/.matchbox/ca.crt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>resource</span> <span class=s2>&#34;matchbox_profile&#34; &#34;worker&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>  name</span>   <span class=o>=</span> <span class=s2>&#34;worker&#34;</span>
</span></span><span class=line><span class=cl><span class=n>  kernel</span> <span class=o>=</span> <span class=s2>&#34;/assets/fedora-coreos/.../kernel&#34;</span>
</span></span><span class=line><span class=cl><span class=n>  initrd</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;--name main /assets/fedora-coreos/.../initramfs.img&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>  args</span>   <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl><span class=n>    &#34;initrd</span><span class=o>=</span><span class=k>main</span><span class=err>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=n>    &#34;coreos.inst.install_dev</span><span class=o>=</span><span class=err>/</span><span class=k>dev</span><span class=err>/</span><span class=k>sda</span><span class=err>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=n>    &#34;coreos.inst.ignition_url</span><span class=o>=</span><span class=n>${var.matchbox_http_endpoint}/ignition?uuid</span><span class=o>=</span><span class=n>$${uuid}&amp;mac</span><span class=o>=</span><span class=err>$</span><span class=si>${</span><span class=err>mac:hexhyp</span><span class=si>}</span><span class=err>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>  raw_ignition</span> <span class=o>=</span> <span class=k>data</span><span class=p>.</span><span class=k>ct_config</span><span class=p>.</span><span class=k>worker</span><span class=p>.</span><span class=k>rendered</span>
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>resource</span> <span class=s2>&#34;matchbox_group&#34; &#34;node1&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>  name</span>    <span class=o>=</span> <span class=s2>&#34;node1&#34;</span>
</span></span><span class=line><span class=cl><span class=n>  profile</span> <span class=o>=</span> <span class=k>matchbox_profile</span><span class=p>.</span><span class=k>worker</span><span class=p>.</span><span class=k>name</span>
</span></span><span class=line><span class=cl><span class=n>  selector</span> <span class=o>=</span> {
</span></span><span class=line><span class=cl><span class=n>    mac</span> <span class=o>=</span> <span class=s2>&#34;52:54:00:89:d8:10&#34;</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl><span class=n>  metadata</span> <span class=o>=</span> {
</span></span><span class=line><span class=cl><span class=n>    node_name</span> <span class=o>=</span> <span class=s2>&#34;worker-01&#34;</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><p><strong>Operations:</strong></p><ul><li><code>CreateProfile</code>, <code>GetProfile</code>, <code>UpdateProfile</code>, <code>DeleteProfile</code></li><li><code>CreateGroup</code>, <code>GetGroup</code>, <code>UpdateGroup</code>, <code>DeleteGroup</code></li></ul><p><strong>TLS client authentication required</strong> (see deployment docs)</p><h2 id=configuration-workflow>Configuration Workflow</h2><h3 id=recommended-terraform--external-configs>Recommended: Terraform + External Configs</h3><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Write Butane configs (YAML)                             â”‚
â”‚    - worker.yaml, controller.yaml                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Terraform ct_config transpiles Butane â†’ Ignition        â”‚
â”‚    data &#34;ct_config&#34; &#34;worker&#34; {                             â”‚
â”‚      content = file(&#34;worker.yaml&#34;)                         â”‚
â”‚      strict  = true                                        â”‚
â”‚    }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Terraform creates profiles + groups in Matchbox         â”‚
â”‚    matchbox_profile.worker â†’ gRPC CreateProfile()          â”‚
â”‚    matchbox_group.node1 â†’ gRPC CreateGroup()               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Machine PXE boots, queries Matchbox                     â”‚
â”‚    GET /ipxe?mac=... â†’ matches group â†’ returns profile     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Ignition fetches rendered config                        â”‚
â”‚    GET /ignition?mac=... â†’ Matchbox returns Ignition       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><p><strong>Benefits:</strong></p><ul><li>Rich Terraform templating (loops, conditionals, external data sources)</li><li>Butane validation before deployment</li><li>Declarative infrastructure (can <code>terraform plan</code> before apply)</li><li>Version control workflow (git + CI/CD)</li></ul><h3 id=alternative-manual-filestore>Alternative: Manual FileStore</h3><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Create profile JSON manually                            â”‚
â”‚    /var/lib/matchbox/profiles/worker.json                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Create group JSON manually                              â”‚
â”‚    /var/lib/matchbox/groups/node1.json                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Write Ignition/Butane config                            â”‚
â”‚    /var/lib/matchbox/ignition/worker.ign                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Restart matchbox (to reload FileStore)                  â”‚
â”‚    systemctl restart matchbox                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><p><strong>Drawbacks:</strong></p><ul><li>Manual file management</li><li>No validation before deployment</li><li>Requires matchbox restart to pick up changes</li><li>Error-prone for large fleets</li></ul><h2 id=storage-backends>Storage Backends</h2><h3 id=filestore-default>FileStore (Default)</h3><p><strong>Config:</strong> <code>-data-path=/var/lib/matchbox</code></p><p><strong>Pros:</strong></p><ul><li>Simple file-based storage</li><li>Easy to version control (git)</li><li>Human-readable JSON</li></ul><p><strong>Cons:</strong></p><ul><li>Requires file system access</li><li>Manual reload for gRPC-created resources</li></ul><h3 id=custom-store-extensible>Custom Store (Extensible)</h3><p>Matchbox&rsquo;s <code>Store</code> interface allows custom backends:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>type</span><span class=w> </span><span class=nx>Store</span><span class=w> </span><span class=kd>interface</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nf>ProfileGet</span><span class=p>(</span><span class=nx>id</span><span class=w> </span><span class=kt>string</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=o>*</span><span class=nx>Profile</span><span class=p>,</span><span class=w> </span><span class=kt>error</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nf>GroupGet</span><span class=p>(</span><span class=nx>id</span><span class=w> </span><span class=kt>string</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=o>*</span><span class=nx>Group</span><span class=p>,</span><span class=w> </span><span class=kt>error</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nf>IgnitionGet</span><span class=p>(</span><span class=nx>name</span><span class=w> </span><span class=kt>string</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=kt>string</span><span class=p>,</span><span class=w> </span><span class=kt>error</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c1>// ... other methods</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p><strong>Potential custom stores:</strong></p><ul><li>etcd backend (for HA Matchbox)</li><li>Database backend (PostgreSQL, MySQL)</li><li>S3/object storage backend</li></ul><p><strong>Note:</strong> Not officially provided by Matchbox project; requires custom implementation</p><h2 id=security-considerations>Security Considerations</h2><ol><li><p><strong>gRPC API authentication:</strong> Requires TLS client certificates</p><ul><li><code>ca.crt</code> - CA that signed client certs</li><li><code>server.crt</code>/<code>server.key</code> - Server TLS identity</li><li><code>client.crt</code>/<code>client.key</code> - Client credentials (Terraform)</li></ul></li><li><p><strong>HTTP endpoints are read-only:</strong> No auth, machines fetch configs</p><ul><li>Do NOT put secrets in Ignition configs</li><li>Use external secret stores (Vault, GCP Secret Manager)</li><li>Reference secrets via Ignition <code>files.source</code> with auth headers</li></ul></li><li><p><strong>Network segmentation:</strong> Matchbox on provisioning VLAN, isolate from production</p></li><li><p><strong>Config validation:</strong> Validate Ignition/Butane before deployment to avoid boot failures</p></li><li><p><strong>Audit logging:</strong> Version control groups/profiles; log gRPC API changes</p></li></ol><h2 id=operational-tips>Operational Tips</h2><ol><li><p><strong>Test groups with curl:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl <span class=s1>&#39;http://matchbox.example.com:8080/ignition?mac=52:54:00:89:d8:10&#39;</span>
</span></span></code></pre></div></li><li><p><strong>List profiles:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ls -la /var/lib/matchbox/profiles/
</span></span></code></pre></div></li><li><p><strong>Validate Butane:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>podman run -i --rm quay.io/coreos/fcct:release --strict &lt; worker.yaml
</span></span></code></pre></div></li><li><p><strong>Check group matching:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Default group (no selectors)</span>
</span></span><span class=line><span class=cl>curl http://matchbox.example.com:8080/ignition
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Specific machine</span>
</span></span><span class=line><span class=cl>curl <span class=s1>&#39;http://matchbox.example.com:8080/ignition?mac=52:54:00:89:d8:10&amp;uuid=550e8400-e29b-41d4-a716-446655440000&#39;</span>
</span></span></code></pre></div></li><li><p><strong>Backup configs:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tar -czf matchbox-backup-<span class=k>$(</span>date +%F<span class=k>)</span>.tar.gz /var/lib/matchbox/<span class=o>{</span>groups,profiles,ignition<span class=o>}</span>
</span></span></code></pre></div></li></ol><h2 id=summary>Summary</h2><p>Matchbox&rsquo;s configuration model provides:</p><ul><li><strong>Separation of concerns:</strong> Profiles (what) vs Groups (who/where)</li><li><strong>Flexible matching:</strong> Label-based, multi-attribute, custom selectors</li><li><strong>Template support:</strong> Go templates for dynamic configs (but prefer external rendering)</li><li><strong>API-driven:</strong> Terraform integration for GitOps workflows</li><li><strong>Storage options:</strong> FileStore (simple) or custom backends (extensible)</li><li><strong>OS-agnostic:</strong> Works with any Ignition-based distro (FCOS, Flatcar, RHCOS)</li></ul><p><strong>Best practice:</strong> Use Terraform + external Butane configs for production; manual FileStore for labs/development.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8e3a89622c44227eb5a7e5a4a31bef5c>1.6.2 - Deployment Patterns</h1><div class=lead>Matchbox deployment options and operational considerations</div><h1 id=matchbox-deployment-patterns>Matchbox Deployment Patterns</h1><p>Analysis of deployment architectures, installation methods, and operational considerations for running Matchbox in production.</p><h2 id=deployment-architectures>Deployment Architectures</h2><h3 id=single-host-deployment>Single-Host Deployment</h3><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Provisioning Host                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Matchbox   â”‚        â”‚  dnsmasq    â”‚            â”‚
â”‚  â”‚  :8080 HTTP â”‚        â”‚  DHCP/TFTP  â”‚            â”‚
â”‚  â”‚  :8081 gRPC â”‚        â”‚  :67,:69    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                      â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                    â”‚                                â”‚
â”‚  /var/lib/matchbox/                                 â”‚
â”‚  â”œâ”€â”€ groups/                                        â”‚
â”‚  â”œâ”€â”€ profiles/                                      â”‚
â”‚  â”œâ”€â”€ ignition/                                      â”‚
â”‚  â””â”€â”€ assets/                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ Network
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ PXE Clients  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><p><strong>Use case:</strong> Lab, development, small deployments (&lt;50 machines)</p><p><strong>Pros:</strong></p><ul><li>Simple setup</li><li>Single service to manage</li><li>Minimal resource requirements</li></ul><p><strong>Cons:</strong></p><ul><li>Single point of failure</li><li>No scalability</li><li>Downtime during updates</li></ul><h3 id=ha-deployment-multiple-matchbox-instances>HA Deployment (Multiple Matchbox Instances)</h3><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Load Balancer (Ingress/HAProxy)        â”‚
â”‚           :8080 HTTP        :8081 gRPC              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                              â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â–¼             â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Matchbox 1â”‚  â”‚Matchbox 2â”‚    â”‚Matchbox Nâ”‚
â”‚ (Pod/VM) â”‚  â”‚ (Pod/VM) â”‚    â”‚ (Pod/VM) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Shared Storage        â”‚
         â”‚  /var/lib/matchbox     â”‚
         â”‚  (NFS, PV, ConfigMap)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><p><strong>Use case:</strong> Production, datacenter-scale (100+ machines)</p><p><strong>Pros:</strong></p><ul><li>High availability (no single point of failure)</li><li>Rolling updates (zero downtime)</li><li>Load distribution</li></ul><p><strong>Cons:</strong></p><ul><li>Complex storage (shared volume or etcd backend)</li><li>More infrastructure required</li></ul><p><strong>Storage options:</strong></p><ol><li><strong>Kubernetes PersistentVolume</strong> (RWX mode)</li><li><strong>NFS share</strong> mounted on multiple hosts</li><li><strong>Custom etcd-backed Store</strong> (requires custom implementation)</li><li><strong>Git-sync sidecar</strong> (read-only, periodic pull)</li></ol><h3 id=kubernetes-deployment>Kubernetes Deployment</h3><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Ingress Controller                     â”‚
â”‚  matchbox.example.com â†’ Service matchbox:8080       â”‚
â”‚  matchbox-rpc.example.com â†’ Service matchbox:8081   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Service: matchbox (ClusterIP)              â”‚
â”‚            ports: 8080/TCP, 8081/TCP                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pod: matchbox  â”‚     â”‚  Pod: matchbox  â”‚
â”‚  replicas: 2+   â”‚     â”‚  replicas: 2+   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    PersistentVolumeClaim: matchbox-data             â”‚
â”‚    /var/lib/matchbox (RWX mode)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><p><strong>Manifest structure:</strong></p><pre tabindex=0><code>contrib/k8s/
â”œâ”€â”€ matchbox-deployment.yaml  # Deployment + replicas
â”œâ”€â”€ matchbox-service.yaml     # Service (8080, 8081)
â”œâ”€â”€ matchbox-ingress.yaml     # Ingress (HTTP + gRPC TLS)
â””â”€â”€ matchbox-pvc.yaml         # PersistentVolumeClaim
</code></pre><p><strong>Key configurations:</strong></p><ol><li><p><strong>Secret for gRPC TLS:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl create secret generic matchbox-rpc <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --from-file<span class=o>=</span>ca.crt <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --from-file<span class=o>=</span>server.crt <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --from-file<span class=o>=</span>server.key
</span></span></code></pre></div></li><li><p><strong>Ingress for gRPC (TLS passthrough):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>nginx.ingress.kubernetes.io/ssl-passthrough</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>nginx.ingress.kubernetes.io/backend-protocol</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;GRPC&#34;</span><span class=w>
</span></span></span></code></pre></div></li><li><p><strong>Volume mount:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>data</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class=l>matchbox-data</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>data</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/var/lib/matchbox</span><span class=w>
</span></span></span></code></pre></div></li></ol><p><strong>Use case:</strong> Cloud-native deployments, Kubernetes-based infrastructure</p><p><strong>Pros:</strong></p><ul><li>Native Kubernetes primitives (Deployments, Services, Ingress)</li><li>Rolling updates via Deployment strategy</li><li>Easy scaling (<code>kubectl scale</code>)</li><li>Health checks + auto-restart</li></ul><p><strong>Cons:</strong></p><ul><li>Requires RWX PersistentVolume or shared storage</li><li>Ingress TLS configuration complexity (gRPC passthrough)</li><li>Cluster dependency (can&rsquo;t provision cluster bootstrap nodes)</li></ul><p>âš ï¸ <strong>Bootstrap problem:</strong> Kubernetes-hosted Matchbox can&rsquo;t PXE boot its own cluster nodes (chicken-and-egg). Use external Matchbox for initial cluster bootstrap, then migrate.</p><h2 id=installation-methods>Installation Methods</h2><h3 id=1-binary-installation-systemd>1. Binary Installation (systemd)</h3><p><strong>Recommended for:</strong> Bare-metal hosts, VMs, traditional Linux servers</p><p><strong>Steps:</strong></p><ol><li><p><strong>Download and verify:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>wget https://github.com/poseidon/matchbox/releases/download/v0.10.0/matchbox-v0.10.0-linux-amd64.tar.gz
</span></span><span class=line><span class=cl>wget https://github.com/poseidon/matchbox/releases/download/v0.10.0/matchbox-v0.10.0-linux-amd64.tar.gz.asc
</span></span><span class=line><span class=cl>gpg --verify matchbox-v0.10.0-linux-amd64.tar.gz.asc
</span></span></code></pre></div></li><li><p><strong>Extract and install:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tar xzf matchbox-v0.10.0-linux-amd64.tar.gz
</span></span><span class=line><span class=cl>sudo cp matchbox-v0.10.0-linux-amd64/matchbox /usr/local/bin/
</span></span></code></pre></div></li><li><p><strong>Create user and directories:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo useradd -U matchbox
</span></span><span class=line><span class=cl>sudo mkdir -p /var/lib/matchbox/<span class=o>{</span>assets,groups,profiles,ignition<span class=o>}</span>
</span></span><span class=line><span class=cl>sudo chown -R matchbox:matchbox /var/lib/matchbox
</span></span></code></pre></div></li><li><p><strong>Install systemd unit:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo cp contrib/systemd/matchbox.service /etc/systemd/system/
</span></span></code></pre></div></li><li><p><strong>Configure via systemd dropin:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo systemctl edit matchbox
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=k>[Service]</span>
</span></span><span class=line><span class=cl><span class=na>Environment</span><span class=o>=</span><span class=s>&#34;MATCHBOX_ADDRESS=0.0.0.0:8080&#34;</span>
</span></span><span class=line><span class=cl><span class=na>Environment</span><span class=o>=</span><span class=s>&#34;MATCHBOX_RPC_ADDRESS=0.0.0.0:8081&#34;</span>
</span></span><span class=line><span class=cl><span class=na>Environment</span><span class=o>=</span><span class=s>&#34;MATCHBOX_LOG_LEVEL=debug&#34;</span>
</span></span></code></pre></div></li><li><p><strong>Start service:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo systemctl daemon-reload
</span></span><span class=line><span class=cl>sudo systemctl start matchbox
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> matchbox
</span></span></code></pre></div></li></ol><p><strong>Pros:</strong></p><ul><li>Direct control over service</li><li>Easy log access (<code>journalctl -u matchbox</code>)</li><li>Native OS integration</li></ul><p><strong>Cons:</strong></p><ul><li>Manual updates required</li><li>OS dependency (package compatibility)</li></ul><h3 id=2-container-deployment-dockerpodman>2. Container Deployment (Docker/Podman)</h3><p><strong>Recommended for:</strong> Docker hosts, quick testing, immutable infrastructure</p><p><strong>Docker:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir -p /var/lib/matchbox/assets
</span></span><span class=line><span class=cl>docker run -d --name matchbox <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --net<span class=o>=</span>host <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -v /var/lib/matchbox:/var/lib/matchbox:Z <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -v /etc/matchbox:/etc/matchbox:Z,ro <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  quay.io/poseidon/matchbox:v0.10.0 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -address<span class=o>=</span>0.0.0.0:8080 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -rpc-address<span class=o>=</span>0.0.0.0:8081 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -log-level<span class=o>=</span>debug
</span></span></code></pre></div><p><strong>Podman:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>podman run -d --name matchbox <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --net<span class=o>=</span>host <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -v /var/lib/matchbox:/var/lib/matchbox:Z <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -v /etc/matchbox:/etc/matchbox:Z,ro <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  quay.io/poseidon/matchbox:v0.10.0 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -address<span class=o>=</span>0.0.0.0:8080 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -rpc-address<span class=o>=</span>0.0.0.0:8081 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -log-level<span class=o>=</span>debug
</span></span></code></pre></div><p><strong>Volume mounts:</strong></p><ul><li><code>/var/lib/matchbox</code> - Data directory (groups, profiles, configs, assets)</li><li><code>/etc/matchbox</code> - TLS certificates (ca.crt, server.crt, server.key)</li></ul><p><strong>Network mode:</strong></p><ul><li><code>--net=host</code> - Required for DHCP/TFTP interaction on same host</li><li>Bridge mode possible if Matchbox is on separate host from dnsmasq</li></ul><p><strong>Pros:</strong></p><ul><li>Immutable deployments</li><li>Easy updates (pull new image)</li><li>Portable across hosts</li></ul><p><strong>Cons:</strong></p><ul><li>Volume management complexity</li><li>SELinux considerations (<code>:Z</code> flag)</li></ul><h3 id=3-kubernetes-deployment>3. Kubernetes Deployment</h3><p><strong>Recommended for:</strong> Kubernetes environments, cloud platforms</p><p><strong>Quick start:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Create TLS secret for gRPC</span>
</span></span><span class=line><span class=cl>kubectl create secret generic matchbox-rpc <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --from-file<span class=o>=</span>ca.crt<span class=o>=</span>~/.matchbox/ca.crt <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --from-file<span class=o>=</span>server.crt<span class=o>=</span>~/.matchbox/server.crt <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --from-file<span class=o>=</span>server.key<span class=o>=</span>~/.matchbox/server.key
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Deploy manifests</span>
</span></span><span class=line><span class=cl>kubectl apply -R -f contrib/k8s/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check status</span>
</span></span><span class=line><span class=cl>kubectl get pods -l <span class=nv>app</span><span class=o>=</span>matchbox
</span></span><span class=line><span class=cl>kubectl get svc matchbox
</span></span><span class=line><span class=cl>kubectl get ingress matchbox matchbox-rpc
</span></span></code></pre></div><p><strong>Persistence options:</strong></p><p><strong>Option 1: emptyDir (ephemeral, dev only):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>data</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>emptyDir</span><span class=p>:</span><span class=w> </span>{}<span class=w>
</span></span></span></code></pre></div><p><strong>Option 2: PersistentVolumeClaim (production):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>data</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class=l>matchbox-data</span><span class=w>
</span></span></span></code></pre></div><p><strong>Option 3: ConfigMap (static configs):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>groups</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>configMap</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>matchbox-groups</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>profiles</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>configMap</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>matchbox-profiles</span><span class=w>
</span></span></span></code></pre></div><p><strong>Option 4: Git-sync sidecar (GitOps):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>initContainers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>git-sync</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>k8s.gcr.io/git-sync:v3.6.3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>env</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>GIT_SYNC_REPO</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=l>https://github.com/example/matchbox-configs</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>GIT_SYNC_DEST</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=l>/var/lib/matchbox</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>data</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/var/lib/matchbox</span><span class=w>
</span></span></span></code></pre></div><p><strong>Pros:</strong></p><ul><li>Native k8s features (scaling, health checks, rolling updates)</li><li>Ingress integration</li><li>GitOps workflows</li></ul><p><strong>Cons:</strong></p><ul><li>Complexity (Ingress, PVC, TLS)</li><li>Can&rsquo;t bootstrap own cluster</li></ul><h2 id=network-boot-environment-setup>Network Boot Environment Setup</h2><p>Matchbox requires separate DHCP/TFTP/DNS services. Options:</p><h3 id=option-1-dnsmasq-container-quickest>Option 1: dnsmasq Container (Quickest)</h3><p><strong>Use case:</strong> Lab, testing, environments without existing DHCP</p><p><strong>Full DHCP + TFTP + DNS:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run -d --name dnsmasq <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --cap-add<span class=o>=</span>NET_ADMIN <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --net<span class=o>=</span>host <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  quay.io/poseidon/dnsmasq:latest <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d -q <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-range<span class=o>=</span>192.168.1.3,192.168.1.254,30m <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --enable-tftp <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --tftp-root<span class=o>=</span>/var/lib/tftpboot <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-match<span class=o>=</span>set:bios,option:client-arch,0 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-boot<span class=o>=</span>tag:bios,undionly.kpxe <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-match<span class=o>=</span>set:efi64,option:client-arch,9 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-boot<span class=o>=</span>tag:efi64,ipxe.efi <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-userclass<span class=o>=</span>set:ipxe,iPXE <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-boot<span class=o>=</span>tag:ipxe,http://matchbox.example.com:8080/boot.ipxe <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --address<span class=o>=</span>/matchbox.example.com/192.168.1.2 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --log-queries <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --log-dhcp
</span></span></code></pre></div><p><strong>Proxy DHCP (alongside existing DHCP):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run -d --name dnsmasq <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --cap-add<span class=o>=</span>NET_ADMIN <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --net<span class=o>=</span>host <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  quay.io/poseidon/dnsmasq:latest <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d -q <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-range<span class=o>=</span>192.168.1.1,proxy,255.255.255.0 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --enable-tftp <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --tftp-root<span class=o>=</span>/var/lib/tftpboot <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-userclass<span class=o>=</span>set:ipxe,iPXE <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --pxe-service<span class=o>=</span>tag:#ipxe,x86PC,<span class=s2>&#34;PXE chainload to iPXE&#34;</span>,undionly.kpxe <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --pxe-service<span class=o>=</span>tag:ipxe,x86PC,<span class=s2>&#34;iPXE&#34;</span>,http://matchbox.example.com:8080/boot.ipxe <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --log-queries <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --log-dhcp
</span></span></code></pre></div><p><strong>Included files:</strong> <code>undionly.kpxe</code>, <code>ipxe.efi</code>, <code>grub.efi</code> (bundled in image)</p><h3 id=option-2-existing-dhcptftp-infrastructure>Option 2: Existing DHCP/TFTP Infrastructure</h3><p><strong>Use case:</strong> Enterprise environments with network admin policies</p><p><strong>Required DHCP options (ISC DHCP example):</strong></p><pre tabindex=0><code>subnet 192.168.1.0 netmask 255.255.255.0 {
  range 192.168.1.10 192.168.1.250;
  
  # BIOS clients
  if option architecture-type = 00:00 {
    filename &#34;undionly.kpxe&#34;;
  }
  # UEFI clients
  elsif option architecture-type = 00:09 {
    filename &#34;ipxe.efi&#34;;
  }
  # iPXE clients
  elsif exists user-class and option user-class = &#34;iPXE&#34; {
    filename &#34;http://matchbox.example.com:8080/boot.ipxe&#34;;
  }
  
  next-server 192.168.1.100;  # TFTP server IP
}
</code></pre><p><strong>TFTP files (place in tftp root):</strong></p><ul><li>Download from <a href=http://boot.ipxe.org/undionly.kpxe>http://boot.ipxe.org/undionly.kpxe</a></li><li>Download from <a href=http://boot.ipxe.org/ipxe.efi>http://boot.ipxe.org/ipxe.efi</a></li></ul><h3 id=option-3-ipxe-only-no-pxe-chainload>Option 3: iPXE-only (No PXE Chainload)</h3><p><strong>Use case:</strong> Modern hardware with native iPXE firmware</p><p><strong>DHCP config (simpler):</strong></p><pre tabindex=0><code>filename &#34;http://matchbox.example.com:8080/boot.ipxe&#34;;
</code></pre><p><strong>No TFTP server needed</strong> (iPXE fetches directly via HTTP)</p><p><strong>Limitation:</strong> Doesn&rsquo;t support legacy BIOS with basic PXE ROM</p><h2 id=tls-certificate-setup>TLS Certificate Setup</h2><p>gRPC API requires TLS client certificates for authentication.</p><h3 id=option-1-provided-cert-gen-script>Option 1: Provided cert-gen Script</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> scripts/tls
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>SAN</span><span class=o>=</span>DNS.1:matchbox.example.com,IP.1:192.168.1.100
</span></span><span class=line><span class=cl>./cert-gen
</span></span></code></pre></div><p><strong>Generates:</strong></p><ul><li><code>ca.crt</code> - Self-signed CA</li><li><code>server.crt</code>, <code>server.key</code> - Server credentials</li><li><code>client.crt</code>, <code>client.key</code> - Client credentials (for Terraform)</li></ul><p><strong>Install server certs:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo mkdir -p /etc/matchbox
</span></span><span class=line><span class=cl>sudo cp ca.crt server.crt server.key /etc/matchbox/
</span></span><span class=line><span class=cl>sudo chown -R matchbox:matchbox /etc/matchbox
</span></span></code></pre></div><p><strong>Save client certs for Terraform:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir -p ~/.matchbox
</span></span><span class=line><span class=cl>cp client.crt client.key ca.crt ~/.matchbox/
</span></span></code></pre></div><h3 id=option-2-corporate-pki>Option 2: Corporate PKI</h3><p><strong>Preferred for production:</strong> Use organization&rsquo;s certificate authority</p><p><strong>Requirements:</strong></p><ul><li>Server cert with SAN: <code>DNS:matchbox.example.com</code></li><li>Client cert issued by same CA</li><li>CA cert for validation</li></ul><p><strong>Matchbox flags:</strong></p><pre tabindex=0><code>-ca-file=/etc/matchbox/ca.crt
-cert-file=/etc/matchbox/server.crt
-key-file=/etc/matchbox/server.key
</code></pre><p><strong>Terraform provider config:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-hcl data-lang=hcl><span class=line><span class=cl><span class=k>provider</span> <span class=s2>&#34;matchbox&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>  endpoint</span>    <span class=o>=</span> <span class=s2>&#34;matchbox.example.com:8081&#34;</span>
</span></span><span class=line><span class=cl><span class=n>  client_cert</span> <span class=o>=</span> <span class=k>file</span><span class=p>(</span><span class=s2>&#34;/path/to/client.crt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>  client_key</span>  <span class=o>=</span> <span class=k>file</span><span class=p>(</span><span class=s2>&#34;/path/to/client.key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>  ca</span>          <span class=o>=</span> <span class=k>file</span><span class=p>(</span><span class=s2>&#34;/path/to/ca.crt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><h3 id=option-3-lets-encrypt-http-api-only>Option 3: Let&rsquo;s Encrypt (HTTP API only)</h3><p><strong>Note:</strong> gRPC requires client cert auth (incompatible with Let&rsquo;s Encrypt)</p><p><strong>Use case:</strong> TLS for HTTP endpoints only (read-only API)</p><p><strong>Matchbox flags:</strong></p><pre tabindex=0><code>-web-ssl=true
-web-cert-file=/etc/letsencrypt/live/matchbox.example.com/fullchain.pem
-web-key-file=/etc/letsencrypt/live/matchbox.example.com/privkey.pem
</code></pre><p><strong>Limitation:</strong> Still need self-signed certs for gRPC API</p><h2 id=configuration-flags>Configuration Flags</h2><h3 id=core-flags>Core Flags</h3><table><thead><tr><th>Flag</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><code>-address</code></td><td><code>127.0.0.1:8080</code></td><td>HTTP API listen address</td></tr><tr><td><code>-rpc-address</code></td><td>``</td><td>gRPC API listen address (empty = disabled)</td></tr><tr><td><code>-data-path</code></td><td><code>/var/lib/matchbox</code></td><td>Data directory (FileStore)</td></tr><tr><td><code>-assets-path</code></td><td><code>/var/lib/matchbox/assets</code></td><td>Static assets directory</td></tr><tr><td><code>-log-level</code></td><td><code>info</code></td><td>Logging level (debug, info, warn, error)</td></tr></tbody></table><h3 id=tls-flags-grpc>TLS Flags (gRPC)</h3><table><thead><tr><th>Flag</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><code>-ca-file</code></td><td><code>/etc/matchbox/ca.crt</code></td><td>CA certificate for client verification</td></tr><tr><td><code>-cert-file</code></td><td><code>/etc/matchbox/server.crt</code></td><td>Server TLS certificate</td></tr><tr><td><code>-key-file</code></td><td><code>/etc/matchbox/server.key</code></td><td>Server TLS private key</td></tr></tbody></table><h3 id=tls-flags-http-optional>TLS Flags (HTTP, optional)</h3><table><thead><tr><th>Flag</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><code>-web-ssl</code></td><td><code>false</code></td><td>Enable TLS for HTTP API</td></tr><tr><td><code>-web-cert-file</code></td><td>``</td><td>HTTP server TLS certificate</td></tr><tr><td><code>-web-key-file</code></td><td>``</td><td>HTTP server TLS private key</td></tr></tbody></table><h3 id=environment-variables>Environment Variables</h3><p>All flags can be set via environment variables with <code>MATCHBOX_</code> prefix:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>MATCHBOX_ADDRESS</span><span class=o>=</span>0.0.0.0:8080
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>MATCHBOX_RPC_ADDRESS</span><span class=o>=</span>0.0.0.0:8081
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>MATCHBOX_LOG_LEVEL</span><span class=o>=</span>debug
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>MATCHBOX_DATA_PATH</span><span class=o>=</span>/custom/path
</span></span></code></pre></div><h2 id=operational-considerations>Operational Considerations</h2><h3 id=firewall-configuration>Firewall Configuration</h3><p><strong>Matchbox host:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>firewall-cmd --permanent --add-port<span class=o>=</span>8080/tcp  <span class=c1># HTTP API</span>
</span></span><span class=line><span class=cl>firewall-cmd --permanent --add-port<span class=o>=</span>8081/tcp  <span class=c1># gRPC API</span>
</span></span><span class=line><span class=cl>firewall-cmd --reload
</span></span></code></pre></div><p><strong>dnsmasq host (if separate):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>firewall-cmd --permanent --add-service<span class=o>=</span>dhcp
</span></span><span class=line><span class=cl>firewall-cmd --permanent --add-service<span class=o>=</span>tftp
</span></span><span class=line><span class=cl>firewall-cmd --permanent --add-service<span class=o>=</span>dns  <span class=c1># optional</span>
</span></span><span class=line><span class=cl>firewall-cmd --reload
</span></span></code></pre></div><h3 id=monitoring>Monitoring</h3><p><strong>Health check endpoints:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># HTTP API</span>
</span></span><span class=line><span class=cl>curl http://matchbox.example.com:8080
</span></span><span class=line><span class=cl><span class=c1># Should return: matchbox</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># gRPC API</span>
</span></span><span class=line><span class=cl>openssl s_client -connect matchbox.example.com:8081 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -CAfile ~/.matchbox/ca.crt <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -cert ~/.matchbox/client.crt <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -key ~/.matchbox/client.key
</span></span></code></pre></div><p><strong>Prometheus metrics:</strong> Not built-in; consider adding reverse proxy (e.g., nginx) with metrics exporter</p><p><strong>Logs (systemd):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>journalctl -u matchbox -f
</span></span></code></pre></div><p><strong>Logs (container):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker logs -f matchbox
</span></span></code></pre></div><h3 id=backup-strategy>Backup Strategy</h3><p><strong>What to backup:</strong></p><ol><li><code>/var/lib/matchbox/{groups,profiles,ignition}</code> - Configs</li><li><code>/etc/matchbox/*.{crt,key}</code> - TLS certificates</li><li>Terraform state (if using Terraform provider)</li></ol><p><strong>Backup command:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tar -czf matchbox-backup-<span class=k>$(</span>date +%F<span class=k>)</span>.tar.gz <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  /var/lib/matchbox/<span class=o>{</span>groups,profiles,ignition<span class=o>}</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  /etc/matchbox
</span></span></code></pre></div><p><strong>Restore:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tar -xzf matchbox-backup-YYYY-MM-DD.tar.gz -C /
</span></span><span class=line><span class=cl>sudo chown -R matchbox:matchbox /var/lib/matchbox
</span></span><span class=line><span class=cl>sudo systemctl restart matchbox
</span></span></code></pre></div><p><strong>GitOps approach:</strong> Store configs in git repository for versioning and auditability</p><h3 id=updates>Updates</h3><p><strong>Binary deployment:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Download new version</span>
</span></span><span class=line><span class=cl>wget https://github.com/poseidon/matchbox/releases/download/vX.Y.Z/matchbox-vX.Y.Z-linux-amd64.tar.gz
</span></span><span class=line><span class=cl>tar xzf matchbox-vX.Y.Z-linux-amd64.tar.gz
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Replace binary</span>
</span></span><span class=line><span class=cl>sudo systemctl stop matchbox
</span></span><span class=line><span class=cl>sudo cp matchbox-vX.Y.Z-linux-amd64/matchbox /usr/local/bin/
</span></span><span class=line><span class=cl>sudo systemctl start matchbox
</span></span></code></pre></div><p><strong>Container deployment:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker pull quay.io/poseidon/matchbox:vX.Y.Z
</span></span><span class=line><span class=cl>docker stop matchbox
</span></span><span class=line><span class=cl>docker rm matchbox
</span></span><span class=line><span class=cl>docker run -d --name matchbox ... quay.io/poseidon/matchbox:vX.Y.Z ...
</span></span></code></pre></div><p><strong>Kubernetes deployment:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl <span class=nb>set</span> image deployment/matchbox <span class=nv>matchbox</span><span class=o>=</span>quay.io/poseidon/matchbox:vX.Y.Z
</span></span><span class=line><span class=cl>kubectl rollout status deployment/matchbox
</span></span></code></pre></div><h3 id=scaling-considerations>Scaling Considerations</h3><p><strong>Vertical scaling (single instance):</strong></p><ul><li>CPU: Minimal (config rendering is lightweight)</li><li>Memory: ~50MB base + asset cache</li><li>Disk: Depends on cached assets (100MB - 10GB+)</li></ul><p><strong>Horizontal scaling (multiple instances):</strong></p><ul><li>Stateless HTTP API (load balance round-robin)</li><li>Shared storage required (RWX PV, NFS, or custom backend)</li><li>gRPC API can be load-balanced with gRPC-aware LB</li></ul><p><strong>Asset serving optimization:</strong></p><ul><li>Use CDN or cache proxy for remote assets</li><li>Local asset caching for &lt;100 machines</li><li>Dedicated HTTP server (nginx) for large deployments (1000+ machines)</li></ul><h3 id=security-best-practices>Security Best Practices</h3><ol><li><p><strong>Don&rsquo;t store secrets in Ignition configs</strong></p><ul><li>Use Ignition <code>files.source</code> with auth headers to fetch from Vault</li><li>Or provision minimal config, fetch secrets post-boot</li></ul></li><li><p><strong>Network segmentation</strong></p><ul><li>Provision VLAN isolated from production</li><li>Firewall rules: only allow provisioning traffic</li></ul></li><li><p><strong>gRPC API access control</strong></p><ul><li>Client cert authentication (mandatory)</li><li>Restrict cert issuance to authorized personnel/systems</li><li>Rotate certs periodically</li></ul></li><li><p><strong>Audit logging</strong></p><ul><li>Version control groups/profiles (git)</li><li>Log gRPC API changes (Terraform state tracking)</li><li>Monitor HTTP endpoint access</li></ul></li><li><p><strong>Validate configs before deployment</strong></p><ul><li><code>fcct --strict</code> for Butane configs</li><li>Terraform plan before apply</li><li>Test in dev environment first</li></ul></li></ol><h2 id=troubleshooting>Troubleshooting</h2><h3 id=common-issues>Common Issues</h3><p><strong>1. Machines not PXE booting:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Check DHCP responses</span>
</span></span><span class=line><span class=cl>tcpdump -i eth0 port <span class=m>67</span> and port <span class=m>68</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Verify TFTP files</span>
</span></span><span class=line><span class=cl>ls -la /var/lib/tftpboot/
</span></span><span class=line><span class=cl>curl tftp://192.168.1.100/undionly.kpxe
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check Matchbox accessibility</span>
</span></span><span class=line><span class=cl>curl http://matchbox.example.com:8080/boot.ipxe
</span></span></code></pre></div><p><strong>2. 404 Not Found on /ignition:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Test group matching</span>
</span></span><span class=line><span class=cl>curl <span class=s1>&#39;http://matchbox.example.com:8080/ignition?mac=52:54:00:89:d8:10&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check group exists</span>
</span></span><span class=line><span class=cl>ls -la /var/lib/matchbox/groups/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check profile referenced by group exists</span>
</span></span><span class=line><span class=cl>ls -la /var/lib/matchbox/profiles/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Verify ignition_id file exists</span>
</span></span><span class=line><span class=cl>ls -la /var/lib/matchbox/ignition/
</span></span></code></pre></div><p><strong>3. gRPC connection refused (Terraform):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Test TLS connection</span>
</span></span><span class=line><span class=cl>openssl s_client -connect matchbox.example.com:8081 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -CAfile ~/.matchbox/ca.crt <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -cert ~/.matchbox/client.crt <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -key ~/.matchbox/client.key
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check Matchbox gRPC is listening</span>
</span></span><span class=line><span class=cl>sudo ss -tlnp <span class=p>|</span> grep <span class=m>8081</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Verify firewall</span>
</span></span><span class=line><span class=cl>sudo firewall-cmd --list-ports
</span></span></code></pre></div><p><strong>4. Ignition config validation errors:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Validate Butane locally</span>
</span></span><span class=line><span class=cl>podman run -i --rm quay.io/coreos/fcct:release --strict &lt; config.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch rendered Ignition</span>
</span></span><span class=line><span class=cl>curl <span class=s1>&#39;http://matchbox.example.com:8080/ignition?mac=...&#39;</span> <span class=p>|</span> jq .
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Validate Ignition spec</span>
</span></span><span class=line><span class=cl>curl <span class=s1>&#39;http://matchbox.example.com:8080/ignition?mac=...&#39;</span> <span class=p>|</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  podman run -i --rm quay.io/coreos/ignition-validate:latest
</span></span></code></pre></div><h2 id=summary>Summary</h2><p>Matchbox deployment considerations:</p><ul><li><strong>Architecture:</strong> Single-host (dev/lab) vs HA (production) vs Kubernetes</li><li><strong>Installation:</strong> Binary (systemd), container (Docker/Podman), or Kubernetes manifests</li><li><strong>Network boot:</strong> dnsmasq container (quick), existing infrastructure (enterprise), or iPXE-only (modern)</li><li><strong>TLS:</strong> Self-signed (dev), corporate PKI (production), Let&rsquo;s Encrypt (HTTP only)</li><li><strong>Scaling:</strong> Vertical (simple) vs horizontal (requires shared storage)</li><li><strong>Security:</strong> Client cert auth, network segmentation, no secrets in configs</li><li><strong>Operations:</strong> Backup configs, GitOps workflow, monitoring/logging</li></ul><p><strong>Recommendation for production:</strong></p><ul><li>HA deployment (2+ instances) with load balancer</li><li>Shared storage (NFS or RWX PV on Kubernetes)</li><li>Corporate PKI for TLS certificates</li><li>GitOps workflow (Terraform + git-controlled configs)</li><li>Network segmentation (dedicated provisioning VLAN)</li><li>Prometheus/Grafana monitoring</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-62ea704f9d07efc4c09282944f58f495>1.6.3 - Network Boot Support</h1><div class=lead>Detailed analysis of Matchbox&rsquo;s network boot capabilities</div><h1 id=network-boot-support-in-matchbox>Network Boot Support in Matchbox</h1><p>Matchbox provides comprehensive network boot support for bare-metal provisioning, supporting multiple boot firmware types and protocols.</p><h2 id=overview>Overview</h2><p>Matchbox serves as an HTTP entrypoint for network-booted machines but <strong>does not implement DHCP, TFTP, or DNS services itself</strong>. Instead, it integrates with existing network infrastructure (or companion services like dnsmasq) to provide a complete PXE boot solution.</p><h2 id=boot-protocol-support>Boot Protocol Support</h2><h3 id=1-pxe-preboot-execution-environment>1. PXE (Preboot Execution Environment)</h3><p><strong>Legacy BIOS support via chainloading to iPXE:</strong></p><pre tabindex=0><code>Machine BIOS â†’ DHCP (gets TFTP server) â†’ TFTP (gets undionly.kpxe) 
â†’ iPXE firmware â†’ HTTP (Matchbox /boot.ipxe)
</code></pre><p><strong>Key characteristics:</strong></p><ul><li>Requires TFTP server to serve <code>undionly.kpxe</code> (iPXE bootloader)</li><li>Chainloads from legacy PXE ROM to modern iPXE</li><li>Supports older hardware with basic PXE firmware</li><li>TFTP only used for initial iPXE bootstrap; subsequent downloads via HTTP</li></ul><h3 id=2-ipxe-enhanced-pxe>2. iPXE (Enhanced PXE)</h3><p><strong>Primary boot method supported by Matchbox:</strong></p><pre tabindex=0><code>iPXE Client â†’ DHCP (gets boot script URL) â†’ HTTP (Matchbox endpoints)
â†’ Kernel/initrd download â†’ Boot with Ignition config
</code></pre><p><strong>Endpoints served by Matchbox:</strong></p><table><thead><tr><th>Endpoint</th><th>Purpose</th></tr></thead><tbody><tr><td><code>/boot.ipxe</code></td><td>Static script that gathers machine attributes (UUID, MAC, hostname, serial)</td></tr><tr><td><code>/ipxe?&lt;labels></code></td><td>Rendered iPXE script with kernel, initrd, and boot args for matched machine</td></tr><tr><td><code>/assets/</code></td><td>Optional local caching of kernel/initrd images</td></tr></tbody></table><p><strong>Example iPXE flow:</strong></p><ol><li>Machine boots with iPXE firmware</li><li>DHCP response points to <code>http://matchbox.example.com:8080/boot.ipxe</code></li><li>iPXE fetches <code>/boot.ipxe</code>:<pre tabindex=0><code>#!ipxe
chain ipxe?uuid=${uuid}&amp;mac=${mac:hexhyp}&amp;domain=${domain}&amp;hostname=${hostname}&amp;serial=${serial}
</code></pre></li><li>iPXE makes request to <code>/ipxe?uuid=...&amp;mac=...</code> with machine attributes</li><li>Matchbox matches machine to group/profile and renders iPXE script:<pre tabindex=0><code>#!ipxe
kernel /assets/coreos/VERSION/coreos_production_pxe.vmlinuz \
  coreos.config.url=http://matchbox.foo:8080/ignition?uuid=${uuid}&amp;mac=${mac:hexhyp} \
  coreos.first_boot=1
initrd /assets/coreos/VERSION/coreos_production_pxe_image.cpio.gz
boot
</code></pre></li></ol><p><strong>Advantages:</strong></p><ul><li>HTTP downloads (faster than TFTP)</li><li>Scriptable boot logic</li><li>Can fetch configs from HTTP endpoints</li><li>Supports HTTPS (if compiled with TLS support)</li></ul><h3 id=3-grub2>3. GRUB2</h3><p><strong>UEFI firmware support:</strong></p><pre tabindex=0><code>UEFI Firmware â†’ DHCP (gets GRUB bootloader) â†’ TFTP (grub.efi)
â†’ GRUB â†’ HTTP (Matchbox /grub endpoint)
</code></pre><p><strong>Matchbox endpoint:</strong> <code>/grub?&lt;labels></code></p><p><strong>Example GRUB config rendered by Matchbox:</strong></p><pre tabindex=0><code>default=0
timeout=1
menuentry &#34;CoreOS&#34; {
  echo &#34;Loading kernel&#34;
  linuxefi &#34;(http;matchbox.foo:8080)/assets/coreos/VERSION/coreos_production_pxe.vmlinuz&#34; \
    &#34;coreos.config.url=http://matchbox.foo:8080/ignition&#34; &#34;coreos.first_boot&#34;
  echo &#34;Loading initrd&#34;
  initrdefi &#34;(http;matchbox.foo:8080)/assets/coreos/VERSION/coreos_production_pxe_image.cpio.gz&#34;
}
</code></pre><p><strong>Use case:</strong></p><ul><li>UEFI systems that prefer GRUB over iPXE</li><li>Environments with existing GRUB network boot infrastructure</li></ul><h3 id=4-pxelinux-legacy-via-tftp>4. PXELINUX (Legacy, via TFTP)</h3><p>While not a primary Matchbox target, PXELINUX clients can be configured to chainload iPXE:</p><pre tabindex=0><code># /var/lib/tftpboot/pxelinux.cfg/default
timeout 10
default iPXE
LABEL iPXE
KERNEL ipxe.lkrn
APPEND dhcp &amp;&amp; chain http://matchbox.example.com:8080/boot.ipxe
</code></pre><h2 id=dhcp-configuration-patterns>DHCP Configuration Patterns</h2><p>Matchbox supports two DHCP deployment models:</p><h3 id=pattern-1-pxe-enabled-dhcp>Pattern 1: PXE-Enabled DHCP</h3><p>Full DHCP server provides IP allocation + PXE boot options.</p><p><strong>Example dnsmasq configuration:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=na>dhcp-range</span><span class=o>=</span><span class=s>192.168.1.1,192.168.1.254,30m</span>
</span></span><span class=line><span class=cl><span class=na>enable-tftp</span>
</span></span><span class=line><span class=cl><span class=na>tftp-root</span><span class=o>=</span><span class=s>/var/lib/tftpboot</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Legacy BIOS â†’ chainload to iPXE</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-match</span><span class=o>=</span><span class=s>set:bios,option:client-arch,0</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-boot</span><span class=o>=</span><span class=s>tag:bios,undionly.kpxe</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># UEFI â†’ iPXE</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-match</span><span class=o>=</span><span class=s>set:efi32,option:client-arch,6</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-boot</span><span class=o>=</span><span class=s>tag:efi32,ipxe.efi</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-match</span><span class=o>=</span><span class=s>set:efi64,option:client-arch,9</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-boot</span><span class=o>=</span><span class=s>tag:efi64,ipxe.efi</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># iPXE clients â†’ Matchbox</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-userclass</span><span class=o>=</span><span class=s>set:ipxe,iPXE</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-boot</span><span class=o>=</span><span class=s>tag:ipxe,http://matchbox.example.com:8080/boot.ipxe</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># DNS for Matchbox</span>
</span></span><span class=line><span class=cl><span class=na>address</span><span class=o>=</span><span class=s>/matchbox.example.com/192.168.1.100</span>
</span></span></code></pre></div><p><strong>Client architecture detection:</strong></p><ul><li>Option 93 (<code>client-arch</code>): Identifies BIOS (0), UEFI32 (6), UEFI64 (9)</li><li>User class: Detects iPXE clients to skip TFTP chainloading</li></ul><h3 id=pattern-2-proxy-dhcp>Pattern 2: Proxy DHCP</h3><p>Runs alongside existing DHCP server; provides only boot options (no IP allocation).</p><p><strong>Example dnsmasq proxy-DHCP:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=na>dhcp-range</span><span class=o>=</span><span class=s>192.168.1.1,proxy,255.255.255.0</span>
</span></span><span class=line><span class=cl><span class=na>enable-tftp</span>
</span></span><span class=line><span class=cl><span class=na>tftp-root</span><span class=o>=</span><span class=s>/var/lib/tftpboot</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Chainload legacy PXE to iPXE</span>
</span></span><span class=line><span class=cl><span class=na>pxe-service</span><span class=o>=</span><span class=s>tag:#ipxe,x86PC,&#34;PXE chainload to iPXE&#34;,undionly.kpxe</span>
</span></span><span class=line><span class=cl><span class=c1># iPXE clients â†’ Matchbox</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-userclass</span><span class=o>=</span><span class=s>set:ipxe,iPXE</span>
</span></span><span class=line><span class=cl><span class=na>pxe-service</span><span class=o>=</span><span class=s>tag:ipxe,x86PC,&#34;iPXE&#34;,http://matchbox.example.com:8080/boot.ipxe</span>
</span></span></code></pre></div><p><strong>Benefits:</strong></p><ul><li>Non-invasive: doesn&rsquo;t replace existing DHCP</li><li>PXE clients receive merged responses from both DHCP servers</li><li>Ideal for environments where main DHCP cannot be modified</li></ul><h2 id=network-boot-flow-complete>Network Boot Flow (Complete)</h2><h3 id=scenario-bios-machine-with-legacy-pxe-firmware>Scenario: BIOS machine with legacy PXE firmware</h3><pre tabindex=0><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Machine powers on, BIOS set to network boot                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. NIC PXE firmware broadcasts DHCPDISCOVER (PXEClient)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. DHCP/proxyDHCP responds with:                                 â”‚
â”‚    - IP address (if full DHCP)                                   â”‚
â”‚    - Next-server: TFTP server IP                                 â”‚
â”‚    - Filename: undionly.kpxe (based on arch=0)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. PXE firmware downloads undionly.kpxe via TFTP                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Execute iPXE (undionly.kpxe)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. iPXE requests DHCP again, identifies as iPXE (user-class)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. DHCP responds with boot URL (not TFTP):                       â”‚
â”‚    http://matchbox.example.com:8080/boot.ipxe                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. iPXE fetches /boot.ipxe via HTTP:                             â”‚
â”‚    #!ipxe                                                        â”‚
â”‚    chain ipxe?uuid=${uuid}&amp;mac=${mac:hexhyp}&amp;...                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. iPXE chains to /ipxe?uuid=XXX&amp;mac=YYY (introspected labels)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. Matchbox matches machine to group/profile                    â”‚
â”‚     - Finds most specific group matching labels                  â”‚
â”‚     - Retrieves profile (kernel, initrd, args, configs)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 11. Matchbox renders iPXE script with:                           â”‚
â”‚     - kernel URL (local asset or remote HTTPS)                   â”‚
â”‚     - initrd URL                                                 â”‚
â”‚     - kernel args (including ignition.config.url)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 12. iPXE downloads kernel + initrd (HTTP/HTTPS)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 13. iPXE boots kernel with specified args                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 14. Fedora CoreOS/Flatcar boots, Ignition runs                   â”‚
â”‚     - Fetches /ignition?uuid=XXX&amp;mac=YYY from Matchbox           â”‚
â”‚     - Matchbox renders Ignition config with group metadata       â”‚
â”‚     - Ignition partitions disk, writes files, creates users      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 15. System reboots (if disk install), boots from disk            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><h2 id=asset-serving>Asset Serving</h2><p>Matchbox can serve static assets (kernel, initrd images) from a local directory to reduce bandwidth and increase speed:</p><p><strong>Asset directory structure:</strong></p><pre tabindex=0><code>/var/lib/matchbox/assets/
â”œâ”€â”€ fedora-coreos/
â”‚   â””â”€â”€ 36.20220906.3.2/
â”‚       â”œâ”€â”€ fedora-coreos-36.20220906.3.2-live-kernel-x86_64
â”‚       â”œâ”€â”€ fedora-coreos-36.20220906.3.2-live-initramfs.x86_64.img
â”‚       â””â”€â”€ fedora-coreos-36.20220906.3.2-live-rootfs.x86_64.img
â””â”€â”€ flatcar/
    â””â”€â”€ 3227.2.0/
        â”œâ”€â”€ flatcar_production_pxe.vmlinuz
        â”œâ”€â”€ flatcar_production_pxe_image.cpio.gz
        â””â”€â”€ version.txt
</code></pre><p><strong>HTTP endpoint:</strong> <code>http://matchbox.example.com:8080/assets/</code></p><p><strong>Scripts provided:</strong></p><ul><li><code>scripts/get-fedora-coreos</code> - Download/verify Fedora CoreOS images</li><li><code>scripts/get-flatcar</code> - Download/verify Flatcar Linux images</li></ul><p><strong>Profile reference:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;boot&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;kernel&#34;</span><span class=p>:</span> <span class=s2>&#34;/assets/fedora-coreos/36.20220906.3.2/fedora-coreos-36.20220906.3.2-live-kernel-x86_64&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;initrd&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;--name main /assets/fedora-coreos/36.20220906.3.2/fedora-coreos-36.20220906.3.2-live-initramfs.x86_64.img&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Alternative:</strong> Profiles can reference remote HTTPS URLs (requires iPXE compiled with TLS support):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;kernel&#34;</span><span class=p>:</span> <span class=s2>&#34;https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/36.20220906.3.2/x86_64/fedora-coreos-36.20220906.3.2-live-kernel-x86_64&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=os-support>OS Support</h2><h3 id=fedora-coreos>Fedora CoreOS</h3><p><strong>Boot types:</strong></p><ol><li><strong>Live PXE</strong> (RAM-only, ephemeral)</li><li><strong>Install to disk</strong> (persistent, recommended)</li></ol><p><strong>Required kernel args:</strong></p><ul><li><code>coreos.inst.install_dev=/dev/sda</code> - Target disk for install</li><li><code>coreos.inst.ignition_url=http://matchbox/ignition?uuid=${uuid}&amp;mac=${mac:hexhyp}</code> - Provisioning config</li><li><code>coreos.live.rootfs_url=...</code> - Root filesystem image</li></ul><p><strong>Ignition fetch:</strong> During first boot, <code>ignition.service</code> fetches config from Matchbox</p><h3 id=flatcar-linux>Flatcar Linux</h3><p><strong>Boot types:</strong></p><ol><li><strong>Live PXE</strong> (RAM-only)</li><li><strong>Install to disk</strong></li></ol><p><strong>Required kernel args:</strong></p><ul><li><code>flatcar.first_boot=yes</code> - Marks first boot</li><li><code>flatcar.config.url=http://matchbox/ignition?uuid=${uuid}&amp;mac=${mac:hexhyp}</code> - Ignition config URL</li><li><code>flatcar.autologin</code> - Auto-login to console (optional, dev/debug)</li></ul><p><strong>Ignition support:</strong> Flatcar uses Ignition v3.x for provisioning</p><h3 id=rhel-coreos>RHEL CoreOS</h3><p>Supported as it uses Ignition like Fedora CoreOS. Requires Red Hat-specific image sources.</p><h2 id=machine-matching--labels>Machine Matching & Labels</h2><p>Matchbox matches machines to profiles using labels extracted during boot:</p><h3 id=reserved-label-selectors>Reserved Label Selectors</h3><table><thead><tr><th>Label</th><th>Source</th><th>Example</th><th>Normalized</th></tr></thead><tbody><tr><td><code>uuid</code></td><td>SMBIOS UUID</td><td><code>550e8400-e29b-41d4-a716-446655440000</code></td><td>Lowercase</td></tr><tr><td><code>mac</code></td><td>NIC MAC address</td><td><code>52:54:00:89:d8:10</code></td><td>Normalized to colons</td></tr><tr><td><code>hostname</code></td><td>Network boot program</td><td><code>node1.example.com</code></td><td>As-is</td></tr><tr><td><code>serial</code></td><td>Hardware serial</td><td><code>VMware-42 1a...</code></td><td>As-is</td></tr></tbody></table><h3 id=custom-labels>Custom Labels</h3><p>Groups can match on arbitrary labels passed as query params:</p><pre tabindex=0><code>/ipxe?mac=52:54:00:89:d8:10&amp;region=us-west&amp;env=prod
</code></pre><p><strong>Matching precedence:</strong> Most specific group wins (most selector matches)</p><h2 id=firmware-compatibility>Firmware Compatibility</h2><table><thead><tr><th>Firmware Type</th><th>Client Arch</th><th>Boot File</th><th>Protocol</th><th>Matchbox Support</th></tr></thead><tbody><tr><td>BIOS (legacy PXE)</td><td>0</td><td><code>undionly.kpxe</code> â†’ iPXE</td><td>TFTP â†’ HTTP</td><td>âœ… Via chainload</td></tr><tr><td>UEFI 32-bit</td><td>6</td><td><code>ipxe.efi</code></td><td>TFTP â†’ HTTP</td><td>âœ…</td></tr><tr><td>UEFI (BIOS compat)</td><td>7</td><td><code>ipxe.efi</code></td><td>TFTP â†’ HTTP</td><td>âœ…</td></tr><tr><td>UEFI 64-bit</td><td>9</td><td><code>ipxe.efi</code></td><td>TFTP â†’ HTTP</td><td>âœ…</td></tr><tr><td>Native iPXE</td><td>-</td><td>N/A</td><td>HTTP</td><td>âœ… Direct</td></tr><tr><td>GRUB (UEFI)</td><td>-</td><td><code>grub.efi</code></td><td>TFTP â†’ HTTP</td><td>âœ… <code>/grub</code> endpoint</td></tr></tbody></table><h2 id=network-requirements>Network Requirements</h2><p><strong>Firewall rules on Matchbox host:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># HTTP API (read-only)</span>
</span></span><span class=line><span class=cl>firewall-cmd --add-port<span class=o>=</span>8080/tcp --permanent
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># gRPC API (authenticated, Terraform)</span>
</span></span><span class=line><span class=cl>firewall-cmd --add-port<span class=o>=</span>8081/tcp --permanent
</span></span></code></pre></div><p><strong>DNS requirement:</strong></p><ul><li><code>matchbox.example.com</code> must resolve to Matchbox server IP</li><li>Can be configured in dnsmasq, corporate DNS, or <code>/etc/hosts</code> on DHCP server</li></ul><p><strong>DHCP/TFTP host (if using dnsmasq):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>firewall-cmd --add-service<span class=o>=</span>dhcp --permanent
</span></span><span class=line><span class=cl>firewall-cmd --add-service<span class=o>=</span>tftp --permanent
</span></span><span class=line><span class=cl>firewall-cmd --add-service<span class=o>=</span>dns --permanent  <span class=c1># optional</span>
</span></span></code></pre></div><h2 id=troubleshooting-tips>Troubleshooting Tips</h2><ol><li><p><strong>Verify Matchbox endpoints:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl http://matchbox.example.com:8080
</span></span><span class=line><span class=cl><span class=c1># Should return: matchbox</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>curl http://matchbox.example.com:8080/boot.ipxe
</span></span><span class=line><span class=cl><span class=c1># Should return iPXE script</span>
</span></span></code></pre></div></li><li><p><strong>Test machine matching:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl <span class=s1>&#39;http://matchbox.example.com:8080/ipxe?mac=52:54:00:89:d8:10&#39;</span>
</span></span><span class=line><span class=cl><span class=c1># Should return rendered iPXE script with kernel/initrd</span>
</span></span></code></pre></div></li><li><p><strong>Check TFTP files:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ls -la /var/lib/tftpboot/
</span></span><span class=line><span class=cl><span class=c1># Should contain: undionly.kpxe, ipxe.efi, grub.efi</span>
</span></span></code></pre></div></li><li><p><strong>Verify DHCP responses:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tcpdump -i eth0 -n port <span class=m>67</span> and port <span class=m>68</span>
</span></span><span class=line><span class=cl><span class=c1># Watch for DHCP offers with PXE options</span>
</span></span></code></pre></div></li><li><p><strong>iPXE console debugging:</strong></p><ul><li>Press Ctrl+B during iPXE boot to enter console</li><li>Commands: <code>dhcp</code>, <code>ifstat</code>, <code>show net0/ip</code>, <code>chain http://...</code></li></ul></li></ol><h2 id=limitations>Limitations</h2><ol><li><strong>HTTPS support:</strong> iPXE must be compiled with crypto support (larger binary, ~80KB vs ~45KB)</li><li><strong>TFTP dependency:</strong> Legacy PXE requires TFTP for initial chainload (can&rsquo;t skip)</li><li><strong>No DHCP/TFTP built-in:</strong> Must use external services or dnsmasq container</li><li><strong>Boot firmware variations:</strong> Some vendor PXE implementations have quirks</li><li><strong>SecureBoot:</strong> iPXE and GRUB must be signed (or SecureBoot disabled)</li></ol><h2 id=reference-implementation-dnsmasq-container>Reference Implementation: dnsmasq Container</h2><p>Matchbox project provides <code>quay.io/poseidon/dnsmasq</code> with:</p><ul><li>Pre-configured DHCP/TFTP/DNS service</li><li>Bundled <code>ipxe.efi</code>, <code>undionly.kpxe</code>, <code>grub.efi</code></li><li>Example configs for PXE-DHCP and proxy-DHCP modes</li></ul><p><strong>Quick start (full DHCP):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run --rm --cap-add<span class=o>=</span>NET_ADMIN --net<span class=o>=</span>host quay.io/poseidon/dnsmasq <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d -q <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-range<span class=o>=</span>192.168.1.3,192.168.1.254 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --enable-tftp --tftp-root<span class=o>=</span>/var/lib/tftpboot <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-match<span class=o>=</span>set:bios,option:client-arch,0 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-boot<span class=o>=</span>tag:bios,undionly.kpxe <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-match<span class=o>=</span>set:efi64,option:client-arch,9 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-boot<span class=o>=</span>tag:efi64,ipxe.efi <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-userclass<span class=o>=</span>set:ipxe,iPXE <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-boot<span class=o>=</span>tag:ipxe,http://matchbox.example.com:8080/boot.ipxe <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --address<span class=o>=</span>/matchbox.example.com/192.168.1.2 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --log-queries --log-dhcp
</span></span></code></pre></div><p><strong>Quick start (proxy-DHCP):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run --rm --cap-add<span class=o>=</span>NET_ADMIN --net<span class=o>=</span>host quay.io/poseidon/dnsmasq <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d -q <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-range<span class=o>=</span>192.168.1.1,proxy,255.255.255.0 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --enable-tftp --tftp-root<span class=o>=</span>/var/lib/tftpboot <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --dhcp-userclass<span class=o>=</span>set:ipxe,iPXE <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --pxe-service<span class=o>=</span>tag:#ipxe,x86PC,<span class=s2>&#34;PXE chainload to iPXE&#34;</span>,undionly.kpxe <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --pxe-service<span class=o>=</span>tag:ipxe,x86PC,<span class=s2>&#34;iPXE&#34;</span>,http://matchbox.example.com:8080/boot.ipxe <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --log-queries --log-dhcp
</span></span></code></pre></div><h2 id=summary>Summary</h2><p>Matchbox provides robust network boot support through:</p><ul><li><strong>Protocol flexibility:</strong> iPXE (primary), GRUB2, legacy PXE (via chainload)</li><li><strong>Firmware compatibility:</strong> BIOS and UEFI</li><li><strong>Modern approach:</strong> HTTP-based with optional local asset caching</li><li><strong>Clean separation:</strong> Matchbox handles config rendering; external services handle DHCP/TFTP</li><li><strong>Production-ready:</strong> Used by Typhoon Kubernetes distributions for bare-metal provisioning</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-177196d5d574619d0c7d1eb930af7a44>1.6.4 - Use Case Evaluation</h1><div class=lead>Evaluation of Matchbox for specific use cases and comparison with alternatives</div><h1 id=matchbox-use-case-evaluation>Matchbox Use Case Evaluation</h1><p>Analysis of Matchbox&rsquo;s suitability for various use cases, strengths, limitations, and comparison with alternative provisioning solutions.</p><h2 id=use-case-fit-analysis>Use Case Fit Analysis</h2><h3 id=-ideal-use-cases>âœ… Ideal Use Cases</h3><h4 id=1-bare-metal-kubernetes-clusters>1. Bare-Metal Kubernetes Clusters</h4><p><strong>Scenario:</strong> Provisioning 10-1000 physical servers for Kubernetes nodes</p><p><strong>Why Matchbox Excels:</strong></p><ul><li>Ignition-native (perfect for Fedora CoreOS/Flatcar)</li><li>Declarative machine provisioning via Terraform</li><li>Label-based matching (region, role, hardware type)</li><li>Integration with Typhoon Kubernetes distribution</li><li>Minimal OS surface (immutable, container-optimized)</li></ul><p><strong>Example workflow:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-hcl data-lang=hcl><span class=line><span class=cl><span class=k>resource</span> <span class=s2>&#34;matchbox_profile&#34; &#34;k8s_controller&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>  name</span>   <span class=o>=</span> <span class=s2>&#34;k8s-controller&#34;</span>
</span></span><span class=line><span class=cl><span class=n>  kernel</span> <span class=o>=</span> <span class=s2>&#34;/assets/fedora-coreos/.../kernel&#34;</span>
</span></span><span class=line><span class=cl><span class=n>  raw_ignition</span> <span class=o>=</span> <span class=k>data</span><span class=p>.</span><span class=k>ct_config</span><span class=p>.</span><span class=k>controller</span><span class=p>.</span><span class=k>rendered</span>
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>resource</span> <span class=s2>&#34;matchbox_group&#34; &#34;controllers&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>  profile</span> <span class=o>=</span> <span class=k>matchbox_profile</span><span class=p>.</span><span class=k>k8s_controller</span><span class=p>.</span><span class=k>name</span>
</span></span><span class=line><span class=cl><span class=n>  selector</span> <span class=o>=</span> {
</span></span><span class=line><span class=cl><span class=n>    role</span> <span class=o>=</span> <span class=s2>&#34;controller&#34;</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><p><strong>Alternatives considered:</strong></p><ul><li><strong>Cloud-init + netboot.xyz</strong>: Less declarative, no native Ignition support</li><li><strong>Foreman</strong>: Heavier, more complex for container-centric workloads</li><li><strong>MetalÂ³</strong>: Kubernetes-native but requires existing cluster</li></ul><p><strong>Verdict:</strong> â­â­â­â­â­ Matchbox is purpose-built for this</p><hr><h4 id=2-labdevelopment-environments>2. Lab/Development Environments</h4><p><strong>Scenario:</strong> Rapid PXE boot testing with QEMU/KVM VMs or homelab servers</p><p><strong>Why Matchbox Excels:</strong></p><ul><li>Quick setup (binary + dnsmasq container)</li><li>No DHCP infrastructure required (proxy-DHCP mode)</li><li>Localhost deployment (no external dependencies)</li><li>Fast iteration (change configs, re-PXE)</li><li>Included examples and scripts</li></ul><p><strong>Example setup:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Start Matchbox locally</span>
</span></span><span class=line><span class=cl>docker run -d --net<span class=o>=</span>host -v /var/lib/matchbox:/var/lib/matchbox <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  quay.io/poseidon/matchbox:latest -address<span class=o>=</span>0.0.0.0:8080
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Start dnsmasq on same host</span>
</span></span><span class=line><span class=cl>docker run -d --net<span class=o>=</span>host --cap-add<span class=o>=</span>NET_ADMIN <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  quay.io/poseidon/dnsmasq ...
</span></span></code></pre></div><p><strong>Alternatives considered:</strong></p><ul><li><strong>netboot.xyz</strong>: Great for manual OS selection, no automation</li><li><strong>PiXE server</strong>: Simpler but less flexible matching logic</li><li><strong>Manual iPXE scripts</strong>: No dynamic matching, manual maintenance</li></ul><p><strong>Verdict:</strong> â­â­â­â­â­ Minimal setup, maximum flexibility</p><hr><h4 id=3-edgeremote-site-provisioning>3. Edge/Remote Site Provisioning</h4><p><strong>Scenario:</strong> Provision machines at 10+ remote datacenters or edge locations</p><p><strong>Why Matchbox Excels:</strong></p><ul><li>Lightweight (single binary, ~20MB)</li><li>Declarative region-based matching</li><li>Centralized config management (Terraform)</li><li>Can run on minimal hardware (ARM support)</li><li>HTTP-based (works over WAN with reverse proxy)</li></ul><p><strong>Architecture:</strong></p><pre tabindex=0><code>Central Matchbox (via Terraform)
  â†“ gRPC API
Regional Matchbox Instances (read-only cache)
  â†“ HTTP
Edge Machines (PXE boot)
</code></pre><p><strong>Label-based routing:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;selector&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;region&#34;</span><span class=p>:</span> <span class=s2>&#34;us-west&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;site&#34;</span><span class=p>:</span> <span class=s2>&#34;pdx-1&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;metadata&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;ntp_servers&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;10.100.1.1&#34;</span><span class=p>,</span> <span class=s2>&#34;10.100.1.2&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Alternatives considered:</strong></p><ul><li><strong>Foreman</strong>: Requires more resources per site</li><li><strong>Ansible + netboot</strong>: No declarative PXE boot, post-install only</li><li><strong>Cloud-init datasources</strong>: Requires cloud metadata service per site</li></ul><p><strong>Verdict:</strong> â­â­â­â­â˜† Good fit, but consider caching strategy for WAN</p><hr><h3 id=-moderate-fit-use-cases>âš ï¸ Moderate Fit Use Cases</h3><h4 id=4-multi-tenant-bare-metal-cloud>4. Multi-Tenant Bare-Metal Cloud</h4><p><strong>Scenario:</strong> Provide bare-metal-as-a-service to multiple customers</p><p><strong>Matchbox challenges:</strong></p><ul><li>No built-in multi-tenancy (single namespace)</li><li>No RBAC (gRPC API is all-or-nothing with client certs)</li><li>No customer self-service portal</li></ul><p><strong>Workarounds:</strong></p><ul><li>Deploy separate Matchbox per tenant (isolation via separate instances)</li><li>Proxy gRPC API with custom RBAC layer</li><li>Use group selectors with customer IDs</li></ul><p><strong>Better alternatives:</strong></p><ul><li><strong>MetalÂ³</strong> (Kubernetes-native, better multi-tenancy)</li><li><strong>OpenStack Ironic</strong> (purpose-built for bare-metal cloud)</li><li><strong>MAAS</strong> (Ubuntu-specific, has RBAC)</li></ul><p><strong>Verdict:</strong> â­â­â˜†â˜†â˜† Possible but architecturally challenging</p><hr><h4 id=5-heterogeneous-os-provisioning>5. Heterogeneous OS Provisioning</h4><p><strong>Scenario:</strong> Need to provision Fedora CoreOS, Ubuntu, RHEL, Windows</p><p><strong>Matchbox challenges:</strong></p><ul><li>Designed for Ignition-based OSes (FCOS, Flatcar, RHCOS)</li><li>No native support for Kickstart (RHEL/CentOS)</li><li>No support for Preseed (Ubuntu/Debian)</li><li>No Windows unattend.xml support</li></ul><p><strong>What works:</strong></p><ul><li>Fedora CoreOS âœ…</li><li>Flatcar Linux âœ…</li><li>RHEL CoreOS âœ…</li><li>Container Linux (deprecated but supported) âœ…</li></ul><p><strong>What requires workarounds:</strong></p><ul><li>RHEL/CentOS: Possible via generic configs + Kickstart URLs, but not native</li><li>Ubuntu: Can PXE boot and point to autoinstall ISO, but loses Matchbox templating benefits</li><li>Debian: Similar to Ubuntu</li><li>Windows: Not supported (different PXE boot mechanisms)</li></ul><p><strong>Better alternatives for heterogeneous environments:</strong></p><ul><li><strong>Foreman</strong> (supports Kickstart, Preseed, unattend.xml)</li><li><strong>MAAS</strong> (Ubuntu-centric but extensible)</li><li><strong>Cobbler</strong> (older but supports many OS types)</li></ul><p><strong>Verdict:</strong> â­â­â˜†â˜†â˜† Stick to Ignition-based OSes or use different tool</p><hr><h3 id=-poor-fit-use-cases>âŒ Poor Fit Use Cases</h3><h4 id=6-windows-pxe-boot>6. Windows PXE Boot</h4><p><strong>Why Matchbox doesn&rsquo;t fit:</strong></p><ul><li>No WinPE support</li><li>No unattend.xml rendering</li><li>Different PXE boot chain (WDS/SCCM model)</li></ul><p><strong>Recommendation:</strong> Use Microsoft WDS or SCCM</p><p><strong>Verdict:</strong> â­â˜†â˜†â˜†â˜† Not designed for this</p><hr><h4 id=7-biosfirmware-updates>7. BIOS/Firmware Updates</h4><p><strong>Why Matchbox doesn&rsquo;t fit:</strong></p><ul><li>Focused on OS provisioning, not firmware</li><li>No vendor-specific tooling (Dell iDRAC, HP iLO integration)</li></ul><p><strong>Recommendation:</strong> Use vendor tools or Ansible with ipmi/redfish modules</p><p><strong>Verdict:</strong> â­â˜†â˜†â˜†â˜† Out of scope</p><hr><h2 id=strengths>Strengths</h2><h3 id=1-ignition-first-design>1. Ignition-First Design</h3><ul><li>Native support for modern immutable OSes</li><li>Declarative, atomic provisioning (no config drift)</li><li>First-boot partition/filesystem setup</li></ul><h3 id=2-label-based-matching>2. Label-Based Matching</h3><ul><li>Flexible machine classification (MAC, UUID, region, role, custom)</li><li>Most-specific-match algorithm (override defaults per machine)</li><li>Query params for dynamic attributes</li></ul><h3 id=3-terraform-integration>3. Terraform Integration</h3><ul><li>Declarative infrastructure as code</li><li>Plan before apply (preview changes)</li><li>State tracking for auditability</li><li>Rich templating (ct_config provider for Butane)</li></ul><h3 id=4-minimal-dependencies>4. Minimal Dependencies</h3><ul><li>Single static binary (~20MB)</li><li>No database required (FileStore default)</li><li>No built-in DHCP/TFTP (separation of concerns)</li><li>Container-ready (OCI image available)</li></ul><h3 id=5-http-centric>5. HTTP-Centric</h3><ul><li>Faster downloads than TFTP (iPXE via HTTP)</li><li>Proxy/CDN friendly for asset distribution</li><li>Standard web tooling (curl, load balancers, Ingress)</li></ul><h3 id=6-production-ready>6. Production-Ready</h3><ul><li>Used by Typhoon Kubernetes (battle-tested)</li><li>Clear upgrade path (SemVer releases)</li><li>OpenPGP signature support for config integrity</li></ul><h2 id=limitations>Limitations</h2><h3 id=1-no-multi-tenancy>1. No Multi-Tenancy</h3><ul><li>Single namespace (all groups/profiles global)</li><li>No RBAC on gRPC API (client cert = full access)</li><li>Requires separate instances per tenant</li></ul><h3 id=2-ignition-only-focus>2. Ignition-Only Focus</h3><ul><li>Cloud-Config deprecated (legacy support only)</li><li>No native Kickstart/Preseed/unattend.xml</li><li>Limits OS choice to CoreOS family</li></ul><h3 id=3-storage-constraints>3. Storage Constraints</h3><ul><li>FileStore doesn&rsquo;t scale to 10,000+ profiles</li><li>No built-in HA storage (requires NFS or custom backend)</li><li>Kubernetes deployment needs RWX PersistentVolume</li></ul><h3 id=4-no-machine-discovery>4. No Machine Discovery</h3><ul><li>Doesn&rsquo;t detect new machines (passive service)</li><li>No inventory management (use external CMDB)</li><li>No hardware introspection (use Ironic for that)</li></ul><h3 id=5-limited-observability>5. Limited Observability</h3><ul><li>No built-in metrics (Prometheus integration requires reverse proxy)</li><li>Logs are minimal (request logging only)</li><li>No audit trail for gRPC API changes (use Terraform state)</li></ul><h3 id=6-tftp-still-required>6. TFTP Still Required</h3><ul><li>Legacy BIOS PXE needs TFTP for chainloading to iPXE</li><li>Can&rsquo;t fully eliminate TFTP unless all machines have native iPXE</li></ul><h2 id=comparison-with-alternatives>Comparison with Alternatives</h2><h3 id=vs-foreman>vs. Foreman</h3><table><thead><tr><th>Feature</th><th>Matchbox</th><th>Foreman</th></tr></thead><tbody><tr><td><strong>OS Support</strong></td><td>Ignition-based</td><td>Kickstart, Preseed, AutoYaST, etc.</td></tr><tr><td><strong>Complexity</strong></td><td>Low (single binary)</td><td>High (Rails app, DB, Puppet/Ansible)</td></tr><tr><td><strong>Config Model</strong></td><td>Declarative (Ignition)</td><td>Imperative (post-install scripts)</td></tr><tr><td><strong>API</strong></td><td>HTTP + gRPC</td><td>REST API</td></tr><tr><td><strong>UI</strong></td><td>None (API-only)</td><td>Full web UI</td></tr><tr><td><strong>Terraform</strong></td><td>Native provider</td><td>Community modules</td></tr><tr><td><strong>Use Case</strong></td><td>Container-centric infra</td><td>Traditional Linux servers</td></tr></tbody></table><p><strong>When to choose Matchbox:</strong> CoreOS-based Kubernetes clusters, minimal infrastructure<br><strong>When to choose Foreman:</strong> Heterogeneous OS, need web UI, traditional config mgmt</p><hr><h3 id=vs-metal>vs. MetalÂ³</h3><table><thead><tr><th>Feature</th><th>Matchbox</th><th>MetalÂ³</th></tr></thead><tbody><tr><td><strong>Platform</strong></td><td>Standalone</td><td>Kubernetes-native (operator)</td></tr><tr><td><strong>Bootstrap</strong></td><td>Can bootstrap k8s cluster</td><td>Needs existing k8s cluster</td></tr><tr><td><strong>Machine Lifecycle</strong></td><td>Provision only</td><td>Provision + decommission + reprovision</td></tr><tr><td><strong>Hardware Introspection</strong></td><td>No (labels passed manually)</td><td>Yes (via Ironic)</td></tr><tr><td><strong>Multi-tenancy</strong></td><td>No</td><td>Yes (via k8s namespaces)</td></tr><tr><td><strong>Complexity</strong></td><td>Low</td><td>High (requires Ironic, DHCP, etc.)</td></tr></tbody></table><p><strong>When to choose Matchbox:</strong> Greenfield bare-metal, no existing k8s<br><strong>When to choose MetalÂ³:</strong> Existing k8s, need hardware mgmt lifecycle</p><hr><h3 id=vs-cobbler>vs. Cobbler</h3><table><thead><tr><th>Feature</th><th>Matchbox</th><th>Cobbler</th></tr></thead><tbody><tr><td><strong>Age</strong></td><td>Modern (2016+)</td><td>Legacy (2008+)</td></tr><tr><td><strong>Config Format</strong></td><td>Ignition (declarative)</td><td>Kickstart/Preseed (imperative)</td></tr><tr><td><strong>Templating</strong></td><td>Go templates (minimal)</td><td>Cheetah templates (extensive)</td></tr><tr><td><strong>Python</strong></td><td>Go (static binary)</td><td>Python (requires interpreter)</td></tr><tr><td><strong>DHCP Management</strong></td><td>External</td><td>Can manage DHCP</td></tr><tr><td><strong>Maintenance</strong></td><td>Active (Poseidon)</td><td>Low activity</td></tr></tbody></table><p><strong>When to choose Matchbox:</strong> Modern immutable OSes, container workloads<br><strong>When to choose Cobbler:</strong> Legacy infra, need DHCP management, heterogeneous OS</p><hr><h3 id=vs-maas-ubuntu>vs. MAAS (Ubuntu)</h3><table><thead><tr><th>Feature</th><th>Matchbox</th><th>MAAS</th></tr></thead><tbody><tr><td><strong>OS Support</strong></td><td>CoreOS family</td><td>Ubuntu (primary), others (limited)</td></tr><tr><td><strong>IPAM</strong></td><td>No (external DHCP)</td><td>Built-in IPAM</td></tr><tr><td><strong>Power Mgmt</strong></td><td>No (manual or scripts)</td><td>Built-in (IPMI, AMT, etc.)</td></tr><tr><td><strong>UI</strong></td><td>No</td><td>Full web UI</td></tr><tr><td><strong>Declarative</strong></td><td>Yes (Terraform)</td><td>Limited (CLI mostly)</td></tr><tr><td><strong>Cloud Integration</strong></td><td>No</td><td>Yes (libvirt, LXD, VM hosts)</td></tr></tbody></table><p><strong>When to choose Matchbox:</strong> Non-Ubuntu, Kubernetes, minimal dependencies<br><strong>When to choose MAAS:</strong> Ubuntu-centric, need power mgmt, cloud integration</p><hr><h3 id=vs-netbootxyz>vs. netboot.xyz</h3><table><thead><tr><th>Feature</th><th>Matchbox</th><th>netboot.xyz</th></tr></thead><tbody><tr><td><strong>Purpose</strong></td><td>Automated provisioning</td><td>Manual OS selection menu</td></tr><tr><td><strong>Automation</strong></td><td>Full (API-driven)</td><td>None (interactive menu)</td></tr><tr><td><strong>Customization</strong></td><td>Per-machine configs</td><td>Global menu</td></tr><tr><td><strong>Ignition</strong></td><td>Native support</td><td>No</td></tr><tr><td><strong>Complexity</strong></td><td>Medium</td><td>Very low</td></tr></tbody></table><p><strong>When to choose Matchbox:</strong> Automated fleet provisioning<br><strong>When to choose netboot.xyz:</strong> Ad-hoc OS installation, homelab</p><hr><h2 id=decision-matrix>Decision Matrix</h2><p>Use this table to evaluate Matchbox for your use case:</p><table><thead><tr><th>Requirement</th><th>Weight</th><th>Matchbox Score</th><th>Notes</th></tr></thead><tbody><tr><td><strong>Ignition/CoreOS support</strong></td><td>High</td><td>â­â­â­â­â­</td><td>Native, first-class</td></tr><tr><td><strong>Heterogeneous OS</strong></td><td>High</td><td>â­â­â˜†â˜†â˜†</td><td>Limited to Ignition OSes</td></tr><tr><td><strong>Declarative provisioning</strong></td><td>Medium</td><td>â­â­â­â­â­</td><td>Terraform native</td></tr><tr><td><strong>Multi-tenancy</strong></td><td>Medium</td><td>â­â˜†â˜†â˜†â˜†</td><td>Requires separate instances</td></tr><tr><td><strong>Web UI</strong></td><td>Medium</td><td>â˜†â˜†â˜†â˜†â˜†</td><td>No UI (API-only)</td></tr><tr><td><strong>Ease of deployment</strong></td><td>Medium</td><td>â­â­â­â­â˜†</td><td>Binary or container, minimal deps</td></tr><tr><td><strong>Scalability</strong></td><td>Medium</td><td>â­â­â­â˜†â˜†</td><td>FileStore limits, need shared storage for HA</td></tr><tr><td><strong>Hardware mgmt</strong></td><td>Low</td><td>â˜†â˜†â˜†â˜†â˜†</td><td>No power mgmt, no introspection</td></tr><tr><td><strong>Cost</strong></td><td>Low</td><td>â­â­â­â­â­</td><td>Open source, Apache 2.0</td></tr></tbody></table><p><strong>Scoring:</strong></p><ul><li>â­â­â­â­â­ Excellent</li><li>â­â­â­â­â˜† Good</li><li>â­â­â­â˜†â˜† Adequate</li><li>â­â­â˜†â˜†â˜† Limited</li><li>â­â˜†â˜†â˜†â˜† Poor</li><li>â˜†â˜†â˜†â˜†â˜† Not supported</li></ul><h2 id=recommendations>Recommendations</h2><h3 id=choose-matchbox-if>Choose Matchbox if:</h3><ol><li>âœ… Provisioning Fedora CoreOS, Flatcar, or RHEL CoreOS</li><li>âœ… Building bare-metal Kubernetes clusters</li><li>âœ… Prefer declarative infrastructure (Terraform)</li><li>âœ… Want minimal dependencies (single binary)</li><li>âœ… Need flexible label-based machine matching</li><li>âœ… Have homogeneous OS requirements (all Ignition-based)</li></ol><h3 id=avoid-matchbox-if>Avoid Matchbox if:</h3><ol><li>âŒ Need multi-OS support (Windows, traditional Linux)</li><li>âŒ Require web UI for operations teams</li><li>âŒ Need built-in hardware management (power, BIOS config)</li><li>âŒ Have strict multi-tenancy requirements</li><li>âŒ Need automated hardware discovery/introspection</li></ol><h3 id=hybrid-approaches>Hybrid Approaches</h3><p><strong>Pattern 1: Matchbox + Ansible</strong></p><ul><li>Matchbox: Initial OS provisioning</li><li>Ansible: Post-boot configuration, app deployment</li><li>Works well for stateful services on bare-metal</li></ul><p><strong>Pattern 2: Matchbox + MetalÂ³</strong></p><ul><li>Matchbox: Bootstrap initial k8s cluster</li><li>MetalÂ³: Ongoing cluster node lifecycle management</li><li>Gradual migration from Matchbox to MetalÂ³</li></ul><p><strong>Pattern 3: Matchbox + Terraform + External Secrets</strong></p><ul><li>Matchbox: Base OS + minimal config</li><li>Ignition: Fetch secrets from Vault/GCP Secret Manager</li><li>Terraform: Orchestrate end-to-end provisioning</li></ul><h2 id=conclusion>Conclusion</h2><p>Matchbox is a <strong>purpose-built, minimalist network boot service</strong> optimized for modern immutable operating systems (Ignition-based). It excels in container-centric bare-metal environments, particularly for Kubernetes clusters built with Fedora CoreOS or Flatcar Linux.</p><p><strong>Best fit:</strong> Organizations adopting immutable infrastructure patterns, container orchestration, and declarative provisioning workflows.</p><p><strong>Not ideal for:</strong> Heterogeneous OS environments, multi-tenant bare-metal clouds, or teams requiring extensive web UI and built-in hardware management.</p><p>For home labs and development, Matchbox offers an excellent balance of simplicity and power. For production Kubernetes deployments, it&rsquo;s a proven, battle-tested solution (via Typhoon). For complex enterprise provisioning with mixed OS requirements, consider Foreman or MAAS instead.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-060cca738381ff58ec9069c277a6de51>1.7 - Ubiquiti Dream Machine Pro Analysis</h1><div class=lead>Comprehensive analysis of the Ubiquiti Dream Machine Pro capabilities, focusing on network boot (PXE) support and infrastructure integration.</div><h2 id=overview>Overview</h2><p>The <strong>Ubiquiti Dream Machine Pro (UDM Pro)</strong> is an all-in-one network gateway, router, and switch designed for enterprise and advanced home lab environments. This analysis focuses on its capabilities relevant to infrastructure automation and network boot scenarios.</p><h2 id=key-specifications>Key Specifications</h2><h3 id=hardware>Hardware</h3><ul><li><strong>Processor</strong>: Quad-core ARM Cortex-A57 @ 1.7 GHz</li><li><strong>RAM</strong>: 4GB DDR4</li><li><strong>Storage</strong>: 128GB eMMC (for UniFi OS, applications, and logs)</li><li><strong>Network Interfaces</strong>:<ul><li>1x WAN port (RJ45, SFP, or SFP+)</li><li>8x LAN ports (1 Gbps RJ45, configurable)</li><li>1x SFP+ port (10 Gbps)</li><li>1x SFP port (1 Gbps)</li></ul></li><li><strong>Additional Features</strong>:<ul><li>3.5" SATA HDD bay (for UniFi Protect surveillance)</li><li>IDS/IPS engine</li><li>Deep packet inspection</li><li>Built-in UniFi Network Controller</li></ul></li></ul><h3 id=software>Software</h3><ul><li><strong>OS</strong>: UniFi OS (Linux-based)</li><li><strong>Controller</strong>: Built-in UniFi Network Controller</li><li><strong>Services</strong>: DHCP, DNS, routing, firewall, VPN (site-to-site and remote access)</li></ul><h2 id=network-boot-pxe-support>Network Boot (PXE) Support</h2><h3 id=native-dhcp-pxe-capabilities>Native DHCP PXE Capabilities</h3><p>The UDM Pro provides <strong>basic PXE boot support</strong> through its DHCP server:</p><p><strong>Supported:</strong></p><ul><li>DHCP Option 66 (<code>next-server</code> / TFTP server address)</li><li>DHCP Option 67 (<code>filename</code> / boot file name)</li><li>Basic single-architecture PXE booting</li></ul><p><strong>Configuration via UniFi Controller:</strong></p><ol><li>Navigate to <strong>Settings</strong> â†’ <strong>Networks</strong> â†’ Select your network</li><li>Scroll to <strong>DHCP</strong> section</li><li>Enable <strong>DHCP</strong></li><li>Under <strong>Advanced DHCP Options</strong>:<ul><li><strong>TFTP Server</strong>: IP address of your TFTP/PXE server (e.g., <code>192.168.42.16</code>)</li><li><strong>Boot Filename</strong>: Name of the bootloader file (e.g., <code>pxelinux.0</code> for BIOS or <code>bootx64.efi</code> for UEFI)</li></ul></li></ol><p><strong>Limitations:</strong></p><ul><li><strong>No multi-architecture support</strong>: Cannot differentiate boot files based on client architecture (BIOS vs. UEFI, x86_64 vs. ARM64)</li><li><strong>No conditional DHCP options</strong>: Cannot vary <code>filename</code> or <code>next-server</code> based on client characteristics</li><li><strong>Fixed boot parameters</strong>: One boot configuration for all PXE clients</li><li><strong>Single bootloader only</strong>: Must choose either BIOS or UEFI bootloader, not both</li></ul><p><strong>Use Cases:</strong></p><ul><li>âœ… Homogeneous environments (all BIOS or all UEFI)</li><li>âœ… Single OS deployment scenarios</li><li>âœ… Simple provisioning workflows</li><li>âŒ Mixed BIOS/UEFI environments (requires external DHCP server with conditional logic)</li></ul><h2 id=network-segmentation--vlans>Network Segmentation & VLANs</h2><p>The UDM Pro excels at network segmentation, critical for infrastructure isolation:</p><ul><li><strong>VLAN Support</strong>: Native 802.1Q tagging</li><li><strong>Firewall Rules</strong>: Inter-VLAN routing with granular firewall policies</li><li><strong>Network Isolation</strong>: Can create fully isolated networks or controlled inter-network traffic</li><li><strong>Use Cases for Infrastructure</strong>:<ul><li>Management VLAN (for PXE/provisioning)</li><li>Production VLAN (workloads)</li><li>IoT/OT VLAN (isolated devices)</li><li>DMZ (exposed services)</li></ul></li></ul><h2 id=vpn-capabilities>VPN Capabilities</h2><h3 id=site-to-site-vpn>Site-to-Site VPN</h3><ul><li><strong>Protocols</strong>: IPsec, WireGuard (experimental)</li><li><strong>Use Case</strong>: Connect home lab to cloud infrastructure (GCP, AWS, Azure)</li><li><strong>Performance</strong>: Hardware-accelerated encryption on UDM Pro</li></ul><h3 id=remote-access-vpn>Remote Access VPN</h3><ul><li><strong>Protocols</strong>: L2TP, OpenVPN</li><li><strong>Use Case</strong>: Remote administration of home lab infrastructure</li><li><strong>Integration</strong>: Can work with Cloudflare Access for additional security layer</li></ul><h2 id=idsips-engine>IDS/IPS Engine</h2><ul><li><strong>Technology</strong>: Suricata-based</li><li><strong>Capabilities</strong>:<ul><li>Intrusion detection</li><li>Intrusion prevention (can drop malicious traffic)</li><li>Threat signatures updated via UniFi</li></ul></li><li><strong>Performance Impact</strong>: Can affect throughput on high-bandwidth connections</li><li><strong>Recommendation</strong>: Enable for security-sensitive infrastructure segments</li></ul><h2 id=dns--dhcp-services>DNS & DHCP Services</h2><h3 id=dns>DNS</h3><ul><li><strong>Local DNS</strong>: Can act as caching DNS resolver</li><li><strong>Custom DNS Records</strong>: Limited to UniFi controller hostname</li><li><strong>Recommendation</strong>: Use external DNS (Pi-hole, Bind9) for advanced features like split-horizon DNS</li></ul><h3 id=dhcp>DHCP</h3><ul><li><strong>Static Leases</strong>: Supports MAC-based static IP assignments</li><li><strong>DHCP Options</strong>: Can configure common options (NTP, DNS, domain name)</li><li><strong>Reservations</strong>: Per-client reservations via GUI</li><li><strong>PXE Options</strong>: Basic Option 66/67 support (as noted above)</li></ul><h2 id=integration-with-infrastructure-as-code>Integration with Infrastructure-as-Code</h2><h3 id=unifi-network-api>UniFi Network API</h3><ul><li><strong>REST API</strong>: Available for configuration automation</li><li><strong>Python Libraries</strong>: <code>pyunifi</code> and others for programmatic access</li><li><strong>Use Cases</strong>:<ul><li>Terraform provider for network state management</li><li>Ansible modules for configuration automation</li><li>CI/CD integration for network-as-code</li></ul></li></ul><h3 id=terraform-provider>Terraform Provider</h3><ul><li><strong>Provider</strong>: <code>paultyng/unifi</code></li><li><strong>Capabilities</strong>: Manage networks, firewall rules, port forwarding, DHCP settings</li><li><strong>Limitations</strong>: Not all UI features exposed via API</li></ul><h3 id=configuration-persistence>Configuration Persistence</h3><ul><li><strong>Backup/Restore</strong>: JSON-based configuration export</li><li><strong>Version Control</strong>: Can track config changes in Git</li><li><strong>Recovery</strong>: Auto-backup to cloud (optional)</li></ul><h2 id=performance-characteristics>Performance Characteristics</h2><h3 id=throughput>Throughput</h3><ul><li><strong>Routing/NAT</strong>: ~3.5 Gbps (without IDS/IPS)</li><li><strong>IDS/IPS Enabled</strong>: ~850 Mbps - 1 Gbps</li><li><strong>VPN (IPsec)</strong>: ~1 Gbps</li><li><strong>Inter-VLAN Routing</strong>: Wire speed (8 Gbps backplane)</li></ul><h3 id=scalability>Scalability</h3><ul><li><strong>Concurrent Devices</strong>: 500+ clients tested</li><li><strong>VLANs</strong>: Up to 32 networks/VLANs</li><li><strong>Firewall Rules</strong>: Thousands (performance depends on complexity)</li><li><strong>DHCP Leases</strong>: Supports large pools efficiently</li></ul><h2 id=comparison-to-alternatives>Comparison to Alternatives</h2><table><thead><tr><th>Feature</th><th>UDM Pro</th><th>pfSense</th><th>OPNsense</th><th>MikroTik</th></tr></thead><tbody><tr><td>Basic PXE</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td></tr><tr><td>Conditional DHCP</td><td>âŒ</td><td>âœ…</td><td>âœ…</td><td>âœ…</td></tr><tr><td>All-in-one</td><td>âœ…</td><td>âŒ</td><td>âŒ</td><td>Varies</td></tr><tr><td>GUI Ease-of-use</td><td>âœ…âœ…</td><td>âš ï¸</td><td>âš ï¸</td><td>âŒ</td></tr><tr><td>API/Automation</td><td>âš ï¸</td><td>âœ…</td><td>âœ…</td><td>âœ…âœ…</td></tr><tr><td>IDS/IPS Built-in</td><td>âœ…</td><td>âš ï¸ (addon)</td><td>âš ï¸ (addon)</td><td>âŒ</td></tr><tr><td>Hardware</td><td>Fixed</td><td>Flexible</td><td>Flexible</td><td>Flexible</td></tr><tr><td>Price</td><td>$$$</td><td>$ (+ hardware)</td><td>$ (+ hardware)</td><td>$ - $$$</td></tr></tbody></table><h2 id=recommendations-for-home-lab-use>Recommendations for Home Lab Use</h2><h3 id=ideal-use-cases>Ideal Use Cases</h3><p>âœ… <strong>Use the UDM Pro when:</strong></p><ul><li>You want an all-in-one solution with minimal configuration</li><li>You need integrated UniFi controller and network management</li><li>Your home lab has mixed UniFi hardware (switches, APs)</li><li>You want a polished GUI and mobile app management</li><li>Network segmentation and VLANs are critical</li></ul><h3 id=consider-alternatives-when>Consider Alternatives When</h3><p>âš ï¸ <strong>Look elsewhere if:</strong></p><ul><li>You need conditional DHCP options or multi-architecture PXE boot</li><li>You require advanced routing protocols (BGP, OSPF beyond basics)</li><li>You need granular firewall control and scripting (pfSense/OPNsense better)</li><li>Budget is tight and you already have x86 hardware (pfSense on old PC)</li><li>You need extremely low latency (sub-1ms) routing</li></ul><h3 id=recommended-configuration-for-infrastructure-lab>Recommended Configuration for Infrastructure Lab</h3><ol><li><p><strong>Network Segmentation</strong>:</p><ul><li><strong>VLAN 10</strong>: Management (PXE, Ansible, provisioning tools)</li><li><strong>VLAN 20</strong>: Kubernetes cluster</li><li><strong>VLAN 30</strong>: Storage network (NFS, iSCSI)</li><li><strong>VLAN 40</strong>: Public-facing services (behind Cloudflare)</li></ul></li><li><p><strong>DHCP Strategy</strong>:</p><ul><li>Use UDM Pro native DHCP with basic PXE options for single-arch PXE needs</li><li>Static reservations for infrastructure components</li><li>Consider external DHCP server if conditional options are required</li></ul></li><li><p><strong>Firewall Rules</strong>:</p><ul><li>Default deny between VLANs</li><li>Allow management VLAN â†’ all (with source IP restrictions)</li><li>Allow cluster VLAN â†’ storage VLAN (on specific ports)</li><li>NAT only on VLAN 40 (public services)</li></ul></li><li><p><strong>VPN Configuration</strong>:</p><ul><li>Site-to-Site to GCP via WireGuard (lower overhead than IPsec)</li><li>Remote access VPN on separate VLAN with restrictive firewall</li></ul></li><li><p><strong>Integration</strong>:</p><ul><li>Terraform for network state management</li><li>Ansible for DHCP/DNS servers in management VLAN</li><li>Cloudflare Access for secure public service exposure</li></ul></li></ol><h2 id=conclusion>Conclusion</h2><p>The UDM Pro is a <strong>capable all-in-one network device</strong> ideal for home labs that prioritize ease-of-use and integration with the UniFi ecosystem. It provides <strong>basic PXE boot support</strong> suitable for single-architecture environments, though conditional DHCP options require external DHCP servers for complex scenarios.</p><p>For infrastructure automation projects, the UDM Pro serves well as a <strong>reliable network foundation</strong> that handles VLANs, routing, and basic services, allowing you to focus on higher-level infrastructure concerns like container orchestration and cloud integration.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a5703edd46d747411f78cc846c637cab>1.7.1 - UDM Pro VLAN Configuration & Capabilities</h1><div class=lead>Detailed analysis of VLAN support on the Ubiquiti Dream Machine Pro, including port-based VLAN assignment and VPN integration.</div><h2 id=overview>Overview</h2><p>The <strong>Ubiquiti Dream Machine Pro (UDM Pro)</strong> provides robust VLAN support through native 802.1Q tagging, enabling network segmentation for security, performance, and organizational purposes. This document covers VLAN configuration capabilities, port assignments, and VPN integration.</p><h2 id=vlan-fundamentals-on-udm-pro>VLAN Fundamentals on UDM Pro</h2><h3 id=supported-standards>Supported Standards</h3><ul><li><strong>802.1Q VLAN Tagging</strong>: Full support for standard VLAN tagging</li><li><strong>VLAN Range</strong>: IDs 1-4094 (standard IEEE 802.1Q range)</li><li><strong>Maximum VLANs</strong>: Up to 32 networks/VLANs per device</li><li><strong>Native VLAN</strong>: Configurable per port (default: VLAN 1)</li></ul><h3 id=vlan-types>VLAN Types</h3><p><strong>Corporate Network</strong></p><ul><li>Default network type for general-purpose VLANs</li><li>Provides DHCP, inter-VLAN routing, and firewall capabilities</li><li>Can enable/disable guest policies, IGMP snooping, and multicast DNS</li></ul><p><strong>Guest Network</strong></p><ul><li>Isolated network with internet-only access</li><li>Automatic firewall rules preventing access to other VLANs</li><li>Captive portal support for guest authentication</li></ul><p><strong>IoT Network</strong></p><ul><li>Optimized for IoT devices with device isolation</li><li>Prevents lateral movement between IoT devices</li><li>Allows communication with controller/gateway only</li></ul><h2 id=port-based-vlan-assignment>Port-Based VLAN Assignment</h2><h3 id=per-port-vlan-configuration>Per-Port VLAN Configuration</h3><p>The UDM Pro&rsquo;s <strong>8x 1 Gbps LAN ports</strong> and <strong>SFP/SFP+ ports</strong> support flexible VLAN assignment:</p><p><strong>Configuration Options per Port:</strong></p><ol><li><strong>Native VLAN/Untagged VLAN</strong>: The default VLAN for untagged traffic on the port</li><li><strong>Tagged VLANs</strong>: Multiple VLANs that can pass through the port with 802.1Q tags</li><li><strong>Port Profile</strong>: Pre-configured VLAN assignments that can be applied to ports</li></ol><h3 id=port-profile-types>Port Profile Types</h3><p><strong>All</strong>: Port accepts all VLANs (trunk mode)</p><ul><li>Passes all configured VLANs with tags</li><li>Used for connecting managed switches or access points</li><li>Native VLAN for untagged traffic</li></ul><p><strong>Specific VLANs</strong>: Port limited to selected VLANs</p><ul><li>Choose which VLANs are allowed (tagged)</li><li>Set native/untagged VLAN</li><li>Used for controlled trunk links</li></ul><p><strong>Single VLAN</strong>: Access port mode</p><ul><li>Port carries only one VLAN (untagged)</li><li>All traffic on this port belongs to specified VLAN</li><li>Used for end devices (PCs, servers, printers)</li></ul><h3 id=configuration-steps>Configuration Steps</h3><p><strong>Via UniFi Controller GUI:</strong></p><ol><li><p><strong>Create Port Profile</strong>:</p><ul><li>Navigate to <strong>Settings</strong> â†’ <strong>Profiles</strong> â†’ <strong>Port Manager</strong></li><li>Click <strong>Create New Port Profile</strong></li><li>Select profile type (All, LAN, or Custom)</li><li>Configure VLAN settings:<ul><li><strong>Native VLAN/Network</strong>: Untagged VLAN</li><li><strong>Tagged VLANs</strong>: Select allowed VLANs (for trunk mode)</li></ul></li><li>Enable/disable settings: PoE, Storm Control, Port Isolation</li></ul></li><li><p><strong>Assign Profile to Ports</strong>:</p><ul><li>Navigate to <strong>UniFi Devices</strong> â†’ Select <strong>UDM Pro</strong></li><li>Go to <strong>Ports</strong> tab</li><li>For each LAN port (1-8) or SFP port:<ul><li>Click port to edit</li><li>Select <strong>Port Profile</strong> from dropdown</li><li>Apply changes</li></ul></li></ul></li><li><p><strong>Quick Port Assignment</strong> (Alternative):</p><ul><li><strong>Settings</strong> â†’ <strong>Networks</strong> â†’ Select VLAN</li><li>Under <strong>Port Manager</strong>, assign specific ports to this network</li><li>Ports become access ports for this VLAN</li></ul></li></ol><h3 id=example-port-layout>Example Port Layout</h3><pre tabindex=0><code>UDM Pro Port Assignment Example:

Port 1: Native VLAN 10 (Management) - Access Mode
        â””â”€â”€ Use: Ansible control server

Port 2: Native VLAN 20 (Kubernetes) - Access Mode
        â””â”€â”€ Use: K8s master node

Port 3: Native VLAN 30 (Storage) - Access Mode
        â””â”€â”€ Use: NAS/SAN device

Port 4: Native VLAN 1, Tagged: 10,20,30,40 - Trunk Mode
        â””â”€â”€ Use: Managed switch uplink

Port 5-7: Native VLAN 40 (DMZ) - Access Mode
          â””â”€â”€ Use: Public-facing servers

Port 8: Native VLAN 1 (Default/Untagged) - Access Mode
        â””â”€â”€ Use: Management laptop (temporary)

SFP+: Native VLAN 1, Tagged: All - Trunk Mode
      â””â”€â”€ Use: 10G uplink to core switch
</code></pre><h2 id=vlan-features-and-capabilities>VLAN Features and Capabilities</h2><h3 id=inter-vlan-routing>Inter-VLAN Routing</h3><p><strong>Enabled by Default:</strong></p><ul><li>Hardware-accelerated routing between VLANs</li><li>Wire-speed performance (8 Gbps backplane)</li><li>Routing decisions made at Layer 3</li></ul><p><strong>Firewall Control:</strong></p><ul><li>Default behavior: Allow all inter-VLAN traffic</li><li>Recommended: Create explicit allow/deny rules per VLAN pair</li><li>Granular control: Protocol, port, source/destination filtering</li></ul><p><strong>Example Firewall Rules:</strong></p><pre tabindex=0><code>Rule 1: Allow Management (VLAN 10) â†’ All VLANs
        Source: 192.168.10.0/24
        Destination: Any
        Action: Accept

Rule 2: Allow K8s (VLAN 20) â†’ Storage (VLAN 30) - NFS only
        Source: 192.168.20.0/24
        Destination: 192.168.30.0/24
        Ports: 2049 (NFS), 111 (Portmapper)
        Action: Accept

Rule 3: Block IoT (VLAN 50) â†’ All Private Networks
        Source: 192.168.50.0/24
        Destination: 192.168.0.0/16, 10.0.0.0/8, 172.16.0.0/12
        Action: Drop

Rule 4 (Implicit): Default Deny Between VLANs
        Source: Any
        Destination: Any
        Action: Drop
</code></pre><h3 id=dhcp-per-vlan>DHCP per VLAN</h3><p><strong>Each VLAN can have its own DHCP server:</strong></p><ul><li>Independent IP ranges per VLAN</li><li>Separate DHCP options (DNS, gateway, NTP, domain)</li><li>Static DHCP reservations per VLAN</li><li>PXE boot options (Option 66/67) per network</li></ul><p><strong>Configuration:</strong></p><ul><li><strong>Settings</strong> â†’ <strong>Networks</strong> â†’ Select VLAN</li><li><strong>DHCP</strong> section:<ul><li>Enable DHCP server</li><li>Define IP range (e.g., 192.168.10.100-192.168.10.254)</li><li>Set lease time</li><li>Configure gateway (usually UDM Pro&rsquo;s IP on this VLAN)</li><li>Add custom DHCP options</li></ul></li></ul><p><strong>Example DHCP Configuration:</strong></p><pre tabindex=0><code>VLAN 10 (Management):
  Subnet: 192.168.10.0/24
  Gateway: 192.168.10.1 (UDM Pro)
  DHCP Range: 192.168.10.100-192.168.10.200
  DNS: 192.168.10.10 (local DNS server)
  TFTP Server (Option 66): 192.168.10.16
  Boot Filename (Option 67): pxelinux.0

VLAN 20 (Kubernetes):
  Subnet: 192.168.20.0/24
  Gateway: 192.168.20.1 (UDM Pro)
  DHCP Range: 192.168.20.50-192.168.20.99
  DNS: 8.8.8.8, 8.8.4.4
  Domain Name: k8s.lab.local
</code></pre><h3 id=vlan-isolation>VLAN Isolation</h3><p><strong>Guest Portal Isolation:</strong></p><ul><li>Guest networks auto-configured with isolation rules</li><li>Prevents access to RFC1918 private networks</li><li>Internet-only access by default</li></ul><p><strong>Manual Isolation (Firewall Rules):</strong></p><ul><li>Create LAN In rules to block inter-VLAN traffic</li><li>Use groups for easier management of multiple VLANs</li><li>Apply port isolation for additional security</li></ul><p><strong>Device Isolation (IoT Networks):</strong></p><ul><li>Prevents devices on same VLAN from communicating</li><li>Only controller/gateway access allowed</li><li>Use for untrusted IoT devices (cameras, smart home)</li></ul><h2 id=vpn-and-vlan-integration>VPN and VLAN Integration</h2><h3 id=site-to-site-vpn-vlan-assignment>Site-to-Site VPN VLAN Assignment</h3><p><strong>âœ… VLANs CAN be assigned to site-to-site VPN connections:</strong></p><p><strong>WireGuard VPN:</strong></p><ul><li>Configure remote subnet to map to specific local VLAN</li><li>Example: GCP subnet 10.128.0.0/20 â†’ routed through VLAN 10</li><li>Routing table automatically updated</li><li>Firewall rules apply to VPN traffic</li></ul><p><strong>IPsec Site-to-Site:</strong></p><ul><li>Specify local networks (can select specific VLANs)</li><li>Remote networks configured in tunnel settings</li><li>Multiple VLANs can traverse single VPN tunnel</li><li>Perfect Forward Secrecy supported</li></ul><p><strong>Configuration Steps:</strong></p><ol><li><strong>Settings</strong> â†’ <strong>VPN</strong> â†’ <strong>Site-to-Site VPN</strong></li><li><strong>Create New</strong> VPN tunnel (WireGuard or IPsec)</li><li>Under <strong>Local Networks</strong>, select VLANs to include:<ul><li>Option 1: Select &ldquo;All&rdquo; networks</li><li>Option 2: Choose specific VLANs (e.g., VLAN 10, 20 only)</li></ul></li><li>Configure <strong>Remote Networks</strong> (cloud provider subnets)</li><li>Set encryption parameters and pre-shared keys</li><li><strong>Create Firewall Rules</strong> for VPN traffic:<ul><li>Allow specific VLAN â†’ VPN tunnel</li><li>Control which VLANs can reach remote networks</li></ul></li></ol><p><strong>Example Site-to-Site Config:</strong></p><pre tabindex=0><code>Home Lab â†’ GCP WireGuard VPN

Local Networks:
  - VLAN 10 (Management): 192.168.10.0/24
  - VLAN 20 (Kubernetes): 192.168.20.0/24

Remote Networks:
  - GCP VPC: 10.128.0.0/20

Firewall Rules:
  - Allow VLAN 10 â†’ GCP VPC (all protocols)
  - Allow VLAN 20 â†’ GCP VPC (HTTPS, kubectl API only)
  - Block all other VLANs from VPN tunnel
</code></pre><h3 id=remote-access-vpn-vlan-assignment>Remote Access VPN VLAN Assignment</h3><p><strong>âœ… VLANs CAN be assigned to remote access VPN clients:</strong></p><p><strong>L2TP/IPsec Remote Access:</strong></p><ul><li>VPN clients land on a specific VLAN</li><li>Default: All clients in same VPN subnet</li><li>Firewall rules control VLAN access from VPN</li></ul><p><strong>OpenVPN Remote Access (via UniFi Network Application addon):</strong></p><ul><li>Not natively built into UDM Pro</li><li>Requires UniFi Network Application 6.0+</li><li>Can route VPN clients to specific VLAN</li></ul><p><strong>Teleport VPN (UniFi&rsquo;s solution):</strong></p><ul><li>Built-in remote access VPN</li><li>Clients route through UDM Pro</li><li>Can access specific VLANs based on firewall rules</li><li>Layer 3 routing to VLANs</li></ul><p><strong>Configuration:</strong></p><ol><li><strong>Settings</strong> â†’ <strong>VPN</strong> â†’ <strong>Remote Access</strong></li><li>Enable <strong>L2TP</strong> or configure <strong>Teleport</strong></li><li>Set <strong>VPN Network</strong> (e.g., 192.168.100.0/24)</li><li><strong>Advanced</strong>:<ul><li>Enable access to specific VLANs</li><li>By default, VPN network is treated as separate VLAN</li></ul></li><li><strong>Firewall Rules</strong> to allow VPN â†’ VLANs:<ul><li>Source: VPN network (192.168.100.0/24)</li><li>Destination: VLAN 10, VLAN 20 (or specific resources)</li><li>Action: Accept</li></ul></li></ol><p><strong>Example Remote Access Config:</strong></p><pre tabindex=0><code>Remote VPN Users â†’ Home Lab Access

VPN Network: 192.168.100.0/24
VPN Gateway: 192.168.100.1 (UDM Pro)

Firewall Rules:
  Rule 1: Allow VPN â†’ Management VLAN (admin users)
          Source: 192.168.100.0/24
          Dest: 192.168.10.0/24
          Ports: SSH (22), HTTPS (443)
  
  Rule 2: Allow VPN â†’ Kubernetes VLAN (developers)
          Source: 192.168.100.0/24
          Dest: 192.168.20.0/24
          Ports: kubectl (6443), app ports (8080-8090)
  
  Rule 3: Block VPN â†’ Storage VLAN (security)
          Source: 192.168.100.0/24
          Dest: 192.168.30.0/24
          Action: Drop
</code></pre><h3 id=vpn-vlan-routing-limitations>VPN VLAN Routing Limitations</h3><p><strong>Current Limitations:</strong></p><ul><li>Cannot assign individual VPN clients to different VLANs dynamically</li><li>No VLAN assignment based on user identity (all clients in same VPN network)</li><li>RADIUS integration does not support per-user VLAN assignment for VPN</li><li>For per-user VLAN control, use firewall rules based on source IP</li></ul><p><strong>Workarounds:</strong></p><ul><li>Use firewall rules with VPN client IP ranges for granular access</li><li>Deploy separate VPN tunnels for different access levels</li><li>Use RADIUS for authentication + firewall rules for authorization</li></ul><h2 id=vlan-best-practices-for-home-lab>VLAN Best Practices for Home Lab</h2><h3 id=network-segmentation-strategy>Network Segmentation Strategy</h3><p><strong>Recommended VLAN Layout:</strong></p><pre tabindex=0><code>VLAN 1:   Default/Management (UDM Pro access)
VLAN 10:  Infrastructure Management (Ansible, PXE, monitoring)
VLAN 20:  Kubernetes Cluster (control plane + workers)
VLAN 30:  Storage Network (NFS, iSCSI, object storage)
VLAN 40:  DMZ/Public Services (exposed to internet via Cloudflare)
VLAN 50:  IoT Devices (isolated smart home devices)
VLAN 60:  Guest Network (visitor WiFi, untrusted devices)
VLAN 100: VPN Remote Access (remote admin/dev access)
</code></pre><h3 id=firewall-policy-design>Firewall Policy Design</h3><p><strong>Default Deny Approach:</strong></p><ol><li>Create explicit allow rules for necessary traffic</li><li>Set implicit deny for all inter-VLAN traffic</li><li>Log dropped packets for troubleshooting</li></ol><p><strong>Rule Order (top to bottom):</strong></p><ol><li>Management VLAN â†’ All (with source IP restrictions)</li><li>Kubernetes â†’ Storage (specific ports)</li><li>DMZ â†’ Internet (outbound only)</li><li>VPN â†’ Specific VLANs (based on role)</li><li>All â†’ Internet (NAT)</li><li>Block RFC1918 from DMZ</li><li>Drop all (implicit)</li></ol><h3 id=performance-optimization>Performance Optimization</h3><p><strong>VLAN Routing Performance:</strong></p><ul><li>Inter-VLAN routing is hardware-accelerated</li><li>No performance penalty for multiple VLANs</li><li>Use VLAN tagging on trunk ports to reduce switch load</li></ul><p><strong>Multicast and Broadcast Control:</strong></p><ul><li>Enable IGMP snooping per VLAN for multicast efficiency</li><li>Disable multicast DNS (mDNS) between VLANs if not needed</li><li>Use multicast routing for cross-VLAN multicast (advanced)</li></ul><h2 id=advanced-vlan-features>Advanced VLAN Features</h2><h3 id=vlan-specific-services>VLAN-Specific Services</h3><p><strong>DNS per VLAN:</strong></p><ul><li>Configure different DNS servers per VLAN via DHCP</li><li>Example: Management VLAN uses local DNS, DMZ uses public DNS</li></ul><p><strong>NTP per VLAN:</strong></p><ul><li>DHCP Option 42 for NTP server</li><li>Different time sources per network segment</li></ul><p><strong>Domain Name per VLAN:</strong></p><ul><li>DHCP Option 15 for domain name</li><li>Useful for split-horizon DNS setups</li></ul><h3 id=vlan-tagging-on-wifi>VLAN Tagging on WiFi</h3><p><strong>UniFi WiFi Integration:</strong></p><ul><li>Each WiFi SSID can map to a specific VLAN</li><li>Multiple SSIDs on same AP â†’ different VLANs</li><li>Seamless VLAN tagging for wireless clients</li></ul><p><strong>Configuration:</strong></p><ul><li>Create WiFi network in UniFi Controller</li><li>Assign VLAN ID to SSID</li><li>Client traffic automatically tagged</li></ul><h3 id=vlan-monitoring-and-troubleshooting>VLAN Monitoring and Troubleshooting</h3><p><strong>Traffic Statistics:</strong></p><ul><li>Per-VLAN bandwidth usage visible in UniFi Controller</li><li>Deep Packet Inspection (DPI) provides application-level stats</li><li>Export data for analysis in external tools</li></ul><p><strong>Debugging Tools:</strong></p><ul><li>Port mirroring for packet capture</li><li>Flow logs for traffic analysis</li><li>Firewall logs show inter-VLAN blocks</li></ul><p><strong>Common Issues:</strong></p><ol><li><strong>VLAN not working</strong>: Check port profile assignment and native VLAN config</li><li><strong>No inter-VLAN routing</strong>: Verify firewall rules aren&rsquo;t blocking traffic</li><li><strong>DHCP not working on VLAN</strong>: Ensure DHCP server enabled on that network</li><li><strong>VPN can&rsquo;t reach VLAN</strong>: Check VPN local networks include the VLAN</li></ol><h2 id=summary>Summary</h2><h3 id=vlan-port-assignment--yes>VLAN Port Assignment: âœ… YES</h3><p>The UDM Pro <strong>fully supports port-based VLAN assignment</strong>:</p><ul><li>Individual ports can be assigned to specific VLANs (access mode)</li><li>Ports can carry multiple tagged VLANs (trunk mode)</li><li>Native/untagged VLAN configurable per port</li><li>Port profiles simplify configuration across multiple devices</li></ul><h3 id=vpn-vlan-assignment--yes>VPN VLAN Assignment: âœ… YES</h3><p>VLANs <strong>can be assigned to VPN connections</strong>:</p><ul><li><strong>Site-to-Site VPN</strong>: Select which VLANs traverse the tunnel</li><li><strong>Remote Access VPN</strong>: VPN clients route to specific VLANs via firewall rules</li><li><strong>Routing Control</strong>: Full control over which VLANs are accessible via VPN</li><li><strong>Limitations</strong>: No per-user VLAN assignment; use firewall rules for granular access</li></ul><h3 id=key-capabilities>Key Capabilities</h3><ul><li>Up to 32 VLANs supported</li><li>Hardware-accelerated inter-VLAN routing</li><li>Per-VLAN DHCP, DNS, and firewall policies</li><li>Full integration with UniFi WiFi for SSID-to-VLAN mapping</li><li>Flexible port profiles for easy configuration</li><li>VPN integration for both site-to-site and remote access scenarios</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-83f5166c05747376993ebd67b3a6de36>2 - Architecture Decision Records</h1><div class=lead>Documentation of architectural decisions made using MADR 4.0.0 standard</div><h2 id=architecture-decision-records-adrs>Architecture Decision Records (ADRs)</h2><p>This section contains architectural decision records that document the key design choices made. Each ADR follows the MADR 4.0.0 format and includes:</p><ul><li>Context and problem statement</li><li>Decision drivers and constraints</li><li>Considered options with pros and cons</li><li>Decision outcome and rationale</li><li>Consequences (positive and negative)</li><li>Confirmation methods</li></ul><h3 id=adr-categories>ADR Categories</h3><p>ADRs are classified into three categories:</p><ul><li><strong>Strategic</strong> - High-level architectural decisions affecting the entire system (frameworks, authentication strategies, cross-cutting patterns). Use for foundational technology choices.</li><li><strong>User Journey</strong> - Decisions solving specific user journey problems. More tactical than strategic, but still architectural. Use when evaluating approaches to implement user-facing features.</li><li><strong>API Design</strong> - API endpoint implementation decisions (pagination, filtering, bulk operations). Use for significant API design trade-offs that warrant documentation.</li></ul><h3 id=status-values>Status Values</h3><p>Each ADR has a status that reflects its current state:</p><ul><li><code>proposed</code> - Decision is under consideration</li><li><code>accepted</code> - Decision has been approved and should be implemented</li><li><code>rejected</code> - Decision was considered but not approved</li><li><code>deprecated</code> - Decision is no longer relevant or has been superseded</li><li><code>superseded by ADR-XXXX</code> - Decision has been replaced by a newer ADR</li></ul><p>These records provide historical context for architectural decisions and help ensure consistency across the platform.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-be14bb13e79709979af80fa8e61452c5>2.1 - [0001] Use MADR for Architecture Decision Records</h1><div class=lead>Adopt Markdown Architectural Decision Records (MADR) as the standard format for documenting architectural decisions in the project.</div><h2 id=context-and-problem-statement>Context and Problem Statement</h2><p>As the project grows, architectural decisions are made that have long-term impacts on the system&rsquo;s design, maintainability, and scalability. Without a structured way to document these decisions, we risk losing the context and rationale behind important choices, making it difficult for current and future team members to understand why certain approaches were taken.</p><p>How should we document architectural decisions in a way that is accessible, maintainable, and provides sufficient context for future reference?</p><h2 id=decision-drivers>Decision Drivers</h2><ul><li>Need for clear documentation of architectural decisions and their rationale</li><li>Easy accessibility and searchability of past decisions</li><li>Low barrier to entry for creating and maintaining decision records</li><li>Integration with existing documentation workflow</li><li>Version control friendly format</li><li>Industry-standard approach that team members may already be familiar with</li></ul><h2 id=considered-options>Considered Options</h2><ul><li>MADR (Markdown Architectural Decision Records)</li><li>ADR using custom format</li><li>Wiki-based documentation</li><li>No formal ADR process</li></ul><h2 id=decision-outcome>Decision Outcome</h2><p>Chosen option: &ldquo;MADR (Markdown Architectural Decision Records)&rdquo;, because it provides a well-established, standardized format that is lightweight, version-controlled, and integrates seamlessly with our existing documentation structure. MADR 4.0.0 offers a clear template that captures all necessary information while remaining flexible enough for different types of decisions.</p><h3 id=consequences>Consequences</h3><ul><li>Good, because MADR is a widely adopted standard with clear documentation and examples</li><li>Good, because markdown files are easy to create, edit, and review through pull requests</li><li>Good, because ADRs will be version-controlled alongside code, maintaining historical context</li><li>Good, because the format is flexible enough to accommodate strategic, user-journey, and API design decisions</li><li>Good, because team members can easily search and reference past decisions</li><li>Neutral, because requires discipline to maintain and update ADR status as decisions evolve</li><li>Bad, because team members need to learn and follow the MADR format conventions</li></ul><h3 id=confirmation>Confirmation</h3><p>Compliance will be confirmed through:</p><ul><li>Code reviews ensuring new architectural decisions are documented as ADRs</li><li>ADRs are stored in <code>docs/content/r&amp;d/adrs/</code> following the naming convention <code>NNNN-title-with-dashes.md</code></li><li>Regular reviews during architecture discussions to reference and update existing ADRs</li></ul><h2 id=pros-and-cons-of-the-options>Pros and Cons of the Options</h2><h3 id=madr-markdown-architectural-decision-records>MADR (Markdown Architectural Decision Records)</h3><p>MADR 4.0.0 is a standardized format for documenting architectural decisions using markdown.</p><ul><li>Good, because it&rsquo;s a well-established standard with extensive documentation</li><li>Good, because markdown is simple, portable, and version-control friendly</li><li>Good, because it provides a clear structure while remaining flexible</li><li>Good, because it integrates with static site generators and documentation tools</li><li>Good, because it&rsquo;s lightweight and doesn&rsquo;t require special tools</li><li>Neutral, because it requires some initial learning of the format</li><li>Neutral, because maintaining consistency requires discipline</li></ul><h3 id=adr-using-custom-format>ADR using custom format</h3><p>Create our own custom format for architectural decision records.</p><ul><li>Good, because we can tailor it exactly to our needs</li><li>Bad, because it requires defining and maintaining our own standard</li><li>Bad, because new team members won&rsquo;t be familiar with the format</li><li>Bad, because we lose the benefits of community knowledge and tooling</li><li>Bad, because it may evolve inconsistently over time</li></ul><h3 id=wiki-based-documentation>Wiki-based documentation</h3><p>Use a wiki system (like Confluence, Notion, or GitHub Wiki) to document decisions.</p><ul><li>Good, because wikis provide easy editing and hyperlinking</li><li>Good, because some team members may be familiar with wiki tools</li><li>Neutral, because it may or may not integrate with version control</li><li>Bad, because content may not be version-controlled alongside code</li><li>Bad, because it creates a separate system to maintain</li><li>Bad, because it&rsquo;s harder to review changes through standard PR process</li><li>Bad, because portability and long-term accessibility may be concerns</li></ul><h3 id=no-formal-adr-process>No formal ADR process</h3><p>Continue without a structured approach to documenting architectural decisions.</p><ul><li>Good, because it requires no additional overhead</li><li>Bad, because context and rationale for decisions are lost over time</li><li>Bad, because new team members struggle to understand why decisions were made</li><li>Bad, because it leads to repeated discussions of previously settled questions</li><li>Bad, because it makes it difficult to track when decisions should be revisited</li></ul><h2 id=more-information>More Information</h2><ul><li>MADR 4.0.0 specification: <a href=https://adr.github.io/madr/>https://adr.github.io/madr/</a></li><li>ADRs will be categorized as: strategic, user-journey, or api-design</li><li>ADR status values: proposed | accepted | rejected | deprecated | superseded by ADR-XXXX</li><li>All ADRs are stored in <code>docs/content/r&amp;d/adrs/</code> directory</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-79e3b41ba15ba3a179ad4b5df5f3f2fe>2.2 - [0002] Network Boot Architecture for Home Lab</h1><div class=lead>Evaluate options for network booting servers in a home lab environment, considering local vs cloud-hosted boot servers.</div><h2 id=context-and-problem-statement>Context and Problem Statement</h2><p>When setting up a home lab infrastructure, servers need to be provisioned and booted over the network using PXE (Preboot Execution Environment). This requires a TFTP/HTTP server to serve boot files to requesting machines. The question is: where should this boot server be hosted to balance security, reliability, cost, and operational complexity?</p><h2 id=decision-drivers>Decision Drivers</h2><ul><li><strong>Security</strong>: Minimize attack surface and ensure only authorized servers receive boot files</li><li><strong>Reliability</strong>: Boot process should be resilient and not dependent on external network connectivity</li><li><strong>Cost</strong>: Minimize ongoing infrastructure costs</li><li><strong>Complexity</strong>: Keep the operational burden manageable</li><li><strong>Trust Model</strong>: Clear verification of requesting server identity</li></ul><h2 id=considered-options>Considered Options</h2><ul><li>Option 1: TFTP/HTTP server locally on home lab network</li><li>Option 2: TFTP/HTTP server on public cloud (without VPN)</li><li>Option 3: TFTP/HTTP server on public cloud (with VPN)</li></ul><h2 id=decision-outcome>Decision Outcome</h2><p>Chosen option: &ldquo;Option 3: TFTP/HTTP server on public cloud (with VPN)&rdquo;, because:</p><ol><li><strong>No local machine management</strong>: Unlike Option 1, this avoids the need to maintain dedicated local hardware for the boot server, reducing operational overhead</li><li><strong>Secure protocol support</strong>: The VPN tunnel encrypts all traffic, allowing unsecured protocols like TFTP to be used without risk of data exposure over public internet routes (unlike Option 2)</li><li><strong>Cost-effective VPN</strong>: The UDM Pro natively supports WireGuard, enabling a self-managed VPN solution that avoids expensive managed VPN services (~$180-300/year vs ~$540-900/year)</li></ol><h3 id=consequences>Consequences</h3><ul><li>Good, because all traffic is encrypted through WireGuard VPN tunnel</li><li>Good, because boot server is not exposed to public internet (no public attack surface)</li><li>Good, because trust model is simple - subnet validation similar to local option</li><li>Good, because centralized cloud management reduces local maintenance burden</li><li>Good, because boot server remains available even if home lab storage fails</li><li>Good, because UDM Pro&rsquo;s native WireGuard support keeps costs at ~$180-300/year</li><li>Bad, because boot process depends on both internet connectivity and VPN availability</li><li>Bad, because VPN adds latency to boot file transfers</li><li>Bad, because VPN gateway becomes an additional failure point</li><li>Bad, because higher ongoing cost compared to local-only option (~$180-300/year vs ~$10/year)</li></ul><h3 id=confirmation>Confirmation</h3><p>The implementation will be confirmed by:</p><ul><li>Successfully network booting a test server using the chosen architecture</li><li>Validating the trust model prevents unauthorized boot requests</li><li>Measuring actual costs against estimates</li></ul><h2 id=pros-and-cons-of-the-options>Pros and Cons of the Options</h2><h3 id=option-1-tftphttp-server-locally-on-home-lab-network>Option 1: TFTP/HTTP server locally on home lab network</h3><p>Run the boot server on local infrastructure (e.g., Raspberry Pi, dedicated VM, or container) within the home lab network.</p><h4 id=boot-flow-sequence>Boot Flow Sequence</h4><pre class=mermaid>sequenceDiagram
    participant Server as Home Lab Server
    participant DHCP as Local DHCP Server
    participant Boot as Local TFTP/HTTP Server

    Server-&gt;&gt;DHCP: PXE Boot Request (DHCP Discover)
    DHCP-&gt;&gt;Server: DHCP Offer with Boot Server IP
    Server-&gt;&gt;Boot: TFTP Request for Boot File
    Boot-&gt;&gt;Boot: Verify MAC/IP against allowlist
    Boot-&gt;&gt;Server: Send iPXE/Boot Loader
    Server-&gt;&gt;Boot: HTTP Request for Kernel/Initrd
    Boot-&gt;&gt;Server: Send Boot Files
    Server-&gt;&gt;Server: Boot into OS</pre><h4 id=trust-model>Trust Model</h4><ul><li><strong>MAC Address Allowlist</strong>: Maintain a list of known server MAC addresses</li><li><strong>Network Isolation</strong>: Boot server only accessible from home lab VLAN</li><li><strong>No external exposure</strong>: Traffic never leaves local network</li><li><strong>Physical security</strong>: Relies on physical access control to home lab</li></ul><h4 id=cost-estimate>Cost Estimate</h4><ul><li><strong>Hardware</strong>: ~$50-100 one-time (Raspberry Pi or repurposed hardware)</li><li><strong>Power</strong>: ~$5-10/year (low power consumption)</li><li><strong>Total</strong>: ~$55-110 initial + ~$10/year ongoing</li></ul><h4 id=pros-and-cons>Pros and Cons</h4><ul><li>Good, because no dependency on internet connectivity for booting</li><li>Good, because lowest latency for boot file transfers</li><li>Good, because all data stays within local network (maximum privacy)</li><li>Good, because lowest ongoing cost</li><li>Good, because simple trust model based on network isolation</li><li>Neutral, because requires dedicated local hardware or resources</li><li>Bad, because single point of failure if boot server goes down</li><li>Bad, because requires local maintenance and updates</li></ul><h3 id=option-2-tftphttp-server-on-public-cloud-without-vpn>Option 2: TFTP/HTTP server on public cloud (without VPN)</h3><p>Host the boot server on a cloud provider (AWS, GCP, Azure) and expose it directly to the internet.</p><h4 id=boot-flow-sequence-1>Boot Flow Sequence</h4><pre class=mermaid>sequenceDiagram
    participant Server as Home Lab Server
    participant DHCP as Local DHCP Server
    participant Router as Home Router/NAT
    participant Internet as Internet
    participant Boot as Cloud TFTP/HTTP Server

    Server-&gt;&gt;DHCP: PXE Boot Request (DHCP Discover)
    DHCP-&gt;&gt;Server: DHCP Offer with Cloud Boot Server IP
    Server-&gt;&gt;Router: TFTP Request
    Router-&gt;&gt;Internet: NAT Translation
    Internet-&gt;&gt;Boot: TFTP Request from Home IP
    Boot-&gt;&gt;Boot: Verify source IP &#43; token/certificate
    Boot-&gt;&gt;Internet: Send iPXE/Boot Loader
    Internet-&gt;&gt;Router: Response
    Router-&gt;&gt;Server: Boot Loader
    Server-&gt;&gt;Router: HTTP Request for Kernel/Initrd
    Router-&gt;&gt;Internet: NAT Translation
    Internet-&gt;&gt;Boot: HTTP Request with auth headers
    Boot-&gt;&gt;Boot: Validate request authenticity
    Boot-&gt;&gt;Internet: Send Boot Files
    Internet-&gt;&gt;Router: Response
    Router-&gt;&gt;Server: Boot Files
    Server-&gt;&gt;Server: Boot into OS</pre><h4 id=trust-model-1>Trust Model</h4><ul><li><strong>Source IP Validation</strong>: Restrict to home lab&rsquo;s public IP (dynamic IP is problematic)</li><li><strong>Certificate/Token Authentication</strong>: Embed certificates in initial bootloader</li><li><strong>TLS for HTTP</strong>: All HTTP traffic encrypted</li><li><strong>Challenge-Response</strong>: Boot server can challenge requesting server</li><li><strong>Risk</strong>: TFTP typically unencrypted, vulnerable to interception</li></ul><h4 id=cost-estimate-1>Cost Estimate</h4><ul><li><strong>Cloud VM (t3.micro or equivalent)</strong>: ~$10-15/month</li><li><strong>Data Transfer</strong>: ~$1-5/month (boot files are typically small)</li><li><strong>Static IP</strong>: ~$3-5/month</li><li><strong>Total</strong>: ~$170-300/year</li></ul><h4 id=pros-and-cons-1>Pros and Cons</h4><ul><li>Good, because boot server remains available even if home lab has issues</li><li>Good, because centralized management in cloud console</li><li>Good, because easy to scale or replicate</li><li>Neutral, because requires internet connectivity for every boot</li><li>Bad, because significantly higher ongoing cost</li><li>Bad, because TFTP protocol is inherently insecure over public internet</li><li>Bad, because complex trust model required (IP validation, certificates)</li><li>Bad, because boot process depends on internet availability</li><li>Bad, because higher latency for boot file transfers</li><li>Bad, because public exposure increases attack surface</li></ul><h3 id=option-3-tftphttp-server-on-public-cloud-with-vpn>Option 3: TFTP/HTTP server on public cloud (with VPN)</h3><p>Host the boot server in the cloud but connect the home lab to the cloud via a site-to-site VPN tunnel.</p><h4 id=boot-flow-sequence-2>Boot Flow Sequence</h4><pre class=mermaid>sequenceDiagram
    participant Server as Home Lab Server
    participant DHCP as Local DHCP Server
    participant VPN as VPN Gateway (Home)
    participant CloudVPN as VPN Gateway (Cloud)
    participant Boot as Cloud TFTP/HTTP Server

    Note over VPN,CloudVPN: Site-to-Site VPN Tunnel Established

    Server-&gt;&gt;DHCP: PXE Boot Request (DHCP Discover)
    DHCP-&gt;&gt;Server: DHCP Offer with Boot Server Private IP
    Server-&gt;&gt;VPN: TFTP Request to Private IP
    VPN-&gt;&gt;CloudVPN: Encrypted VPN Tunnel
    CloudVPN-&gt;&gt;Boot: TFTP Request (appears local)
    Boot-&gt;&gt;Boot: Verify source IP from home lab subnet
    Boot-&gt;&gt;CloudVPN: Send iPXE/Boot Loader
    CloudVPN-&gt;&gt;VPN: Encrypted Response
    VPN-&gt;&gt;Server: Boot Loader
    Server-&gt;&gt;VPN: HTTP Request for Kernel/Initrd
    VPN-&gt;&gt;CloudVPN: Encrypted VPN Tunnel
    CloudVPN-&gt;&gt;Boot: HTTP Request
    Boot-&gt;&gt;Boot: Validate subnet membership
    Boot-&gt;&gt;CloudVPN: Send Boot Files
    CloudVPN-&gt;&gt;VPN: Encrypted Response
    VPN-&gt;&gt;Server: Boot Files
    Server-&gt;&gt;Server: Boot into OS</pre><h4 id=trust-model-2>Trust Model</h4><ul><li><strong>VPN Tunnel Encryption</strong>: All traffic encrypted end-to-end</li><li><strong>Private IP Addressing</strong>: Boot server only accessible via VPN</li><li><strong>Subnet Validation</strong>: Verify requests come from trusted home lab subnet</li><li><strong>VPN Authentication</strong>: Strong auth at tunnel level (certificates, pre-shared keys)</li><li><strong>No public exposure</strong>: Boot server has no public IP</li></ul><h4 id=cost-estimate-2>Cost Estimate</h4><ul><li><strong>Cloud VM (t3.micro or equivalent)</strong>: ~$10-15/month</li><li><strong>Data Transfer (VPN)</strong>: ~$5-10/month</li><li><strong>VPN Gateway Service (if using managed)</strong>: ~$30-50/month OR</li><li><strong>Self-managed VPN (WireGuard/OpenVPN)</strong>: ~$0 additional</li><li><strong>Total (self-managed VPN)</strong>: ~$180-300/year</li><li><strong>Total (managed VPN)</strong>: ~$540-900/year</li></ul><h4 id=pros-and-cons-2>Pros and Cons</h4><ul><li>Good, because all traffic encrypted through VPN tunnel</li><li>Good, because boot server not exposed to public internet</li><li>Good, because trust model similar to local option (subnet validation)</li><li>Good, because centralized cloud management benefits</li><li>Good, because boot server available if home lab storage fails</li><li>Neutral, because moderate complexity (VPN setup and maintenance)</li><li>Bad, because higher cost than local option</li><li>Bad, because boot process still depends on internet + VPN availability</li><li>Bad, because VPN adds latency to boot process</li><li>Bad, because VPN gateway becomes additional failure point</li><li>Bad, because most expensive option if using managed VPN service</li></ul><h2 id=more-information>More Information</h2><h3 id=related-resources>Related Resources</h3><ul><li><a href=https://en.wikipedia.org/wiki/Preboot_Execution_Environment>PXE Boot Specification</a></li><li><a href=https://ipxe.org/>iPXE - Open Source Boot Firmware</a></li><li><a href=https://tools.ietf.org/html/rfc1350>TFTP Protocol (RFC 1350)</a></li></ul><h3 id=key-questions-for-decision>Key Questions for Decision</h3><ol><li>How critical is boot availability during internet outages?</li><li>Is the home lab public IP static or dynamic?</li><li>What is the acceptable boot time latency?</li><li>How many servers need to be supported?</li><li>Is there existing VPN infrastructure?</li></ol><h3 id=related-issues>Related Issues</h3><ul><li><a href=https://github.com/Zaba505/infra/issues/595>Issue #595</a> - story(docs): create adr for network boot architecture</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-853f5ec590d44937c1ebd528cd046965>2.3 - [0003] Cloud Provider Selection for Network Boot Infrastructure</h1><div class=lead>Evaluate Google Cloud Platform vs Amazon Web Services for hosting network boot server infrastructure as required by ADR-0002.</div><h2 id=context-and-problem-statement>Context and Problem Statement</h2><p><a href=./0002-network-boot-architecture/>ADR-0002</a> established that network boot infrastructure will be hosted on a cloud provider and accessed via VPN (specifically WireGuard from the UDM Pro). The decision to use cloud hosting provides resilience against local hardware failures while maintaining security through encrypted VPN tunnels.</p><p>The question now is: <strong>Which cloud provider should host the network boot infrastructure?</strong></p><p>This decision will affect:</p><ul><li><strong>Cost</strong>: Ongoing monthly/annual infrastructure costs</li><li><strong>Protocol Support</strong>: Ability to serve TFTP, HTTP, and HTTPS boot files</li><li><strong>VPN Integration</strong>: Ease of WireGuard deployment and management</li><li><strong>Operational Complexity</strong>: Management overhead and maintenance burden</li><li><strong>Performance</strong>: Boot file transfer latency and throughput</li><li><strong>Vendor Lock-in</strong>: Future flexibility to migrate or multi-cloud</li></ul><h2 id=decision-drivers>Decision Drivers</h2><ul><li><strong>Cost Efficiency</strong>: Minimize ongoing infrastructure costs for home lab scale</li><li><strong>Protocol Support</strong>: Must support TFTP (UDP/69), HTTP (TCP/80), and HTTPS (TCP/443) for network boot workflows</li><li><strong>WireGuard Compatibility</strong>: Must support self-managed WireGuard VPN with reasonable effort</li><li><strong>UDM Pro Integration</strong>: Should work seamlessly with UniFi Dream Machine Pro&rsquo;s native WireGuard client</li><li><strong>Simplicity</strong>: Minimize operational complexity for a single-person home lab</li><li><strong>Existing Expertise</strong>: Leverage existing team knowledge and infrastructure</li><li><strong>Performance</strong>: Sufficient throughput and low latency for boot file transfers (50-200MB per boot)</li></ul><h2 id=considered-options>Considered Options</h2><ul><li><strong>Option 1</strong>: Google Cloud Platform (GCP)</li><li><strong>Option 2</strong>: Amazon Web Services (AWS)</li></ul><h2 id=decision-outcome>Decision Outcome</h2><p>Chosen option: &ldquo;<strong>Option 1: Google Cloud Platform (GCP)</strong>&rdquo;, because:</p><ol><li><strong>Existing Infrastructure</strong>: The home lab already uses GCP extensively (Cloud Run services, load balancers, mTLS infrastructure per existing codebase), reducing operational overhead and leveraging existing expertise</li><li><strong>Comparable Costs</strong>: Both providers offer similar costs for the required infrastructure (~$6-12/month for compute + VPN), with GCP&rsquo;s e2-micro being sufficient</li><li><strong>Equivalent Protocol Support</strong>: Both support TFTP/HTTP/HTTPS via direct VM access (load balancers unnecessary for single boot server), meeting all protocol requirements</li><li><strong>WireGuard Compatibility</strong>: Both require self-managed WireGuard deployment (neither has native WireGuard support), with nearly identical implementation complexity</li><li><strong>Unified Management</strong>: Consolidating all cloud infrastructure on GCP simplifies monitoring, billing, IAM, and operational workflows</li></ol><p>While AWS would be a viable alternative (especially with t4g.micro ARM instances offering slightly better price/performance), the <strong>existing GCP investment</strong> makes it the pragmatic choice to avoid multi-cloud complexity.</p><h3 id=consequences>Consequences</h3><ul><li>Good, because consolidates all cloud infrastructure on a single provider (reduced operational complexity)</li><li>Good, because leverages existing GCP expertise and IAM configurations</li><li>Good, because unified Cloud Monitoring/Logging across all services</li><li>Good, because single cloud bill simplifies cost tracking</li><li>Good, because existing Terraform modules and patterns can be reused</li><li>Good, because GCP&rsquo;s e2-micro instances (~$6.50/month) are cost-effective for the workload</li><li>Good, because self-managed WireGuard provides flexibility and low cost (~$10/month total)</li><li>Neutral, because both providers have comparable protocol support (TFTP/HTTP/HTTPS via VM)</li><li>Neutral, because both require self-managed WireGuard (no native support)</li><li>Bad, because creates vendor lock-in to GCP (migration would require relearning and reconfiguration)</li><li>Bad, because foregoes AWS&rsquo;s slightly cheaper t4g.micro ARM instances (~$6/month vs GCP&rsquo;s ~$6.50/month)</li><li>Bad, because multi-cloud strategy could provide redundancy (accepted trade-off for simplicity)</li></ul><h3 id=confirmation>Confirmation</h3><p>The implementation will be confirmed by:</p><ul><li>Successfully deploying WireGuard VPN gateway on GCP Compute Engine</li><li>Establishing site-to-site VPN tunnel between UDM Pro and GCP</li><li>Network booting a test server via VPN using TFTP and HTTP protocols</li><li>Measuring actual costs against estimates (~$10-15/month)</li><li>Validating boot performance (transfer time &lt; 30 seconds for typical boot)</li></ul><h2 id=pros-and-cons-of-the-options>Pros and Cons of the Options</h2><h3 id=option-1-google-cloud-platform-gcp>Option 1: Google Cloud Platform (GCP)</h3><p>Host network boot infrastructure on Google Cloud Platform.</p><h4 id=architecture-overview>Architecture Overview</h4><pre class=mermaid>graph TB
    subgraph &#34;Home Lab Network&#34;
        A[Home Lab Servers]
        B[UDM Pro - WireGuard Client]
    end
    
    subgraph &#34;GCP VPC&#34;
        C[WireGuard Gateway VM&lt;br/&gt;e2-micro]
        D[Boot Server VM&lt;br/&gt;e2-micro]
        C --&gt;|VPC Routing| D
    end
    
    A --&gt;|PXE Boot Request| B
    B --&gt;|WireGuard Tunnel| C
    C --&gt;|TFTP/HTTP/HTTPS| D
    D --&gt;|Boot Files| C
    C --&gt;|Encrypted Response| B
    B --&gt;|Boot Files| A</pre><h4 id=implementation-details>Implementation Details</h4><p><strong>Compute</strong>:</p><ul><li><strong>WireGuard Gateway</strong>: e2-micro VM (~$6.50/month) running Ubuntu 22.04<ul><li>Self-managed WireGuard server</li><li>IP forwarding enabled</li><li>Static external IP (~$3.50/month if VM ever stops)</li></ul></li><li><strong>Boot Server</strong>: e2-micro VM (same or consolidated with gateway)<ul><li>TFTP server (<code>tftpd-hpa</code>)</li><li>HTTP server (nginx or simple Python server)</li><li>Optional HTTPS with self-signed cert or Let&rsquo;s Encrypt</li></ul></li></ul><p><strong>Networking</strong>:</p><ul><li><strong>VPC</strong>: Default VPC or custom VPC with private subnets</li><li><strong>Firewall Rules</strong>:<ul><li>Allow UDP/51820 from home lab public IP (WireGuard)</li><li>Allow UDP/69, TCP/80, TCP/443 from VPN subnet (boot protocols)</li></ul></li><li><strong>Routes</strong>: Custom route to direct home lab subnet through WireGuard gateway</li><li><strong>Cloud VPN</strong>: Not used (self-managed WireGuard instead to save ~$65/month)</li></ul><p><strong>WireGuard Setup</strong>:</p><ul><li>Install WireGuard on Compute Engine VM</li><li>Configure <code>wg0</code> interface with PostUp/PostDown iptables rules</li><li>Store private key in Secret Manager</li><li>UDM Pro connects as WireGuard peer</li></ul><p><strong>Cost Breakdown</strong> (US regions):</p><table><thead><tr><th>Component</th><th>Monthly Cost</th></tr></thead><tbody><tr><td>e2-micro VM (WireGuard + Boot)</td><td>~$6.50</td></tr><tr><td>Static External IP (if attached)</td><td>~$3.50</td></tr><tr><td>Egress (10 boots Ã— 150MB)</td><td>~$0.18</td></tr><tr><td><strong>Total</strong></td><td><strong>~$10.18</strong></td></tr><tr><td><strong>Annual</strong></td><td><strong>~$122</strong></td></tr></tbody></table><h4 id=pros-and-cons>Pros and Cons</h4><ul><li>Good, because existing home lab infrastructure already uses GCP extensively</li><li>Good, because consolidates all cloud resources on single provider (unified billing, IAM, monitoring)</li><li>Good, because leverages existing GCP expertise and Terraform modules</li><li>Good, because Cloud Monitoring/Logging already configured for other services</li><li>Good, because Secret Manager integration for WireGuard key storage</li><li>Good, because e2-micro instance size is sufficient for network boot workload</li><li>Good, because low cost (~$10/month for self-managed WireGuard)</li><li>Good, because VPC networking is familiar and well-documented</li><li>Neutral, because requires self-managed WireGuard (no native support, same as AWS)</li><li>Neutral, because TFTP/HTTP/HTTPS served directly from VM (no special GCP features needed)</li><li>Bad, because slightly more expensive than AWS t4g.micro (~$6.50/month vs ~$6/month)</li><li>Bad, because creates vendor lock-in to GCP ecosystem</li><li>Bad, because Cloud VPN (managed IPsec) is expensive (~$73/month), so must use self-managed WireGuard</li></ul><h3 id=option-2-amazon-web-services-aws>Option 2: Amazon Web Services (AWS)</h3><p>Host network boot infrastructure on Amazon Web Services.</p><h4 id=architecture-overview-1>Architecture Overview</h4><pre class=mermaid>graph TB
    subgraph &#34;Home Lab Network&#34;
        A[Home Lab Servers]
        B[UDM Pro - WireGuard Client]
    end
    
    subgraph &#34;AWS VPC&#34;
        C[WireGuard Gateway EC2&lt;br/&gt;t4g.micro]
        D[Boot Server EC2&lt;br/&gt;t4g.micro]
        C --&gt;|VPC Routing| D
    end
    
    A --&gt;|PXE Boot Request| B
    B --&gt;|WireGuard Tunnel| C
    C --&gt;|TFTP/HTTP/HTTPS| D
    D --&gt;|Boot Files| C
    C --&gt;|Encrypted Response| B
    B --&gt;|Boot Files| A</pre><h4 id=implementation-details-1>Implementation Details</h4><p><strong>Compute</strong>:</p><ul><li><strong>WireGuard Gateway</strong>: t4g.micro EC2 (~$6/month, ARM-based Graviton)<ul><li>Self-managed WireGuard server</li><li>Source/Dest check disabled for IP forwarding</li><li>Elastic IP (free when attached to running instance)</li></ul></li><li><strong>Boot Server</strong>: t4g.micro EC2 (same or consolidated with gateway)<ul><li>TFTP server (<code>tftpd-hpa</code>)</li><li>HTTP server (nginx)</li><li>Optional HTTPS with Let&rsquo;s Encrypt or self-signed cert</li></ul></li></ul><p><strong>Networking</strong>:</p><ul><li><strong>VPC</strong>: Default VPC or custom VPC with private subnets</li><li><strong>Security Groups</strong>:<ul><li>WireGuard SG: Allow UDP/51820 from home lab public IP</li><li>Boot Server SG: Allow UDP/69, TCP/80, TCP/443 from WireGuard SG</li></ul></li><li><strong>Route Table</strong>: Add route for home lab subnet via WireGuard instance</li><li><strong>Site-to-Site VPN</strong>: Not used (self-managed WireGuard saves ~$30/month)</li></ul><p><strong>WireGuard Setup</strong>:</p><ul><li>Install WireGuard on Ubuntu 22.04 or Amazon Linux 2023 EC2</li><li>Configure <code>wg0</code> with iptables MASQUERADE</li><li>Store private key in Secrets Manager</li><li>UDM Pro connects as WireGuard peer</li></ul><p><strong>Cost Breakdown</strong> (US East):</p><table><thead><tr><th>Component</th><th>Monthly Cost</th></tr></thead><tbody><tr><td>t4g.micro EC2 (WireGuard + Boot)</td><td>~$6.00</td></tr><tr><td>Elastic IP (attached)</td><td>$0.00</td></tr><tr><td>Egress (10 boots Ã— 150MB)</td><td>~$0.09</td></tr><tr><td><strong>Total (On-Demand)</strong></td><td><strong>~$6.09</strong></td></tr><tr><td><strong>Total (1-yr Reserved)</strong></td><td><strong>~$3.59</strong></td></tr><tr><td><strong>Annual (On-Demand)</strong></td><td><strong>~$73</strong></td></tr><tr><td><strong>Annual (Reserved)</strong></td><td><strong>~$43</strong></td></tr></tbody></table><h4 id=pros-and-cons-1>Pros and Cons</h4><ul><li>Good, because t4g.micro ARM instances offer best price/performance (~$6/month on-demand)</li><li>Good, because Reserved Instances provide significant savings (~40% with 1-year commitment)</li><li>Good, because Elastic IP is free when attached to running instance</li><li>Good, because AWS has extensive documentation and community support</li><li>Good, because potential for future multi-cloud strategy</li><li>Good, because ACM provides free SSL certificates (if public domain used)</li><li>Good, because Secrets Manager for WireGuard key storage</li><li>Good, because low cost (~$6/month on-demand, ~$3.50/month with RI)</li><li>Neutral, because requires self-managed WireGuard (no native support, same as GCP)</li><li>Neutral, because TFTP/HTTP/HTTPS served directly from EC2 (no special AWS features)</li><li>Bad, because introduces multi-cloud complexity (separate billing, IAM, monitoring)</li><li>Bad, because no existing AWS infrastructure in home lab (new learning curve)</li><li>Bad, because requires separate monitoring/logging setup (CloudWatch vs Cloud Monitoring)</li><li>Bad, because separate Terraform state and modules needed</li><li>Bad, because Site-to-Site VPN is expensive (~$36/month), so must use self-managed WireGuard</li></ul><h2 id=more-information>More Information</h2><h3 id=detailed-analysis>Detailed Analysis</h3><p>For in-depth analysis of each provider&rsquo;s capabilities:</p><ul><li><p><a href=../analysis/google-cloud/><strong>Google Cloud Platform Analysis</strong></a></p><ul><li><a href=../analysis/google-cloud/network-boot/>Network Boot Protocol Support (TFTP, HTTP, HTTPS)</a></li><li><a href=../analysis/google-cloud/wireguard/>WireGuard VPN Support and Deployment</a></li></ul></li><li><p><a href=../analysis/aws/><strong>Amazon Web Services Analysis</strong></a></p><ul><li><a href=../analysis/aws/network-boot/>Network Boot Protocol Support (TFTP, HTTP, HTTPS)</a></li><li><a href=../analysis/aws/wireguard/>WireGuard VPN Support and Deployment</a></li></ul></li></ul><h3 id=key-findings-summary>Key Findings Summary</h3><p>Both providers offer:</p><ul><li>âœ… <strong>TFTP Support</strong>: Via direct VM/EC2 access (load balancers don&rsquo;t support TFTP)</li><li>âœ… <strong>HTTP/HTTPS Support</strong>: Full support via direct VM/EC2 or load balancers</li><li>âœ… <strong>WireGuard Compatibility</strong>: Self-managed deployment on VM/EC2 (neither has native support)</li><li>âœ… <strong>UDM Pro Integration</strong>: Native WireGuard client works with both</li><li>âœ… <strong>Low Cost</strong>: $6-12/month for compute + VPN infrastructure</li><li>âœ… <strong>Sufficient Performance</strong>: 100+ Mbps throughput on smallest instances</li></ul><p>Key differences:</p><ul><li><strong>GCP</strong>: Slightly higher cost (~$10/month), but consolidates with existing infrastructure</li><li><strong>AWS</strong>: Slightly lower cost (~$6/month on-demand, ~$3.50/month Reserved), but introduces multi-cloud complexity</li></ul><h3 id=cost-comparison-table>Cost Comparison Table</h3><table><thead><tr><th>Component</th><th>GCP (e2-micro)</th><th>AWS (t4g.micro On-Demand)</th><th>AWS (t4g.micro 1-yr RI)</th></tr></thead><tbody><tr><td>Compute</td><td>$6.50/month</td><td>$6.00/month</td><td>$3.50/month</td></tr><tr><td>Static IP</td><td>$3.50/month</td><td>$0.00 (Elastic IP free when attached)</td><td>$0.00</td></tr><tr><td>Egress (1.5GB)</td><td>$0.18/month</td><td>$0.09/month</td><td>$0.09/month</td></tr><tr><td><strong>Monthly</strong></td><td><strong>$10.18</strong></td><td><strong>$6.09</strong></td><td><strong>$3.59</strong></td></tr><tr><td><strong>Annual</strong></td><td><strong>$122</strong></td><td><strong>$73</strong></td><td><strong>$43</strong></td></tr></tbody></table><p><strong>Savings Analysis</strong>: AWS is ~$49-79/year cheaper, but introduces operational complexity.</p><h3 id=protocol-support-comparison>Protocol Support Comparison</h3><table><thead><tr><th>Protocol</th><th>GCP Support</th><th>AWS Support</th><th>Implementation</th></tr></thead><tbody><tr><td>TFTP (UDP/69)</td><td>âš ï¸ Via VM</td><td>âš ï¸ Via EC2</td><td>Direct VM/EC2 access (no LB support)</td></tr><tr><td>HTTP (TCP/80)</td><td>âœ… Full</td><td>âœ… Full</td><td>Direct VM/EC2 or Load Balancer</td></tr><tr><td>HTTPS (TCP/443)</td><td>âœ… Full</td><td>âœ… Full</td><td>Direct VM/EC2 or Load Balancer + cert</td></tr><tr><td>WireGuard</td><td>âš ï¸ Self-managed</td><td>âš ï¸ Self-managed</td><td>Install on VM/EC2</td></tr></tbody></table><h3 id=wireguard-deployment-comparison>WireGuard Deployment Comparison</h3><table><thead><tr><th>Aspect</th><th>GCP</th><th>AWS</th></tr></thead><tbody><tr><td><strong>Native Support</strong></td><td>âŒ No (IPsec Cloud VPN only)</td><td>âŒ No (IPsec Site-to-Site VPN only)</td></tr><tr><td><strong>Self-Managed</strong></td><td>âœ… Compute Engine</td><td>âœ… EC2</td></tr><tr><td><strong>Setup Complexity</strong></td><td>Similar (install, configure, firewall)</td><td>Similar (install, configure, SG)</td></tr><tr><td><strong>IP Forwarding</strong></td><td>Enable on VM</td><td>Disable Source/Dest check</td></tr><tr><td><strong>Firewall</strong></td><td>VPC Firewall rules</td><td>Security Groups</td></tr><tr><td><strong>Key Storage</strong></td><td>Secret Manager</td><td>Secrets Manager</td></tr><tr><td><strong>Cost</strong></td><td>~$10/month total</td><td>~$6/month total</td></tr></tbody></table><h3 id=trade-offs-analysis>Trade-offs Analysis</h3><p><strong>Choosing GCP</strong>:</p><ul><li><strong>Wins</strong>: Operational simplicity, unified infrastructure, existing expertise</li><li><strong>Loses</strong>: ~$50-80/year higher cost, vendor lock-in</li></ul><p><strong>Choosing AWS</strong>:</p><ul><li><strong>Wins</strong>: Lower cost, Reserved Instance savings, multi-cloud optionality</li><li><strong>Loses</strong>: Multi-cloud complexity, separate monitoring/billing, new tooling</li></ul><p>For a home lab prioritizing <strong>simplicity over cost optimization</strong>, GCP&rsquo;s consolidation benefits outweigh the modest cost difference.</p><h3 id=related-adrs>Related ADRs</h3><ul><li><a href=./0002-network-boot-architecture/>ADR-0002: Network Boot Architecture</a> - Established requirement for cloud-hosted boot server with VPN</li><li><a href=./0001-use-madr-for-architecture-decision-records/>ADR-0001: Use MADR for Architecture Decision Records</a> - MADR format used for this ADR</li></ul><h3 id=future-considerations>Future Considerations</h3><ol><li><strong>Cost Reevaluation</strong>: If annual costs become significant, reconsider AWS Reserved Instances</li><li><strong>Multi-Cloud</strong>: If multi-cloud strategy emerges, migrate boot server to AWS</li><li><strong>Managed WireGuard</strong>: If GCP or AWS adds native WireGuard support, reevaluate managed option</li><li><strong>High Availability</strong>: If HA required, evaluate multi-region deployment costs on both providers</li></ol><h3 id=related-issues>Related Issues</h3><ul><li><a href=https://github.com/Zaba505/infra/issues/597>Issue #597</a> - story(docs): create adr for cloud provider selection</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-dab026fd06f98a03a459f97073d21662>2.4 - [0004] Server Operating System Selection</h1><div class=lead>Evaluate operating systems for homelab server infrastructure with focus on Kubernetes cluster setup and maintenance.</div><h2 id=context-and-problem-statement>Context and Problem Statement</h2><p>The homelab infrastructure requires a server operating system to run Kubernetes clusters for container workloads. The choice of operating system significantly impacts ease of cluster initialization, ongoing maintenance burden, security posture, and operational complexity.</p><p>The question is: <strong>Which operating system should be used for homelab Kubernetes servers?</strong></p><p>This decision will affect:</p><ul><li><strong>Cluster Initialization</strong>: Complexity and time required to bootstrap Kubernetes</li><li><strong>Maintenance Burden</strong>: Frequency and complexity of OS updates, Kubernetes upgrades, and patching</li><li><strong>Security Posture</strong>: Attack surface, built-in security features, and hardening requirements</li><li><strong>Resource Efficiency</strong>: RAM, CPU, and disk overhead</li><li><strong>Operational Complexity</strong>: Day-to-day management, troubleshooting, and debugging</li><li><strong>Learning Curve</strong>: Time required for team to become proficient</li></ul><h2 id=decision-drivers>Decision Drivers</h2><ul><li><strong>Ease of Kubernetes Setup</strong>: Minimize steps and complexity for cluster initialization</li><li><strong>Maintenance Simplicity</strong>: Reduce ongoing operational burden for updates and upgrades</li><li><strong>Security-First Design</strong>: Minimal attack surface and strong security defaults</li><li><strong>Resource Efficiency</strong>: Low RAM/CPU/disk overhead for cost-effective homelab</li><li><strong>Learning Curve</strong>: Reasonable adoption time for single-person homelab</li><li><strong>Community Support</strong>: Strong documentation and active community</li><li><strong>Immutability</strong>: Prefer declarative, version-controlled configuration (GitOps-friendly)</li><li><strong>Purpose-Built</strong>: OS optimized specifically for Kubernetes vs general-purpose</li></ul><h2 id=considered-options>Considered Options</h2><ul><li><strong>Option 1</strong>: Ubuntu Server with k3s</li><li><strong>Option 2</strong>: Fedora Server with kubeadm</li><li><strong>Option 3</strong>: Talos Linux (purpose-built Kubernetes OS)</li><li><strong>Option 4</strong>: Harvester HCI (hyperconverged platform)</li></ul><h2 id=decision-outcome>Decision Outcome</h2><p>Chosen option: &ldquo;<strong>Option 3: Talos Linux</strong>&rdquo;, because:</p><ol><li><strong>Minimal Attack Surface</strong>: No SSH, shell, or package manager eliminates entire classes of vulnerabilities, providing the strongest security posture</li><li><strong>Built-in Kubernetes</strong>: No separate installation or configuration complexity - Kubernetes is included and optimized</li><li><strong>Declarative Configuration</strong>: API-driven, immutable infrastructure aligns with GitOps principles and prevents configuration drift</li><li><strong>Lowest Resource Overhead</strong>: ~768MB RAM vs 1-2GB+ for traditional distros, maximizing homelab hardware efficiency</li><li><strong>Simplified Maintenance</strong>: Declarative upgrades (<code>talosctl upgrade</code>) for both OS and Kubernetes reduce operational burden</li><li><strong>Security by Default</strong>: Immutable filesystem, no shell, KSPP compliance - secure without manual hardening</li></ol><p>While the learning curve is steeper than traditional Linux distributions, the benefits of purpose-built Kubernetes infrastructure, minimal maintenance, and superior security outweigh the initial learning investment for a dedicated Kubernetes homelab.</p><h3 id=consequences>Consequences</h3><ul><li>Good, because minimal attack surface (no SSH/shell) provides strongest security posture</li><li>Good, because declarative configuration enables GitOps workflows and prevents drift</li><li>Good, because lowest resource overhead (~768MB RAM) maximizes homelab efficiency</li><li>Good, because built-in Kubernetes eliminates installation complexity</li><li>Good, because immutable infrastructure prevents configuration drift</li><li>Good, because simplified upgrades (single command for OS + K8s) reduce maintenance burden</li><li>Good, because smallest disk footprint (~500MB) vs 10GB+ for traditional distros</li><li>Good, because secure by default (no manual hardening required)</li><li>Good, because purpose-built design optimized specifically for Kubernetes</li><li>Good, because API-driven management (talosctl) enables automation</li><li>Neutral, because steeper learning curve (paradigm shift from shell-based management)</li><li>Neutral, because smaller community than Ubuntu/Fedora (but active and helpful)</li><li>Bad, because limited to Kubernetes workloads only (not general-purpose)</li><li>Bad, because no shell access requires different troubleshooting approach</li><li>Bad, because newer platform (less mature than Ubuntu/Fedora)</li><li>Bad, because no escape hatch for manual intervention when needed</li></ul><h3 id=confirmation>Confirmation</h3><p>The implementation will be confirmed by:</p><ul><li>Successfully bootstrapping a Talos cluster using talosctl</li><li>Deploying test workloads and validating functionality</li><li>Performing declarative OS and Kubernetes upgrades</li><li>Measuring actual resource usage (RAM &lt; 1GB per node)</li><li>Validating security posture (no SSH/shell, immutable filesystem)</li><li>Testing GitOps workflow (machine configs in version control)</li></ul><h2 id=pros-and-cons-of-the-options>Pros and Cons of the Options</h2><h3 id=option-1-ubuntu-server-with-k3s>Option 1: Ubuntu Server with k3s</h3><p>Host Kubernetes using Ubuntu Server 24.04 LTS with k3s lightweight Kubernetes distribution.</p><h4 id=architecture-overview>Architecture Overview</h4><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Ubuntu Server
    participant K3s as k3s Components
    
    Admin-&gt;&gt;Server: Install Ubuntu 24.04 LTS
    Server-&gt;&gt;Server: Configure network (static IP)
    Admin-&gt;&gt;Server: Update system
    Admin-&gt;&gt;Server: curl -sfL https://get.k3s.io | sh -
    Server-&gt;&gt;K3s: Download k3s binary
    K3s-&gt;&gt;Server: Configure containerd
    K3s-&gt;&gt;Server: Start k3s service
    K3s-&gt;&gt;Server: Initialize etcd (embedded)
    K3s-&gt;&gt;Server: Start API server
    K3s-&gt;&gt;Server: Deploy built-in CNI (Flannel)
    K3s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;Server: Retrieve node token
    Admin-&gt;&gt;Server: Install k3s agent on workers
    K3s-&gt;&gt;Server: Join workers to cluster
    K3s--&gt;&gt;Admin: Cluster ready (5-10 minutes)</pre><h4 id=implementation-details>Implementation Details</h4><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Single-command k3s install</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> sh -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get token for workers</span>
</span></span><span class=line><span class=cl>sudo cat /var/lib/rancher/k3s/server/node-token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install on workers</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> <span class=nv>K3S_URL</span><span class=o>=</span>https://control-plane:6443 <span class=nv>K3S_TOKEN</span><span class=o>=</span>&lt;token&gt; sh -
</span></span></code></pre></div><p><strong>Resource Requirements</strong>:</p><ul><li><strong>RAM</strong>: 1GB total (512MB OS + 512MB k3s)</li><li><strong>CPU</strong>: 1-2 cores</li><li><strong>Disk</strong>: 20GB (10GB OS + 10GB containers)</li></ul><p><strong>Maintenance</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># OS updates</span>
</span></span><span class=line><span class=cl>sudo apt update <span class=o>&amp;&amp;</span> sudo apt upgrade
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># k3s upgrade</span>
</span></span><span class=line><span class=cl>curl -sfL https://get.k3s.io <span class=p>|</span> <span class=nv>INSTALL_K3S_VERSION</span><span class=o>=</span>v1.32.0+k3s1 sh -
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Or automatic via system-upgrade-controller</span>
</span></span></code></pre></div><h4 id=pros-and-cons>Pros and Cons</h4><ul><li>Good, because most familiar Linux distribution (easy adoption)</li><li>Good, because 5-year LTS support (10 years with Ubuntu Pro)</li><li>Good, because k3s provides single-command setup</li><li>Good, because extensive documentation and community support</li><li>Good, because compatible with all Kubernetes tooling</li><li>Good, because automatic security updates available</li><li>Good, because general-purpose (can run non-K8s workloads)</li><li>Good, because low learning curve</li><li>Neutral, because moderate resource overhead (1GB RAM)</li><li>Bad, because general-purpose OS has larger attack surface</li><li>Bad, because requires manual OS updates and reboots</li><li>Bad, because managing OS + Kubernetes lifecycle separately</li><li>Bad, because imperative configuration (not GitOps-native)</li><li>Bad, because mutable filesystem (configuration drift possible)</li></ul><h3 id=option-2-fedora-server-with-kubeadm>Option 2: Fedora Server with kubeadm</h3><p>Host Kubernetes using Fedora Server with kubeadm (official Kubernetes tool) and CRI-O container runtime.</p><h4 id=architecture-overview-1>Architecture Overview</h4><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Fedora Server
    participant K8s as Kubernetes Components
    
    Admin-&gt;&gt;Server: Install Fedora 41
    Server-&gt;&gt;Server: Configure network
    Admin-&gt;&gt;Server: Update system (dnf update)
    Admin-&gt;&gt;Server: Install CRI-O
    Server-&gt;&gt;Server: Configure CRI-O runtime
    Admin-&gt;&gt;Server: Install kubeadm/kubelet/kubectl
    Server-&gt;&gt;Server: Disable swap, load kernel modules
    Server-&gt;&gt;Server: Configure SELinux
    Admin-&gt;&gt;K8s: kubeadm init --cri-socket=unix:///var/run/crio/crio.sock
    K8s-&gt;&gt;Server: Generate certificates
    K8s-&gt;&gt;Server: Start etcd
    K8s-&gt;&gt;Server: Start API server
    K8s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;K8s: kubectl apply CNI
    K8s-&gt;&gt;Server: Deploy CNI pods
    Admin-&gt;&gt;K8s: kubeadm join (workers)
    K8s--&gt;&gt;Admin: Cluster ready (15-20 minutes)</pre><h4 id=implementation-details-1>Implementation Details</h4><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Install CRI-O</span>
</span></span><span class=line><span class=cl>sudo dnf install -y cri-o
</span></span><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> --now crio
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install kubeadm components</span>
</span></span><span class=line><span class=cl>sudo dnf install -y kubelet kubeadm kubectl
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize cluster</span>
</span></span><span class=line><span class=cl>sudo kubeadm init --pod-network-cidr<span class=o>=</span>10.244.0.0/16 --cri-socket<span class=o>=</span>unix:///var/run/crio/crio.sock
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Install CNI</span>
</span></span><span class=line><span class=cl>kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml
</span></span></code></pre></div><p><strong>Resource Requirements</strong>:</p><ul><li><strong>RAM</strong>: 2.2GB total (700MB OS + 1.5GB Kubernetes)</li><li><strong>CPU</strong>: 2+ cores</li><li><strong>Disk</strong>: 35GB (15GB OS + 20GB containers)</li></ul><p><strong>Maintenance</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># OS updates (every 13 months major upgrade)</span>
</span></span><span class=line><span class=cl>sudo dnf update -y
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Kubernetes upgrade</span>
</span></span><span class=line><span class=cl>sudo dnf update -y kubeadm
</span></span><span class=line><span class=cl>sudo kubeadm upgrade apply v1.32.0
</span></span><span class=line><span class=cl>sudo dnf update -y kubelet kubectl
</span></span></code></pre></div><h4 id=pros-and-cons-1>Pros and Cons</h4><ul><li>Good, because SELinux enabled by default (stronger than AppArmor)</li><li>Good, because latest kernel and packages (bleeding edge)</li><li>Good, because native CRI-O support (OpenShift compatibility)</li><li>Good, because upstream for RHEL (enterprise patterns)</li><li>Good, because kubeadm provides full control over cluster</li><li>Neutral, because faster release cycle (latest features, but more upgrades)</li><li>Bad, because short support cycle (13 months per release)</li><li>Bad, because bleeding-edge can introduce instability</li><li>Bad, because complex kubeadm setup (many manual steps)</li><li>Bad, because higher resource overhead (2.2GB RAM)</li><li>Bad, because SELinux configuration for Kubernetes is complex</li><li>Bad, because frequent OS upgrades required (every 13 months)</li><li>Bad, because managing OS + Kubernetes separately</li><li>Bad, because imperative configuration (not GitOps-native)</li></ul><h3 id=option-3-talos-linux-purpose-built-kubernetes-os>Option 3: Talos Linux (purpose-built Kubernetes OS)</h3><p>Use Talos Linux, an immutable, API-driven operating system designed specifically for Kubernetes with built-in cluster management.</p><h4 id=architecture-overview-2>Architecture Overview</h4><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Bare Metal Server
    participant Talos as Talos Linux
    participant K8s as Kubernetes Components
    
    Admin-&gt;&gt;Server: Boot Talos ISO (PXE or USB)
    Server-&gt;&gt;Talos: Start in maintenance mode
    Talos--&gt;&gt;Admin: API endpoint ready
    Admin-&gt;&gt;Admin: Generate configs (talosctl gen config)
    Admin-&gt;&gt;Talos: talosctl apply-config (controlplane.yaml)
    Talos-&gt;&gt;Server: Install Talos to disk
    Server-&gt;&gt;Server: Reboot from disk
    Talos-&gt;&gt;K8s: Start kubelet
    Talos-&gt;&gt;K8s: Start etcd
    Talos-&gt;&gt;K8s: Start API server
    Admin-&gt;&gt;Talos: talosctl bootstrap
    Talos-&gt;&gt;K8s: Initialize cluster
    K8s-&gt;&gt;Talos: Start controller-manager
    K8s--&gt;&gt;Admin: Control plane ready
    Admin-&gt;&gt;K8s: Apply CNI
    Admin-&gt;&gt;Talos: Apply worker configs
    Talos-&gt;&gt;K8s: Join workers
    K8s--&gt;&gt;Admin: Cluster ready (10-15 minutes)</pre><h4 id=implementation-details-2>Implementation Details</h4><p><strong>Installation</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Generate machine configs</span>
</span></span><span class=line><span class=cl>talosctl gen config homelab https://192.168.1.10:6443
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply config to control plane (booted from ISO)</span>
</span></span><span class=line><span class=cl>talosctl apply-config --insecure --nodes 192.168.1.10 --file controlplane.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Bootstrap Kubernetes</span>
</span></span><span class=line><span class=cl>talosctl bootstrap --nodes 192.168.1.10 --endpoints 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get kubeconfig</span>
</span></span><span class=line><span class=cl>talosctl kubeconfig --nodes 192.168.1.10
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Add workers</span>
</span></span><span class=line><span class=cl>talosctl apply-config --insecure --nodes 192.168.1.11 --file worker.yaml
</span></span></code></pre></div><p><strong>Machine Configuration</strong> (declarative YAML):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=l>v1alpha1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>machine</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>controlplane</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>install</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>disk</span><span class=p>:</span><span class=w> </span><span class=l>/dev/sda</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>control-plane-1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>interfaces</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>interface</span><span class=p>:</span><span class=w> </span><span class=l>eth0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>addresses</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=m>192.168.1.10</span><span class=l>/24</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>cluster</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>clusterName</span><span class=p>:</span><span class=w> </span><span class=l>homelab</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>controlPlane</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>endpoint</span><span class=p>:</span><span class=w> </span><span class=l>https://192.168.1.10:6443</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cni</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>custom</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>urls</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=l>https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml</span><span class=w>
</span></span></span></code></pre></div><p><strong>Resource Requirements</strong>:</p><ul><li><strong>RAM</strong>: 768MB total (256MB OS + 512MB Kubernetes)</li><li><strong>CPU</strong>: 1-2 cores</li><li><strong>Disk</strong>: 10-15GB (500MB OS + 10GB containers)</li></ul><p><strong>Maintenance</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Upgrade Talos (OS + Kubernetes)</span>
</span></span><span class=line><span class=cl>talosctl upgrade --nodes 192.168.1.10 --image ghcr.io/siderolabs/installer:v1.9.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upgrade Kubernetes version</span>
</span></span><span class=line><span class=cl>talosctl upgrade-k8s --nodes 192.168.1.10 --to 1.32.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply config changes</span>
</span></span><span class=line><span class=cl>talosctl apply-config --nodes 192.168.1.10 --file controlplane.yaml
</span></span></code></pre></div><h4 id=pros-and-cons-2>Pros and Cons</h4><ul><li>Good, because Kubernetes built-in (no separate installation)</li><li>Good, because minimal attack surface (no SSH, shell, package manager)</li><li>Good, because immutable infrastructure (config drift impossible)</li><li>Good, because API-driven management (GitOps-friendly)</li><li>Good, because lowest resource overhead (~768MB RAM)</li><li>Good, because declarative configuration (YAML in version control)</li><li>Good, because secure by default (no manual hardening)</li><li>Good, because smallest disk footprint (~500MB OS)</li><li>Good, because designed specifically for Kubernetes</li><li>Good, because simple declarative upgrades (OS + K8s)</li><li>Good, because UEFI Secure Boot support</li><li>Neutral, because smaller community (but active and helpful)</li><li>Bad, because steep learning curve (paradigm shift)</li><li>Bad, because limited to Kubernetes workloads only</li><li>Bad, because troubleshooting without shell requires different approach</li><li>Bad, because relatively new (less mature than Ubuntu/Fedora)</li><li>Bad, because no escape hatch for manual intervention</li></ul><h3 id=option-4-harvester-hci-hyperconverged-platform>Option 4: Harvester HCI (hyperconverged platform)</h3><p>Use Harvester, a hyperconverged infrastructure platform built on K3s and KubeVirt for unified VM + container management.</p><h4 id=architecture-overview-3>Architecture Overview</h4><pre class=mermaid>sequenceDiagram
    participant Admin
    participant Server as Bare Metal Server
    participant Harvester as Harvester HCI
    participant K3s as K3s / KubeVirt
    participant Storage as Longhorn Storage
    
    Admin-&gt;&gt;Server: Boot Harvester ISO
    Server-&gt;&gt;Harvester: Installation wizard
    Admin-&gt;&gt;Harvester: Configure cluster (VIP, storage)
    Harvester-&gt;&gt;Server: Install RancherOS 2.0
    Harvester-&gt;&gt;Server: Install K3s
    Server-&gt;&gt;Server: Reboot
    Harvester-&gt;&gt;K3s: Start K3s server
    K3s-&gt;&gt;Storage: Deploy Longhorn
    K3s-&gt;&gt;Server: Deploy KubeVirt
    K3s-&gt;&gt;Server: Deploy multus CNI
    Harvester--&gt;&gt;Admin: Web UI ready
    Admin-&gt;&gt;Harvester: Add nodes
    Harvester-&gt;&gt;K3s: Join cluster
    K3s--&gt;&gt;Admin: Cluster ready (20-30 minutes)</pre><h4 id=implementation-details-3>Implementation Details</h4><p><strong>Installation</strong>: Interactive ISO wizard or cloud-init config</p><p><strong>Resource Requirements</strong>:</p><ul><li><strong>RAM</strong>: 8GB minimum per node (16GB+ recommended)</li><li><strong>CPU</strong>: 4+ cores per node</li><li><strong>Disk</strong>: 250GB+ per node (100GB OS + 150GB storage)</li><li><strong>Nodes</strong>: 3+ for production HA</li></ul><p><strong>Features</strong>:</p><ul><li>Web UI management</li><li>Built-in storage (Longhorn)</li><li>VM support (KubeVirt)</li><li>Live migration</li><li>Rancher integration</li></ul><h4 id=pros-and-cons-3>Pros and Cons</h4><ul><li>Good, because unified VM + container platform</li><li>Good, because built-in K3s (Kubernetes included)</li><li>Good, because web UI simplifies management</li><li>Good, because built-in persistent storage (Longhorn)</li><li>Good, because VM live migration</li><li>Good, because Rancher integration</li><li>Neutral, because immutable OS layer</li><li>Bad, because very heavy resource requirements (8GB+ RAM)</li><li>Bad, because complex architecture (KubeVirt, Longhorn, multus)</li><li>Bad, because overkill for container-only workloads</li><li>Bad, because larger attack surface (web UI, VM layer)</li><li>Bad, because requires 3+ nodes for HA (not single-node friendly)</li><li>Bad, because steep learning curve for full feature set</li></ul><h2 id=more-information>More Information</h2><h3 id=detailed-analysis>Detailed Analysis</h3><p>For in-depth analysis of each operating system:</p><ul><li><p><a href=../analysis/server-os/ubuntu/><strong>Ubuntu Server Analysis</strong></a></p><ul><li>Installation methods (kubeadm, k3s, MicroK8s)</li><li>Cluster initialization sequences</li><li>Maintenance requirements and upgrade procedures</li><li>Resource overhead and security posture</li></ul></li><li><p><a href=../analysis/server-os/fedora/><strong>Fedora Server Analysis</strong></a></p><ul><li>kubeadm with CRI-O installation</li><li>SELinux configuration for Kubernetes</li><li>Rapid release cycle implications</li><li>RHEL ecosystem compatibility</li></ul></li><li><p><a href=../analysis/server-os/talos-linux/><strong>Talos Linux Analysis</strong></a></p><ul><li>API-driven, immutable architecture</li><li>Declarative configuration model</li><li>Security-first design principles</li><li>Production readiness and advanced features</li></ul></li><li><p><a href=../analysis/server-os/harvester/><strong>Harvester HCI Analysis</strong></a></p><ul><li>Hyperconverged infrastructure capabilities</li><li>VM + container unified platform</li><li>KubeVirt and Longhorn integration</li><li>Multi-node cluster requirements</li></ul></li></ul><h3 id=key-findings-summary>Key Findings Summary</h3><p>Resource efficiency comparison:</p><ul><li>âœ… <strong>Talos</strong>: 768MB RAM, 500MB disk (most efficient)</li><li>âœ… <strong>Ubuntu + k3s</strong>: 1GB RAM, 20GB disk (efficient)</li><li>âš ï¸ <strong>Fedora + kubeadm</strong>: 2.2GB RAM, 35GB disk (moderate)</li><li>âŒ <strong>Harvester</strong>: 8GB+ RAM, 250GB+ disk (heavy)</li></ul><p>Security posture comparison:</p><ul><li>âœ… <strong>Talos</strong>: Minimal attack surface (no SSH/shell, immutable)</li><li>âœ… <strong>Fedora</strong>: SELinux by default (strong MAC)</li><li>âš ï¸ <strong>Ubuntu</strong>: AppArmor (moderate security)</li><li>âš ï¸ <strong>Harvester</strong>: Larger attack surface (web UI, VM layer)</li></ul><p>Operational complexity comparison:</p><ul><li>âœ… <strong>Ubuntu + k3s</strong>: Single command install, familiar management</li><li>âœ… <strong>Talos</strong>: Declarative, automated (after learning curve)</li><li>âš ï¸ <strong>Fedora + kubeadm</strong>: Manual kubeadm steps, frequent OS upgrades</li><li>âŒ <strong>Harvester</strong>: Complex HCI architecture, heavy requirements</li></ul><h3 id=decision-matrix>Decision Matrix</h3><table><thead><tr><th>Criterion</th><th>Ubuntu + k3s</th><th>Fedora + kubeadm</th><th>Talos Linux</th><th>Harvester</th></tr></thead><tbody><tr><td><strong>Setup Simplicity</strong></td><td>â­â­â­â­â­</td><td>â­â­â­</td><td>â­â­â­â­</td><td>â­â­â­</td></tr><tr><td><strong>Maintenance Burden</strong></td><td>â­â­â­â­</td><td>â­â­</td><td>â­â­â­â­â­</td><td>â­â­â­â­</td></tr><tr><td><strong>Security Posture</strong></td><td>â­â­â­</td><td>â­â­â­â­</td><td>â­â­â­â­â­</td><td>â­â­â­</td></tr><tr><td><strong>Resource Efficiency</strong></td><td>â­â­â­â­</td><td>â­â­â­</td><td>â­â­â­â­â­</td><td>â­</td></tr><tr><td><strong>Learning Curve</strong></td><td>â­â­â­â­â­</td><td>â­â­â­â­</td><td>â­â­</td><td>â­â­â­</td></tr><tr><td><strong>Community Support</strong></td><td>â­â­â­â­â­</td><td>â­â­â­â­</td><td>â­â­â­</td><td>â­â­â­â­</td></tr><tr><td><strong>Immutability</strong></td><td>â­</td><td>â­</td><td>â­â­â­â­â­</td><td>â­â­â­â­</td></tr><tr><td><strong>GitOps-Friendly</strong></td><td>â­â­</td><td>â­â­</td><td>â­â­â­â­â­</td><td>â­â­â­</td></tr><tr><td><strong>Purpose-Built</strong></td><td>â­â­</td><td>â­â­</td><td>â­â­â­â­â­</td><td>â­â­â­â­</td></tr><tr><td><strong>Overall Score</strong></td><td>29/45</td><td>24/45</td><td>38/45</td><td>28/45</td></tr></tbody></table><p><strong>Talos Linux scores highest</strong> for Kubernetes-dedicated homelab infrastructure prioritizing security, efficiency, and GitOps workflows.</p><h3 id=trade-offs-analysis>Trade-offs Analysis</h3><p><strong>Choosing Talos Linux</strong>:</p><ul><li><strong>Wins</strong>: Best security, lowest overhead, declarative configuration, minimal maintenance</li><li><strong>Loses</strong>: Steeper learning curve, no shell access, smaller community</li></ul><p><strong>Choosing Ubuntu + k3s</strong>:</p><ul><li><strong>Wins</strong>: Easiest adoption, largest community, general-purpose flexibility</li><li><strong>Loses</strong>: Higher attack surface, manual OS management, imperative config</li></ul><p><strong>Choosing Fedora + kubeadm</strong>:</p><ul><li><strong>Wins</strong>: Latest features, SELinux, enterprise compatibility</li><li><strong>Loses</strong>: Frequent OS upgrades, complex setup, higher overhead</li></ul><p><strong>Choosing Harvester</strong>:</p><ul><li><strong>Wins</strong>: VM + container unified platform, web UI</li><li><strong>Loses</strong>: Heavy resources, complex architecture, overkill for K8s-only</li></ul><p>For a <strong>Kubernetes-dedicated homelab prioritizing security and efficiency</strong>, Talos Linux&rsquo;s benefits outweigh the learning curve investment.</p><h3 id=related-adrs>Related ADRs</h3><ul><li><a href=./0001-use-madr-for-architecture-decision-records/>ADR-0001: Use MADR for Architecture Decision Records</a> - MADR format used for this ADR</li><li><a href=./0002-network-boot-architecture/>ADR-0002: Network Boot Architecture</a> - Server provisioning architecture</li><li><a href=./0003-cloud-provider-selection/>ADR-0003: Cloud Provider Selection</a> - Cloud infrastructure decisions</li></ul><h3 id=future-considerations>Future Considerations</h3><ol><li><strong>Team Growth</strong>: If team grows beyond single person, reassess Ubuntu for familiarity</li><li><strong>VM Requirements</strong>: If VM workloads emerge, consider Harvester or KubeVirt on Talos</li><li><strong>Enterprise Patterns</strong>: If RHEL compatibility needed, reconsider Fedora/CentOS Stream</li><li><strong>Maintenance Burden</strong>: If Talos learning curve proves too steep, fallback to k3s</li><li><strong>Talos Maturity</strong>: Monitor Talos ecosystem growth and production adoption</li></ol><h3 id=related-issues>Related Issues</h3><ul><li><a href=https://github.com/Zaba505/infra/issues/598>Issue #598</a> - story(docs): create adr for server operating system</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-be9e21cdab9183bad0c60fa6e3ba225b>2.5 - [0005] Network Boot Infrastructure Implementation on Google Cloud</h1><div class=lead>Evaluate implementation approaches for deploying network boot infrastructure on Google Cloud Platform using UEFI HTTP boot, comparing custom server implementation versus Matchbox-based solution.</div><h2 id=context-and-problem-statement>Context and Problem Statement</h2><p><a href=./0002-network-boot-architecture/>ADR-0002</a> established that network boot infrastructure will be hosted on a cloud provider accessed via WireGuard VPN. <a href=./0003-cloud-provider-selection/>ADR-0003</a> selected Google Cloud Platform as the hosting provider to consolidate infrastructure and leverage existing expertise.</p><p>The remaining question is: <strong>How should the network boot server itself be implemented?</strong></p><p>This decision affects:</p><ul><li><strong>Development Effort</strong>: Time required to build, test, and maintain the solution</li><li><strong>Feature Completeness</strong>: Capabilities for boot image management, machine mapping, and provisioning workflows</li><li><strong>Operational Complexity</strong>: Deployment, monitoring, and troubleshooting burden</li><li><strong>Security</strong>: Boot image integrity, access control, and audit capabilities</li><li><strong>Scalability</strong>: Ability to grow from single home lab to multiple environments</li></ul><p>The boot server must handle:</p><ol><li><strong>HTTP/HTTPS requests</strong> for UEFI boot scripts, kernels, initrd images, and cloud-init configurations</li><li><strong>Machine-to-image mapping</strong> to serve appropriate boot files based on MAC address, hardware profile, or tags</li><li><strong>Boot image lifecycle management</strong> including upload, versioning, and rollback capabilities</li></ol><h3 id=hardware-specific-context>Hardware-Specific Context</h3><p>The target bare metal servers (HP DL360 Gen 9) have the following network boot capabilities:</p><ul><li><strong>UEFI HTTP Boot</strong>: Supported in iLO 4 firmware v2.40+ (released 2016)</li><li><strong>TLS Support</strong>: Server-side TLS only (no client certificate authentication)</li><li><strong>Boot Process</strong>: Firmware handles initial HTTP requests directly (no PXE/TFTP chain loading required)</li><li><strong>Configuration</strong>: Boot URL configured via iLO RBSU or UEFI System Utilities</li></ul><p><strong>Security Implications</strong>: Since the servers cannot present client certificates for mTLS authentication with Cloudflare, the WireGuard VPN serves as the secure transport layer for boot traffic. The HTTP boot server is only accessible through the VPN tunnel.</p><p><strong>Reference</strong>: <a href=../../analysis/hp_dl360_gen9/network-boot.md>HP DL360 Gen 9 Network Boot Analysis</a></p><h2 id=decision-drivers>Decision Drivers</h2><ul><li><strong>Time to Production</strong>: Minimize time to get a working network boot infrastructure</li><li><strong>Feature Requirements</strong>: Must support machine-specific boot configurations, image versioning, and cloud-init integration</li><li><strong>Maintenance Burden</strong>: Prefer solutions that minimize ongoing maintenance and updates</li><li><strong>GCP Integration</strong>: Should leverage GCP services (Cloud Storage, Secret Manager, IAM)</li><li><strong>Security</strong>: Boot images must be served securely with access control and integrity verification</li><li><strong>Observability</strong>: Comprehensive logging and monitoring for troubleshooting boot failures</li><li><strong>Cost</strong>: Minimize infrastructure costs while meeting functional requirements</li><li><strong>Future Flexibility</strong>: Ability to extend or customize as needs evolve</li></ul><h2 id=considered-options>Considered Options</h2><ul><li><strong>Option 1</strong>: Custom server implementation (Go-based)</li><li><strong>Option 2</strong>: Matchbox-based solution</li></ul><h2 id=decision-outcome>Decision Outcome</h2><p><strong>Chosen option</strong>: &ldquo;<strong>Option 1: Custom implementation</strong>&rdquo;, because:</p><ol><li><strong>UEFI HTTP Boot Simplification</strong>: Elimination of TFTP/PXE dramatically reduces implementation complexity</li><li><strong>Cloud Run Deployment</strong>: HTTP-only boot enables serverless deployment (~$5/month vs $8-17/month)</li><li><strong>Development Time Manageable</strong>: UEFI HTTP boot reduces custom development to 2-3 weeks</li><li><strong>Full Control</strong>: Custom implementation maintains flexibility for future home lab requirements</li><li><strong>GCP Native Integration</strong>: Direct Cloud Storage, Firestore, Secret Manager, and IAM integration</li><li><strong>Existing Framework</strong>: Leverages <code>z5labs/humus</code> patterns already in use across services</li><li><strong>HTTP REST API</strong>: Native HTTP REST admin API via <code>z5labs/humus</code> framework provides better integration with existing tooling</li><li><strong>Microservices Architecture</strong>: Separation into Boot Service and Machine Management Service provides better separation of concerns</li></ol><h3 id=architecture>Architecture</h3><p>The implementation consists of two services:</p><ol><li><p><strong>Boot Service</strong>: Serves UEFI HTTP boot endpoints (<code>/boot.ipxe</code>, <code>/assets/{id}/kernel</code>, <code>/assets/{id}/initrd</code>)</p><ul><li>Accessed by bare metal servers during boot</li><li>Calls Machine Management Service API to resolve machine mappings and profiles</li><li>Streams kernel/initrd data from Machine Management Service</li></ul></li><li><p><strong>Machine Management Service</strong>: Provides REST API for managing profiles and machine mappings</p><ul><li>Stores boot profiles and machine mappings in Firestore</li><li>Manages kernel/initrd blobs in Cloud Storage</li><li>Provides admin API for creating/updating profiles and machines</li><li>Streams kernel/initrd binaries to Boot Service and admin clients</li></ul></li></ol><h3 id=consequences>Consequences</h3><ul><li>Good, because UEFI HTTP boot eliminates TFTP complexity entirely</li><li>Good, because Cloud Run deployment reduces operational overhead and cost</li><li>Good, because leverages existing <code>z5labs/humus</code> framework and Go expertise</li><li>Good, because GCP native integration (Cloud Storage, Firestore, Secret Manager, IAM)</li><li>Good, because full control over implementation enables future customization</li><li>Good, because microservices architecture separates boot operations from management operations</li><li>Good, because Boot Service can scale independently from Machine Management Service</li><li>Good, because simplified testing (HTTP-only, no TFTP/PXE edge cases)</li><li>Good, because OpenTelemetry observability built-in from existing patterns</li><li>Neutral, because requires 2-3 weeks development time vs 1 week for Matchbox setup</li><li>Neutral, because ongoing maintenance responsibility (no upstream project support)</li><li>Neutral, because two services require coordination but provide clearer boundaries</li><li>Bad, because custom implementation may miss edge cases that Matchbox handles</li><li>Bad, because reinvents machine matching and boot configuration patterns</li><li>Bad, because Cloud Run cold start latency needs monitoring (mitigated with min instances = 1)</li><li>Bad, because service-to-service communication adds latency (mitigated by GCP regional networking)</li></ul><h3 id=confirmation>Confirmation</h3><p>The implementation success will be validated by:</p><ul><li>Successfully deploying custom boot server on GCP Cloud Run</li><li>Successfully network booting HP DL360 Gen 9 via UEFI HTTP boot through WireGuard VPN</li><li>Confirming iLO 4 firmware v2.40+ compatibility with HTTP boot workflow</li><li>Validating boot image upload and versioning workflows via HTTP REST API</li><li>Measuring Cloud Run cold start latency for boot requests (target: &lt; 100ms)</li><li>Measuring boot file request latency for kernel/initrd downloads (target: &lt; 100ms)</li><li>Confirming Cloud Storage integration for boot asset storage</li><li>Testing machine-to-image mapping based on MAC address using Firestore</li><li>Validating WireGuard VPN security for boot traffic (compensating for lack of client cert support)</li><li>Verifying OpenTelemetry observability integration with Cloud Monitoring</li></ul><h2 id=pros-and-cons-of-the-options>Pros and Cons of the Options</h2><h3 id=option-1-custom-server-implementation-go-based>Option 1: Custom Server Implementation (Go-based)</h3><p>Build a custom network boot server in Go, leveraging the existing <code>z5labs/humus</code> framework for HTTP services.</p><h4 id=architecture-overview>Architecture Overview</h4><pre class=mermaid>architecture-beta
    group gcp(cloud)[GCP VPC]

    service wg_nlb(internet)[Network LB] in gcp
    service wireguard(server)[WireGuard Gateway] in gcp
    service https_lb(internet)[HTTPS LB] in gcp
    service compute(server)[Compute Engine] in gcp
    service storage(database)[Cloud Storage] in gcp
    service firestore(database)[Firestore] in gcp
    service secrets(disk)[Secret Manager] in gcp
    service monitoring(internet)[Cloud Monitoring] in gcp

    group homelab(cloud)[Home Lab]
    service udm(server)[UDM Pro] in homelab
    service servers(server)[Bare Metal Servers] in homelab

    servers:L -- R:udm
    udm:R -- L:wg_nlb
    wg_nlb:R -- L:wireguard
    wireguard:R -- L:https_lb
    https_lb:R -- L:compute
    compute:B --&gt; T:storage
    compute:B --&gt; T:firestore
    compute:R --&gt; L:secrets
    compute:T --&gt; B:monitoring</pre><p><strong>Components</strong>:</p><ul><li><strong>Boot Server</strong>: Go service deployed to Cloud Run (or Compute Engine VM as fallback)<ul><li>HTTP/HTTPS server (using <code>z5labs/humus</code> framework with OpenAPI)</li><li>UEFI HTTP boot endpoint serving boot scripts and assets</li><li>HTTP REST admin API for boot configuration management</li></ul></li><li><strong>Cloud Storage</strong>: Buckets for boot images, boot scripts, kernels, initrd files</li><li><strong>Firestore/Datastore</strong>: Machine-to-image mapping database (MAC â†’ boot profile)</li><li><strong>Secret Manager</strong>: WireGuard keys, TLS certificates (optional for HTTPS boot)</li><li><strong>Cloud Monitoring</strong>: Metrics for boot requests, success/failure rates, latency</li></ul><h4 id=boot-image-lifecycle>Boot Image Lifecycle</h4><pre class=mermaid>sequenceDiagram
    participant Admin
    participant API as Boot Server API
    participant Storage as Cloud Storage
    participant DB as Firestore
    participant Monitor as Cloud Monitoring

    Note over Admin,Monitor: Upload Boot Image
    Admin-&gt;&gt;API: POST /api/v1/images (kernel, initrd, metadata)
    API-&gt;&gt;API: Validate image integrity (checksum)
    API-&gt;&gt;Storage: Upload kernel to gs://boot-images/kernels/
    API-&gt;&gt;Storage: Upload initrd to gs://boot-images/initrd/
    API-&gt;&gt;DB: Store metadata (version, checksum, tags)
    API-&gt;&gt;Monitor: Log upload event
    API-&gt;&gt;Admin: 201 Created (image ID)

    Note over Admin,Monitor: Map Machine to Image
    Admin-&gt;&gt;API: POST /api/v1/machines (MAC, image_id, profile)
    API-&gt;&gt;DB: Store machine mapping
    API-&gt;&gt;Admin: 201 Created

    Note over Admin,Monitor: UEFI HTTP Boot Request
    participant Server as Home Lab Server
    Note right of Server: iLO 4 firmware v2.40&#43; initiates HTTP request directly
    Server-&gt;&gt;API: HTTP GET /boot?mac=aa:bb:cc:dd:ee:ff (via WireGuard VPN)
    API-&gt;&gt;DB: Query machine mapping by MAC
    API-&gt;&gt;API: Generate iPXE script (kernel, initrd URLs)
    API-&gt;&gt;Monitor: Log boot script request
    API-&gt;&gt;Server: Send iPXE script
    
    Server-&gt;&gt;API: HTTP GET /kernels/ubuntu-22.04.img
    API-&gt;&gt;Storage: Fetch kernel from Cloud Storage
    API-&gt;&gt;Monitor: Log kernel download (size, duration)
    API-&gt;&gt;Server: Stream kernel file
    
    Server-&gt;&gt;API: HTTP GET /initrd/ubuntu-22.04.img
    API-&gt;&gt;Storage: Fetch initrd from Cloud Storage
    API-&gt;&gt;Monitor: Log initrd download
    API-&gt;&gt;Server: Stream initrd file
    
    Server-&gt;&gt;Server: Boot into OS
    
    Note over Admin,Monitor: Rollback Image Version
    Admin-&gt;&gt;API: POST /api/v1/machines/{mac}/rollback
    API-&gt;&gt;DB: Update machine mapping to previous image_id
    API-&gt;&gt;Monitor: Log rollback event
    API-&gt;&gt;Admin: 200 OK</pre><h4 id=implementation-details>Implementation Details</h4><p><strong>Development Stack</strong>:</p><ul><li><strong>Language</strong>: Go 1.24 (leverage existing Go expertise)</li><li><strong>HTTP Framework</strong>: <code>z5labs/humus</code> (consistent with existing services)</li><li><strong>UEFI Boot</strong>: Standard HTTP handlers (no special libraries needed)</li><li><strong>Storage Client</strong>: <code>cloud.google.com/go/storage</code></li><li><strong>Database</strong>: Firestore for machine mappings (or simple JSON config in Cloud Storage)</li><li><strong>Observability</strong>: OpenTelemetry (metrics, traces, logs to Cloud Monitoring/Trace)</li></ul><p><strong>Deployment</strong>:</p><ul><li><strong>Cloud Run</strong> (preferred - HTTP-only boot enables serverless deployment):<ul><li>Min instances: 1 (ensures fast boot response, avoids cold start delays)</li><li>Max instances: 2 (home lab scale)</li><li>Memory: 512MB</li><li>CPU: 1 vCPU</li><li>Health checks: <code>/health/startup</code>, <code>/health/liveness</code></li><li>Concurrency: 10 requests per instance</li></ul></li><li><strong>Alternative - Compute Engine VM</strong> (if Cloud Run latency unacceptable):<ul><li>e2-micro instance ($6.50/month)</li><li>Container-Optimized OS with Docker</li><li>systemd service for boot server</li><li>Health checks: <code>/health/startup</code>, <code>/health/liveness</code></li></ul></li><li><strong>Networking</strong>:<ul><li>VPC firewall: Allow TCP/80, TCP/443 from WireGuard subnet (no UDP/69 needed)</li><li>Static internal IP for boot server (Compute Engine) or HTTPS Load Balancer (Cloud Run)</li><li>Cloud NAT for outbound connectivity (Cloud Storage access)</li></ul></li></ul><p><strong>Configuration Management</strong>:</p><ul><li>Machine mappings stored in Firestore or Cloud Storage JSON files</li><li>Boot profiles defined in YAML (similar to Matchbox groups):<div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>profiles</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-22.04-server</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>kernel</span><span class=p>:</span><span class=w> </span><span class=l>gs://boot-images/kernels/ubuntu-22.04.img</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>initrd</span><span class=p>:</span><span class=w> </span><span class=l>gs://boot-images/initrd/ubuntu-22.04.img</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cmdline</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;console=tty0 console=ttyS0&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cloud_init</span><span class=p>:</span><span class=w> </span><span class=l>gs://boot-images/cloud-init/ubuntu-base.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>machines</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>mac</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;aa:bb:cc:dd:ee:ff&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>profile</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-22.04-server</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>node-01</span><span class=w>
</span></span></span></code></pre></div></li></ul><p><strong>Cost Breakdown</strong>:</p><p><strong>Option A: Cloud Run Deployment</strong> (Preferred):</p><table><thead><tr><th>Component</th><th>Monthly Cost</th></tr></thead><tbody><tr><td>Cloud Run (1 min instance, 512MB, always-on)</td><td>$3.50</td></tr><tr><td>Cloud Storage (50GB boot images)</td><td>$1.00</td></tr><tr><td>Firestore (minimal reads/writes)</td><td>$0.50</td></tr><tr><td>Egress (10 boots Ã— 150MB)</td><td>$0.18</td></tr><tr><td><strong>Total</strong></td><td><strong>~$5.18</strong></td></tr></tbody></table><p><strong>Option B: Compute Engine Deployment</strong> (If Cloud Run latency unacceptable):</p><table><thead><tr><th>Component</th><th>Monthly Cost</th></tr></thead><tbody><tr><td>e2-micro VM (boot server)</td><td>$6.50</td></tr><tr><td>Cloud Storage (50GB boot images)</td><td>$1.00</td></tr><tr><td>Firestore (minimal reads/writes)</td><td>$0.50</td></tr><tr><td>Egress (10 boots Ã— 150MB)</td><td>$0.18</td></tr><tr><td><strong>Total</strong></td><td><strong>~$8.18</strong></td></tr></tbody></table><h4 id=pros-and-cons>Pros and Cons</h4><ul><li>Good, because UEFI HTTP boot eliminates TFTP complexity entirely</li><li>Good, because Cloud Run deployment option reduces operational overhead and infrastructure cost</li><li>Good, because full control over boot server implementation and features</li><li>Good, because leverages existing Go expertise and <code>z5labs/humus</code> framework patterns</li><li>Good, because seamless GCP integration (Cloud Storage, Firestore, Secret Manager, IAM)</li><li>Good, because minimal dependencies (no external projects to track)</li><li>Good, because customizable to specific home lab requirements</li><li>Good, because OpenTelemetry observability built-in from existing patterns</li><li>Good, because can optimize for home lab scale (&lt; 20 machines)</li><li>Good, because lightweight implementation (no unnecessary features)</li><li>Good, because simplified testing (HTTP-only, no TFTP/PXE edge cases)</li><li>Good, because standard HTTP serving is well-understood (lower risk than TFTP)</li><li>Neutral, because development effort required (2-3 weeks for MVP, reduced from 3-4 weeks)</li><li>Neutral, because requires ongoing maintenance and security updates</li><li>Neutral, because Cloud Run cold start latency needs validation (POC required)</li><li>Bad, because reinvents machine matching and boot configuration patterns</li><li>Bad, because testing network boot scenarios still requires hardware</li><li>Bad, because potential for bugs in custom implementation</li><li>Bad, because no community support or established best practices</li><li>Bad, because development time still longer than Matchbox (2-3 weeks vs 1 week)</li></ul><h3 id=option-2-matchbox-based-solution>Option 2: Matchbox-Based Solution</h3><p>Deploy <a href=https://matchbox.psdn.io/>Matchbox</a>, an open-source network boot server developed by CoreOS (now part of Red Hat), to handle UEFI HTTP boot workflows.</p><h4 id=architecture-overview-1>Architecture Overview</h4><pre class=mermaid>architecture-beta
    group gcp(cloud)[GCP VPC]
    
    service wg_nlb(internet)[Network LB] in gcp
    service wireguard(server)[WireGuard Gateway] in gcp
    service https_lb(internet)[HTTPS LB] in gcp
    service compute(server)[Compute Engine] in gcp
    service storage(database)[Cloud Storage] in gcp
    service secrets(disk)[Secret Manager] in gcp
    service monitoring(internet)[Cloud Monitoring] in gcp
    
    group homelab(cloud)[Home Lab]
    service udm(server)[UDM Pro] in homelab
    service servers(server)[Bare Metal Servers] in homelab
    
    servers:L -- R:udm
    udm:R -- L:wg_nlb
    wg_nlb:R -- L:wireguard
    wireguard:R -- L:https_lb
    https_lb:R -- L:compute
    compute:B --&gt; T:storage
    compute:R --&gt; L:secrets
    compute:T --&gt; B:monitoring</pre><p><strong>Components</strong>:</p><ul><li><strong>Matchbox Server</strong>: Container deployed to Cloud Run or Compute Engine VM<ul><li>HTTP/gRPC APIs for boot workflows and configuration</li><li>UEFI HTTP boot support (TFTP disabled)</li><li>Machine grouping and profile templating</li><li>Ignition, Cloud-Init, and generic boot support</li></ul></li><li><strong>Cloud Storage</strong>: Backend for boot assets (mounted via gcsfuse or synced periodically)</li><li><strong>Local Storage</strong> (Compute Engine only): <code>/var/lib/matchbox</code> for assets and configuration (synced from Cloud Storage)</li><li><strong>Secret Manager</strong>: WireGuard keys, Matchbox TLS certificates</li><li><strong>Cloud Monitoring</strong>: Logs from Matchbox container, custom metrics via log parsing</li></ul><h4 id=boot-image-lifecycle-1>Boot Image Lifecycle</h4><pre class=mermaid>sequenceDiagram
    participant Admin
    participant CLI as matchbox CLI / API
    participant Matchbox as Matchbox Server
    participant Storage as Cloud Storage
    participant Monitor as Cloud Monitoring

    Note over Admin,Monitor: Upload Boot Image
    Admin-&gt;&gt;CLI: Upload kernel/initrd via gRPC API
    CLI-&gt;&gt;Matchbox: gRPC CreateAsset(kernel, initrd)
    Matchbox-&gt;&gt;Matchbox: Validate asset integrity
    Matchbox-&gt;&gt;Matchbox: Store to /var/lib/matchbox/assets/
    Matchbox-&gt;&gt;Storage: Sync to gs://boot-assets/ (via sidecar script)
    Matchbox-&gt;&gt;Monitor: Log asset upload event
    Matchbox-&gt;&gt;CLI: Asset ID, checksum

    Note over Admin,Monitor: Create Boot Profile
    Admin-&gt;&gt;CLI: Create profile YAML (kernel, initrd, cmdline)
    CLI-&gt;&gt;Matchbox: gRPC CreateProfile(profile.yaml)
    Matchbox-&gt;&gt;Matchbox: Store to /var/lib/matchbox/profiles/
    Matchbox-&gt;&gt;Storage: Sync profiles to gs://boot-config/
    Matchbox-&gt;&gt;CLI: Profile ID

    Note over Admin,Monitor: Create Machine Group
    Admin-&gt;&gt;CLI: Create group YAML (MAC selector, profile mapping)
    CLI-&gt;&gt;Matchbox: gRPC CreateGroup(group.yaml)
    Matchbox-&gt;&gt;Matchbox: Store to /var/lib/matchbox/groups/
    Matchbox-&gt;&gt;Storage: Sync groups to gs://boot-config/
    Matchbox-&gt;&gt;CLI: Group ID

    Note over Admin,Monitor: UEFI HTTP Boot Request
    participant Server as Home Lab Server
    Note right of Server: iLO 4 firmware v2.40&#43; initiates HTTP request directly
    Server-&gt;&gt;Matchbox: HTTP GET /boot.ipxe?mac=aa:bb:cc:dd:ee:ff (via WireGuard VPN)
    Matchbox-&gt;&gt;Matchbox: Match MAC to group
    Matchbox-&gt;&gt;Matchbox: Render iPXE template with profile
    Matchbox-&gt;&gt;Monitor: Log boot request (MAC, group, profile)
    Matchbox-&gt;&gt;Server: Send iPXE script
    
    Server-&gt;&gt;Matchbox: HTTP GET /assets/ubuntu-22.04-kernel.img
    Matchbox-&gt;&gt;Matchbox: Serve from /var/lib/matchbox/assets/
    Matchbox-&gt;&gt;Monitor: Log asset download (size, duration)
    Matchbox-&gt;&gt;Server: Stream kernel file
    
    Server-&gt;&gt;Matchbox: HTTP GET /assets/ubuntu-22.04-initrd.img
    Matchbox-&gt;&gt;Matchbox: Serve from /var/lib/matchbox/assets/
    Matchbox-&gt;&gt;Monitor: Log asset download
    Matchbox-&gt;&gt;Server: Stream initrd file
    
    Server-&gt;&gt;Server: Boot into OS
    
    Note over Admin,Monitor: Rollback Machine Group
    Admin-&gt;&gt;CLI: Update group YAML (change profile reference)
    CLI-&gt;&gt;Matchbox: gRPC UpdateGroup(group.yaml)
    Matchbox-&gt;&gt;Matchbox: Update /var/lib/matchbox/groups/
    Matchbox-&gt;&gt;Storage: Sync updated group config
    Matchbox-&gt;&gt;Monitor: Log group update
    Matchbox-&gt;&gt;CLI: Success</pre><h4 id=implementation-details-1>Implementation Details</h4><p><strong>Matchbox Deployment</strong>:</p><ul><li><strong>Container</strong>: <code>quay.io/poseidon/matchbox:latest</code> (official image)</li><li><strong>Deployment Options</strong>:<ul><li><strong>Cloud Run</strong> (preferred - HTTP-only boot enables serverless deployment):<ul><li>Min instances: 1 (ensures fast boot response)</li><li>Memory: 1GB RAM (Matchbox recommendation)</li><li>CPU: 1 vCPU</li><li>Storage: Cloud Storage for assets/profiles/groups (via HTTP API)</li></ul></li><li><strong>Compute Engine VM</strong> (if persistent local storage preferred):<ul><li>e2-small instance ($14/month, 2GB RAM recommended for Matchbox)</li><li><code>/var/lib/matchbox</code>: Persistent disk (10GB SSD, $1.70/month)</li><li>Cloud Storage sync: Periodic backup of assets/profiles/groups to <code>gs://matchbox-config/</code></li><li>Option: Use <code>gcsfuse</code> to mount Cloud Storage directly (adds latency but simplifies backups)</li></ul></li></ul></li></ul><p><strong>Configuration Structure</strong>:</p><pre tabindex=0><code>/var/lib/matchbox/
â”œâ”€â”€ assets/           # Boot images (kernels, initrds, ISOs)
â”‚   â”œâ”€â”€ ubuntu-22.04-kernel.img
â”‚   â”œâ”€â”€ ubuntu-22.04-initrd.img
â”‚   â””â”€â”€ flatcar-stable.img.gz
â”œâ”€â”€ profiles/         # Boot profiles (YAML)
â”‚   â”œâ”€â”€ ubuntu-server.yaml
â”‚   â””â”€â”€ flatcar-container.yaml
â””â”€â”€ groups/           # Machine groups (YAML)
    â”œâ”€â”€ default.yaml
    â”œâ”€â”€ node-01.yaml
    â””â”€â”€ storage-nodes.yaml
</code></pre><p><strong>Example Profile</strong> (<code>profiles/ubuntu-server.yaml</code>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>id</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-22.04-server</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Ubuntu 22.04 LTS Server</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>boot</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kernel</span><span class=p>:</span><span class=w> </span><span class=l>/assets/ubuntu-22.04-kernel.img</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>initrd</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>/assets/ubuntu-22.04-initrd.img</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>args</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>console=tty0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>console=ttyS0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>ip=dhcp</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>ignition_id</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-base.yaml</span><span class=w>
</span></span></span></code></pre></div><p><strong>Example Group</strong> (<code>groups/node-01.yaml</code>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>id</span><span class=p>:</span><span class=w> </span><span class=l>node-01</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Node 01 - Ubuntu Server</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>profile</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-22.04-server</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mac</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;aa:bb:cc:dd:ee:ff&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hostname</span><span class=p>:</span><span class=w> </span><span class=l>node-01.homelab.local</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>ssh_authorized_keys</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;ssh-ed25519 AAAA...&#34;</span><span class=w>
</span></span></span></code></pre></div><p><strong>GCP Integration</strong>:</p><ul><li><strong>Cloud Storage Sync</strong>: Cron job or sidecar container to sync <code>/var/lib/matchbox</code> to Cloud Storage<div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Sync every 5 minutes</span>
</span></span><span class=line><span class=cl>*/5 * * * * gsutil -m rsync -r /var/lib/matchbox gs://matchbox-config/
</span></span></code></pre></div></li><li><strong>Secret Manager</strong>: Store Matchbox TLS certificates for gRPC API authentication</li><li><strong>Cloud Monitoring</strong>: Ship Matchbox logs to Cloud Logging, parse for metrics:<ul><li>Boot request count by MAC/group</li><li>Asset download success/failure rates</li><li>TFTP vs HTTP request distribution</li></ul></li></ul><p><strong>Networking</strong>:</p><ul><li>VPC firewall: Allow TCP/8080 (HTTP), TCP/8081 (gRPC) from WireGuard subnet (no UDP/69 needed)</li><li>Optional: Internal load balancer if high availability required (adds ~$18/month)</li><li>Note: Cloud Run deployment includes integrated HTTPS load balancing</li></ul><p><strong>Cost Breakdown</strong>:</p><p><strong>Option A: Cloud Run Deployment</strong> (Preferred):</p><table><thead><tr><th>Component</th><th>Monthly Cost</th></tr></thead><tbody><tr><td>Cloud Run (1 min instance, 1GB RAM, always-on)</td><td>$7.00</td></tr><tr><td>Cloud Storage (50GB boot images)</td><td>$1.00</td></tr><tr><td>Egress (10 boots Ã— 150MB)</td><td>$0.18</td></tr><tr><td><strong>Total</strong></td><td><strong>~$8.18</strong></td></tr></tbody></table><p><strong>Option B: Compute Engine Deployment</strong> (If persistent local storage preferred):</p><table><thead><tr><th>Component</th><th>Monthly Cost</th></tr></thead><tbody><tr><td>e2-small VM (Matchbox server)</td><td>$14.00</td></tr><tr><td>Persistent SSD (10GB)</td><td>$1.70</td></tr><tr><td>Cloud Storage (50GB backups)</td><td>$1.00</td></tr><tr><td>Egress (10 boots Ã— 150MB)</td><td>$0.18</td></tr><tr><td><strong>Total</strong></td><td><strong>~$16.88</strong></td></tr></tbody></table><h4 id=pros-and-cons-1>Pros and Cons</h4><ul><li>Good, because HTTP-only boot enables Cloud Run deployment (reduces cost significantly)</li><li>Good, because UEFI HTTP boot eliminates TFTP complexity and potential failure points</li><li>Good, because production-ready boot server with extensive real-world usage</li><li>Good, because feature-complete with machine grouping, templating, and multi-OS support</li><li>Good, because gRPC API for programmatic boot configuration management</li><li>Good, because supports Ignition (Flatcar, CoreOS), Cloud-Init, and generic boot workflows</li><li>Good, because well-documented with established best practices</li><li>Good, because active community and upstream maintenance (Red Hat/CoreOS)</li><li>Good, because reduces development time to days (deploy + configure vs weeks of coding)</li><li>Good, because avoids reinventing network boot patterns (machine matching, boot configuration)</li><li>Good, because proven security model (TLS for gRPC, asset integrity checks)</li><li>Neutral, because requires learning Matchbox configuration patterns (YAML profiles/groups)</li><li>Neutral, because containerized deployment (Docker on Compute Engine or Cloud Run)</li><li>Neutral, because Cloud Run deployment option competitive with custom implementation cost</li><li>Bad, because introduces external dependency (Matchbox project maintenance)</li><li>Bad, because some features unnecessary for home lab scale (large-scale provisioning, etcd backend)</li><li>Bad, because less control over implementation details (limited customization)</li><li>Bad, because Cloud Storage integration requires custom sync scripts (Matchbox doesn&rsquo;t natively support GCS backend)</li><li>Bad, because dependency on upstream for security patches and bug fixes</li></ul><h2 id=uefi-http-boot-architecture>UEFI HTTP Boot Architecture</h2><p>This section documents the UEFI HTTP boot capability that fundamentally changes the network boot infrastructure design.</p><h3 id=boot-process-overview>Boot Process Overview</h3><p><strong>Traditional PXE Boot</strong> (NOT USED - shown for comparison):</p><pre class=mermaid>sequenceDiagram
    participant Server as Bare Metal Server
    participant DHCP as DHCP Server
    participant TFTP as TFTP Server
    participant HTTP as HTTP Server

    Note over Server,HTTP: Traditional PXE Boot Chain (NOT USED)
    Server-&gt;&gt;DHCP: DHCP Discover
    DHCP-&gt;&gt;Server: DHCP Offer (TFTP server, boot filename)
    Server-&gt;&gt;TFTP: TFTP GET /pxelinux.0
    TFTP-&gt;&gt;Server: Send PXE bootloader
    Server-&gt;&gt;TFTP: TFTP GET /ipxe.efi
    TFTP-&gt;&gt;Server: Send iPXE binary
    Server-&gt;&gt;HTTP: HTTP GET /boot.ipxe
    HTTP-&gt;&gt;Server: Send boot script
    Server-&gt;&gt;HTTP: HTTP GET /kernel, /initrd
    HTTP-&gt;&gt;Server: Stream boot files</pre><p><strong>UEFI HTTP Boot</strong> (ACTUAL IMPLEMENTATION):</p><pre class=mermaid>sequenceDiagram
    participant Server as HP DL360 Gen 9&lt;br/&gt;(iLO 4 v2.40&#43;)
    participant DHCP as DHCP Server&lt;br/&gt;(UDM Pro)
    participant VPN as WireGuard VPN
    participant HTTP as HTTP Boot Server&lt;br/&gt;(GCP Cloud Run)

    Note over Server,HTTP: UEFI HTTP Boot (ACTUAL IMPLEMENTATION)
    Server-&gt;&gt;DHCP: DHCP Discover
    DHCP-&gt;&gt;Server: DHCP Offer (boot URL: http://boot.internal/boot.ipxe?mac=...)
    Note right of Server: Firmware initiates HTTP request directly&lt;br/&gt;(no TFTP/PXE chain loading)
    Server-&gt;&gt;VPN: WireGuard tunnel established
    Server-&gt;&gt;HTTP: HTTP GET /boot.ipxe?mac=aa:bb:cc:dd:ee:ff
    HTTP-&gt;&gt;Server: Send boot script with kernel/initrd URLs
    Server-&gt;&gt;HTTP: HTTP GET /assets/talos-kernel.img
    HTTP-&gt;&gt;Server: Stream kernel (via WireGuard)
    Server-&gt;&gt;HTTP: HTTP GET /assets/talos-initrd.img
    HTTP-&gt;&gt;Server: Stream initrd (via WireGuard)
    Server-&gt;&gt;Server: Boot into OS</pre><h3 id=key-differences>Key Differences</h3><table><thead><tr><th>Aspect</th><th>Traditional PXE</th><th>UEFI HTTP Boot</th></tr></thead><tbody><tr><td><strong>Initial Protocol</strong></td><td>TFTP (UDP/69)</td><td>HTTP (TCP/80) or HTTPS (TCP/443)</td></tr><tr><td><strong>Boot Loader</strong></td><td>Requires TFTP transfer of iPXE binary</td><td>Firmware has HTTP client built-in</td></tr><tr><td><strong>Chain Loading</strong></td><td>PXE â†’ TFTP â†’ iPXE â†’ HTTP</td><td>Direct HTTP boot (no chain)</td></tr><tr><td><strong>Firewall Rules</strong></td><td>UDP/69, TCP/80, TCP/443</td><td>TCP/80, TCP/443 only</td></tr><tr><td><strong>Cloud Run Support</strong></td><td>âŒ (UDP not supported)</td><td>âœ… (HTTP-only)</td></tr><tr><td><strong>Transfer Speed</strong></td><td>~1-5 Mbps (TFTP)</td><td>10-100 Mbps (HTTP)</td></tr><tr><td><strong>Complexity</strong></td><td>High (multiple protocols)</td><td>Low (HTTP-only)</td></tr></tbody></table><h3 id=security-architecture>Security Architecture</h3><p><strong>Challenge</strong>: HP DL360 Gen 9 UEFI HTTP boot does not support client-side TLS certificates (mTLS).</p><p><strong>Solution</strong>: WireGuard VPN provides transport-layer security:</p><pre class=mermaid>flowchart LR
    subgraph homelab[Home Lab]
        server[HP DL360 Gen 9&lt;br/&gt;UEFI HTTP Boot&lt;br/&gt;iLO 4 v2.40&#43;]
        udm[UDM Pro&lt;br/&gt;WireGuard Client]
    end

    subgraph gcp[Google Cloud Platform]
        wg_gw[WireGuard Gateway&lt;br/&gt;Compute Engine]
        cr[Boot Server&lt;br/&gt;Cloud Run]
    end

    server --&gt;|HTTP| udm
    udm --&gt;|Encrypted WireGuard Tunnel| wg_gw
    wg_gw --&gt;|HTTP| cr

    style server fill:#f9f,stroke:#333
    style udm fill:#bbf,stroke:#333
    style wg_gw fill:#bfb,stroke:#333
    style cr fill:#fbb,stroke:#333</pre><p><strong>Why WireGuard instead of Cloudflare mTLS?</strong></p><ul><li><strong>Cloudflare mTLS Limitation</strong>: Requires client certificates at TLS layer</li><li><strong>UEFI Firmware Limitation</strong>: Cannot present client certificates during TLS handshake</li><li><strong>WireGuard Solution</strong>: Provides mutual authentication at network layer (pre-shared keys)</li><li><strong>Security Equivalent</strong>: WireGuard offers same security properties as mTLS:<ul><li>Mutual authentication (both endpoints authenticated)</li><li>Confidentiality (all traffic encrypted)</li><li>Integrity (authenticated encryption via ChaCha20-Poly1305)</li><li>No Internet exposure (boot server only accessible via VPN)</li></ul></li></ul><h3 id=firmware-configuration>Firmware Configuration</h3><p><strong>HP iLO 4 UEFI HTTP Boot Setup</strong>:</p><ol><li><p><strong>Access Configuration</strong>:</p><ul><li>iLO web interface â†’ Remote Console â†’ Power On â†’ Press F9 (RBSU)</li><li>Or: Direct RBSU access during POST (Press F9)</li></ul></li><li><p><strong>Enable UEFI HTTP Boot</strong>:</p><ul><li>Navigate: <code>System Configuration â†’ BIOS/Platform Configuration (RBSU) â†’ Network Options</code></li><li>Set <code>Network Boot</code> to <code>Enabled</code></li><li>Set <code>Boot Mode</code> to <code>UEFI</code> (not Legacy BIOS)</li><li>Enable <code>UEFI HTTP Boot Support</code></li></ul></li><li><p><strong>Configure NIC</strong>:</p><ul><li>Navigate: <code>RBSU â†’ Network Options â†’ [FlexibleLOM/PCIe NIC]</code></li><li>Set <code>Option ROM</code> to <code>Enabled</code> (required for UEFI boot option to appear)</li><li>Set <code>Network Boot</code> to <code>Enabled</code></li><li>Configure IPv4/IPv6 settings (DHCP or static)</li></ul></li><li><p><strong>Set Boot Order</strong>:</p><ul><li>Navigate: <code>RBSU â†’ Boot Options â†’ UEFI Boot Order</code></li><li>Move network device to top priority</li></ul></li><li><p><strong>Configure Boot URL</strong> (via DHCP or static):</p><ul><li>DHCP option 67: <code>http://10.x.x.x/boot.ipxe?mac=${net0/mac}</code></li><li>Or: Static configuration in UEFI System Utilities</li></ul></li></ol><p><strong>Required Firmware Versions</strong>:</p><ul><li><strong>iLO 4</strong>: v2.40 or later (for UEFI HTTP boot support)</li><li><strong>System ROM</strong>: P89 v2.60 or later (recommended)</li></ul><p><strong>Verification</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Check iLO firmware version via REST API</span>
</span></span><span class=line><span class=cl>curl -k -u admin:password https://ilo-address/redfish/v1/Managers/1/ <span class=p>|</span> jq <span class=s1>&#39;.FirmwareVersion&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Expected output: &#34;2.40&#34; or higher</span>
</span></span></code></pre></div><h3 id=architectural-implications>Architectural Implications</h3><p><strong>TFTP Elimination Impact</strong>:</p><ol><li><strong>Deployment</strong>: Cloud Run becomes viable (no UDP/TFTP requirement)</li><li><strong>Cost</strong>: Reduced infrastructure costs (~$5-8/month vs $8-17/month)</li><li><strong>Complexity</strong>: Simplified networking (TCP-only firewall rules)</li><li><strong>Development</strong>: Reduced effort (no TFTP library, testing, edge cases)</li><li><strong>Scalability</strong>: Cloud Run autoscaling vs fixed VM capacity</li><li><strong>Maintenance</strong>: Serverless reduces operational overhead</li></ol><p><strong>Decision Impact</strong>:</p><p>The removal of TFTP complexity fundamentally shifts the cost/benefit analysis:</p><ul><li><strong>Custom Implementation</strong>: More attractive (Cloud Run, reduced development time)</li><li><strong>Matchbox</strong>: Still valid but cost/complexity advantage reduced</li><li><strong>TCO Gap</strong>: Narrowed from ~$8,000-12,000 to ~$4,000-8,000 (Year 1)</li><li><strong>Development Gap</strong>: Reduced from 2-3 weeks to 1-2 weeks</li></ul><h2 id=detailed-comparison>Detailed Comparison</h2><h3 id=feature-comparison>Feature Comparison</h3><table><thead><tr><th>Feature</th><th>Custom Implementation</th><th>Matchbox</th></tr></thead><tbody><tr><td><strong>UEFI HTTP Boot</strong></td><td>âœ… Native (standard HTTP)</td><td>âœ… Built-in</td></tr><tr><td><strong>HTTP/HTTPS Boot</strong></td><td>âœ… Via z5labs/humus</td><td>âœ… Built-in</td></tr><tr><td><strong>Cloud Run Deployment</strong></td><td>âœ… Preferred option</td><td>âœ… Enabled by HTTP-only</td></tr><tr><td><strong>Boot Scripting</strong></td><td>âœ… Custom templates</td><td>âœ… Go templates</td></tr><tr><td><strong>Machine-to-Image Mapping</strong></td><td>âœ… Firestore/JSON</td><td>âœ… YAML groups with selectors</td></tr><tr><td><strong>Boot Profile Management</strong></td><td>âœ… Custom API</td><td>âœ… gRPC API + YAML</td></tr><tr><td><strong>Cloud-Init Support</strong></td><td>âš ï¸ Requires implementation</td><td>âœ… Native support</td></tr><tr><td><strong>Ignition Support</strong></td><td>âŒ Not planned</td><td>âœ… Native support (Flatcar, CoreOS)</td></tr><tr><td><strong>Asset Versioning</strong></td><td>âš ï¸ Requires implementation</td><td>âš ï¸ Manual (via Cloud Storage versioning)</td></tr><tr><td><strong>Rollback Capability</strong></td><td>âš ï¸ Requires implementation</td><td>âœ… Update group to previous profile</td></tr><tr><td><strong>OpenTelemetry Observability</strong></td><td>âœ… Built-in</td><td>âš ï¸ Logs only (requires parsing)</td></tr><tr><td><strong>GCP Cloud Storage Integration</strong></td><td>âœ… Native SDK</td><td>âš ï¸ Requires sync scripts</td></tr><tr><td><strong>HTTP REST Admin API</strong></td><td>âœ… Native (z5labs/humus)</td><td>âš ï¸ gRPC only</td></tr><tr><td><strong>Multi-Environment Support</strong></td><td>âš ï¸ Requires implementation</td><td>âœ… Groups + metadata</td></tr></tbody></table><h3 id=development-effort-comparison>Development Effort Comparison</h3><table><thead><tr><th>Task</th><th>Custom Implementation</th><th>Matchbox</th></tr></thead><tbody><tr><td><strong>Initial Setup</strong></td><td>1-2 days (project scaffolding)</td><td>4-8 hours (deployment + config)</td></tr><tr><td><strong>UEFI HTTP Boot</strong></td><td>1-2 days (standard HTTP endpoints)</td><td>âœ… Included</td></tr><tr><td><strong>HTTP Boot API</strong></td><td>2-3 days (z5labs/humus endpoints)</td><td>âœ… Included</td></tr><tr><td><strong>Machine Matching Logic</strong></td><td>2-3 days (database queries, selectors)</td><td>âœ… Included</td></tr><tr><td><strong>Boot Script Templates</strong></td><td>2-3 days (boot script templating)</td><td>âœ… Included</td></tr><tr><td><strong>Cloud-Init Support</strong></td><td>3-5 days (parsing, injection)</td><td>âœ… Included</td></tr><tr><td><strong>Asset Management</strong></td><td>2-3 days (upload, storage)</td><td>âœ… Included</td></tr><tr><td><strong>HTTP REST Admin API</strong></td><td>2-3 days (OpenAPI endpoints)</td><td>âœ… Included (gRPC)</td></tr><tr><td><strong>Cloud Run Deployment</strong></td><td>1 day (Cloud Run config)</td><td>1 day (Cloud Run config)</td></tr><tr><td><strong>Testing</strong></td><td>3-5 days (unit, integration, E2E - simplified)</td><td>2-3 days (integration only)</td></tr><tr><td><strong>Documentation</strong></td><td>2-3 days</td><td>1 day (reference existing docs)</td></tr><tr><td><strong>Total Effort</strong></td><td><strong>2-3 weeks</strong></td><td><strong>1 week</strong></td></tr></tbody></table><h3 id=operational-complexity>Operational Complexity</h3><table><thead><tr><th>Aspect</th><th>Custom Implementation</th><th>Matchbox</th></tr></thead><tbody><tr><td><strong>Deployment</strong></td><td>Docker container on Compute Engine</td><td>Docker container on Compute Engine</td></tr><tr><td><strong>Configuration Updates</strong></td><td>API calls or Terraform updates</td><td>YAML file updates + API/filesystem sync</td></tr><tr><td><strong>Monitoring</strong></td><td>OpenTelemetry metrics to Cloud Monitoring</td><td>Log parsing + custom metrics</td></tr><tr><td><strong>Troubleshooting</strong></td><td>Full access to code, custom logging</td><td>Matchbox logs + gRPC API inspection</td></tr><tr><td><strong>Security Patches</strong></td><td>Manual code updates</td><td>Upstream container image updates</td></tr><tr><td><strong>Dependency Updates</strong></td><td>Manual Go module updates</td><td>Upstream Matchbox updates</td></tr><tr><td><strong>Backup/Restore</strong></td><td>Cloud Storage + Firestore backups</td><td>Sync <code>/var/lib/matchbox</code> to Cloud Storage</td></tr></tbody></table><h3 id=cost-comparison-summary>Cost Comparison Summary</h3><p><strong>Comparing Cloud Run Deployments</strong> (Preferred for both options):</p><table><thead><tr><th>Item</th><th>Custom (Cloud Run)</th><th>Matchbox (Cloud Run)</th><th>Difference</th></tr></thead><tbody><tr><td><strong>Compute</strong></td><td>Cloud Run ($3.50/month)</td><td>Cloud Run ($7/month)</td><td>+$3.50/month</td></tr><tr><td><strong>Storage</strong></td><td>Cloud Storage ($1/month)</td><td>Cloud Storage ($1/month)</td><td>$0</td></tr><tr><td><strong>Development</strong></td><td>2-3 weeks @ $100/hour = $8,000-12,000</td><td>1 week @ $100/hour = $4,000</td><td>-$4,000-8,000</td></tr><tr><td><strong>Annual Infrastructure</strong></td><td>~$54</td><td>~$96</td><td>+$42/year</td></tr><tr><td><strong>TCO (Year 1)</strong></td><td>~$8,054-12,054</td><td>~$4,096</td><td><strong>-$3,958-7,958</strong></td></tr><tr><td><strong>TCO (Year 3)</strong></td><td>~$8,162-12,162</td><td>~$4,288</td><td><strong>-$3,874-7,874</strong></td></tr></tbody></table><p><strong>Key Insights</strong>:</p><ul><li>UEFI HTTP boot enables Cloud Run deployment for both options, dramatically reducing infrastructure costs</li><li>Custom implementation TCO gap narrowed from $7,895-11,895 to $3,958-7,958 (Year 1)</li><li>Both options now cost ~$5-8/month for infrastructure (vs $8-17/month with TFTP)</li><li>Development time difference reduced from 2-3 weeks to 1-2 weeks</li><li>Decision is much closer than originally assessed</li></ul><h3 id=risk-analysis>Risk Analysis</h3><table><thead><tr><th>Risk</th><th>Custom Implementation</th><th>Matchbox</th><th>Mitigation</th></tr></thead><tbody><tr><td><strong>Security Vulnerabilities</strong></td><td>Medium (standard HTTP code, well-understood)</td><td>Medium (upstream dependency)</td><td>Both: Monitor for security updates, automated deployments</td></tr><tr><td><strong>Boot Failures</strong></td><td>Medium (HTTP-only reduces complexity)</td><td>Low (battle-tested)</td><td>Custom: Comprehensive E2E testing with real hardware</td></tr><tr><td><strong>Cloud Run Cold Starts</strong></td><td>Medium (needs validation)</td><td>Medium (needs validation)</td><td>Both: Min instances = 1 (always-on)</td></tr><tr><td><strong>Maintenance Burden</strong></td><td>Medium (ongoing code maintenance)</td><td>Low (upstream handles updates)</td><td>Both: Automated deployment pipelines</td></tr><tr><td><strong>GCP Integration Issues</strong></td><td>Low (native SDK)</td><td>Medium (sync scripts)</td><td>Matchbox: Robust sync with error handling</td></tr><tr><td><strong>Scalability Limits</strong></td><td>Low (Cloud Run autoscaling)</td><td>Low (handles thousands of nodes)</td><td>Both: Monitor boot request latency</td></tr><tr><td><strong>Dependency Abandonment</strong></td><td>N/A (no external deps)</td><td>Low (Red Hat backing)</td><td>Matchbox: Can fork if necessary</td></tr></tbody></table><h2 id=implementation-plan>Implementation Plan</h2><h3 id=phase-1-machine-management-service-week-1>Phase 1: Machine Management Service (Week 1)</h3><ol><li><p><strong>Project Setup</strong> (1-2 days)</p><ul><li>Create Go project with <code>z5labs/humus</code> framework</li><li>Set up OpenAPI specification for HTTP REST admin API</li><li>Configure Cloud Storage and Firestore clients</li><li>Implement basic health check endpoints</li></ul></li><li><p><strong>Profile Management API</strong> (2-3 days)</p><ul><li>Boot profile upload endpoint (kernel, initrd, metadata)</li><li>Profile listing and retrieval endpoints</li><li>Kernel/initrd streaming endpoints (<code>GET /api/v1/profiles/{id}/kernel</code>, <code>GET /api/v1/profiles/{id}/initrd</code>)</li><li>Cloud Storage integration for blob management</li></ul></li><li><p><strong>Machine Management API</strong> (2-3 days)</p><ul><li>Machine registration endpoints</li><li>MAC address to profile mapping</li><li>Machine listing and updates</li><li>Firestore integration for machine mappings</li></ul></li></ol><h3 id=phase-2-boot-service-week-2>Phase 2: Boot Service (Week 2)</h3><ol><li><p><strong>UEFI HTTP Boot Endpoints</strong> (2-3 days)</p><ul><li>HTTP endpoint serving boot scripts (iPXE format)</li><li>Kernel and initrd streaming endpoints (proxy to Machine Management Service)</li><li>MAC-based machine matching via Machine Management Service API</li><li>Boot script templating with machine-specific parameters</li></ul></li><li><p><strong>Testing & Deployment</strong> (2-3 days)</p><ul><li>Deploy both services to Cloud Run with min instances = 1</li><li>Configure WireGuard VPN connectivity</li><li>Test UEFI HTTP boot from HP DL360 Gen 9 (iLO 4 v2.40+)</li><li>Validate boot latency and service-to-service communication</li></ul></li></ol><h3 id=phase-3-integration--observability-week-2-3>Phase 3: Integration & Observability (Week 2-3)</h3><ol><li><p><strong>Service Integration</strong> (1-2 days)</p><ul><li>Configure service-to-service authentication (if needed)</li><li>Optimize streaming performance between services</li><li>Handle error scenarios and fallbacks</li></ul></li><li><p><strong>Observability & Documentation</strong> (2-3 days)</p><ul><li>OpenTelemetry metrics integration (both services)</li><li>Distributed tracing across services</li><li>Cloud Monitoring dashboards</li><li>API documentation</li><li>Operational runbooks</li></ul></li></ol><h3 id=success-criteria>Success Criteria</h3><ul><li>âœ… Successfully boot HP DL360 Gen 9 via UEFI HTTP boot through WireGuard VPN</li><li>âœ… Boot latency &lt; 100ms for HTTP requests to Boot Service</li><li>âœ… Service-to-service latency &lt; 50ms (Boot Service â†’ Machine Management Service)</li><li>âœ… Cloud Run cold start latency &lt; 100ms (with min instances = 1 for both services)</li><li>âœ… Machine-to-profile mapping works correctly based on MAC address</li><li>âœ… Cloud Storage integration functional (upload, retrieve boot assets)</li><li>âœ… HTTP REST API fully functional for boot configuration management</li><li>âœ… Firestore stores machine mappings and boot profiles correctly</li><li>âœ… OpenTelemetry distributed tracing works across both services</li><li>âœ… Configuration update workflow clear and documented</li><li>âœ… Firmware compatibility confirmed (no TFTP fallback needed)</li></ul><h2 id=more-information>More Information</h2><h3 id=related-resources>Related Resources</h3><ul><li><a href=https://matchbox.psdn.io/>Matchbox Documentation</a></li><li><a href=https://github.com/poseidon/matchbox>Matchbox GitHub Repository</a></li><li><a href=https://ipxe.org/howto/chainloading>iPXE Boot Process</a></li><li><a href=https://en.wikipedia.org/wiki/Preboot_Execution_Environment>PXE Boot Specification</a></li><li><a href=https://www.flatcar.org/docs/latest/provisioning/network-boot/>Flatcar Linux Provisioning with Matchbox</a></li><li><a href=https://coreos.github.io/ignition/>CoreOS Ignition Specification</a></li><li><a href=https://cloudinit.readthedocs.io/>Cloud-Init Documentation</a></li></ul><h3 id=related-adrs>Related ADRs</h3><ul><li><a href=./0002-network-boot-architecture/>ADR-0002: Network Boot Architecture</a> - Established cloud-hosted boot server with VPN</li><li><a href=./0003-cloud-provider-selection/>ADR-0003: Cloud Provider Selection</a> - Selected GCP as hosting provider</li><li><a href=./0001-use-madr-for-architecture-decision-records/>ADR-0001: Use MADR for Architecture Decision Records</a> - MADR format</li></ul><h3 id=future-considerations>Future Considerations</h3><ol><li><strong>High Availability</strong>: If boot server uptime becomes critical, evaluate multi-region deployment or failover strategies</li><li><strong>Multi-Cloud</strong>: If multi-cloud strategy emerges, custom implementation provides better portability</li><li><strong>Enterprise Features</strong>: If advanced provisioning workflows required (bare metal Kubernetes, Ignition support, etc.), evaluate adding features to custom implementation</li><li><strong>Asset Versioning</strong>: Implement comprehensive boot image versioning and rollback capabilities beyond basic Cloud Storage versioning</li><li><strong>Multi-Environment Support</strong>: Add support for multiple environments (dev, staging, prod) with environment-specific boot profiles</li></ol><h3 id=related-issues>Related Issues</h3><ul><li><a href=https://github.com/Zaba505/infra/issues/601>Issue #601</a> - story(docs): create adr for network boot infrastructure on google cloud</li><li><a href=https://github.com/Zaba505/infra/issues/595>Issue #595</a> - story(docs): create adr for network boot architecture</li><li><a href=https://github.com/Zaba505/infra/issues/597>Issue #597</a> - story(docs): create adr for cloud provider selection</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d234efec001fb7b9899c0a45bea1ae5d>2.6 - [0006] Universal Resource Identifier Standard</h1><div class=lead>Select a consistent resource identifier format to be used across all types of resources in the system for tracking, linking, and reference.</div><h2 id=context-and-problem-statement>Context and Problem Statement</h2><p>As the infrastructure and services grow, we need a consistent way to identify resources across different systems, databases, APIs, and logs. Resources include servers, VMs, containers, services, configurations, and any other trackable entities. Without a standardized identifier format, we risk inconsistencies in references, difficulty correlating logs and traces, and challenges in cross-system integration.</p><p>What identifier format should we standardize on for all resources to ensure uniqueness, readability, and compatibility across our entire infrastructure?</p><h2 id=decision-drivers>Decision Drivers</h2><ul><li>Global uniqueness across all resources and systems</li><li>Human readability for debugging and operational tasks</li><li>Compatibility with various systems (databases, URLs, file systems, logs)</li><li>Sortability and ability to extract creation time information</li><li>Low collision probability without coordination</li><li>Performance considerations for generation and storage</li><li>Industry standard practices and ecosystem tooling support</li></ul><h2 id=considered-options>Considered Options</h2><ul><li>UUIDv4 (Random UUID)</li><li>UUIDv7 (Time-ordered UUID)</li><li>ULID (Universally Unique Lexicographically Sortable Identifier)</li><li>Custom sequential IDs</li><li>Snowflake IDs</li></ul><h2 id=decision-outcome>Decision Outcome</h2><p>Chosen option: &ldquo;UUIDv7 (Time-ordered UUID)&rdquo;, because it provides the best balance of standardization, performance, and functionality. UUIDv7 maintains full UUID compatibility while addressing the major weaknesses of UUIDv4 (poor database index performance and lack of temporal ordering). As a new IETF standard (RFC 9562), it has growing ecosystem support and is becoming available in standard libraries, making it a future-proof choice.</p><h3 id=consequences>Consequences</h3><ul><li>Good, because time-ordered IDs improve database index performance and reduce fragmentation</li><li>Good, because sortability by creation time simplifies debugging and operational tasks</li><li>Good, because extractable timestamps provide valuable metadata without additional storage</li><li>Good, because full UUID compatibility ensures broad system and tool support</li><li>Good, because no coordination needed between distributed systems for generation</li><li>Good, because growing standard library support reduces dependency burden</li><li>Neutral, because migration from existing UUIDv4 identifiers will need to be managed incrementally</li><li>Bad, because not all systems have UUIDv7 support yet (requires library updates or polyfills)</li><li>Bad, because IDs are still 36 characters, less compact than alternatives like ULID</li></ul><h3 id=confirmation>Confirmation</h3><p>Implementation compliance will be confirmed by:</p><ul><li>Code reviews ensuring all new resource types use the standardized identifier format</li><li>Linting rules or code generation templates that enforce the identifier format</li><li>Documentation updates reflecting the standard identifier format</li><li>Database schema reviews to verify proper column types and indexing</li></ul><h2 id=pros-and-cons-of-the-options>Pros and Cons of the Options</h2><h3 id=uuidv4-random-uuid>UUIDv4 (Random UUID)</h3><p>Standard 128-bit random identifier following RFC 4122, format: <code>550e8400-e29b-41d4-a716-446655440000</code></p><ul><li>Good, because widely supported across all languages, databases, and systems</li><li>Good, because cryptographically random with extremely low collision probability</li><li>Good, because no coordination needed between systems for generation</li><li>Good, because standard library support in most languages</li><li>Neutral, because 36 characters (with hyphens) or 32 hex characters</li><li>Bad, because not time-ordered, leading to poor database index performance</li><li>Bad, because not sortable by creation time</li><li>Bad, because difficult for humans to read or verify</li><li>Bad, because provides no temporal information</li></ul><h3 id=uuidv7-time-ordered-uuid>UUIDv7 (Time-ordered UUID)</h3><p>Latest UUID standard (RFC 9562) with millisecond timestamp prefix, format: <code>018c7dbd-9265-7000-8000-123456789abc</code></p><ul><li>Good, because maintains UUID compatibility while adding time-ordering</li><li>Good, because better database index performance than UUIDv4 due to ordering</li><li>Good, because sortable by creation time (millisecond precision)</li><li>Good, because extractable timestamp for debugging</li><li>Good, because growing ecosystem support and standard library adoption</li><li>Good, because globally unique without coordination</li><li>Neutral, because same 36/32 character length as UUIDv4</li><li>Neutral, because newer standard, not yet universally supported in all systems</li><li>Bad, because still not particularly human-readable</li></ul><h3 id=ulid-universally-unique-lexicographically-sortable-identifier>ULID (Universally Unique Lexicographically Sortable Identifier)</h3><p>26-character base32 encoded identifier with millisecond timestamp, format: <code>01ARZ3NDEKTSV4RRFFQ69G5FAV</code></p><ul><li>Good, because lexicographically sortable by creation time</li><li>Good, because shorter than UUID (26 chars vs 36) making it more readable</li><li>Good, because case-insensitive base32 encoding avoids ambiguous characters</li><li>Good, because extractable millisecond timestamp</li><li>Good, because URL-safe without escaping</li><li>Good, because better database index performance due to ordering</li><li>Neutral, because requires library support (not in standard libraries yet)</li><li>Neutral, because growing adoption but not as universal as UUID</li><li>Bad, because not an official IETF standard (though widely used)</li><li>Bad, because 26 characters still not trivially human-memorable</li></ul><h3 id=custom-sequential-ids>Custom sequential IDs</h3><p>System-specific sequential numbering (e.g., <code>SRV-00001</code>, <code>VM-12345</code>)</p><ul><li>Good, because very human-readable and memorable</li><li>Good, because short and compact</li><li>Good, because naturally sortable</li><li>Bad, because requires centralized coordination for uniqueness</li><li>Bad, because difficult to merge or sync across distributed systems</li><li>Bad, because exposes information about total resource count</li><li>Bad, because not globally unique without namespace management</li><li>Bad, because potential security concerns (predictability, enumeration)</li></ul><h3 id=snowflake-ids>Snowflake IDs</h3><p>64-bit IDs with timestamp, datacenter, and sequence components (Twitter Snowflake pattern)</p><ul><li>Good, because compact 64-bit integer format</li><li>Good, because time-ordered and sortable</li><li>Good, because efficient storage and indexing</li><li>Good, because high performance generation</li><li>Neutral, because requires coordination for datacenter/worker IDs</li><li>Bad, because not human-readable (large integers)</li><li>Bad, because requires infrastructure for ID generation service</li><li>Bad, because 64-bit limit may be reached for very high-volume systems</li><li>Bad, because less portable across systems than string-based identifiers</li></ul><h2 id=more-information>More Information</h2><ul><li>UUIDv7 specification: RFC 9562 - <a href=https://datatracker.ietf.org/doc/html/rfc9562>https://datatracker.ietf.org/doc/html/rfc9562</a></li><li>UUIDv4 specification: RFC 4122 - <a href=https://datatracker.ietf.org/doc/html/rfc4122>https://datatracker.ietf.org/doc/html/rfc4122</a></li><li>ULID specification: <a href=https://github.com/ulid/spec>https://github.com/ulid/spec</a></li><li>Considerations for database indexing performance with different ID types</li><li>Impact on API design, URL structure, and client implementation</li><li>Migration strategy for existing resources using different identifier formats</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2c1965560a830318e2bbed312ba620ee>2.7 - [0007] Standard API Error Response Format</h1><div class=lead>Define a consistent error response structure for all API endpoints to improve client error handling and debugging</div><h2 id=context-and-problem-statement>Context and Problem Statement</h2><p>Currently, there is no standardized error response format across API endpoints in the infrastructure. This inconsistency makes it difficult for clients to handle errors uniformly, complicates debugging, and reduces the overall developer experience. How should we structure error responses to ensure consistency, provide adequate debugging information, and follow industry best practices?</p><h2 id=decision-drivers>Decision Drivers</h2><ul><li>Client needs consistent error parsing across all endpoints</li><li>Debugging requires sufficient context and error details</li><li>Security considerations (avoid leaking sensitive implementation details)</li><li>OpenAPI specification compatibility (services use OpenAPI-first design)</li><li>Machine-readable error codes for programmatic handling</li><li>Human-readable error messages for logging and debugging</li><li>Support for field-level validation errors</li><li>Alignment with REST/HTTP standards and industry practices</li></ul><h2 id=considered-options>Considered Options</h2><ul><li>RFC 7807 Problem Details (application/problem+json)</li><li>Custom structured error format with error codes</li><li>Simple error message string</li><li>Google API error response format (errors array)</li></ul><h2 id=decision-outcome>Decision Outcome</h2><p>Chosen option: &ldquo;RFC 7807 Problem Details (application/problem+json)&rdquo;, because it is an industry standard (RFC), provides extensibility, is widely supported by tooling and libraries, includes standard fields for error identification and debugging, and integrates well with OpenAPI specifications.</p><h3 id=consequences>Consequences</h3><ul><li>Good, because RFC 7807 is a well-established standard with broad ecosystem support</li><li>Good, because it provides a consistent structure with required and optional fields</li><li>Good, because it supports extensibility through custom properties</li><li>Good, because OpenAPI 3.x has native support for Problem Details via schemas</li><li>Good, because it includes both machine-readable (type) and human-readable (title, detail) information</li><li>Neutral, because it requires clients to handle a specific content type (application/problem+json)</li><li>Bad, because it adds slight complexity compared to simple error strings</li><li>Bad, because developers need to learn the RFC 7807 structure if unfamiliar</li></ul><h3 id=confirmation>Confirmation</h3><p>Implementation compliance will be confirmed through:</p><ol><li>OpenAPI schema definitions requiring RFC 7807 structure for error responses</li><li>Code review process ensuring endpoints use the standard error format</li><li>Integration tests validating error response structure and content type</li><li>Go service framework helpers/middleware to generate RFC 7807 responses</li></ol><h2 id=pros-and-cons-of-the-options>Pros and Cons of the Options</h2><h3 id=rfc-7807-problem-details-applicationproblemjson>RFC 7807 Problem Details (application/problem+json)</h3><p>RFC 7807 defines a standard JSON structure for HTTP API error responses with fields: <code>type</code> (URI reference), <code>title</code>, <code>status</code> (HTTP status code), <code>detail</code>, and <code>instance</code> (URI reference to specific occurrence).</p><ul><li>Good, because it is an IETF standard (RFC 7807) with wide industry adoption</li><li>Good, because it provides both machine-readable (<code>type</code>, <code>status</code>) and human-readable (<code>title</code>, <code>detail</code>) information</li><li>Good, because it supports extension fields for custom data (e.g., validation errors)</li><li>Good, because OpenAPI 3.x natively supports RFC 7807 schemas</li><li>Good, because many HTTP libraries and frameworks have built-in support</li><li>Good, because the <code>instance</code> field helps trace specific error occurrences</li><li>Neutral, because requires specific <code>Content-Type: application/problem+json</code> header</li><li>Bad, because it requires more implementation effort than simple error strings</li><li>Bad, because teams unfamiliar with RFC 7807 face a learning curve</li></ul><h3 id=custom-structured-error-format-with-error-codes>Custom structured error format with error codes</h3><p>Define a project-specific JSON error structure with custom fields like <code>error_code</code>, <code>message</code>, <code>details</code>, etc.</p><ul><li>Good, because it can be tailored exactly to project needs</li><li>Good, because it&rsquo;s flexible and can evolve with requirements</li><li>Good, because it avoids external standard dependencies</li><li>Neutral, because requires defining and documenting the structure</li><li>Bad, because it lacks ecosystem tooling and library support</li><li>Bad, because clients must learn a custom format instead of a standard</li><li>Bad, because it reinvents a solution that already exists as an RFC</li><li>Bad, because it&rsquo;s harder to integrate with standard OpenAPI tooling</li></ul><h3 id=simple-error-message-string>Simple error message string</h3><p>Return errors as plain text strings or simple JSON objects with a single <code>message</code> field.</p><ul><li>Good, because it is extremely simple to implement</li><li>Good, because it requires minimal client parsing logic</li><li>Good, because it has no learning curve</li><li>Neutral, because it works for very simple APIs</li><li>Bad, because it lacks structure for programmatic error handling</li><li>Bad, because it cannot distinguish between error types without parsing messages</li><li>Bad, because it provides no standard fields for HTTP status, error codes, or metadata</li><li>Bad, because it doesn&rsquo;t scale well for complex validation errors</li><li>Bad, because it complicates debugging without structured fields</li></ul><h3 id=google-api-error-response-format-errors-array>Google API error response format (errors array)</h3><p>Use Google&rsquo;s error response format with a top-level <code>error</code> object containing <code>code</code>, <code>message</code>, and an <code>errors</code> array with detailed error information.</p><ul><li>Good, because it is used by a major tech company (Google)</li><li>Good, because it supports multiple errors in a single response</li><li>Good, because it includes structured error details</li><li>Good, because it is well-documented in Google&rsquo;s API design guide</li><li>Neutral, because it is familiar to developers who use Google APIs</li><li>Bad, because it is not a formal standard (not an RFC)</li><li>Bad, because it has less ecosystem support than RFC 7807</li><li>Bad, because it duplicates HTTP status code in the JSON payload</li><li>Bad, because it requires custom schema definitions rather than using standard patterns</li></ul><h2 id=more-information>More Information</h2><h3 id=rfc-7807-example-response>RFC 7807 Example Response</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;https://api.example.com/errors/validation-error&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Validation Error&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;status&#34;</span><span class=p>:</span> <span class=mi>400</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;detail&#34;</span><span class=p>:</span> <span class=s2>&#34;The request body failed validation&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;instance&#34;</span><span class=p>:</span> <span class=s2>&#34;/api/v1/users/create&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;invalid_fields&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;field&#34;</span><span class=p>:</span> <span class=s2>&#34;email&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;reason&#34;</span><span class=p>:</span> <span class=s2>&#34;must be a valid email address&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=references>References</h3><ul><li>RFC 7807 - Problem Details for HTTP APIs: <a href=https://www.rfc-editor.org/rfc/rfc7807.html>https://www.rfc-editor.org/rfc/rfc7807.html</a></li><li>OpenAPI 3.x support for Problem Details</li><li>Go implementation libraries: <code>github.com/moogar0880/problems</code> or custom implementation</li><li>Related ADR: Resource Identifier Standard (0006) for <code>type</code> and <code>instance</code> URI patterns</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8c73fa9172ced19b5feab910bc9e7f1e>3 - Services</h1><div class=lead>Documentation for GCP Cloud Run microservices</div><p>This section contains documentation for the Go microservices deployed to GCP Cloud Run as part of the home lab infrastructure.</p><h2 id=service-architecture>Service Architecture</h2><p>All services follow a consistent architecture pattern:</p><ul><li><strong>Framework</strong>: Built using <code>z5labs/humus</code> framework with OpenAPI-first design</li><li><strong>Runtime</strong>: Go 1.24+ deployed to GCP Cloud Run</li><li><strong>Observability</strong>: OpenTelemetry metrics, traces, and logs</li><li><strong>Health Checks</strong>: Standard <code>/health/startup</code> and <code>/health/liveness</code> endpoints</li><li><strong>Configuration</strong>: Embedded <code>config.yaml</code> with OpenAPI specifications</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4ce2427a9523f0ff078049ecbd3abed9>3.1 - Boot Service</h1><div class=lead>UEFI HTTP boot endpoints and boot profile management</div><p>The Boot Service is a custom Go microservice that provides UEFI HTTP boot endpoints for bare metal servers and manages boot profiles. It serves boot scripts, streams kernel/initrd assets, and handles boot profile administration (kernel/initrd upload, storage, and lifecycle management).</p><h2 id=architecture-overview>Architecture Overview</h2><p>The Boot Service is deployed on GCP Cloud Run and accessed through a WireGuard VPN tunnel from bare metal servers. It integrates with:</p><ul><li><strong>Machine Service</strong>: Retrieves machine hardware profiles by MAC address</li><li><strong>Cloud Storage</strong>: Stores and retrieves kernel/initrd blobs</li><li><strong>Firestore</strong>: Stores boot profile metadata</li><li><strong>Cloud Monitoring</strong>: OpenTelemetry observability with distributed tracing</li></ul><h2 id=related-documentation>Related Documentation</h2><ul><li><a href=../machine-mgmt/>Machine Service</a> - Machine hardware profile management</li><li><a href=../../adrs/0005-network-boot-infrastructure-gcp/>ADR-0005: Network Boot Infrastructure Implementation on Google Cloud</a> - Architecture decision and design rationale</li><li><a href=../../adrs/0002-network-boot-architecture/>ADR-0002: Network Boot Architecture</a> - Overall network boot strategy</li></ul><h2 id=api-endpoints>API Endpoints</h2><h3 id=uefi-http-boot-endpoints>UEFI HTTP Boot Endpoints</h3><p>Accessed by bare metal servers during boot process (via WireGuard VPN):</p><ul><li><a href=./boot-ipxe/>GET /boot.ipxe</a> - Serves iPXE boot scripts customized for the requesting machine</li><li><a href=./asset-kernel/>GET /asset/{boot_profile_id}/kernel</a> - Streams kernel images from Cloud Storage</li><li><a href=./asset-initrd/>GET /asset/{boot_profile_id}/initrd</a> - Streams initrd images from Cloud Storage</li></ul><h3 id=admin-api>Admin API</h3><p>Boot profile management endpoints for administrators:</p><ul><li><a href=./post-profiles/>POST /api/v1/profiles</a> - Create a new boot profile for a machine</li><li><a href=./get-profile/>GET /api/v1/boot/{machine_id}/profile</a> - Retrieve the active boot profile for a machine</li><li><a href=./put-profile/>PUT /api/v1/boot/{machine_id}/profile</a> - Update the boot profile for a machine</li><li><a href=./delete-profile/>DELETE /api/v1/boot/{machine_id}/profile</a> - Delete a machine&rsquo;s boot profile</li></ul><h3 id=health-check-endpoints>Health Check Endpoints</h3><p>Standard Cloud Run health endpoints:</p><ul><li><a href=./health-startup/>GET /health/startup</a> - Startup probe endpoint</li><li><a href=./health-liveness/>GET /health/liveness</a> - Liveness probe endpoint</li></ul><h2 id=security-model>Security Model</h2><h3 id=vpn-based-access-control>VPN-Based Access Control</h3><p>Since HP DL360 Gen 9 servers do not support client-side TLS certificates for UEFI HTTP boot, all boot traffic is secured via WireGuard VPN:</p><ul><li><strong>Boot Endpoints</strong>: Only accessible through WireGuard tunnel (source IP validation)</li><li><strong>Transport Security</strong>: WireGuard provides mutual authentication and encryption</li></ul><h3 id=authentication-methods>Authentication Methods</h3><ul><li><strong>UEFI Boot Endpoints</strong>: VPN source IP validation (bare metal servers)</li><li><strong>Health Checks</strong>: Unauthenticated (used by Cloud Run for liveness/startup probes)</li></ul><h2 id=common-patterns>Common Patterns</h2><h3 id=error-responses>Error Responses</h3><p>All API endpoints follow the RFC 7807 Problem Details standard (see <a href=../../adrs/0007-standard-api-error-response/>ADR-0007</a>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;https://api.example.com/errors/resource-not-found&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Resource Not Found&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;status&#34;</span><span class=p>:</span> <span class=mi>404</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;detail&#34;</span><span class=p>:</span> <span class=s2>&#34;Machine with MAC address aa:bb:cc:dd:ee:ff not found&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;instance&#34;</span><span class=p>:</span> <span class=s2>&#34;/api/v1/boot/aa:bb:cc:dd:ee:ff/profile&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;mac_address&#34;</span><span class=p>:</span> <span class=s2>&#34;aa:bb:cc:dd:ee:ff&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Error responses use <code>Content-Type: application/problem+json</code>.</p><h3 id=standard-http-status-codes>Standard HTTP Status Codes</h3><ul><li><code>200 OK</code> - Successful request</li><li><code>201 Created</code> - Resource created successfully</li><li><code>204 No Content</code> - Successful deletion</li><li><code>400 Bad Request</code> - Invalid request parameters</li><li><code>401 Unauthorized</code> - Missing or invalid authentication</li><li><code>403 Forbidden</code> - Insufficient permissions</li><li><code>404 Not Found</code> - Resource not found</li><li><code>409 Conflict</code> - Resource already exists</li><li><code>422 Unprocessable Entity</code> - Validation error</li><li><code>500 Internal Server Error</code> - Server error</li></ul><h3 id=content-types>Content Types</h3><ul><li><code>application/json</code> - JSON responses (admin API)</li><li><code>application/problem+json</code> - RFC 7807 error responses</li><li><code>text/plain</code> - iPXE boot scripts</li><li><code>application/octet-stream</code> - Binary boot assets (kernel, initrd)</li><li><code>text/cloud-config</code> - Cloud-init configuration files</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-45291fef6ecf8bf28903c56a01df0197>3.1.1 - GET /boot.ipxe</h1><div class=lead>Serves iPXE boot scripts customized for the requesting machine</div><p>Serves iPXE boot scripts customized for the requesting machine based on its MAC address. This endpoint is accessed by bare metal servers (HP DL360 Gen 9) during the UEFI HTTP boot process through the WireGuard VPN tunnel.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Bare Metal Server
    participant Boot as Boot Service
    participant MachineAPI as Machine Service
    participant DB as Firestore

    Client-&gt;&gt;Boot: GET /boot.ipxe?mac=52:54:00:12:34:56
    Boot-&gt;&gt;Boot: Validate MAC address format
    Boot-&gt;&gt;MachineAPI: GET /api/v1/machines?mac=52:54:00:12:34:56
    MachineAPI-&gt;&gt;DB: Query machine by NIC MAC
    DB--&gt;&gt;MachineAPI: Machine profile (machine_id)
    MachineAPI--&gt;&gt;Boot: Machine profile
    Boot-&gt;&gt;DB: Query boot profile by machine_id
    DB--&gt;&gt;Boot: Boot profile (profile_id, kernel_id, initrd_id, kernel args)
    Boot-&gt;&gt;Boot: Generate iPXE script with profile_id
    Boot--&gt;&gt;Client: 200 OK (iPXE script)</pre><h2 id=request>Request</h2><p><strong>Query Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>mac</code></td><td>string</td><td>Yes</td><td>MAC address of the requesting machine (format: <code>aa:bb:cc:dd:ee:ff</code>)</td></tr></tbody></table><p><strong>Request Example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/boot.ipxe?mac=52:54:00:12:34:56</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.internal</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response Example (200 OK):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>#!ipxe
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># Boot configuration for node-01 (52:54:00:12:34:56)
</span></span><span class=line><span class=cl># Boot Profile ID: 018c7dbd-a1b2-7000-8000-987654321def
</span></span><span class=line><span class=cl># Generated: 2025-11-19T06:00:00Z
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>kernel /asset/018c7dbd-a1b2-7000-8000-987654321def/kernel console=tty0 console=ttyS0 ip=dhcp
</span></span><span class=line><span class=cl>initrd /asset/018c7dbd-a1b2-7000-8000-987654321def/initrd
</span></span><span class=line><span class=cl>boot
</span></span></code></pre></div><p><strong>Response Headers:</strong></p><ul><li><code>Content-Type: text/plain; charset=utf-8</code></li><li><code>Cache-Control: no-cache, no-store, must-revalidate</code></li></ul><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>400 Bad Request</td><td>Missing or invalid MAC address</td><td><code>{"error": {"code": "INVALID_MAC_ADDRESS", "message": "MAC address must be in format aa:bb:cc:dd:ee:ff"}}</code></td></tr><tr><td>404 Not Found</td><td>No boot configuration found for MAC</td><td><code>{"error": {"code": "MACHINE_NOT_CONFIGURED", "message": "No boot configuration found for MAC 52:54:00:12:34:56"}}</code></td></tr><tr><td>500 Internal Server Error</td><td>Database or template error</td><td><code>{"error": {"code": "INTERNAL_ERROR", "message": "Failed to generate boot script"}}</code></td></tr></tbody></table><h2 id=boot-script-variables>Boot Script Variables</h2><p>The iPXE script may include the following dynamic values:</p><ul><li>Machine-specific kernel parameters</li><li>Asset download URLs (using boot profile ID format)</li><li>Network configuration parameters</li></ul><h2 id=security-considerations>Security Considerations</h2><h3 id=vpn-source-ip-validation>VPN Source IP Validation</h3><p>All boot endpoints validate that requests originate from the WireGuard VPN subnet:</p><ul><li><strong>Allowed CIDR</strong>: <code>10.x.x.0/24</code> (WireGuard VPN network)</li><li><strong>Validation</strong>: Performed at Cloud Run ingress or application layer</li><li><strong>Rejection</strong>: Requests from outside VPN return <code>403 Forbidden</code></li></ul><h3 id=rate-limiting>Rate Limiting</h3><p>To prevent abuse, boot endpoints are rate-limited:</p><ul><li><strong>Boot Script</strong>: 10 requests/minute per MAC address</li></ul><h2 id=observability>Observability</h2><p>All boot endpoint requests are instrumented with OpenTelemetry following HTTP semantic conventions:</p><ul><li><strong>Metrics</strong>: OpenTelemetry HTTP server metrics (request count, duration, size)<ul><li><code>http.server.request.duration</code> - Request duration histogram</li><li><code>http.server.request.body.size</code> - Request body size</li><li><code>http.server.response.body.size</code> - Response body size</li></ul></li><li><strong>Traces</strong>: End-to-end tracing from request to database retrieval<ul><li>HTTP server span captures request details (method, route, status code)</li><li>Child spans for database queries and Machine Service API calls</li></ul></li><li><strong>Logs</strong>: Structured logs with MAC address, boot profile ID, response status</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-49010b536d53c75102b246a30e774cb6>3.1.2 - GET /asset/{boot_profile_id}/kernel</h1><div class=lead>Streams kernel images from Cloud Storage for the boot process</div><p>Streams kernel images from Cloud Storage for the boot process. This endpoint is accessed by bare metal servers during UEFI HTTP boot through the WireGuard VPN tunnel.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Bare Metal Server
    participant Boot as Boot Service
    participant Storage as Cloud Storage
    participant DB as Firestore

    Client-&gt;&gt;Boot: GET /asset/018c7dbd-a1b2-7000-8000-987654321def/kernel
    Boot-&gt;&gt;Boot: Validate UUIDv7 format
    Boot-&gt;&gt;DB: Query boot profile by ID
    DB--&gt;&gt;Boot: Boot profile (kernel_id)
    Boot-&gt;&gt;Storage: GET gs://bucket/blobs/{kernel_id}
    Storage--&gt;&gt;Boot: Kernel data stream
    Boot--&gt;&gt;Client: 200 OK (kernel stream)</pre><h2 id=request>Request</h2><p><strong>Path Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>boot_profile_id</code></td><td>string (UUIDv7)</td><td>Yes</td><td>Boot profile identifier (UUIDv7 format: <code>018c7dbd-a1b2-7000-8000-987654321def</code>)</td></tr></tbody></table><p><strong>Request Example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/asset/018c7dbd-a1b2-7000-8000-987654321def/kernel</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.internal</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response Example (200 OK):</strong></p><p>Binary kernel image streamed from Cloud Storage.</p><p><strong>Response Headers:</strong></p><ul><li><code>Content-Type: application/octet-stream</code></li><li><code>Content-Length: 8388608</code> (actual kernel size in bytes)</li><li><code>Cache-Control: public, max-age=3600</code></li><li><code>ETag: "abc123..."</code></li></ul><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>404 Not Found</td><td>Kernel image not found</td><td><code>{"error": {"code": "KERNEL_NOT_FOUND", "message": "Kernel image not found for boot profile"}}</code></td></tr><tr><td>500 Internal Server Error</td><td>Cloud Storage error</td><td><code>{"error": {"code": "STORAGE_ERROR", "message": "Failed to retrieve kernel from storage"}}</code></td></tr></tbody></table><h2 id=performance-characteristics>Performance Characteristics</h2><ul><li><strong>Streaming</strong>: File is streamed directly from Cloud Storage (no buffering in memory)</li><li><strong>Target Latency</strong>: &lt; 100ms to first byte</li><li><strong>Typical Size</strong>: 8-15 MB for Linux kernels</li></ul><h2 id=security-considerations>Security Considerations</h2><h3 id=vpn-source-ip-validation>VPN Source IP Validation</h3><p>All boot endpoints validate that requests originate from the WireGuard VPN subnet:</p><ul><li><strong>Allowed CIDR</strong>: <code>10.x.x.0/24</code> (WireGuard VPN network)</li><li><strong>Validation</strong>: Performed at Cloud Run ingress or application layer</li><li><strong>Rejection</strong>: Requests from outside VPN return <code>403 Forbidden</code></li></ul><h3 id=rate-limiting>Rate Limiting</h3><p>To prevent abuse, asset download endpoints are rate-limited:</p><ul><li><strong>Asset Downloads</strong>: 5 concurrent downloads per MAC address</li></ul><h3 id=asset-integrity>Asset Integrity</h3><p>Boot assets are validated for integrity:</p><ul><li><strong>Checksums</strong>: SHA-256 checksums stored in Firestore</li><li><strong>Verification</strong>: Computed on upload, verified on download (optional)</li><li><strong>ETag Headers</strong>: Enable client-side caching and integrity checks</li></ul><h2 id=observability>Observability</h2><p>All boot endpoint requests are instrumented with OpenTelemetry following HTTP semantic conventions:</p><ul><li><strong>Metrics</strong>: OpenTelemetry HTTP server metrics<ul><li><code>http.server.request.duration</code> - Request duration histogram</li><li><code>http.server.response.body.size</code> - Response body size (tracks bytes transferred)</li></ul></li><li><strong>Traces</strong>: End-to-end tracing from request to Cloud Storage retrieval<ul><li>HTTP server span captures request details (method, route, status code)</li><li>Child spans for database queries and Cloud Storage operations</li></ul></li><li><strong>Logs</strong>: Structured logs with boot profile ID, kernel ID, response status</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-5874d39e2aede664368cbb3c16dfb190>3.1.3 - GET /asset/{boot_profile_id}/initrd</h1><div class=lead>Streams initial ramdisk images from Cloud Storage for the boot process</div><p>Streams initial ramdisk (initrd) images from Cloud Storage for the boot process. This endpoint is accessed by bare metal servers during UEFI HTTP boot through the WireGuard VPN tunnel.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Bare Metal Server
    participant Boot as Boot Service
    participant Storage as Cloud Storage
    participant DB as Firestore

    Client-&gt;&gt;Boot: GET /asset/018c7dbd-a1b2-7000-8000-987654321def/initrd
    Boot-&gt;&gt;Boot: Validate UUIDv7 format
    Boot-&gt;&gt;DB: Query boot profile by ID
    DB--&gt;&gt;Boot: Boot profile (initrd_id)
    Boot-&gt;&gt;Storage: GET gs://bucket/blobs/{initrd_id}
    Storage--&gt;&gt;Boot: Initrd data stream
    Boot--&gt;&gt;Client: 200 OK (initrd stream)</pre><h2 id=request>Request</h2><p><strong>Path Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>boot_profile_id</code></td><td>string (UUIDv7)</td><td>Yes</td><td>Boot profile identifier (UUIDv7 format: <code>018c7dbd-a1b2-7000-8000-987654321def</code>)</td></tr></tbody></table><p><strong>Request Example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/asset/018c7dbd-a1b2-7000-8000-987654321def/initrd</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.internal</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response Example (200 OK):</strong></p><p>Binary initrd image streamed from Cloud Storage.</p><p><strong>Response Headers:</strong></p><ul><li><code>Content-Type: application/octet-stream</code></li><li><code>Content-Length: 52428800</code> (actual initrd size in bytes)</li><li><code>Cache-Control: public, max-age=3600</code></li><li><code>ETag: "def456..."</code></li></ul><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>404 Not Found</td><td>Initrd image not found</td><td><code>{"error": {"code": "INITRD_NOT_FOUND", "message": "Initrd image not found for boot profile"}}</code></td></tr><tr><td>500 Internal Server Error</td><td>Cloud Storage error</td><td><code>{"error": {"code": "STORAGE_ERROR", "message": "Failed to retrieve initrd from storage"}}</code></td></tr></tbody></table><h2 id=performance-characteristics>Performance Characteristics</h2><ul><li><strong>Streaming</strong>: File is streamed directly from Cloud Storage (no buffering in memory)</li><li><strong>Target Latency</strong>: &lt; 100ms to first byte</li><li><strong>Typical Size</strong>: 50-150 MB for Linux initrd images</li></ul><h2 id=security-considerations>Security Considerations</h2><h3 id=vpn-source-ip-validation>VPN Source IP Validation</h3><p>All boot endpoints validate that requests originate from the WireGuard VPN subnet:</p><ul><li><strong>Allowed CIDR</strong>: <code>10.x.x.0/24</code> (WireGuard VPN network)</li><li><strong>Validation</strong>: Performed at Cloud Run ingress or application layer</li><li><strong>Rejection</strong>: Requests from outside VPN return <code>403 Forbidden</code></li></ul><h3 id=rate-limiting>Rate Limiting</h3><p>To prevent abuse, asset download endpoints are rate-limited:</p><ul><li><strong>Asset Downloads</strong>: 5 concurrent downloads per MAC address</li></ul><h3 id=asset-integrity>Asset Integrity</h3><p>Boot assets are validated for integrity:</p><ul><li><strong>Checksums</strong>: SHA-256 checksums stored in Firestore</li><li><strong>Verification</strong>: Computed on upload, verified on download (optional)</li><li><strong>ETag Headers</strong>: Enable client-side caching and integrity checks</li></ul><h2 id=observability>Observability</h2><p>All boot endpoint requests are instrumented with OpenTelemetry following HTTP semantic conventions:</p><ul><li><strong>Metrics</strong>: OpenTelemetry HTTP server metrics<ul><li><code>http.server.request.duration</code> - Request duration histogram</li><li><code>http.server.response.body.size</code> - Response body size (tracks bytes transferred)</li></ul></li><li><strong>Traces</strong>: End-to-end tracing from request to Cloud Storage retrieval<ul><li>HTTP server span captures request details (method, route, status code)</li><li>Child spans for database queries and Cloud Storage operations</li></ul></li><li><strong>Logs</strong>: Structured logs with boot profile ID, initrd ID, response status</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-a68897d6c4ed5365b996f10a697552e4>3.1.4 - POST /api/v1/profiles</h1><div class=lead>Create a new boot profile for a machine</div><p>Create a new boot profile for a machine. If the machine already has a boot profile, this operation will fail - use PUT to update instead.</p><h2 id=cloud-storage-structure>Cloud Storage Structure</h2><p>Kernel and initrd binaries are stored in Google Cloud Storage using their UUIDv7 identifiers as object keys:</p><pre tabindex=0><code>gs://{bucket}/blobs/{kernel_id}
gs://{bucket}/blobs/{initrd_id}
</code></pre><p>For example:</p><pre tabindex=0><code>gs://boot-server-blobs/blobs/018c7dbd-b100-7000-8000-123456789abc
gs://boot-server-blobs/blobs/018c7dbd-b200-7000-8000-987654321fed
</code></pre><p>The UUIDv7 identifiers are generated server-side during upload, ensuring:</p><ul><li>Globally unique object keys</li><li>Time-ordered storage (UUIDv7 timestamp prefix)</li><li>No namespace collisions between profiles</li></ul><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant Boot as Boot Service
    participant Machine as Machine Service
    participant Storage as Cloud Storage
    participant DB as Firestore

    Client-&gt;&gt;Boot: POST /api/v1/profiles (multipart/form-data)
    Boot-&gt;&gt;DB: Check if machine already has a boot profile
    DB--&gt;&gt;Boot: No existing profile
    Boot-&gt;&gt;Machine: GET /api/v1/machines/{machine_id}
    Machine-&gt;&gt;DB: Query machine by ID
    DB--&gt;&gt;Machine: Machine profile
    Machine--&gt;&gt;Boot: Machine profile
    Boot-&gt;&gt;Boot: Generate UUIDv7 for profile
    Boot-&gt;&gt;Boot: Generate UUIDv7 for kernel blob
    Boot-&gt;&gt;Boot: Generate UUIDv7 for initrd blob
    Boot-&gt;&gt;Storage: PUT gs://bucket/blobs/{kernel_id}
    Storage--&gt;&gt;Boot: Kernel stored
    Boot-&gt;&gt;Storage: PUT gs://bucket/blobs/{initrd_id}
    Storage--&gt;&gt;Boot: Initrd stored
    Boot-&gt;&gt;DB: Store profile metadata (profile_id, kernel_id, initrd_id, machine_id)
    DB--&gt;&gt;Boot: Profile created
    Boot--&gt;&gt;Client: 201 Created (profile metadata with IDs)</pre><h2 id=request>Request</h2><p><strong>Request Body (multipart/form-data):</strong></p><p>Form fields:</p><ul><li><code>machine_id</code> (text): Machine identifier (UUIDv7)</li><li><code>kernel</code> (file): Kernel image file</li><li><code>initrd</code> (file): Initrd image file</li><li><code>kernel_args</code> (JSON array): Kernel command-line arguments</li></ul><p><strong>Example Request:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>POST</span> <span class=nn>/api/v1/profiles</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.example.com</span>
</span></span><span class=line><span class=cl><span class=n>Content-Type</span><span class=o>:</span> <span class=l>multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW
</span></span><span class=line><span class=cl>Content-Disposition: form-data; name=&#34;machine_id&#34;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>018c7dbd-c000-7000-8000-fedcba987654
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW
</span></span><span class=line><span class=cl>Content-Disposition: form-data; name=&#34;kernel&#34;; filename=&#34;vmlinuz&#34;
</span></span><span class=line><span class=cl>Content-Type: application/octet-stream
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;kernel binary data&gt;
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW
</span></span><span class=line><span class=cl>Content-Disposition: form-data; name=&#34;initrd&#34;; filename=&#34;initrd.img&#34;
</span></span><span class=line><span class=cl>Content-Type: application/octet-stream
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;initrd binary data&gt;
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW
</span></span><span class=line><span class=cl>Content-Disposition: form-data; name=&#34;kernel_args&#34;
</span></span><span class=line><span class=cl>Content-Type: application/json
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[&#34;console=tty0&#34;, &#34;console=ttyS0&#34;, &#34;ip=dhcp&#34;]
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW--
</span></span></code></pre></div><p><strong>Request Headers:</strong></p><ul><li><code>Content-Type: multipart/form-data</code></li></ul><h2 id=response>Response</h2><p><strong>Response (201 Created):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-a000-7000-8000-abcdef123456&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;machine_id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-c000-7000-8000-fedcba987654&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;kernel&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-b100-7000-8000-123456789abc&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;args&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;console=tty0&#34;</span><span class=p>,</span> <span class=s2>&#34;console=ttyS0&#34;</span><span class=p>,</span> <span class=s2>&#34;ip=dhcp&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;initrd&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-b200-7000-8000-987654321fed&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th></tr></thead><tbody><tr><td>400 Bad Request</td><td>Invalid request body or missing required fields</td></tr><tr><td>409 Conflict</td><td>Machine already has a boot profile (use PUT to update)</td></tr><tr><td>422 Unprocessable Entity</td><td>Validation error (file too large, invalid JSON, machine_id not found)</td></tr></tbody></table><h2 id=data-models>Data Models</h2><p>All data models are defined as Protocol Buffer (protobuf) messages and stored in Firestore.</p><h3 id=boot-profile>Boot Profile</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-protobuf data-lang=protobuf><span class=line><span class=cl><span class=n>syntax</span> <span class=o>=</span> <span class=s>&#34;proto3&#34;</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>Kernel</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>string</span> <span class=n>id</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>              <span class=c1>// UUIDv7 blob identifier
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=k>repeated</span> <span class=kt>string</span> <span class=n>args</span> <span class=o>=</span> <span class=mi>2</span><span class=p>;</span>   <span class=c1>// Kernel command-line arguments
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>Initrd</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>string</span> <span class=n>id</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>              <span class=c1>// UUIDv7 blob identifier
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>BootProfile</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>string</span> <span class=n>id</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>              <span class=c1>// UUIDv7 identifier
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>string</span> <span class=n>machine_id</span> <span class=o>=</span> <span class=mi>2</span><span class=p>;</span>      <span class=c1>// Reference to machine (UUIDv7) - unique constraint
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=n>Kernel</span> <span class=n>kernel</span> <span class=o>=</span> <span class=mi>3</span><span class=p>;</span>          <span class=c1>// Kernel configuration
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=n>Initrd</span> <span class=n>initrd</span> <span class=o>=</span> <span class=mi>4</span><span class=p>;</span>          <span class=c1>// Initrd configuration
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span><span class=err>
</span></span></span></code></pre></div><p><strong>Note</strong>: The <code>machine_id</code> field has a unique constraint in Firestore, ensuring each machine has exactly one active boot profile.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c820ed2058fb4588fc0c6b0b04c9d922>3.1.5 - GET /api/v1/boot/{machine_id}/profile</h1><div class=lead>Retrieve the active boot profile for a specific machine</div><p>Retrieve the active boot profile for a specific machine.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant Boot as Boot Service
    participant DB as Firestore

    Client-&gt;&gt;Boot: GET /api/v1/boot/{machine_id}/profile
    Boot-&gt;&gt;DB: Query active boot profile for machine
    DB--&gt;&gt;Boot: Boot profile
    Boot--&gt;&gt;Client: 200 OK (boot profile)</pre><h2 id=request>Request</h2><p><strong>Path Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>machine_id</code></td><td>string</td><td>Yes</td><td>Machine identifier (UUIDv7 format)</td></tr></tbody></table><p><strong>Example Request:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/api/v1/boot/018c7dbd-c000-7000-8000-fedcba987654/profile</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.example.com</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (200 OK):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-a000-7000-8000-abcdef123456&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;machine_id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-c000-7000-8000-fedcba987654&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;kernel&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-b100-7000-8000-123456789abc&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;args&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;console=tty0&#34;</span><span class=p>,</span> <span class=s2>&#34;console=ttyS0&#34;</span><span class=p>,</span> <span class=s2>&#34;ip=dhcp&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;initrd&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-b200-7000-8000-987654321fed&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th></tr></thead><tbody><tr><td>404 Not Found</td><td>Machine not found or has no boot profile</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-24acd1badff3bbd194cd6cb31d3500cd>3.1.6 - PUT /api/v1/boot/{machine_id}/profile</h1><div class=lead>Update the boot profile for a machine</div><p>Update the boot profile for a machine (replaces the existing profile).</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant Boot as Boot Service
    participant Storage as Cloud Storage
    participant DB as Firestore

    Client-&gt;&gt;Boot: PUT /api/v1/boot/{machine_id}/profile
    Boot-&gt;&gt;DB: Get current active profile
    DB--&gt;&gt;Boot: Current profile (old kernel_id, old initrd_id)
    Boot-&gt;&gt;Boot: Generate UUIDs for new kernel/initrd
    Boot-&gt;&gt;Storage: PUT new kernel/initrd blobs
    Storage--&gt;&gt;Boot: Blobs stored
    Boot-&gt;&gt;DB: Update boot profile (replace kernel_id, initrd_id, args)
    DB--&gt;&gt;Boot: Profile updated
    Boot-&gt;&gt;Storage: DELETE old kernel/initrd blobs
    Boot--&gt;&gt;Client: 200 OK (updated profile)</pre><h2 id=request>Request</h2><p><strong>Path Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>machine_id</code></td><td>string</td><td>Yes</td><td>Machine identifier (UUIDv7 format)</td></tr></tbody></table><p><strong>Request Body (multipart/form-data):</strong></p><p>Form fields:</p><ul><li><code>kernel</code> (file): Kernel image file</li><li><code>initrd</code> (file): Initrd image file</li><li><code>kernel_args</code> (JSON array): Kernel command-line arguments</li></ul><p><strong>Example Request:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>PUT</span> <span class=nn>/api/v1/boot/018c7dbd-c000-7000-8000-fedcba987654/profile</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.example.com</span>
</span></span><span class=line><span class=cl><span class=n>Content-Type</span><span class=o>:</span> <span class=l>multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW
</span></span><span class=line><span class=cl>Content-Disposition: form-data; name=&#34;kernel&#34;; filename=&#34;vmlinuz&#34;
</span></span><span class=line><span class=cl>Content-Type: application/octet-stream
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;kernel binary data&gt;
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW
</span></span><span class=line><span class=cl>Content-Disposition: form-data; name=&#34;initrd&#34;; filename=&#34;initrd.img&#34;
</span></span><span class=line><span class=cl>Content-Type: application/octet-stream
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>&lt;initrd binary data&gt;
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW
</span></span><span class=line><span class=cl>Content-Disposition: form-data; name=&#34;kernel_args&#34;
</span></span><span class=line><span class=cl>Content-Type: application/json
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[&#34;console=tty0&#34;, &#34;console=ttyS0&#34;, &#34;ip=dhcp&#34;]
</span></span><span class=line><span class=cl>------WebKitFormBoundary7MA4YWxkTrZu0gW--
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (200 OK):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-a000-7000-8000-abcdef123456&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;machine_id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-c000-7000-8000-fedcba987654&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;kernel&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-b100-7000-8000-123456789abc&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;args&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;console=tty0&#34;</span><span class=p>,</span> <span class=s2>&#34;console=ttyS0&#34;</span><span class=p>,</span> <span class=s2>&#34;ip=dhcp&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;initrd&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-b200-7000-8000-987654321fed&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th></tr></thead><tbody><tr><td>404 Not Found</td><td>Machine not found or has no boot profile</td></tr><tr><td>422 Unprocessable Entity</td><td>Validation error</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-7cfea44dc34c48588b9295791a22e7b8>3.1.7 - DELETE /api/v1/boot/{machine_id}/profile</h1><div class=lead>Delete a machine&rsquo;s boot profile and its associated blobs</div><p>Delete a machine&rsquo;s boot profile and its associated blobs.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant Boot as Boot Service
    participant Storage as Cloud Storage
    participant DB as Firestore

    Client-&gt;&gt;Boot: DELETE /api/v1/boot/{machine_id}/profile
    Boot-&gt;&gt;DB: Get kernel_id and initrd_id
    DB--&gt;&gt;Boot: Blob IDs
    Boot-&gt;&gt;Storage: DELETE gs://bucket/blobs/{kernel_id}
    Boot-&gt;&gt;Storage: DELETE gs://bucket/blobs/{initrd_id}
    Boot-&gt;&gt;DB: Delete boot profile
    Boot--&gt;&gt;Client: 204 No Content</pre><h2 id=request>Request</h2><p><strong>Path Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>machine_id</code></td><td>string</td><td>Yes</td><td>Machine identifier (UUIDv7 format)</td></tr></tbody></table><p><strong>Example Request:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>DELETE</span> <span class=nn>/api/v1/boot/018c7dbd-c000-7000-8000-fedcba987654/profile</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.example.com</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (204 No Content):</strong></p><p>Empty response body.</p><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th></tr></thead><tbody><tr><td>404 Not Found</td><td>Machine not found or has no boot profile</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-4f0fd89b3946db2c7d5ec65a6880347c>3.1.8 - GET /health/startup</h1><div class=lead>Startup probe endpoint for Cloud Run</div><p>Indicates whether the application has completed initialization and is ready to receive traffic.</p><h2 id=request>Request</h2><p><strong>Request Example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/health/startup</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.example.com</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (200 OK):</strong></p><p>Empty response body with HTTP 200 status code.</p><p><strong>Response (503 Service Unavailable):</strong></p><p>Empty response body with HTTP 503 status code.</p><p><strong>Response Headers:</strong></p><ul><li><code>Cache-Control: no-cache, no-store, must-revalidate</code></li></ul><h2 id=startup-check-components>Startup Check Components</h2><ol><li><strong>Firestore Connection</strong> - Verifies database connectivity</li><li><strong>Cloud Storage Access</strong> - Validates access to boot image buckets</li></ol><h2 id=cloud-run-configuration>Cloud Run Configuration</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>startupProbe</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>httpGet</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/health/startup</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>port</span><span class=p>:</span><span class=w> </span><span class=m>8080</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>initialDelaySeconds</span><span class=p>:</span><span class=w> </span><span class=m>0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>timeoutSeconds</span><span class=p>:</span><span class=w> </span><span class=m>30</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>periodSeconds</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>failureThreshold</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span></code></pre></div><h2 id=behavior>Behavior</h2><ul><li><strong>Success (200)</strong>: Application is fully initialized and ready to serve requests</li><li><strong>Failure (503)</strong>: Application is still starting up or encountered initialization errors</li><li><strong>Timeout</strong>: After 30 seconds of no response, Cloud Run considers startup failed</li></ul><h2 id=observability>Observability</h2><p><strong>Metrics:</strong></p><ul><li><code>health_check_total{probe="startup",status="ok"}</code> - Successful startup checks</li><li><code>health_check_total{probe="startup",status="error"}</code> - Failed startup checks</li><li><code>health_check_duration_ms{probe="startup"}</code> - Startup check duration</li></ul><p><strong>Structured Logs:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;severity&#34;</span><span class=p>:</span> <span class=s2>&#34;INFO&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2025-11-19T06:00:00Z&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;message&#34;</span><span class=p>:</span> <span class=s2>&#34;Health check completed&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;probe&#34;</span><span class=p>:</span> <span class=s2>&#34;startup&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;status&#34;</span><span class=p>:</span> <span class=s2>&#34;ok&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;duration_ms&#34;</span><span class=p>:</span> <span class=mi>15</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Alerts:</strong></p><ul><li><strong>Startup Failure</strong>: Alert if startup check fails for > 1 minute</li></ul><h2 id=testing>Testing</h2><h3 id=manual-testing>Manual Testing</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -v http://localhost:8080/health/startup
</span></span></code></pre></div><h3 id=automated-testing>Automated Testing</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span><span class=w> </span><span class=nf>TestHealthStartup</span><span class=p>(</span><span class=nx>t</span><span class=w> </span><span class=o>*</span><span class=nx>testing</span><span class=p>.</span><span class=nx>T</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nx>resp</span><span class=p>,</span><span class=w> </span><span class=nx>err</span><span class=w> </span><span class=o>:=</span><span class=w> </span><span class=nx>http</span><span class=p>.</span><span class=nf>Get</span><span class=p>(</span><span class=s>&#34;http://localhost:8080/health/startup&#34;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nx>require</span><span class=p>.</span><span class=nf>NoError</span><span class=p>(</span><span class=nx>t</span><span class=p>,</span><span class=w> </span><span class=nx>err</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>defer</span><span class=w> </span><span class=nx>resp</span><span class=p>.</span><span class=nx>Body</span><span class=p>.</span><span class=nf>Close</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nx>assert</span><span class=p>.</span><span class=nf>Equal</span><span class=p>(</span><span class=nx>t</span><span class=p>,</span><span class=w> </span><span class=nx>http</span><span class=p>.</span><span class=nx>StatusOK</span><span class=p>,</span><span class=w> </span><span class=nx>resp</span><span class=p>.</span><span class=nx>StatusCode</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><h2 id=troubleshooting>Troubleshooting</h2><h3 id=startup-check-never-succeeds>Startup Check Never Succeeds</h3><p><strong>Symptoms:</strong></p><ul><li>Container restarts repeatedly</li><li>Cloud Run shows &ldquo;unhealthy&rdquo; status</li><li>Startup probe returns 503</li></ul><p><strong>Debugging:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Check Cloud Run logs for startup errors</span>
</span></span><span class=line><span class=cl>gcloud logging <span class=nb>read</span> <span class=s2>&#34;resource.type=cloud_run_revision AND labels.service_name=boot-server&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --limit <span class=m>50</span> --format json <span class=p>|</span> jq <span class=s1>&#39;.[] | select(.jsonPayload.probe==&#34;startup&#34;)&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Test locally with debug logging</span>
</span></span><span class=line><span class=cl><span class=nv>DEBUG</span><span class=o>=</span><span class=nb>true</span> go run main.go
</span></span></code></pre></div><p><strong>Common Causes:</strong></p><ul><li>Firestore credentials not configured</li><li>Cloud Storage bucket permissions missing</li><li>Network connectivity issues</li><li>Timeout too short for slow dependencies</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c0c1465faa50c9fac75d82a69edfcd31>3.1.9 - GET /health/liveness</h1><div class=lead>Liveness probe endpoint for Cloud Run</div><p>Indicates whether the application is alive and healthy. Used by Cloud Run to detect and restart unhealthy instances.</p><h2 id=request>Request</h2><p><strong>Request Example:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/health/liveness</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>boot.example.com</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (200 OK):</strong></p><p>Empty response body with HTTP 200 status code.</p><p><strong>Response (503 Service Unavailable):</strong></p><p>Empty response body with HTTP 503 status code.</p><p><strong>Response Headers:</strong></p><ul><li><code>Cache-Control: no-cache, no-store, must-revalidate</code></li></ul><h2 id=liveness-check-components>Liveness Check Components</h2><ol><li><strong>HTTP Server Health</strong> - Verifies the HTTP server is responsive</li><li><strong>Basic health validation</strong> - Ensures the application can handle requests</li></ol><h2 id=cloud-run-configuration>Cloud Run Configuration</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>livenessProbe</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>httpGet</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/health/liveness</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>port</span><span class=p>:</span><span class=w> </span><span class=m>8080</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>initialDelaySeconds</span><span class=p>:</span><span class=w> </span><span class=m>0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>timeoutSeconds</span><span class=p>:</span><span class=w> </span><span class=m>30</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>periodSeconds</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>failureThreshold</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span></code></pre></div><h2 id=behavior>Behavior</h2><ul><li><strong>Success (200)</strong>: Application is healthy and functioning normally</li><li><strong>Failure (503)</strong>: Application is unhealthy and should be restarted</li><li><strong>Consecutive Failures</strong>: After 3 consecutive failures (30 seconds), Cloud Run restarts the instance</li></ul><h2 id=graceful-degradation>Graceful Degradation</h2><p>The health check is designed with graceful degradation in mind:</p><ul><li><strong>Critical Failures</strong>: Return 503 and trigger restart (e.g., database connection lost)</li><li><strong>Non-Critical Failures</strong>: Log warnings but return 200 (e.g., temporary Cloud Storage timeout)</li><li><strong>Transient Errors</strong>: Retry internally before reporting failure</li></ul><h2 id=observability>Observability</h2><p><strong>Metrics:</strong></p><ul><li><code>health_check_total{probe="liveness",status="ok"}</code> - Successful liveness checks</li><li><code>health_check_total{probe="liveness",status="error"}</code> - Failed liveness checks</li><li><code>health_check_duration_ms{probe="liveness"}</code> - Liveness check duration</li></ul><p><strong>Structured Logs:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;severity&#34;</span><span class=p>:</span> <span class=s2>&#34;INFO&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2025-11-19T06:00:00Z&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;message&#34;</span><span class=p>:</span> <span class=s2>&#34;Health check completed&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;probe&#34;</span><span class=p>:</span> <span class=s2>&#34;liveness&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;status&#34;</span><span class=p>:</span> <span class=s2>&#34;ok&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;duration_ms&#34;</span><span class=p>:</span> <span class=mi>15</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Alerts:</strong></p><ul><li><strong>Liveness Failure</strong>: Alert if liveness check fails 3+ times consecutively</li><li><strong>High Restart Rate</strong>: Alert if container restarts > 3 times in 5 minutes</li></ul><h2 id=testing>Testing</h2><h3 id=manual-testing>Manual Testing</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -v http://localhost:8080/health/liveness
</span></span></code></pre></div><h3 id=load-testing>Load Testing</h3><p>Health check endpoints should handle high request rates without degrading application performance:</p><ul><li><strong>Target</strong>: 100 requests/second sustained</li><li><strong>Timeout</strong>: &lt; 10ms average response time</li><li><strong>Resource Impact</strong>: &lt; 1% CPU, &lt; 10MB memory overhead</li></ul><h2 id=troubleshooting>Troubleshooting</h2><h3 id=liveness-check-intermittent-failures>Liveness Check Intermittent Failures</h3><p><strong>Symptoms:</strong></p><ul><li>Occasional container restarts</li><li>Liveness probe returns 503 sporadically</li><li>High request latency</li></ul><p><strong>Debugging:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Check error rate in last 5 minutes</span>
</span></span><span class=line><span class=cl>gcloud monitoring time-series list <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --filter<span class=o>=</span><span class=s1>&#39;metric.type=&#34;custom.googleapis.com/health_check_total&#34; AND metric.labels.status=&#34;error&#34;&#39;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --interval-start-time<span class=o>=</span><span class=s2>&#34;5 minutes ago&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check for resource exhaustion (Cloud Run)</span>
</span></span><span class=line><span class=cl>gcloud run services describe boot-server --region<span class=o>=</span>&lt;region&gt; --format<span class=o>=</span>json <span class=p>|</span> jq <span class=s1>&#39;.status&#39;</span>
</span></span></code></pre></div><p><strong>Common Causes:</strong></p><ul><li>Database connection pool exhausted</li><li>Memory pressure triggering GC pauses</li><li>High request volume overwhelming server</li><li>Dependency timeouts</li></ul><h2 id=security-considerations>Security Considerations</h2><h3 id=unauthenticated-access>Unauthenticated Access</h3><p>Health check endpoints are <strong>intentionally unauthenticated</strong> to allow Cloud Run infrastructure to probe without credentials. This is safe because:</p><ol><li>Endpoints return only HTTP status codes (no response body)</li><li>No sensitive data is returned</li><li>Rate limiting prevents abuse</li><li>Endpoints are read-only</li></ol><h3 id=information-disclosure>Information Disclosure</h3><p>Health checks return only HTTP status codes with no response body, ensuring:</p><ul><li>No internal IP addresses disclosed</li><li>No error messages or stack traces exposed</li><li>No database connection strings revealed</li><li>No API keys or secrets leaked</li></ul><p>Detailed diagnostics are logged internally (not returned in response):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;severity&#34;</span><span class=p>:</span> <span class=s2>&#34;ERROR&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;message&#34;</span><span class=p>:</span> <span class=s2>&#34;Firestore connection failed&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;error&#34;</span><span class=p>:</span> <span class=s2>&#34;rpc error: code = PermissionDenied desc = Missing or insufficient permissions&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-0fbab3644f8f6a3202867e1dbfd01125>3.2 - Machine Service</h1><div class=lead>Service for managing machine hardware profiles</div><p>The Machine Service is a REST API that manages machine hardware profiles for the network boot infrastructure. It stores machine specifications (CPUs, memory, NICs, drives, accelerators) in Firestore and is queried by the Boot Service during boot operations and by administrators for configuration management.</p><h2 id=architecture>Architecture</h2><p>The service is responsible for:</p><ul><li><strong>Machine Profile Management</strong>: Creating, listing, retrieving, updating, and deleting machine hardware profiles</li><li><strong>Hardware Specification Storage</strong>: Storing detailed hardware specifications in Firestore</li><li><strong>Machine Lookup</strong>: Providing machine profile queries by ID or NIC MAC address</li></ul><h2 id=components>Components</h2><ul><li><strong>Firestore</strong>: Stores machine hardware profiles</li><li><strong>REST API</strong>: HTTP endpoints for machine profile management</li></ul><h2 id=clients>Clients</h2><p>The service is consumed by:</p><ol><li><strong>Boot Service</strong>: Queries machine profiles by MAC address during boot operations</li><li><strong>Admin Tools</strong>: CLI or web interfaces for managing machine inventory</li><li><strong>Monitoring Systems</strong>: Hardware inventory and asset management tools</li></ol><h2 id=deployment>Deployment</h2><ul><li><strong>Platform</strong>: GCP Cloud Run</li><li><strong>Scaling</strong>: Automatic scaling based on request load</li><li><strong>Availability</strong>: Min instances = 1 for low-latency responses</li><li><strong>Region</strong>: Same region as Boot Service for minimal latency</li></ul><h2 id=api-endpoints>API Endpoints</h2><h3 id=machine-management>Machine Management</h3><ul><li><a href=./post-machines/>POST /api/v1/machines</a> - Register a new machine with hardware specifications</li><li><a href=./get-machines/>GET /api/v1/machines</a> - List all registered machines</li><li><a href=./get-machine/>GET /api/v1/machines/{id}</a> - Retrieve a specific machine by ID</li><li><a href=./put-machine/>PUT /api/v1/machines/{id}</a> - Update a machine&rsquo;s hardware profile</li><li><a href=./delete-machine/>DELETE /api/v1/machines/{id}</a> - Delete a machine registration</li></ul><h2 id=rate-limiting>Rate Limiting</h2><p>Admin API endpoints are rate-limited to prevent abuse:</p><ul><li><strong>Per User/Service Account</strong>: 100 requests/minute</li><li><strong>Per IP Address</strong>: 300 requests/minute</li><li><strong>Global</strong>: 1000 requests/minute</li></ul><p>Rate limit headers are included in responses:</p><pre tabindex=0><code>X-RateLimit-Limit: 100
X-RateLimit-Remaining: 95
X-RateLimit-Reset: 1700000000
</code></pre><p>When rate limit is exceeded, API returns <code>429 Too Many Requests</code> using RFC 7807 Problem Details format (see <a href=../../adrs/0007-standard-api-error-response/>ADR-0007</a>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;https://api.example.com/errors/rate-limit-exceeded&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Rate Limit Exceeded&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;status&#34;</span><span class=p>:</span> <span class=mi>429</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;detail&#34;</span><span class=p>:</span> <span class=s2>&#34;Rate limit exceeded. Try again in 30 seconds.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;instance&#34;</span><span class=p>:</span> <span class=s2>&#34;/api/v1/machines&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;retry_after&#34;</span><span class=p>:</span> <span class=mi>30</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>All error responses use <code>Content-Type: application/problem+json</code>.</p><h2 id=versioning>Versioning</h2><p>The Admin API uses URL versioning (<code>/api/v1/</code>):</p><ul><li><strong>Current Version</strong>: v1</li><li><strong>Deprecation Policy</strong>: Minimum 6 months notice before version deprecation</li><li><strong>Version Header</strong>: <code>X-API-Version: v1</code> included in all responses</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8161b025f023eea715281eff4619dd04>3.2.1 - POST /api/v1/machines</h1><div class=lead>Register a new machine with hardware specifications</div><p>Register a new machine with hardware specifications.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant API as Machine Service
    participant DB as Firestore

    Client-&gt;&gt;API: POST /api/v1/machines
    API-&gt;&gt;API: Generate machine id (UUIDv7)
    API-&gt;&gt;API: Validate machine profile
    API-&gt;&gt;DB: Insert machine profile
    DB--&gt;&gt;API: Machine created
    API--&gt;&gt;Client: 201 Created (machine id)</pre><h2 id=request>Request</h2><p><strong>Request Body:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;cpus&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;manufacturer&#34;</span><span class=p>:</span> <span class=s2>&#34;Intel&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;clock_frequency&#34;</span><span class=p>:</span> <span class=mi>2400000000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;cores&#34;</span><span class=p>:</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;memory_modules&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;accelerators&#34;</span><span class=p>:</span> <span class=p>[],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;nics&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;mac&#34;</span><span class=p>:</span> <span class=s2>&#34;52:54:00:12:34:56&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;drives&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;capacity&#34;</span><span class=p>:</span> <span class=mi>500107862016</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (201 Created):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-c000-7000-8000-fedcba987654&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;cpus&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;manufacturer&#34;</span><span class=p>:</span> <span class=s2>&#34;Intel&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;clock_frequency&#34;</span><span class=p>:</span> <span class=mi>2400000000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;cores&#34;</span><span class=p>:</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;memory_modules&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;accelerators&#34;</span><span class=p>:</span> <span class=p>[],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;nics&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;mac&#34;</span><span class=p>:</span> <span class=s2>&#34;52:54:00:12:34:56&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;drives&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;capacity&#34;</span><span class=p>:</span> <span class=mi>500107862016</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th></tr></thead><tbody><tr><td>400 Bad Request</td><td>Invalid request body or missing required fields</td></tr><tr><td>409 Conflict</td><td>Machine with the same NIC MAC address already exists</td></tr></tbody></table><h2 id=notes>Notes</h2><ul><li>The machine ID is generated server-side (UUIDv7)</li><li>MAC addresses must be unique across all machines</li><li>All size/capacity values are in bytes</li><li>Clock frequency is in hertz</li></ul><h2 id=data-models>Data Models</h2><p>All data models are defined as Protocol Buffer (protobuf) messages and stored in Firestore.</p><h3 id=machine>Machine</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-protobuf data-lang=protobuf><span class=line><span class=cl><span class=n>syntax</span> <span class=o>=</span> <span class=s>&#34;proto3&#34;</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>CPU</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>string</span> <span class=n>manufacturer</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>int64</span> <span class=n>clock_frequency</span> <span class=o>=</span> <span class=mi>2</span><span class=p>;</span>  <span class=c1>// measured in hertz
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kt>int64</span> <span class=n>cores</span> <span class=o>=</span> <span class=mi>3</span><span class=p>;</span>            <span class=c1>// number of cores
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>MemoryModule</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>int64</span> <span class=n>size</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>             <span class=c1>// measured in bytes
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>Accelerator</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>string</span> <span class=n>manufacturer</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=p>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>NIC</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>string</span> <span class=n>mac</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>             <span class=c1>// mac address
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>Drive</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>int64</span> <span class=n>capacity</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>         <span class=c1>// capacity in bytes
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=kd>message</span> <span class=nc>Machine</span> <span class=p>{</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=kt>string</span> <span class=n>id</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>              <span class=c1>// UUIDv7 machine identifier
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=k>repeated</span> <span class=n>CPU</span> <span class=n>cpus</span> <span class=o>=</span> <span class=mi>2</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=k>repeated</span> <span class=n>MemoryModule</span> <span class=n>memory_modules</span> <span class=o>=</span> <span class=mi>3</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=k>repeated</span> <span class=n>Accelerator</span> <span class=n>accelerators</span> <span class=o>=</span> <span class=mi>4</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=k>repeated</span> <span class=n>NIC</span> <span class=n>nics</span> <span class=o>=</span> <span class=mi>5</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  <span class=k>repeated</span> <span class=n>Drive</span> <span class=n>drives</span> <span class=o>=</span> <span class=mi>6</span><span class=p>;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=p>}</span><span class=err>
</span></span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-ab6cbac66e8cf3fa0a5a8998d224f183>3.2.2 - GET /api/v1/machines</h1><div class=lead>List all registered machines</div><p>List all registered machines with optional filtering by MAC address.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant API as Machine Service
    participant DB as Firestore

    Client-&gt;&gt;API: GET /api/v1/machines?mac=...
    API-&gt;&gt;DB: Query machines with filters
    DB--&gt;&gt;API: Machine list
    API--&gt;&gt;Client: 200 OK (machines list)</pre><h2 id=request>Request</h2><p><strong>Query Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th><th>Default</th></tr></thead><tbody><tr><td><code>page</code></td><td>integer</td><td>No</td><td>Page number (1-indexed)</td><td>1</td></tr><tr><td><code>per_page</code></td><td>integer</td><td>No</td><td>Results per page (1-100)</td><td>20</td></tr><tr><td><code>mac</code></td><td>string</td><td>No</td><td>Filter by NIC MAC address</td><td>-</td></tr></tbody></table><p><strong>Example Request:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/api/v1/machines?page=1&amp;per_page=20</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>machine.example.com</span>
</span></span></code></pre></div><p><strong>Example Request with MAC filter:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/api/v1/machines?mac=52:54:00:12:34:56</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>machine.example.com</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (200 OK):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;machines&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-c000-7000-8000-fedcba987654&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;cpus&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=nt>&#34;manufacturer&#34;</span><span class=p>:</span> <span class=s2>&#34;Intel&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=nt>&#34;clock_frequency&#34;</span><span class=p>:</span> <span class=mi>2400000000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=nt>&#34;cores&#34;</span><span class=p>:</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=p>],</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;memory_modules&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=p>],</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;accelerators&#34;</span><span class=p>:</span> <span class=p>[],</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;nics&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=nt>&#34;mac&#34;</span><span class=p>:</span> <span class=s2>&#34;52:54:00:12:34:56&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=p>],</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;drives&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=nt>&#34;capacity&#34;</span><span class=p>:</span> <span class=mi>500107862016</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;pagination&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;total&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;page&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;per_page&#34;</span><span class=p>:</span> <span class=mi>20</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;total_pages&#34;</span><span class=p>:</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-5c3e0835220581b8bba64831f6f7f2be>3.2.3 - GET /api/v1/machines/{id}</h1><div class=lead>Retrieve a specific machine by ID</div><p>Retrieve a specific machine by ID.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant API as Machine Service
    participant DB as Firestore

    Client-&gt;&gt;API: GET /api/v1/machines/{id}
    API-&gt;&gt;DB: Query machine by ID
    DB--&gt;&gt;API: Machine profile
    API--&gt;&gt;Client: 200 OK (machine profile)</pre><h2 id=request>Request</h2><p><strong>Path Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>id</code></td><td>string</td><td>Yes</td><td>Machine identifier (UUIDv7 format)</td></tr></tbody></table><p><strong>Example Request:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>GET</span> <span class=nn>/api/v1/machines/018c7dbd-c000-7000-8000-fedcba987654</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>machine.example.com</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (200 OK):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-c000-7000-8000-fedcba987654&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;cpus&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;manufacturer&#34;</span><span class=p>:</span> <span class=s2>&#34;Intel&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;clock_frequency&#34;</span><span class=p>:</span> <span class=mi>2400000000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;cores&#34;</span><span class=p>:</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;memory_modules&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;accelerators&#34;</span><span class=p>:</span> <span class=p>[],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;nics&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;mac&#34;</span><span class=p>:</span> <span class=s2>&#34;52:54:00:12:34:56&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;drives&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;capacity&#34;</span><span class=p>:</span> <span class=mi>500107862016</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th></tr></thead><tbody><tr><td>404 Not Found</td><td>Machine with specified ID not found</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-469e776cf0ea53aa67c4999bef12df53>3.2.4 - PUT /api/v1/machines/{id}</h1><div class=lead>Update a machine&rsquo;s hardware profile</div><p>Update a machine&rsquo;s hardware profile.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant API as Machine Service
    participant DB as Firestore

    Client-&gt;&gt;API: PUT /api/v1/machines/{id}
    API-&gt;&gt;DB: Update machine profile
    DB--&gt;&gt;API: Machine updated
    API--&gt;&gt;Client: 200 OK (updated profile)</pre><h2 id=request>Request</h2><p><strong>Path Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>id</code></td><td>string</td><td>Yes</td><td>Machine identifier (UUIDv7 format)</td></tr></tbody></table><p><strong>Request Body:</strong></p><p>Full machine profile (same structure as POST /api/v1/machines):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;cpus&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;manufacturer&#34;</span><span class=p>:</span> <span class=s2>&#34;Intel&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;clock_frequency&#34;</span><span class=p>:</span> <span class=mi>2400000000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;cores&#34;</span><span class=p>:</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;memory_modules&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;accelerators&#34;</span><span class=p>:</span> <span class=p>[],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;nics&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;mac&#34;</span><span class=p>:</span> <span class=s2>&#34;52:54:00:12:34:56&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;drives&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;capacity&#34;</span><span class=p>:</span> <span class=mi>500107862016</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (200 OK):</strong></p><p>Full machine profile with updated fields:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=s2>&#34;018c7dbd-c000-7000-8000-fedcba987654&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;cpus&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;manufacturer&#34;</span><span class=p>:</span> <span class=s2>&#34;Intel&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;clock_frequency&#34;</span><span class=p>:</span> <span class=mi>2400000000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;cores&#34;</span><span class=p>:</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;memory_modules&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;size&#34;</span><span class=p>:</span> <span class=mi>17179869184</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;accelerators&#34;</span><span class=p>:</span> <span class=p>[],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;nics&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;mac&#34;</span><span class=p>:</span> <span class=s2>&#34;52:54:00:12:34:56&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;drives&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;capacity&#34;</span><span class=p>:</span> <span class=mi>500107862016</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th></tr></thead><tbody><tr><td>404 Not Found</td><td>Machine with specified ID not found</td></tr><tr><td>400 Bad Request</td><td>Invalid request body</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-8b6e001a582334f5057d88dd3d1a31c3>3.2.5 - DELETE /api/v1/machines/{id}</h1><div class=lead>Delete a machine registration</div><p>Delete a machine registration.</p><h2 id=sequence-diagram>Sequence Diagram</h2><pre class=mermaid>sequenceDiagram
    participant Client as Admin Client
    participant API as Machine Service
    participant DB as Firestore

    Client-&gt;&gt;API: DELETE /api/v1/machines/{id}
    API-&gt;&gt;DB: Delete machine by ID
    DB--&gt;&gt;API: Machine deleted
    API--&gt;&gt;Client: 204 No Content</pre><h2 id=request>Request</h2><p><strong>Path Parameters:</strong></p><table><thead><tr><th>Parameter</th><th>Type</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><code>id</code></td><td>string</td><td>Yes</td><td>Machine identifier (UUIDv7 format)</td></tr></tbody></table><p><strong>Example Request:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=nf>DELETE</span> <span class=nn>/api/v1/machines/018c7dbd-c000-7000-8000-fedcba987654</span> <span class=kr>HTTP</span><span class=o>/</span><span class=m>1.1</span>
</span></span><span class=line><span class=cl><span class=n>Host</span><span class=o>:</span> <span class=l>machine.example.com</span>
</span></span></code></pre></div><h2 id=response>Response</h2><p><strong>Response (204 No Content):</strong></p><p>Empty response body.</p><p><strong>Error Responses:</strong></p><table><thead><tr><th>Status Code</th><th>Description</th></tr></thead><tbody><tr><td>404 Not Found</td><td>Machine with specified ID not found</td></tr></tbody></table></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/Zaba505/infra aria-label=GitHub><i class="fab fa-github"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2024&ndash;2025
<span class=td-footer__authors>Zaba505 | <a href=https://creativecommons.org/licenses/by/4.0>CC BY 4.0</a> |</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span></div></div></div></footer></div><script src=/infra/pr-preview/pr-626/js/main.min.eb40505784d893e4b5c8dbd67b59c353e735d847f4ffbfe9d6921dec08dbacba.js integrity="sha256-60BQV4TYk+S1yNvWe1nDU+c12Ef0/7/p1pId7AjbrLo=" crossorigin=anonymous></script><script defer src=/infra/pr-preview/pr-626/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/infra/pr-preview/pr-626/js/tabpane-persist.js></script></body></html>